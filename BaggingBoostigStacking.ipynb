{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3c00aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "#importo libreria panda per leggere ed elaborare csv\n",
    "import pandas as pd\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "\n",
    "data=pd.read_csv('/Users/sgira/Downloads/ProgettoMLDM/ProgettoMLDM-main/Dataset/dataset_clean.csv')\n",
    "train_data=pd.read_csv('/Users/sgira/Downloads/ProgettoMLDM/ProgettoMLDM-main/Dataset/train_data.csv')\n",
    "test_data=pd.read_csv('/Users/sgira/Downloads/ProgettoMLDM/ProgettoMLDM-main/Dataset/test_data.csv')\n",
    "y_train=pd.read_csv('/Users/sgira/Downloads/ProgettoMLDM/ProgettoMLDM-main/Dataset/train_y.csv')\n",
    "y_test=pd.read_csv('/Users/sgira/Downloads/ProgettoMLDM/ProgettoMLDM-main/Dataset/test_y.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2811c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#dataset=data.drop('Status',axis=1)\n",
    "#y=data['Status']\n",
    "\n",
    "#x_train, x_test, y_train, y_test = train_test_split(dataset, y, train_size=0.8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "17deb9e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8749827085350671\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#bagging con 1000 alberi di decisione\n",
    "bag_clf = BaggingClassifier(\n",
    "    estimator=DecisionTreeClassifier(ccp_alpha=0.0001, criterion='entropy', max_depth=20, random_state=10, min_samples_leaf=4, min_samples_split=6), n_estimators=1000,\n",
    "    max_samples=30000, bootstrap=True, random_state=10, n_jobs=-1)\n",
    "bag_clf.fit(train_data, np.ravel(y_train))\n",
    "y_pred = bag_clf.predict(test_data)\n",
    "print(accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6eb1dadc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8714206667588879"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_clf = DecisionTreeClassifier(ccp_alpha=0.0001, criterion='entropy', max_depth=20, random_state=10, min_samples_leaf=4, min_samples_split=6)\n",
    "tree_clf.fit(train_data, np.ravel(y_train))\n",
    "\n",
    "tree_clf.score(test_data, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "70111564",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8709666263185198"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#bagging con out-of-bag evaluation\n",
    "outbag_clf = BaggingClassifier(\n",
    "    DecisionTreeClassifier(ccp_alpha=0.0001, criterion='entropy', max_depth=20, random_state=10, min_samples_leaf=4, min_samples_split=6), n_estimators=1000,\n",
    "    max_samples=30000, bootstrap=True, oob_score=True, random_state=10, n_jobs=-1)\n",
    "outbag_clf.fit(train_data, np.ravel(y_train))\n",
    "outbag_clf.oob_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6053c754",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8662332272790151\n"
     ]
    }
   ],
   "source": [
    "#Adaboost con 200 alberi di decisione di un solo livello\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "ada_clf = AdaBoostClassifier(\n",
    "    DecisionTreeClassifier(max_depth=1), n_estimators=200,\n",
    "    algorithm=\"SAMME.R\", learning_rate=0.5, random_state=42)\n",
    "ada_clf.fit(train_data, np.ravel(y_train))\n",
    "y_pred = ada_clf.predict(test_data)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b4209bbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "[CV 1/5] END estimator=DecisionTreeClassifier(ccp_alpha=0.0001, criterion='log_loss', max_depth=5), n_estimators=50; accuracy: (train=1.000, test=1.000) balanced_accuracy: (train=1.000, test=1.000) f1: (train=1.000, test=1.000) total time=   0.0s\n",
      "[CV 2/5] END estimator=DecisionTreeClassifier(ccp_alpha=0.0001, criterion='log_loss', max_depth=5), n_estimators=50; accuracy: (train=1.000, test=1.000) balanced_accuracy: (train=1.000, test=1.000) f1: (train=1.000, test=1.000) total time=   0.0s\n",
      "[CV 3/5] END estimator=DecisionTreeClassifier(ccp_alpha=0.0001, criterion='log_loss', max_depth=5), n_estimators=50; accuracy: (train=1.000, test=1.000) balanced_accuracy: (train=1.000, test=1.000) f1: (train=1.000, test=1.000) total time=   0.0s\n",
      "[CV 4/5] END estimator=DecisionTreeClassifier(ccp_alpha=0.0001, criterion='log_loss', max_depth=5), n_estimators=50; accuracy: (train=1.000, test=1.000) balanced_accuracy: (train=1.000, test=1.000) f1: (train=1.000, test=1.000) total time=   0.0s\n",
      "[CV 5/5] END estimator=DecisionTreeClassifier(ccp_alpha=0.0001, criterion='log_loss', max_depth=5), n_estimators=50; accuracy: (train=1.000, test=1.000) balanced_accuracy: (train=1.000, test=1.000) f1: (train=1.000, test=1.000) total time=   0.1s\n",
      "[CV 1/5] END estimator=DecisionTreeClassifier(ccp_alpha=0.0001, criterion='log_loss', max_depth=5), n_estimators=100; accuracy: (train=1.000, test=1.000) balanced_accuracy: (train=1.000, test=1.000) f1: (train=1.000, test=1.000) total time=   0.1s\n",
      "[CV 2/5] END estimator=DecisionTreeClassifier(ccp_alpha=0.0001, criterion='log_loss', max_depth=5), n_estimators=100; accuracy: (train=1.000, test=1.000) balanced_accuracy: (train=1.000, test=1.000) f1: (train=1.000, test=1.000) total time=   0.0s\n",
      "[CV 3/5] END estimator=DecisionTreeClassifier(ccp_alpha=0.0001, criterion='log_loss', max_depth=5), n_estimators=100; accuracy: (train=1.000, test=1.000) balanced_accuracy: (train=1.000, test=1.000) f1: (train=1.000, test=1.000) total time=   0.0s\n",
      "[CV 4/5] END estimator=DecisionTreeClassifier(ccp_alpha=0.0001, criterion='log_loss', max_depth=5), n_estimators=100; accuracy: (train=1.000, test=1.000) balanced_accuracy: (train=1.000, test=1.000) f1: (train=1.000, test=1.000) total time=   0.0s\n",
      "[CV 5/5] END estimator=DecisionTreeClassifier(ccp_alpha=0.0001, criterion='log_loss', max_depth=5), n_estimators=100; accuracy: (train=1.000, test=1.000) balanced_accuracy: (train=1.000, test=1.000) f1: (train=1.000, test=1.000) total time=   0.1s\n",
      "[CV 1/5] END estimator=DecisionTreeClassifier(ccp_alpha=0.0001, criterion='log_loss', max_depth=5), n_estimators=150; accuracy: (train=1.000, test=1.000) balanced_accuracy: (train=1.000, test=1.000) f1: (train=1.000, test=1.000) total time=   0.0s\n",
      "[CV 2/5] END estimator=DecisionTreeClassifier(ccp_alpha=0.0001, criterion='log_loss', max_depth=5), n_estimators=150; accuracy: (train=1.000, test=1.000) balanced_accuracy: (train=1.000, test=1.000) f1: (train=1.000, test=1.000) total time=   0.0s\n",
      "[CV 3/5] END estimator=DecisionTreeClassifier(ccp_alpha=0.0001, criterion='log_loss', max_depth=5), n_estimators=150; accuracy: (train=1.000, test=1.000) balanced_accuracy: (train=1.000, test=1.000) f1: (train=1.000, test=1.000) total time=   0.1s\n",
      "[CV 4/5] END estimator=DecisionTreeClassifier(ccp_alpha=0.0001, criterion='log_loss', max_depth=5), n_estimators=150; accuracy: (train=1.000, test=1.000) balanced_accuracy: (train=1.000, test=1.000) f1: (train=1.000, test=1.000) total time=   0.1s\n",
      "[CV 5/5] END estimator=DecisionTreeClassifier(ccp_alpha=0.0001, criterion='log_loss', max_depth=5), n_estimators=150; accuracy: (train=1.000, test=1.000) balanced_accuracy: (train=1.000, test=1.000) f1: (train=1.000, test=1.000) total time=   0.1s\n",
      "[CV 1/5] END estimator=DecisionTreeClassifier(ccp_alpha=0.0001, criterion='entropy', max_depth=5), n_estimators=50; accuracy: (train=1.000, test=1.000) balanced_accuracy: (train=1.000, test=1.000) f1: (train=1.000, test=1.000) total time=   0.1s\n",
      "[CV 2/5] END estimator=DecisionTreeClassifier(ccp_alpha=0.0001, criterion='entropy', max_depth=5), n_estimators=50; accuracy: (train=1.000, test=1.000) balanced_accuracy: (train=1.000, test=1.000) f1: (train=1.000, test=1.000) total time=   0.1s\n",
      "[CV 3/5] END estimator=DecisionTreeClassifier(ccp_alpha=0.0001, criterion='entropy', max_depth=5), n_estimators=50; accuracy: (train=1.000, test=1.000) balanced_accuracy: (train=1.000, test=1.000) f1: (train=1.000, test=1.000) total time=   0.1s\n",
      "[CV 4/5] END estimator=DecisionTreeClassifier(ccp_alpha=0.0001, criterion='entropy', max_depth=5), n_estimators=50; accuracy: (train=1.000, test=1.000) balanced_accuracy: (train=1.000, test=1.000) f1: (train=1.000, test=1.000) total time=   0.1s\n",
      "[CV 5/5] END estimator=DecisionTreeClassifier(ccp_alpha=0.0001, criterion='entropy', max_depth=5), n_estimators=50; accuracy: (train=1.000, test=1.000) balanced_accuracy: (train=1.000, test=1.000) f1: (train=1.000, test=1.000) total time=   0.1s\n",
      "[CV 1/5] END estimator=DecisionTreeClassifier(ccp_alpha=0.0001, criterion='entropy', max_depth=5), n_estimators=100; accuracy: (train=1.000, test=1.000) balanced_accuracy: (train=1.000, test=1.000) f1: (train=1.000, test=1.000) total time=   0.1s\n",
      "[CV 2/5] END estimator=DecisionTreeClassifier(ccp_alpha=0.0001, criterion='entropy', max_depth=5), n_estimators=100; accuracy: (train=1.000, test=1.000) balanced_accuracy: (train=1.000, test=1.000) f1: (train=1.000, test=1.000) total time=   0.1s\n",
      "[CV 3/5] END estimator=DecisionTreeClassifier(ccp_alpha=0.0001, criterion='entropy', max_depth=5), n_estimators=100; accuracy: (train=1.000, test=1.000) balanced_accuracy: (train=1.000, test=1.000) f1: (train=1.000, test=1.000) total time=   0.1s\n",
      "[CV 4/5] END estimator=DecisionTreeClassifier(ccp_alpha=0.0001, criterion='entropy', max_depth=5), n_estimators=100; accuracy: (train=1.000, test=1.000) balanced_accuracy: (train=1.000, test=1.000) f1: (train=1.000, test=1.000) total time=   0.1s\n",
      "[CV 5/5] END estimator=DecisionTreeClassifier(ccp_alpha=0.0001, criterion='entropy', max_depth=5), n_estimators=100; accuracy: (train=1.000, test=1.000) balanced_accuracy: (train=1.000, test=1.000) f1: (train=1.000, test=1.000) total time=   0.1s\n",
      "[CV 1/5] END estimator=DecisionTreeClassifier(ccp_alpha=0.0001, criterion='entropy', max_depth=5), n_estimators=150; accuracy: (train=1.000, test=1.000) balanced_accuracy: (train=1.000, test=1.000) f1: (train=1.000, test=1.000) total time=   0.1s\n",
      "[CV 2/5] END estimator=DecisionTreeClassifier(ccp_alpha=0.0001, criterion='entropy', max_depth=5), n_estimators=150; accuracy: (train=1.000, test=1.000) balanced_accuracy: (train=1.000, test=1.000) f1: (train=1.000, test=1.000) total time=   0.1s\n",
      "[CV 3/5] END estimator=DecisionTreeClassifier(ccp_alpha=0.0001, criterion='entropy', max_depth=5), n_estimators=150; accuracy: (train=1.000, test=1.000) balanced_accuracy: (train=1.000, test=1.000) f1: (train=1.000, test=1.000) total time=   0.1s\n",
      "[CV 4/5] END estimator=DecisionTreeClassifier(ccp_alpha=0.0001, criterion='entropy', max_depth=5), n_estimators=150; accuracy: (train=1.000, test=1.000) balanced_accuracy: (train=1.000, test=1.000) f1: (train=1.000, test=1.000) total time=   0.1s\n",
      "[CV 5/5] END estimator=DecisionTreeClassifier(ccp_alpha=0.0001, criterion='entropy', max_depth=5), n_estimators=150; accuracy: (train=1.000, test=1.000) balanced_accuracy: (train=1.000, test=1.000) f1: (train=1.000, test=1.000) total time=   0.1s\n",
      "[CV 1/5] END estimator=DecisionTreeClassifier(ccp_alpha=0.0001, max_depth=5), n_estimators=50; accuracy: (train=1.000, test=1.000) balanced_accuracy: (train=1.000, test=1.000) f1: (train=1.000, test=1.000) total time=   0.1s\n",
      "[CV 2/5] END estimator=DecisionTreeClassifier(ccp_alpha=0.0001, max_depth=5), n_estimators=50; accuracy: (train=1.000, test=1.000) balanced_accuracy: (train=1.000, test=1.000) f1: (train=1.000, test=1.000) total time=   0.1s\n",
      "[CV 3/5] END estimator=DecisionTreeClassifier(ccp_alpha=0.0001, max_depth=5), n_estimators=50; accuracy: (train=1.000, test=1.000) balanced_accuracy: (train=1.000, test=1.000) f1: (train=1.000, test=1.000) total time=   0.1s\n",
      "[CV 4/5] END estimator=DecisionTreeClassifier(ccp_alpha=0.0001, max_depth=5), n_estimators=50; accuracy: (train=1.000, test=1.000) balanced_accuracy: (train=1.000, test=1.000) f1: (train=1.000, test=1.000) total time=   0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END estimator=DecisionTreeClassifier(ccp_alpha=0.0001, max_depth=5), n_estimators=50; accuracy: (train=1.000, test=1.000) balanced_accuracy: (train=1.000, test=1.000) f1: (train=1.000, test=1.000) total time=   0.1s\n",
      "[CV 1/5] END estimator=DecisionTreeClassifier(ccp_alpha=0.0001, max_depth=5), n_estimators=100; accuracy: (train=1.000, test=1.000) balanced_accuracy: (train=1.000, test=1.000) f1: (train=1.000, test=1.000) total time=   0.1s\n",
      "[CV 2/5] END estimator=DecisionTreeClassifier(ccp_alpha=0.0001, max_depth=5), n_estimators=100; accuracy: (train=1.000, test=1.000) balanced_accuracy: (train=1.000, test=1.000) f1: (train=1.000, test=1.000) total time=   0.1s\n",
      "[CV 3/5] END estimator=DecisionTreeClassifier(ccp_alpha=0.0001, max_depth=5), n_estimators=100; accuracy: (train=1.000, test=1.000) balanced_accuracy: (train=1.000, test=1.000) f1: (train=1.000, test=1.000) total time=   0.1s\n",
      "[CV 4/5] END estimator=DecisionTreeClassifier(ccp_alpha=0.0001, max_depth=5), n_estimators=100; accuracy: (train=1.000, test=1.000) balanced_accuracy: (train=1.000, test=1.000) f1: (train=1.000, test=1.000) total time=   0.1s\n",
      "[CV 5/5] END estimator=DecisionTreeClassifier(ccp_alpha=0.0001, max_depth=5), n_estimators=100; accuracy: (train=1.000, test=1.000) balanced_accuracy: (train=1.000, test=1.000) f1: (train=1.000, test=1.000) total time=   0.1s\n",
      "[CV 1/5] END estimator=DecisionTreeClassifier(ccp_alpha=0.0001, max_depth=5), n_estimators=150; accuracy: (train=1.000, test=1.000) balanced_accuracy: (train=1.000, test=1.000) f1: (train=1.000, test=1.000) total time=   0.0s\n",
      "[CV 2/5] END estimator=DecisionTreeClassifier(ccp_alpha=0.0001, max_depth=5), n_estimators=150; accuracy: (train=1.000, test=1.000) balanced_accuracy: (train=1.000, test=1.000) f1: (train=1.000, test=1.000) total time=   0.1s\n",
      "[CV 3/5] END estimator=DecisionTreeClassifier(ccp_alpha=0.0001, max_depth=5), n_estimators=150; accuracy: (train=1.000, test=1.000) balanced_accuracy: (train=1.000, test=1.000) f1: (train=1.000, test=1.000) total time=   0.1s\n",
      "[CV 4/5] END estimator=DecisionTreeClassifier(ccp_alpha=0.0001, max_depth=5), n_estimators=150; accuracy: (train=1.000, test=1.000) balanced_accuracy: (train=1.000, test=1.000) f1: (train=1.000, test=1.000) total time=   0.1s\n",
      "[CV 5/5] END estimator=DecisionTreeClassifier(ccp_alpha=0.0001, max_depth=5), n_estimators=150; accuracy: (train=1.000, test=1.000) balanced_accuracy: (train=1.000, test=1.000) f1: (train=1.000, test=1.000) total time=   0.1s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(estimator=AdaBoostClassifier(),\n",
       "             param_grid={&#x27;estimator&#x27;: [DecisionTreeClassifier(ccp_alpha=0.0001,\n",
       "                                                              criterion=&#x27;log_loss&#x27;,\n",
       "                                                              max_depth=5),\n",
       "                                       DecisionTreeClassifier(ccp_alpha=0.0001,\n",
       "                                                              criterion=&#x27;entropy&#x27;,\n",
       "                                                              max_depth=5),\n",
       "                                       DecisionTreeClassifier(ccp_alpha=0.0001,\n",
       "                                                              max_depth=5)],\n",
       "                         &#x27;n_estimators&#x27;: [50, 100, 150]},\n",
       "             refit=&#x27;balanced_accuracy&#x27;, return_train_score=True,\n",
       "             scoring={&#x27;accuracy&#x27;: &#x27;accuracy&#x27;,\n",
       "                      &#x27;balanced_accuracy&#x27;: &#x27;balanced_accuracy&#x27;,\n",
       "                      &#x27;f1&#x27;: &#x27;f1_macro&#x27;},\n",
       "             verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(estimator=AdaBoostClassifier(),\n",
       "             param_grid={&#x27;estimator&#x27;: [DecisionTreeClassifier(ccp_alpha=0.0001,\n",
       "                                                              criterion=&#x27;log_loss&#x27;,\n",
       "                                                              max_depth=5),\n",
       "                                       DecisionTreeClassifier(ccp_alpha=0.0001,\n",
       "                                                              criterion=&#x27;entropy&#x27;,\n",
       "                                                              max_depth=5),\n",
       "                                       DecisionTreeClassifier(ccp_alpha=0.0001,\n",
       "                                                              max_depth=5)],\n",
       "                         &#x27;n_estimators&#x27;: [50, 100, 150]},\n",
       "             refit=&#x27;balanced_accuracy&#x27;, return_train_score=True,\n",
       "             scoring={&#x27;accuracy&#x27;: &#x27;accuracy&#x27;,\n",
       "                      &#x27;balanced_accuracy&#x27;: &#x27;balanced_accuracy&#x27;,\n",
       "                      &#x27;f1&#x27;: &#x27;f1_macro&#x27;},\n",
       "             verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: AdaBoostClassifier</label><div class=\"sk-toggleable__content\"><pre>AdaBoostClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">AdaBoostClassifier</label><div class=\"sk-toggleable__content\"><pre>AdaBoostClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(estimator=AdaBoostClassifier(),\n",
       "             param_grid={'estimator': [DecisionTreeClassifier(ccp_alpha=0.0001,\n",
       "                                                              criterion='log_loss',\n",
       "                                                              max_depth=5),\n",
       "                                       DecisionTreeClassifier(ccp_alpha=0.0001,\n",
       "                                                              criterion='entropy',\n",
       "                                                              max_depth=5),\n",
       "                                       DecisionTreeClassifier(ccp_alpha=0.0001,\n",
       "                                                              max_depth=5)],\n",
       "                         'n_estimators': [50, 100, 150]},\n",
       "             refit='balanced_accuracy', return_train_score=True,\n",
       "             scoring={'accuracy': 'accuracy',\n",
       "                      'balanced_accuracy': 'balanced_accuracy',\n",
       "                      'f1': 'f1_macro'},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler,PolynomialFeatures,MinMaxScaler\n",
    "from sklearn.model_selection import (\n",
    "    GridSearchCV,\n",
    "    StratifiedKFold,\n",
    "    cross_val_score,\n",
    "    train_test_split,\n",
    ")\n",
    "#adaboost con cross validation\n",
    "scaled_dataset = StandardScaler().fit_transform(data)\n",
    "\n",
    "\n",
    "abc = AdaBoostClassifier()\n",
    "\n",
    "# n_estimators=150, random_state=10, algorithm='SAMME'\n",
    "# Create the parameter grids\n",
    "parameter_grid = {\n",
    "     \"n_estimators\": [50, 100, 150],\n",
    "     #\"learning_rate\": [.5, 1, 1.5],\n",
    "     #\"algorithm\": ['SAMME', 'SAMME.R'],\n",
    "    # 'random_state': [5, 10, 22, 50],\n",
    "    'estimator': [#DecisionTreeClassifier(criterion='entropy', max_depth=2),\n",
    "    #              DecisionTreeClassifier(criterion='entropy', max_depth=2),\n",
    "    #              DecisionTreeClassifier(criterion='log_loss', max_depth=2),\n",
    "    #              DecisionTreeClassifier(criterion='log_loss', max_depth=1),\n",
    "                  # LinearSVC(dual=False, max_iter=200),\n",
    "                  # LinearSVC(dual=False, max_iter=200, C = 10),\n",
    "                  # LinearSVC(dual=False, max_iter=200, C = 50),\n",
    "    #              SVC(kernel='rbf', max_iter=200),\n",
    "    #              SVC(kernel='rbf', gamma='auto', max_iter=200),\n",
    "    #              SVC(kernel='sigmoid', max_iter=200)\n",
    "                  DecisionTreeClassifier(criterion='log_loss', max_depth=5,\n",
    "                                         ccp_alpha=0.0001,),\n",
    "                  DecisionTreeClassifier(criterion='entropy', max_depth=5,\n",
    "                                         ccp_alpha=0.0001),\n",
    "                  DecisionTreeClassifier(criterion='gini', max_depth=5,\n",
    "                                         ccp_alpha=0.0001),\n",
    "                  ]\n",
    "}\n",
    "\n",
    "# Create Stratified folds\n",
    "# primi tentativi n_splits = 5 per limitare i tempi di esecuzione della gridSearch poi aumentato\n",
    "cross_validation = StratifiedKFold(n_splits=5)\n",
    "cross_validation.get_n_splits(data, y)\n",
    "\n",
    "# Create the scoring dictionary\n",
    "SCORING = {\n",
    "    \"accuracy\": \"accuracy\",\n",
    "    \"balanced_accuracy\": \"balanced_accuracy\",\n",
    "    \"f1\": \"f1_macro\",\n",
    "}\n",
    "\n",
    "# Create and fit the GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=abc,\n",
    "    param_grid=parameter_grid,\n",
    "    # cv=cross_validation,\n",
    "    verbose=3,\n",
    "    scoring=SCORING,\n",
    "    return_train_score=True,\n",
    "    refit=\"balanced_accuracy\",\n",
    "    # error_score='raise'\n",
    ")\n",
    "\n",
    "grid_search.fit(scaled_dataset, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3dfff65f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 1.0\n",
      "Best parameters: {'estimator': DecisionTreeClassifier(ccp_alpha=0.0001, criterion='log_loss', max_depth=5), 'n_estimators': 50}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>AdaBoostClassifier(estimator=DecisionTreeClassifier(ccp_alpha=0.0001,\n",
       "                                                    criterion=&#x27;log_loss&#x27;,\n",
       "                                                    max_depth=5))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">AdaBoostClassifier</label><div class=\"sk-toggleable__content\"><pre>AdaBoostClassifier(estimator=DecisionTreeClassifier(ccp_alpha=0.0001,\n",
       "                                                    criterion=&#x27;log_loss&#x27;,\n",
       "                                                    max_depth=5))</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(ccp_alpha=0.0001, criterion=&#x27;log_loss&#x27;, max_depth=5)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(ccp_alpha=0.0001, criterion=&#x27;log_loss&#x27;, max_depth=5)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "AdaBoostClassifier(estimator=DecisionTreeClassifier(ccp_alpha=0.0001,\n",
       "                                                    criterion='log_loss',\n",
       "                                                    max_depth=5))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Best score: {}\".format(grid_search.best_score_))\n",
    "print(\"Best parameters: {}\".format(grid_search.best_params_))\n",
    "\n",
    "best_abc = grid_search.best_estimator_\n",
    "best_abc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c0386809",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model = best_abc\n",
    "my_model.fit(scaled_dataset, y)\n",
    "my_model.score(scaled_dataset, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e37300c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Xgboost\n",
    "try:\n",
    "    import xgboost\n",
    "except ImportError as ex:\n",
    "    print(\"Error: the xgboost library is not installed.\")\n",
    "    xgboost = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88146738",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation RMSE: 0.12550145248305436\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "if xgboost is not None:  # not shown in the book\n",
    "    xgb_reg = xgboost.XGBClassifier(random_state=10, n_estimators=200,objective='binary:logistic')\n",
    "    xgb_reg.fit(train_data, np.ravel(y_train))\n",
    "    y_pred = xgb_reg.predict(test_data)\n",
    "    val_error = mean_squared_error(y_test, y_pred) \n",
    "    print(\"Validation RMSE:\", val_error)     \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1326666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-logloss:0.45484\n",
      "[1]\tvalidation_0-logloss:0.41554\n",
      "[2]\tvalidation_0-logloss:0.39258\n",
      "[3]\tvalidation_0-logloss:0.37772\n",
      "[4]\tvalidation_0-logloss:0.36607\n",
      "[5]\tvalidation_0-logloss:0.35801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sgira\\anaconda3\\Lib\\site-packages\\xgboost\\sklearn.py:885: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6]\tvalidation_0-logloss:0.35269\n",
      "[7]\tvalidation_0-logloss:0.34919\n",
      "[8]\tvalidation_0-logloss:0.34740\n",
      "[9]\tvalidation_0-logloss:0.34492\n",
      "[10]\tvalidation_0-logloss:0.34329\n",
      "[11]\tvalidation_0-logloss:0.34216\n",
      "[12]\tvalidation_0-logloss:0.34049\n",
      "[13]\tvalidation_0-logloss:0.34014\n",
      "[14]\tvalidation_0-logloss:0.33915\n",
      "[15]\tvalidation_0-logloss:0.33754\n",
      "[16]\tvalidation_0-logloss:0.33725\n",
      "[17]\tvalidation_0-logloss:0.33602\n",
      "[18]\tvalidation_0-logloss:0.33537\n",
      "[19]\tvalidation_0-logloss:0.33396\n",
      "[20]\tvalidation_0-logloss:0.33315\n",
      "[21]\tvalidation_0-logloss:0.33253\n",
      "[22]\tvalidation_0-logloss:0.33261\n",
      "[23]\tvalidation_0-logloss:0.33187\n",
      "[24]\tvalidation_0-logloss:0.33171\n",
      "[25]\tvalidation_0-logloss:0.33158\n",
      "[26]\tvalidation_0-logloss:0.33090\n",
      "[27]\tvalidation_0-logloss:0.33061\n",
      "[28]\tvalidation_0-logloss:0.33064\n",
      "[29]\tvalidation_0-logloss:0.33039\n",
      "[30]\tvalidation_0-logloss:0.33046\n",
      "[31]\tvalidation_0-logloss:0.33034\n",
      "[32]\tvalidation_0-logloss:0.33036\n",
      "[33]\tvalidation_0-logloss:0.32985\n",
      "[34]\tvalidation_0-logloss:0.32966\n",
      "[35]\tvalidation_0-logloss:0.32963\n",
      "[36]\tvalidation_0-logloss:0.32935\n",
      "[37]\tvalidation_0-logloss:0.32920\n",
      "[38]\tvalidation_0-logloss:0.32923\n",
      "[39]\tvalidation_0-logloss:0.32895\n",
      "[40]\tvalidation_0-logloss:0.32905\n",
      "[41]\tvalidation_0-logloss:0.32880\n",
      "[42]\tvalidation_0-logloss:0.32891\n",
      "[43]\tvalidation_0-logloss:0.32894\n",
      "Validation MSE: 0.12411813528842164\n"
     ]
    }
   ],
   "source": [
    "if xgboost is not None:  # not shown in the book\n",
    "    xgb_reg.fit(train_data, np.ravel(y_train),\n",
    "                eval_set=[(test_data, y_test)], early_stopping_rounds=2)\n",
    "    y_pred = xgb_reg.predict(test_data)\n",
    "    val_error = mean_squared_error(y_test, y_pred)  # Not shown\n",
    "    print(\"Validation MSE:\", val_error)            # Not shown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2dd15c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
