{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "86789fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "#importo libreria panda per leggere ed elaborare csv\n",
    "import pandas as pd\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"decision_trees\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
    "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)\n",
    "\n",
    "from sklearn.model_selection import (\n",
    "    GridSearchCV,\n",
    "    StratifiedKFold,\n",
    "    cross_val_score,\n",
    "    train_test_split,\n",
    ")\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3ff2e821",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=pd.read_csv('/Users/ragno/Documents/Progetti/Mldm/ProgettoMLDM/Dataset/train_data.csv')\n",
    "test_data=pd.read_csv('/Users/ragno/Documents/Progetti/Mldm/ProgettoMLDM/Dataset/test_data.csv')\n",
    "y_train=pd.read_csv('/Users/ragno/Documents/Progetti/Mldm/ProgettoMLDM/Dataset/train_y.csv')\n",
    "y_test=pd.read_csv('/Users/ragno/Documents/Progetti/Mldm/ProgettoMLDM/Dataset/test_y.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "34e752bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "column = ['criterion', 'max_depth', 'ccp_alpha', 'min_samples_leaf', 'min_samples_split', 'accuracy']\n",
    "column_bar = ['try', 'Parameter_changed', 'Accuracy']\n",
    "\n",
    "def plot_depthsVSaccuracy(depths, ccp_alpha, title):\n",
    "  accs = pd.DataFrame(columns=column)\n",
    "  for d in depths:\n",
    "    tree_clf = DecisionTreeClassifier(criterion='log_loss',max_depth=d, min_samples_leaf=4, ccp_alpha=ccp_alpha,min_samples_split=8 )\n",
    "    tree_clf.fit(train_data, y_train)\n",
    "    testset_score = tree_clf.score(test_data, y_test)\n",
    "    row = pd.DataFrame(data=[['log_loss', d, ccp_alpha, 4, 8 ,testset_score]], columns=column)\n",
    "    accs = pd.concat([accs, row])\n",
    "\n",
    "  # plot\n",
    "  fig, ax = plt.subplots()\n",
    "  ax.plot(accs.max_depth, accs.accuracy)\n",
    "\n",
    "  ax.set(xlabel='Max depth', ylabel='Accuracy',\n",
    "        title=title)\n",
    "  ax.grid()\n",
    "  plt.show()\n",
    "\n",
    "### Create a single row equivalent to a single try for decision tree\n",
    "def create_bar_row(criterion, depth, leaf, ccp, split, attempt, parameter):\n",
    "  tree_clf = DecisionTreeClassifier(criterion=criterion,max_depth=depth, min_samples_leaf=leaf, ccp_alpha=ccp,min_samples_split=split )\n",
    "  tree_clf.fit(train_data, y_train)\n",
    "  testset_score = tree_clf.score(test_data, y_test)\n",
    "  row = pd.DataFrame(data=[[attempt, parameter, testset_score]], columns=column_bar)\n",
    "  return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "efa3b0b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "depths = np.linspace(10, 50, 41, dtype=int)\n",
    "\n",
    "plot_depthsVSaccuracy(depths, 0.0001, 'Variazione accuracy CON PRUNING') # with pruning\n",
    "plot_depthsVSaccuracy(depths, 0.0, 'Variazione accuracy SENZA PRUNING') # without pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7c0ef8e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  try  Parameter_changed  Accuracy\n",
      "0   1              start  0.831270\n",
      "0   2          max_depth  0.840019\n",
      "0   3   min_samples_leaf  0.851120\n",
      "0   4  min_samples_split  0.858625\n",
      "0   5          ccp_alpha  0.868965\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'Score sul testset durante il tuning dei parametri'}, xlabel='Accuracy', ylabel='Parameter_changed'>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "df = pd.DataFrame(columns=column_bar)\n",
    "df = pd.concat([df, create_bar_row('entropy', 50, 1, 0.0, 20, 1, 'start')]) # try 1\n",
    "df = pd.concat([df, create_bar_row('entropy', 25, 1, 0.0, 20, 2, 'max_depth')]) # try 2\n",
    "df = pd.concat([df, create_bar_row('entropy', 25, 10, 0.0, 20, 3, 'min_samples_leaf')]) # try 3\n",
    "df = pd.concat([df, create_bar_row('entropy', 25, 10, 0.0, 40, 4, 'min_samples_split')]) # try 4\n",
    "df = pd.concat([df, create_bar_row('entropy', 25, 10, 0.0001, 40, 5, 'ccp_alpha')]) # try 5\n",
    "print(df)\n",
    "\n",
    "fig, axs = plt.subplots()\n",
    "axs.set_xlim([0.70,0.89])\n",
    "axs.set_title(\"Score sul testset durante il tuning dei parametri\")\n",
    "\n",
    "sns.barplot(data=df, x='Accuracy',y=\"Parameter_changed\",ax=axs, orient=\"h\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "328fa9b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 288 candidates, totalling 1440 fits\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.782) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.870, test=0.866) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.785, test=0.777) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.740, test=0.738) f1: (train=0.783, test=0.780) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.784, test=0.781) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.872) balanced_accuracy: (train=0.741, test=0.748) f1: (train=0.783, test=0.790) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.782) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.870, test=0.866) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.785, test=0.777) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.740, test=0.738) f1: (train=0.783, test=0.780) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.784, test=0.781) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.872) balanced_accuracy: (train=0.741, test=0.748) f1: (train=0.783, test=0.790) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.782) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.870, test=0.866) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.785, test=0.777) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.740, test=0.738) f1: (train=0.783, test=0.780) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.784, test=0.781) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.872) balanced_accuracy: (train=0.741, test=0.748) f1: (train=0.783, test=0.790) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.782) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.870, test=0.866) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.785, test=0.777) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.740, test=0.738) f1: (train=0.783, test=0.780) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.784, test=0.781) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.872) balanced_accuracy: (train=0.741, test=0.748) f1: (train=0.783, test=0.790) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.782) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.870, test=0.866) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.785, test=0.777) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.740, test=0.738) f1: (train=0.783, test=0.780) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.784, test=0.781) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.872) balanced_accuracy: (train=0.741, test=0.748) f1: (train=0.783, test=0.790) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.782) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.870, test=0.866) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.785, test=0.777) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.740, test=0.738) f1: (train=0.783, test=0.780) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.784, test=0.781) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.872) balanced_accuracy: (train=0.741, test=0.748) f1: (train=0.783, test=0.790) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.785, test=0.782) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.742, test=0.735) f1: (train=0.784, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.737) f1: (train=0.782, test=0.779) total time=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.737) f1: (train=0.782, test=0.779) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.739, test=0.747) f1: (train=0.780, test=0.788) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.785, test=0.782) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.742, test=0.735) f1: (train=0.784, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.737) f1: (train=0.782, test=0.779) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.737) f1: (train=0.782, test=0.779) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.739, test=0.747) f1: (train=0.780, test=0.788) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.785, test=0.782) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.742, test=0.735) f1: (train=0.784, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.737) f1: (train=0.782, test=0.779) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.737) f1: (train=0.782, test=0.779) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.739, test=0.747) f1: (train=0.780, test=0.788) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.785, test=0.782) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.742, test=0.735) f1: (train=0.784, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.737) f1: (train=0.782, test=0.779) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.737) f1: (train=0.782, test=0.779) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.739, test=0.747) f1: (train=0.780, test=0.788) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.785, test=0.782) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.742, test=0.735) f1: (train=0.784, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.737) f1: (train=0.782, test=0.779) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.737) f1: (train=0.782, test=0.779) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.739, test=0.747) f1: (train=0.780, test=0.788) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.785, test=0.782) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.742, test=0.735) f1: (train=0.784, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.737) f1: (train=0.782, test=0.779) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.737) f1: (train=0.782, test=0.779) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.739, test=0.747) f1: (train=0.780, test=0.788) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.866) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.784, test=0.781) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.742, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.736) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.739, test=0.736) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.738, test=0.746) f1: (train=0.779, test=0.788) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.866) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.784, test=0.781) total time=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.742, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.736) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.739, test=0.736) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.738, test=0.746) f1: (train=0.779, test=0.788) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.866) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.784, test=0.781) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.742, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.736) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.739, test=0.736) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.738, test=0.746) f1: (train=0.779, test=0.788) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.866) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.784, test=0.781) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.742, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.736) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.739, test=0.736) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.738, test=0.746) f1: (train=0.779, test=0.788) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.866) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.784, test=0.781) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.742, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.736) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.739, test=0.736) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.738, test=0.746) f1: (train=0.779, test=0.788) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.866) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.784, test=0.781) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.742, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.736) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.739, test=0.736) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.738, test=0.746) f1: (train=0.779, test=0.788) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.866, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.866, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.866, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.866, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.866, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.866, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.871, test=0.868) balanced_accuracy: (train=0.745, test=0.741) f1: (train=0.787, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.870, test=0.866) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.741, test=0.739) f1: (train=0.784, test=0.781) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.782) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.872) balanced_accuracy: (train=0.743, test=0.750) f1: (train=0.784, test=0.791) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.871, test=0.868) balanced_accuracy: (train=0.745, test=0.741) f1: (train=0.787, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.870, test=0.866) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.741, test=0.739) f1: (train=0.784, test=0.781) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.782) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.872) balanced_accuracy: (train=0.743, test=0.750) f1: (train=0.784, test=0.791) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.871, test=0.868) balanced_accuracy: (train=0.745, test=0.741) f1: (train=0.787, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.870, test=0.866) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.741, test=0.739) f1: (train=0.784, test=0.781) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.782) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.872) balanced_accuracy: (train=0.743, test=0.750) f1: (train=0.784, test=0.791) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.871, test=0.868) balanced_accuracy: (train=0.745, test=0.741) f1: (train=0.787, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.870, test=0.866) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.741, test=0.739) f1: (train=0.784, test=0.781) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.782) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.872) balanced_accuracy: (train=0.743, test=0.750) f1: (train=0.784, test=0.791) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.871, test=0.868) balanced_accuracy: (train=0.745, test=0.741) f1: (train=0.787, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.870, test=0.866) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.741, test=0.739) f1: (train=0.784, test=0.781) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.782) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.872) balanced_accuracy: (train=0.743, test=0.750) f1: (train=0.784, test=0.791) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.871, test=0.868) balanced_accuracy: (train=0.745, test=0.741) f1: (train=0.787, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.870, test=0.866) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.741, test=0.739) f1: (train=0.784, test=0.781) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.782) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.872) balanced_accuracy: (train=0.743, test=0.750) f1: (train=0.784, test=0.791) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.784, test=0.777) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.740, test=0.738) f1: (train=0.782, test=0.780) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.742, test=0.738) f1: (train=0.784, test=0.780) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.872) balanced_accuracy: (train=0.741, test=0.749) f1: (train=0.782, test=0.790) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.784, test=0.777) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.740, test=0.738) f1: (train=0.782, test=0.780) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.742, test=0.738) f1: (train=0.784, test=0.780) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.872) balanced_accuracy: (train=0.741, test=0.749) f1: (train=0.782, test=0.790) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.784, test=0.777) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.740, test=0.738) f1: (train=0.782, test=0.780) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.742, test=0.738) f1: (train=0.784, test=0.780) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.872) balanced_accuracy: (train=0.741, test=0.749) f1: (train=0.782, test=0.790) total time=   0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.784, test=0.777) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.740, test=0.738) f1: (train=0.782, test=0.780) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.742, test=0.738) f1: (train=0.784, test=0.780) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.872) balanced_accuracy: (train=0.741, test=0.749) f1: (train=0.782, test=0.790) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.784, test=0.777) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.740, test=0.738) f1: (train=0.782, test=0.780) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.742, test=0.738) f1: (train=0.784, test=0.780) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.872) balanced_accuracy: (train=0.741, test=0.749) f1: (train=0.782, test=0.790) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.784, test=0.777) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.740, test=0.738) f1: (train=0.782, test=0.780) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.742, test=0.738) f1: (train=0.784, test=0.780) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.872) balanced_accuracy: (train=0.741, test=0.749) f1: (train=0.782, test=0.790) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.785, test=0.782) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.742, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.736) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.739, test=0.736) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.739, test=0.748) f1: (train=0.780, test=0.789) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.785, test=0.782) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.742, test=0.735) f1: (train=0.783, test=0.776) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.736) f1: (train=0.781, test=0.778) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.739, test=0.736) f1: (train=0.781, test=0.778) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.739, test=0.748) f1: (train=0.780, test=0.789) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.785, test=0.782) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.742, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.736) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.739, test=0.736) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.739, test=0.748) f1: (train=0.780, test=0.789) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.785, test=0.782) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.742, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.736) f1: (train=0.781, test=0.778) total time=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.739, test=0.736) f1: (train=0.781, test=0.778) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.739, test=0.748) f1: (train=0.780, test=0.789) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.785, test=0.782) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.742, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.736) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.739, test=0.736) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.739, test=0.748) f1: (train=0.780, test=0.789) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.785, test=0.782) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.742, test=0.735) f1: (train=0.783, test=0.776) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.736) f1: (train=0.781, test=0.778) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.739, test=0.736) f1: (train=0.781, test=0.778) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.739, test=0.748) f1: (train=0.780, test=0.789) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.866, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.866, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.866, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.866, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.866, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.866, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.871, test=0.868) balanced_accuracy: (train=0.745, test=0.741) f1: (train=0.787, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.870, test=0.866) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.741, test=0.739) f1: (train=0.784, test=0.781) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.782) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.872) balanced_accuracy: (train=0.743, test=0.750) f1: (train=0.784, test=0.791) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.871, test=0.868) balanced_accuracy: (train=0.745, test=0.741) f1: (train=0.787, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.870, test=0.866) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.741, test=0.739) f1: (train=0.784, test=0.781) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.782) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.872) balanced_accuracy: (train=0.743, test=0.750) f1: (train=0.784, test=0.791) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.871, test=0.868) balanced_accuracy: (train=0.745, test=0.741) f1: (train=0.787, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.870, test=0.866) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.741, test=0.739) f1: (train=0.784, test=0.781) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.782) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.872) balanced_accuracy: (train=0.743, test=0.750) f1: (train=0.784, test=0.791) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.871, test=0.868) balanced_accuracy: (train=0.745, test=0.741) f1: (train=0.787, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.870, test=0.866) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.741, test=0.739) f1: (train=0.784, test=0.781) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.782) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.872) balanced_accuracy: (train=0.743, test=0.750) f1: (train=0.784, test=0.791) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.871, test=0.868) balanced_accuracy: (train=0.745, test=0.741) f1: (train=0.787, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.870, test=0.866) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.741, test=0.739) f1: (train=0.784, test=0.781) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.782) total time=   0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.872) balanced_accuracy: (train=0.743, test=0.750) f1: (train=0.784, test=0.791) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.871, test=0.868) balanced_accuracy: (train=0.745, test=0.741) f1: (train=0.787, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.870, test=0.866) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.741, test=0.739) f1: (train=0.784, test=0.781) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.782) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.872) balanced_accuracy: (train=0.743, test=0.750) f1: (train=0.784, test=0.791) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.784, test=0.777) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.740, test=0.738) f1: (train=0.782, test=0.780) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.742, test=0.738) f1: (train=0.784, test=0.780) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.872) balanced_accuracy: (train=0.741, test=0.749) f1: (train=0.782, test=0.790) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.784, test=0.777) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.740, test=0.738) f1: (train=0.782, test=0.780) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.742, test=0.738) f1: (train=0.784, test=0.780) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.872) balanced_accuracy: (train=0.741, test=0.749) f1: (train=0.782, test=0.790) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.784, test=0.777) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.740, test=0.738) f1: (train=0.782, test=0.780) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.742, test=0.738) f1: (train=0.784, test=0.780) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.872) balanced_accuracy: (train=0.741, test=0.749) f1: (train=0.782, test=0.790) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.784, test=0.777) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.740, test=0.738) f1: (train=0.782, test=0.780) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.742, test=0.738) f1: (train=0.784, test=0.780) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.872) balanced_accuracy: (train=0.741, test=0.749) f1: (train=0.782, test=0.790) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.784, test=0.777) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.740, test=0.738) f1: (train=0.782, test=0.780) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.742, test=0.738) f1: (train=0.784, test=0.780) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.872) balanced_accuracy: (train=0.741, test=0.749) f1: (train=0.782, test=0.790) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.784, test=0.777) total time=   0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.740, test=0.738) f1: (train=0.782, test=0.780) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.742, test=0.738) f1: (train=0.784, test=0.780) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.872) balanced_accuracy: (train=0.741, test=0.749) f1: (train=0.782, test=0.790) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.785, test=0.782) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.742, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.736) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.739, test=0.736) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.739, test=0.748) f1: (train=0.780, test=0.789) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.785, test=0.782) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.742, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.736) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.739, test=0.736) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.739, test=0.748) f1: (train=0.780, test=0.789) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.785, test=0.782) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.742, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.736) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.739, test=0.736) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.739, test=0.748) f1: (train=0.780, test=0.789) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.785, test=0.782) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.742, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.736) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.739, test=0.736) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.739, test=0.748) f1: (train=0.780, test=0.789) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.785, test=0.782) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.742, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.736) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.739, test=0.736) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.739, test=0.748) f1: (train=0.780, test=0.789) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.785, test=0.782) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.742, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.736) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.739, test=0.736) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.739, test=0.748) f1: (train=0.780, test=0.789) total time=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.866, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.866, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.866, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.866, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.866, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.866, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.871, test=0.868) balanced_accuracy: (train=0.745, test=0.741) f1: (train=0.787, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.870, test=0.866) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.741, test=0.739) f1: (train=0.784, test=0.781) total time=   0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.782) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.872) balanced_accuracy: (train=0.743, test=0.750) f1: (train=0.784, test=0.791) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.871, test=0.868) balanced_accuracy: (train=0.745, test=0.741) f1: (train=0.787, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.870, test=0.866) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.741, test=0.739) f1: (train=0.784, test=0.781) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.782) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.872) balanced_accuracy: (train=0.743, test=0.750) f1: (train=0.784, test=0.791) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.871, test=0.868) balanced_accuracy: (train=0.745, test=0.741) f1: (train=0.787, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.870, test=0.866) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.741, test=0.739) f1: (train=0.784, test=0.781) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.782) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.872) balanced_accuracy: (train=0.743, test=0.750) f1: (train=0.784, test=0.791) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.871, test=0.868) balanced_accuracy: (train=0.745, test=0.741) f1: (train=0.787, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.870, test=0.866) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.741, test=0.739) f1: (train=0.784, test=0.781) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.782) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.872) balanced_accuracy: (train=0.743, test=0.750) f1: (train=0.784, test=0.791) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.871, test=0.868) balanced_accuracy: (train=0.745, test=0.741) f1: (train=0.787, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.870, test=0.866) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.741, test=0.739) f1: (train=0.784, test=0.781) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.782) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.872) balanced_accuracy: (train=0.743, test=0.750) f1: (train=0.784, test=0.791) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.871, test=0.868) balanced_accuracy: (train=0.745, test=0.741) f1: (train=0.787, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.870, test=0.866) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.741, test=0.739) f1: (train=0.784, test=0.781) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.782) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.872) balanced_accuracy: (train=0.743, test=0.750) f1: (train=0.784, test=0.791) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.784, test=0.777) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.740, test=0.738) f1: (train=0.782, test=0.780) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.742, test=0.738) f1: (train=0.784, test=0.780) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.872) balanced_accuracy: (train=0.741, test=0.749) f1: (train=0.782, test=0.790) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.784, test=0.777) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.740, test=0.738) f1: (train=0.782, test=0.780) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.742, test=0.738) f1: (train=0.784, test=0.780) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.872) balanced_accuracy: (train=0.741, test=0.749) f1: (train=0.782, test=0.790) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.784, test=0.777) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.740, test=0.738) f1: (train=0.782, test=0.780) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.742, test=0.738) f1: (train=0.784, test=0.780) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.872) balanced_accuracy: (train=0.741, test=0.749) f1: (train=0.782, test=0.790) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.784, test=0.777) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.740, test=0.738) f1: (train=0.782, test=0.780) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.742, test=0.738) f1: (train=0.784, test=0.780) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.872) balanced_accuracy: (train=0.741, test=0.749) f1: (train=0.782, test=0.790) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.784, test=0.777) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.740, test=0.738) f1: (train=0.782, test=0.780) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.742, test=0.738) f1: (train=0.784, test=0.780) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.872) balanced_accuracy: (train=0.741, test=0.749) f1: (train=0.782, test=0.790) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.784, test=0.777) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.740, test=0.738) f1: (train=0.782, test=0.780) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.742, test=0.738) f1: (train=0.784, test=0.780) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.872) balanced_accuracy: (train=0.741, test=0.749) f1: (train=0.782, test=0.790) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.785, test=0.782) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.742, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.736) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.739, test=0.736) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.739, test=0.748) f1: (train=0.780, test=0.789) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.785, test=0.782) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.742, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.736) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.739, test=0.736) f1: (train=0.781, test=0.778) total time=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.739, test=0.748) f1: (train=0.780, test=0.789) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.785, test=0.782) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.742, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.736) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.739, test=0.736) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.739, test=0.748) f1: (train=0.780, test=0.789) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.785, test=0.782) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.742, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.736) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.739, test=0.736) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.739, test=0.748) f1: (train=0.780, test=0.789) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.785, test=0.782) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.742, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.736) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.739, test=0.736) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.739, test=0.748) f1: (train=0.780, test=0.789) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.785, test=0.782) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.742, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.736) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.739, test=0.736) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.739, test=0.748) f1: (train=0.780, test=0.789) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.866, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.866, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.866, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.866, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.866, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.866, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.746, test=0.743) f1: (train=0.787, test=0.784) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.870, test=0.866) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.786, test=0.778) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.782) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.871, test=0.868) balanced_accuracy: (train=0.744, test=0.741) f1: (train=0.787, test=0.783) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.873) balanced_accuracy: (train=0.744, test=0.752) f1: (train=0.785, test=0.793) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.746, test=0.743) f1: (train=0.787, test=0.784) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.870, test=0.866) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.786, test=0.778) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.782) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.871, test=0.868) balanced_accuracy: (train=0.744, test=0.741) f1: (train=0.787, test=0.783) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.873) balanced_accuracy: (train=0.744, test=0.752) f1: (train=0.785, test=0.793) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.746, test=0.743) f1: (train=0.787, test=0.784) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.870, test=0.866) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.786, test=0.778) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.782) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.871, test=0.868) balanced_accuracy: (train=0.744, test=0.741) f1: (train=0.787, test=0.783) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.873) balanced_accuracy: (train=0.744, test=0.752) f1: (train=0.785, test=0.793) total time=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.746, test=0.743) f1: (train=0.787, test=0.784) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.870, test=0.866) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.786, test=0.778) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.782) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.871, test=0.868) balanced_accuracy: (train=0.744, test=0.741) f1: (train=0.787, test=0.783) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.873) balanced_accuracy: (train=0.744, test=0.752) f1: (train=0.785, test=0.793) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.746, test=0.743) f1: (train=0.787, test=0.784) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.870, test=0.866) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.786, test=0.778) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.782) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.871, test=0.868) balanced_accuracy: (train=0.744, test=0.741) f1: (train=0.787, test=0.783) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.873) balanced_accuracy: (train=0.744, test=0.752) f1: (train=0.785, test=0.793) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.746, test=0.743) f1: (train=0.787, test=0.784) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.870, test=0.866) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.786, test=0.778) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.782) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.871, test=0.868) balanced_accuracy: (train=0.744, test=0.741) f1: (train=0.787, test=0.783) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.873) balanced_accuracy: (train=0.744, test=0.752) f1: (train=0.785, test=0.793) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.743, test=0.741) f1: (train=0.785, test=0.782) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.742, test=0.735) f1: (train=0.784, test=0.777) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.785, test=0.782) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.784, test=0.781) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.872) balanced_accuracy: (train=0.742, test=0.750) f1: (train=0.783, test=0.791) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.743, test=0.741) f1: (train=0.785, test=0.782) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.742, test=0.735) f1: (train=0.784, test=0.777) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.785, test=0.782) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.784, test=0.781) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.872) balanced_accuracy: (train=0.742, test=0.750) f1: (train=0.783, test=0.791) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.743, test=0.741) f1: (train=0.785, test=0.782) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.742, test=0.735) f1: (train=0.784, test=0.777) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.785, test=0.782) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.784, test=0.781) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.872) balanced_accuracy: (train=0.742, test=0.750) f1: (train=0.783, test=0.791) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.743, test=0.741) f1: (train=0.785, test=0.782) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.742, test=0.735) f1: (train=0.784, test=0.777) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.785, test=0.782) total time=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.784, test=0.781) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.872) balanced_accuracy: (train=0.742, test=0.750) f1: (train=0.783, test=0.791) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.743, test=0.741) f1: (train=0.785, test=0.782) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.742, test=0.735) f1: (train=0.784, test=0.777) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.785, test=0.782) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.784, test=0.781) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.872) balanced_accuracy: (train=0.742, test=0.750) f1: (train=0.783, test=0.791) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.743, test=0.741) f1: (train=0.785, test=0.782) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.742, test=0.735) f1: (train=0.784, test=0.777) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.785, test=0.782) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.784, test=0.781) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.872) balanced_accuracy: (train=0.742, test=0.750) f1: (train=0.783, test=0.791) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.737) f1: (train=0.781, test=0.779) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.738) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.740, test=0.749) f1: (train=0.781, test=0.789) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.737) f1: (train=0.781, test=0.779) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.738) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.740, test=0.749) f1: (train=0.781, test=0.789) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.737) f1: (train=0.781, test=0.779) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.738) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.740, test=0.749) f1: (train=0.781, test=0.789) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.737) f1: (train=0.781, test=0.779) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.738) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.740, test=0.749) f1: (train=0.781, test=0.789) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.737) f1: (train=0.781, test=0.779) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.738) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.740, test=0.749) f1: (train=0.781, test=0.789) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.737) f1: (train=0.781, test=0.779) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.738) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.740, test=0.749) f1: (train=0.781, test=0.789) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.780, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.865, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.780, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.865, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.780, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.865, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.780, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.865, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.780, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.865, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.780, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.865, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.749, test=0.745) f1: (train=0.790, test=0.786) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.746, test=0.738) f1: (train=0.788, test=0.780) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.789, test=0.785) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.788, test=0.784) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.870, test=0.873) balanced_accuracy: (train=0.746, test=0.754) f1: (train=0.788, test=0.795) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.749, test=0.745) f1: (train=0.790, test=0.786) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.746, test=0.738) f1: (train=0.788, test=0.780) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.789, test=0.785) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.788, test=0.784) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.870, test=0.873) balanced_accuracy: (train=0.746, test=0.754) f1: (train=0.788, test=0.795) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.749, test=0.745) f1: (train=0.790, test=0.786) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.746, test=0.738) f1: (train=0.788, test=0.780) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.789, test=0.785) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.788, test=0.784) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.870, test=0.873) balanced_accuracy: (train=0.746, test=0.754) f1: (train=0.788, test=0.795) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.749, test=0.745) f1: (train=0.790, test=0.786) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.746, test=0.738) f1: (train=0.788, test=0.780) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.789, test=0.785) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.788, test=0.784) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.870, test=0.873) balanced_accuracy: (train=0.746, test=0.754) f1: (train=0.788, test=0.795) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.749, test=0.745) f1: (train=0.790, test=0.786) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.746, test=0.738) f1: (train=0.788, test=0.780) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.789, test=0.785) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.788, test=0.784) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.870, test=0.873) balanced_accuracy: (train=0.746, test=0.754) f1: (train=0.788, test=0.795) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.749, test=0.745) f1: (train=0.790, test=0.786) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.746, test=0.738) f1: (train=0.788, test=0.780) total time=   0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.789, test=0.785) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.788, test=0.784) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.870, test=0.873) balanced_accuracy: (train=0.746, test=0.754) f1: (train=0.788, test=0.795) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.870, test=0.865) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.784, test=0.781) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.872) balanced_accuracy: (train=0.744, test=0.752) f1: (train=0.785, test=0.793) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.870, test=0.865) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.784, test=0.781) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.872) balanced_accuracy: (train=0.744, test=0.752) f1: (train=0.785, test=0.793) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.870, test=0.865) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.784, test=0.781) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.872) balanced_accuracy: (train=0.744, test=0.752) f1: (train=0.785, test=0.793) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.870, test=0.865) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.784, test=0.781) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.872) balanced_accuracy: (train=0.744, test=0.752) f1: (train=0.785, test=0.793) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.870, test=0.865) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.784, test=0.781) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.872) balanced_accuracy: (train=0.744, test=0.752) f1: (train=0.785, test=0.793) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.870, test=0.865) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.784, test=0.781) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.872) balanced_accuracy: (train=0.744, test=0.752) f1: (train=0.785, test=0.793) total time=   0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.737) f1: (train=0.781, test=0.779) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.738) f1: (train=0.783, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.740, test=0.749) f1: (train=0.781, test=0.789) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.737) f1: (train=0.781, test=0.779) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.738) f1: (train=0.783, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.740, test=0.749) f1: (train=0.781, test=0.789) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.737) f1: (train=0.781, test=0.779) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.738) f1: (train=0.783, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.740, test=0.749) f1: (train=0.781, test=0.789) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.737) f1: (train=0.781, test=0.779) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.738) f1: (train=0.783, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.740, test=0.749) f1: (train=0.781, test=0.789) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.737) f1: (train=0.781, test=0.779) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.738) f1: (train=0.783, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.740, test=0.749) f1: (train=0.781, test=0.789) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.737) f1: (train=0.781, test=0.779) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.738) f1: (train=0.783, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.740, test=0.749) f1: (train=0.781, test=0.789) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.780, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.865, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.780, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.737, test=0.734) f1: (train=0.780, test=0.777) total time=   1.4s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.779, test=0.776) total time=   1.6s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   2.9s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.780, test=0.776) total time=   3.9s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.779, test=0.776) total time=   2.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.737, test=0.731) f1: (train=0.780, test=0.773) total time=   4.1s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.872, test=0.870) balanced_accuracy: (train=0.747, test=0.742) f1: (train=0.789, test=0.785) total time=   5.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.872, test=0.870) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.790, test=0.786) total time=   8.5s\n",
      "[CV 2/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.872, test=0.867) balanced_accuracy: (train=0.746, test=0.738) f1: (train=0.789, test=0.780) total time=  16.4s\n",
      "[CV 1/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   1.2s\n",
      "[CV 2/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.779, test=0.772) total time=   1.4s\n",
      "[CV 5/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.866, test=0.870) balanced_accuracy: (train=0.733, test=0.741) f1: (train=0.776, test=0.784) total time=   1.8s\n",
      "[CV 3/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   2.6s\n",
      "[CV 3/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.735, test=0.732) f1: (train=0.779, test=0.775) total time=   4.6s\n",
      "[CV 2/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.737, test=0.730) f1: (train=0.780, test=0.773) total time=   1.3s\n",
      "[CV 2/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.737, test=0.731) f1: (train=0.780, test=0.774) total time=   2.2s\n",
      "[CV 5/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.866, test=0.871) balanced_accuracy: (train=0.733, test=0.742) f1: (train=0.776, test=0.785) total time=   2.1s\n",
      "[CV 2/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.737, test=0.731) f1: (train=0.780, test=0.773) total time=   4.2s\n",
      "[CV 4/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.872, test=0.870) balanced_accuracy: (train=0.747, test=0.742) f1: (train=0.790, test=0.785) total time=   5.4s\n",
      "[CV 1/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.872, test=0.870) balanced_accuracy: (train=0.748, test=0.744) f1: (train=0.790, test=0.786) total time=   7.2s\n",
      "[CV 3/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.873, test=0.870) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.790, test=0.786) total time=  17.3s\n",
      "[CV 3/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.737, test=0.733) f1: (train=0.780, test=0.775) total time=   1.2s\n",
      "[CV 4/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   1.3s\n",
      "[CV 1/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   2.4s\n",
      "[CV 1/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   2.6s\n",
      "[CV 4/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   3.3s\n",
      "[CV 1/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   1.4s\n",
      "[CV 4/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.737, test=0.735) f1: (train=0.779, test=0.778) total time=   1.4s\n",
      "[CV 1/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   2.2s\n",
      "[CV 5/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.787) total time=   4.2s\n",
      "[CV 2/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.873, test=0.868) balanced_accuracy: (train=0.747, test=0.739) f1: (train=0.790, test=0.781) total time=   5.2s\n",
      "[CV 1/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.872, test=0.870) balanced_accuracy: (train=0.748, test=0.744) f1: (train=0.790, test=0.786) total time=   8.7s\n",
      "[CV 4/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.872, test=0.870) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.789, test=0.784) total time=  16.6s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.732) f1: (train=0.779, test=0.775) total time=   1.6s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   1.6s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.866, test=0.870) balanced_accuracy: (train=0.733, test=0.742) f1: (train=0.776, test=0.785) total time=   1.9s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   2.4s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.733, test=0.743) f1: (train=0.776, test=0.786) total time=   4.4s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   1.7s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   1.3s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   2.4s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   4.5s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.783) total time=   5.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.744, test=0.741) f1: (train=0.787, test=0.784) total time=   8.5s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.785, test=0.782) total time=  17.1s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.870, test=0.874) balanced_accuracy: (train=0.741, test=0.751) f1: (train=0.784, test=0.794) total time=  13.8s\n",
      "[CV 1/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.778, test=0.776) total time=   1.4s\n",
      "[CV 4/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   1.4s\n",
      "[CV 5/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.866, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.776, test=0.787) total time=   2.2s\n",
      "[CV 2/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.780, test=0.773) total time=   4.3s\n",
      "[CV 5/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.733, test=0.743) f1: (train=0.777, test=0.786) total time=   4.4s\n",
      "[CV 1/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.744, test=0.740) f1: (train=0.787, test=0.783) total time=   4.9s\n",
      "[CV 2/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.872, test=0.867) balanced_accuracy: (train=0.745, test=0.737) f1: (train=0.788, test=0.779) total time=   8.9s\n",
      "[CV 5/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.870, test=0.874) balanced_accuracy: (train=0.742, test=0.750) f1: (train=0.785, test=0.793) total time=  17.8s\n",
      "[CV 3/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.732) f1: (train=0.779, test=0.775) total time=   1.4s\n",
      "[CV 2/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.736, test=0.729) f1: (train=0.779, test=0.772) total time=   1.6s\n",
      "[CV 4/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.778, test=0.775) total time=   1.5s\n",
      "[CV 1/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.735) f1: (train=0.779, test=0.778) total time=   2.5s\n",
      "[CV 1/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   4.5s\n",
      "[CV 2/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.780, test=0.773) total time=   4.2s\n",
      "[CV 1/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.735) f1: (train=0.779, test=0.778) total time=   2.1s\n",
      "[CV 3/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   4.1s\n",
      "[CV 4/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.779, test=0.777) total time=   4.8s\n",
      "[CV 2/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.872, test=0.867) balanced_accuracy: (train=0.744, test=0.736) f1: (train=0.787, test=0.779) total time=   3.7s\n",
      "[CV 3/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.786, test=0.783) total time=   9.1s\n",
      "[CV 1/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.744, test=0.741) f1: (train=0.787, test=0.784) total time=  15.3s\n",
      "[CV 5/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.870, test=0.874) balanced_accuracy: (train=0.742, test=0.751) f1: (train=0.785, test=0.794) total time=  17.0s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   1.2s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.735, test=0.735) f1: (train=0.778, test=0.778) total time=   1.3s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   2.0s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.780, test=0.772) total time=   3.9s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   4.3s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.872, test=0.867) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.787, test=0.779) total time=   5.1s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.870, test=0.874) balanced_accuracy: (train=0.741, test=0.750) f1: (train=0.784, test=0.793) total time=   8.2s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.787, test=0.778) total time=  18.6s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.866, test=0.869) balanced_accuracy: (train=0.732, test=0.741) f1: (train=0.775, test=0.784) total time=   1.4s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.737, test=0.731) f1: (train=0.780, test=0.773) total time=   2.0s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.779, test=0.776) total time=   2.2s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.776, test=0.786) total time=   4.3s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.866, test=0.871) balanced_accuracy: (train=0.733, test=0.742) f1: (train=0.776, test=0.785) total time=   1.4s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.776) total time=   1.3s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.866, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.776, test=0.787) total time=   2.3s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.780, test=0.773) total time=   4.3s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.779, test=0.777) total time=   4.5s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.744, test=0.740) f1: (train=0.787, test=0.783) total time=   5.4s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.786, test=0.783) total time=   8.7s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.744, test=0.741) f1: (train=0.787, test=0.784) total time=  19.0s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.779, test=0.776) total time=   1.3s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.776) total time=   1.2s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.779, test=0.776) total time=   2.0s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.780, test=0.772) total time=   2.4s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   4.3s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.736, test=0.729) f1: (train=0.779, test=0.772) total time=   1.2s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.776) total time=   2.2s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.779, test=0.776) total time=   2.0s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.866, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.786) total time=   4.3s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.872, test=0.867) balanced_accuracy: (train=0.745, test=0.737) f1: (train=0.788, test=0.779) total time=   6.3s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.741) f1: (train=0.786, test=0.784) total time=   9.7s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.744, test=0.741) f1: (train=0.787, test=0.783) total time=  20.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   1.2s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   1.3s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.786) total time=   2.2s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   2.2s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.733, test=0.743) f1: (train=0.776, test=0.786) total time=   3.8s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.776) total time=   1.4s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.737, test=0.730) f1: (train=0.780, test=0.772) total time=   1.3s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   1.4s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   1.9s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.778) total time=   4.0s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.782) total time=   5.3s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.744, test=0.740) f1: (train=0.787, test=0.783) total time=   8.5s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.785, test=0.782) total time=   8.7s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.744, test=0.740) f1: (train=0.786, test=0.783) total time=  18.0s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   3.9s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   4.2s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.776) total time=   1.0s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.737, test=0.731) f1: (train=0.780, test=0.773) total time=   2.1s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.779, test=0.776) total time=   4.4s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.741) f1: (train=0.786, test=0.783) total time=   5.5s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.870, test=0.875) balanced_accuracy: (train=0.742, test=0.752) f1: (train=0.785, test=0.795) total time=   5.8s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.787, test=0.779) total time=   8.9s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.783) total time=  17.2s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.866, test=0.870) balanced_accuracy: (train=0.733, test=0.742) f1: (train=0.776, test=0.785) total time=   1.1s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.778, test=0.775) total time=   1.2s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.866, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.776, test=0.787) total time=   2.0s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.778, test=0.776) total time=   2.0s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.779, test=0.776) total time=   4.4s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.864) balanced_accuracy: (train=0.735, test=0.729) f1: (train=0.778, test=0.771) total time=   1.3s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.866, test=0.870) balanced_accuracy: (train=0.733, test=0.742) f1: (train=0.776, test=0.785) total time=   1.4s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   2.2s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   4.2s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.777) total time=   4.7s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.744, test=0.740) f1: (train=0.787, test=0.783) total time=   5.6s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.870, test=0.874) balanced_accuracy: (train=0.742, test=0.751) f1: (train=0.785, test=0.794) total time=  10.3s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.785, test=0.782) total time=  15.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.865, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   1.3s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.786) total time=   1.6s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   2.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.735) f1: (train=0.780, test=0.778) total time=   4.2s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.786) total time=   1.2s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.786) total time=   1.9s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.735) f1: (train=0.779, test=0.778) total time=   3.9s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   3.7s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.871, test=0.875) balanced_accuracy: (train=0.746, test=0.753) f1: (train=0.788, test=0.795) total time=   4.6s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.872, test=0.870) balanced_accuracy: (train=0.746, test=0.743) f1: (train=0.789, test=0.785) total time=   5.7s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.871, test=0.875) balanced_accuracy: (train=0.744, test=0.753) f1: (train=0.787, test=0.796) total time=   8.1s\n",
      "[CV 2/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.872, test=0.867) balanced_accuracy: (train=0.746, test=0.738) f1: (train=0.789, test=0.780) total time=  15.9s\n",
      "[CV 3/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.779, test=0.776) total time=   2.3s\n",
      "[CV 2/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.780, test=0.773) total time=   4.2s\n",
      "[CV 3/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.737, test=0.733) f1: (train=0.780, test=0.775) total time=   1.4s\n",
      "[CV 4/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.737, test=0.735) f1: (train=0.779, test=0.778) total time=   1.2s\n",
      "[CV 3/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   1.9s\n",
      "[CV 4/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   4.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.872, test=0.870) balanced_accuracy: (train=0.748, test=0.743) f1: (train=0.791, test=0.785) total time=   5.3s\n",
      "[CV 1/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.872, test=0.870) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.790, test=0.785) total time=   7.1s\n",
      "[CV 3/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.872, test=0.870) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.789, test=0.785) total time=   8.4s\n",
      "[CV 5/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.871, test=0.875) balanced_accuracy: (train=0.745, test=0.753) f1: (train=0.787, test=0.796) total time=  12.7s\n",
      "[CV 2/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.779, test=0.772) total time=   1.4s\n",
      "[CV 3/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.737, test=0.734) f1: (train=0.780, test=0.777) total time=   1.1s\n",
      "[CV 4/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.780, test=0.777) total time=   2.2s\n",
      "[CV 2/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.737, test=0.730) f1: (train=0.780, test=0.773) total time=   2.3s\n",
      "[CV 1/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.737, test=0.735) f1: (train=0.780, test=0.777) total time=   4.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.737, test=0.733) f1: (train=0.780, test=0.775) total time=   1.3s\n",
      "[CV 4/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   1.3s\n",
      "[CV 4/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.780, test=0.777) total time=   1.7s\n",
      "[CV 4/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   2.1s\n",
      "[CV 1/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.735) f1: (train=0.779, test=0.778) total time=   4.1s\n",
      "[CV 3/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.872, test=0.870) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.790, test=0.786) total time=   5.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.872, test=0.870) balanced_accuracy: (train=0.747, test=0.742) f1: (train=0.790, test=0.785) total time=   8.3s\n",
      "[CV 1/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.872, test=0.870) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.790, test=0.785) total time=  16.6s\n",
      "[CV 4/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.872, test=0.870) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.789, test=0.785) total time=  15.8s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.777) total time=   1.4s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   1.3s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   2.1s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.778) total time=   4.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.782) total time=   5.2s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.744, test=0.740) f1: (train=0.787, test=0.783) total time=   8.5s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.783) total time=   8.6s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.744, test=0.740) f1: (train=0.786, test=0.783) total time=  17.5s\n",
      "[CV 3/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   2.4s\n",
      "[CV 3/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   4.2s\n",
      "[CV 2/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.864) balanced_accuracy: (train=0.735, test=0.729) f1: (train=0.778, test=0.771) total time=   1.2s\n",
      "[CV 2/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.736, test=0.729) f1: (train=0.779, test=0.772) total time=   1.3s\n",
      "[CV 5/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.866, test=0.869) balanced_accuracy: (train=0.732, test=0.741) f1: (train=0.775, test=0.784) total time=   1.3s\n",
      "[CV 2/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.780, test=0.772) total time=   2.1s\n",
      "[CV 4/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   4.3s\n",
      "[CV 4/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.741) f1: (train=0.786, test=0.783) total time=   5.5s\n",
      "[CV 4/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.783) total time=   5.9s\n",
      "[CV 2/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.787, test=0.779) total time=  10.2s\n",
      "[CV 4/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.783) total time=  15.8s\n",
      "[CV 3/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.779, test=0.776) total time=   1.5s\n",
      "[CV 5/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.866, test=0.869) balanced_accuracy: (train=0.732, test=0.741) f1: (train=0.775, test=0.784) total time=   1.5s\n",
      "[CV 2/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.737, test=0.731) f1: (train=0.780, test=0.773) total time=   2.1s\n",
      "[CV 5/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.866, test=0.871) balanced_accuracy: (train=0.733, test=0.742) f1: (train=0.776, test=0.786) total time=   2.3s\n",
      "[CV 4/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   4.6s\n",
      "[CV 2/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.736, test=0.729) f1: (train=0.779, test=0.772) total time=   1.4s\n",
      "[CV 5/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.866, test=0.869) balanced_accuracy: (train=0.732, test=0.741) f1: (train=0.775, test=0.784) total time=   1.4s\n",
      "[CV 2/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.780, test=0.772) total time=   2.2s\n",
      "[CV 4/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   4.1s\n",
      "[CV 1/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.744, test=0.741) f1: (train=0.787, test=0.783) total time=   5.4s\n",
      "[CV 2/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.744, test=0.736) f1: (train=0.787, test=0.779) total time=   9.2s\n",
      "[CV 5/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.870, test=0.874) balanced_accuracy: (train=0.742, test=0.751) f1: (train=0.785, test=0.794) total time=   9.4s\n",
      "[CV 2/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.787, test=0.778) total time=  18.5s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.733, test=0.743) f1: (train=0.777, test=0.786) total time=   2.1s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   4.2s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.777) total time=   1.3s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.864) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.779, test=0.772) total time=   1.3s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.779, test=0.776) total time=   1.9s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   4.1s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.745, test=0.741) f1: (train=0.788, test=0.783) total time=   5.4s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.785, test=0.782) total time=   3.5s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.783) total time=   8.1s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.870, test=0.874) balanced_accuracy: (train=0.741, test=0.751) f1: (train=0.784, test=0.794) total time=  14.8s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.783) total time=  12.6s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.866, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.786) total time=   4.2s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.737, test=0.731) f1: (train=0.780, test=0.773) total time=   1.4s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.735) f1: (train=0.779, test=0.778) total time=   2.2s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.776, test=0.786) total time=   4.1s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.745, test=0.741) f1: (train=0.787, test=0.783) total time=   5.6s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.785, test=0.782) total time=   5.8s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.744, test=0.741) f1: (train=0.787, test=0.783) total time=   8.6s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.785, test=0.782) total time=  18.8s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.737, test=0.731) f1: (train=0.780, test=0.773) total time=   1.4s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   2.2s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   2.4s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.776, test=0.786) total time=   4.2s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.778, test=0.776) total time=   1.3s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   1.5s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.779, test=0.776) total time=   2.0s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.866, test=0.871) balanced_accuracy: (train=0.733, test=0.742) f1: (train=0.776, test=0.786) total time=   2.2s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.780, test=0.773) total time=   4.0s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.785, test=0.782) total time=   5.9s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.870, test=0.874) balanced_accuracy: (train=0.742, test=0.751) f1: (train=0.785, test=0.794) total time=   9.8s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.744, test=0.736) f1: (train=0.787, test=0.779) total time=  19.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.780, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.786) total time=   1.3s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.786) total time=   1.4s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   2.1s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.737, test=0.731) f1: (train=0.780, test=0.773) total time=   2.0s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.780, test=0.772) total time=   4.2s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.737, test=0.730) f1: (train=0.780, test=0.773) total time=   4.1s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.735) f1: (train=0.779, test=0.778) total time=   2.1s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.733, test=0.743) f1: (train=0.776, test=0.786) total time=   4.2s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.744, test=0.736) f1: (train=0.787, test=0.778) total time=   5.4s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.871, test=0.870) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.783) total time=   5.4s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.744, test=0.740) f1: (train=0.786, test=0.783) total time=   8.4s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.783) total time=  13.3s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.778, test=0.776) total time=   1.5s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.778, test=0.776) total time=   1.2s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.866, test=0.870) balanced_accuracy: (train=0.733, test=0.742) f1: (train=0.776, test=0.785) total time=   1.6s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.779, test=0.773) total time=   2.3s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.866, test=0.870) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.785) total time=   2.2s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   4.2s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.778, test=0.776) total time=   1.5s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.777) total time=   1.6s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.776) total time=   2.2s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.779, test=0.776) total time=   2.1s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.866, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.786) total time=   4.3s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.872, test=0.867) balanced_accuracy: (train=0.745, test=0.737) f1: (train=0.788, test=0.779) total time=   5.7s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.745, test=0.741) f1: (train=0.787, test=0.784) total time=   8.9s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.785, test=0.783) total time=  15.2s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.741) f1: (train=0.786, test=0.783) total time=  13.6s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.778) total time=   4.4s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.732) f1: (train=0.779, test=0.775) total time=   1.3s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.776) total time=   1.3s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.866, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.776, test=0.787) total time=   2.1s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.780, test=0.773) total time=   4.3s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.779, test=0.777) total time=   4.9s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.870, test=0.875) balanced_accuracy: (train=0.742, test=0.752) f1: (train=0.785, test=0.795) total time=   5.6s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.787, test=0.779) total time=   8.6s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.870, test=0.874) balanced_accuracy: (train=0.742, test=0.750) f1: (train=0.785, test=0.793) total time=  19.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.865, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.780, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.778) total time=   3.9s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.863) balanced_accuracy: (train=0.736, test=0.729) f1: (train=0.778, test=0.771) total time=   1.4s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.732) f1: (train=0.779, test=0.775) total time=   1.2s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   1.4s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   2.0s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.737, test=0.730) f1: (train=0.780, test=0.773) total time=   4.1s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.870, test=0.875) balanced_accuracy: (train=0.741, test=0.751) f1: (train=0.784, test=0.794) total time=   5.3s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.785, test=0.782) total time=   8.6s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.783) total time=   7.3s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.870, test=0.874) balanced_accuracy: (train=0.741, test=0.750) f1: (train=0.784, test=0.793) total time=  12.6s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.736, test=0.729) f1: (train=0.779, test=0.772) total time=   1.0s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.737, test=0.731) f1: (train=0.780, test=0.773) total time=   1.5s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.779, test=0.776) total time=   2.3s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.866, test=0.871) balanced_accuracy: (train=0.733, test=0.742) f1: (train=0.776, test=0.786) total time=   2.2s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.778) total time=   4.1s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.864) balanced_accuracy: (train=0.735, test=0.729) f1: (train=0.778, test=0.771) total time=   1.3s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.779, test=0.776) total time=   1.4s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.779, test=0.773) total time=   2.2s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.779, test=0.777) total time=   2.2s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   4.3s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.783) total time=   5.1s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.870, test=0.874) balanced_accuracy: (train=0.742, test=0.751) f1: (train=0.785, test=0.794) total time=   8.9s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.744, test=0.736) f1: (train=0.787, test=0.779) total time=  18.8s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.864) balanced_accuracy: (train=0.735, test=0.729) f1: (train=0.778, test=0.771) total time=   1.3s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.778, test=0.776) total time=   1.3s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.736, test=0.729) f1: (train=0.779, test=0.772) total time=   1.5s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.866, test=0.869) balanced_accuracy: (train=0.732, test=0.741) f1: (train=0.775, test=0.784) total time=   1.3s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.735) f1: (train=0.779, test=0.778) total time=   2.2s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.779, test=0.777) total time=   2.3s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.866, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.786) total time=   4.0s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.866, test=0.871) balanced_accuracy: (train=0.733, test=0.742) f1: (train=0.776, test=0.785) total time=   1.2s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.776) total time=   1.3s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   2.2s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   4.3s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.741) f1: (train=0.786, test=0.783) total time=   4.6s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.785, test=0.782) total time=   5.4s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.783) total time=   9.8s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.744, test=0.741) f1: (train=0.787, test=0.784) total time=  19.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.869, test=0.864) balanced_accuracy: (train=0.739, test=0.731) f1: (train=0.782, test=0.773) total time=   1.2s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   2.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.737, test=0.730) f1: (train=0.780, test=0.773) total time=   3.5s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.786) total time=   4.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.737, test=0.735) f1: (train=0.780, test=0.778) total time=   2.1s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.735) f1: (train=0.780, test=0.778) total time=   4.2s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.872, test=0.870) balanced_accuracy: (train=0.746, test=0.743) f1: (train=0.789, test=0.785) total time=   5.2s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.872, test=0.870) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.790, test=0.786) total time=   8.4s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.746, test=0.741) f1: (train=0.789, test=0.783) total time=  13.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.746, test=0.741) f1: (train=0.789, test=0.784) total time=  12.6s\n",
      "[CV 1/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.735) f1: (train=0.779, test=0.778) total time=   3.9s\n",
      "[CV 5/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.786) total time=   1.3s\n",
      "[CV 3/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.737, test=0.734) f1: (train=0.780, test=0.777) total time=   1.2s\n",
      "[CV 2/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.737, test=0.730) f1: (train=0.780, test=0.773) total time=   1.9s\n",
      "[CV 2/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.780, test=0.773) total time=   4.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.871, test=0.875) balanced_accuracy: (train=0.745, test=0.754) f1: (train=0.788, test=0.796) total time=   5.2s\n",
      "[CV 3/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.873, test=0.870) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.790, test=0.786) total time=   8.5s\n",
      "[CV 4/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.872, test=0.870) balanced_accuracy: (train=0.746, test=0.743) f1: (train=0.789, test=0.785) total time=   8.2s\n",
      "[CV 1/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.873, test=0.870) balanced_accuracy: (train=0.748, test=0.743) f1: (train=0.790, test=0.786) total time=  16.3s\n",
      "[CV 4/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.737, test=0.734) f1: (train=0.780, test=0.777) total time=   2.1s\n",
      "[CV 3/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.735, test=0.732) f1: (train=0.779, test=0.775) total time=   4.2s\n",
      "[CV 4/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.780, test=0.776) total time=   3.8s\n",
      "[CV 2/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.737, test=0.730) f1: (train=0.780, test=0.773) total time=   1.9s\n",
      "[CV 2/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.737, test=0.730) f1: (train=0.780, test=0.773) total time=   4.1s\n",
      "[CV 4/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.780, test=0.776) total time=   4.4s\n",
      "[CV 2/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.873, test=0.868) balanced_accuracy: (train=0.747, test=0.739) f1: (train=0.791, test=0.781) total time=   5.3s\n",
      "[CV 5/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.871, test=0.875) balanced_accuracy: (train=0.745, test=0.753) f1: (train=0.788, test=0.796) total time=   8.4s\n",
      "[CV 3/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.873, test=0.870) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.790, test=0.785) total time=  16.5s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.732) f1: (train=0.779, test=0.775) total time=   1.4s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   1.3s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.737, test=0.731) f1: (train=0.780, test=0.773) total time=   2.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.778) total time=   4.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   4.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.864) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.779, test=0.772) total time=   1.3s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.779, test=0.776) total time=   1.9s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.733, test=0.743) f1: (train=0.776, test=0.786) total time=   4.1s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.745, test=0.741) f1: (train=0.788, test=0.783) total time=   5.3s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.871, test=0.870) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.783) total time=   4.9s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.870, test=0.874) balanced_accuracy: (train=0.741, test=0.750) f1: (train=0.784, test=0.793) total time=   7.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.744, test=0.740) f1: (train=0.787, test=0.783) total time=  16.8s\n",
      "[CV 3/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.732) f1: (train=0.779, test=0.775) total time=   1.4s\n",
      "[CV 4/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   1.6s\n",
      "[CV 1/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.776) total time=   2.2s\n",
      "[CV 4/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   2.5s\n",
      "[CV 4/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.779, test=0.776) total time=   3.1s\n",
      "[CV 3/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.777) total time=   3.6s\n",
      "[CV 4/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.779, test=0.776) total time=   2.4s\n",
      "[CV 1/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   4.3s\n",
      "[CV 4/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.779, test=0.777) total time=   4.5s\n",
      "[CV 2/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.872, test=0.867) balanced_accuracy: (train=0.744, test=0.736) f1: (train=0.787, test=0.779) total time=   5.3s\n",
      "[CV 4/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.783) total time=  10.2s\n",
      "[CV 1/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.744, test=0.741) f1: (train=0.787, test=0.784) total time=  18.1s\n",
      "[CV 1/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.777) total time=   1.6s\n",
      "[CV 3/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.776) total time=   1.4s\n",
      "[CV 5/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.866, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.776, test=0.787) total time=   2.1s\n",
      "[CV 4/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.779, test=0.777) total time=   2.1s\n",
      "[CV 2/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.780, test=0.773) total time=   4.7s\n",
      "[CV 5/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.866, test=0.871) balanced_accuracy: (train=0.733, test=0.742) f1: (train=0.776, test=0.785) total time=   1.6s\n",
      "[CV 3/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.776) total time=   1.5s\n",
      "[CV 4/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   2.2s\n",
      "[CV 3/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   4.3s\n",
      "[CV 5/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.870, test=0.874) balanced_accuracy: (train=0.741, test=0.750) f1: (train=0.784, test=0.793) total time=   5.4s\n",
      "[CV 1/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.744, test=0.740) f1: (train=0.786, test=0.783) total time=   9.2s\n",
      "[CV 3/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.785, test=0.783) total time=   9.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.870, test=0.874) balanced_accuracy: (train=0.742, test=0.751) f1: (train=0.785, test=0.794) total time=  18.8s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.777) total time=   2.1s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.737, test=0.730) f1: (train=0.780, test=0.773) total time=   3.9s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.732) f1: (train=0.779, test=0.775) total time=   1.2s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   1.3s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.737, test=0.730) f1: (train=0.780, test=0.772) total time=   2.1s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.733, test=0.743) f1: (train=0.777, test=0.786) total time=   2.1s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.737, test=0.730) f1: (train=0.780, test=0.773) total time=   4.4s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.783) total time=   5.5s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.744, test=0.741) f1: (train=0.787, test=0.784) total time=   8.2s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.785, test=0.782) total time=  12.7s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.785, test=0.782) total time=  16.8s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.780, test=0.773) total time=   4.3s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.866, test=0.869) balanced_accuracy: (train=0.732, test=0.741) f1: (train=0.775, test=0.784) total time=   1.4s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.780, test=0.772) total time=   2.1s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   3.9s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.744, test=0.741) f1: (train=0.787, test=0.783) total time=   5.6s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.785, test=0.782) total time=   9.0s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.744, test=0.741) f1: (train=0.787, test=0.783) total time=  12.3s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.785, test=0.782) total time=  15.9s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   4.3s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.777) total time=   4.2s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.735) f1: (train=0.779, test=0.778) total time=   2.1s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   4.2s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.733, test=0.743) f1: (train=0.777, test=0.786) total time=   4.6s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.872, test=0.867) balanced_accuracy: (train=0.744, test=0.736) f1: (train=0.787, test=0.779) total time=   5.4s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.786, test=0.783) total time=  10.1s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.872, test=0.867) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.787, test=0.779) total time=  18.7s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.865, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.780, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.735, test=0.732) f1: (train=0.779, test=0.775) total time=   1.3s\n",
      "[CV 2/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.737, test=0.731) f1: (train=0.780, test=0.773) total time=   1.8s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.779, test=0.776) total time=   1.9s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.744) f1: (train=0.777, test=0.787) total time=   4.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.735, test=0.732) f1: (train=0.779, test=0.775) total time=   1.2s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.732) f1: (train=0.779, test=0.775) total time=   2.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.866, test=0.871) balanced_accuracy: (train=0.733, test=0.742) f1: (train=0.776, test=0.786) total time=   1.8s\n",
      "[CV 2/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.738, test=0.730) f1: (train=0.781, test=0.773) total time=   3.9s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.789, test=0.784) total time=   4.7s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.746, test=0.741) f1: (train=0.789, test=0.784) total time=   8.3s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.872, test=0.870) balanced_accuracy: (train=0.747, test=0.742) f1: (train=0.790, test=0.785) total time=  16.3s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.871, test=0.875) balanced_accuracy: (train=0.745, test=0.753) f1: (train=0.787, test=0.796) total time=  12.6s\n",
      "[CV 2/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.737, test=0.731) f1: (train=0.780, test=0.773) total time=   3.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.787) total time=   1.3s\n",
      "[CV 4/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.780, test=0.777) total time=   1.9s\n",
      "[CV 1/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.735) f1: (train=0.779, test=0.778) total time=   3.9s\n",
      "[CV 3/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   4.1s\n",
      "[CV 5/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.871, test=0.875) balanced_accuracy: (train=0.746, test=0.753) f1: (train=0.788, test=0.796) total time=   4.9s\n",
      "[CV 2/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.873, test=0.868) balanced_accuracy: (train=0.747, test=0.739) f1: (train=0.790, test=0.781) total time=   8.4s\n",
      "[CV 1/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.873, test=0.870) balanced_accuracy: (train=0.748, test=0.744) f1: (train=0.791, test=0.786) total time=  13.8s\n",
      "[CV 4/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.872, test=0.870) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.789, test=0.785) total time=  12.6s\n",
      "[CV 5/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.787) total time=   4.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.737, test=0.734) f1: (train=0.780, test=0.777) total time=   1.2s\n",
      "[CV 5/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.787) total time=   2.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.737, test=0.735) f1: (train=0.780, test=0.777) total time=   4.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.873, test=0.870) balanced_accuracy: (train=0.747, test=0.744) f1: (train=0.790, test=0.786) total time=   5.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.872, test=0.870) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.790, test=0.785) total time=   9.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.872, test=0.870) balanced_accuracy: (train=0.746, test=0.743) f1: (train=0.789, test=0.785) total time=   8.4s\n",
      "[CV 2/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.872, test=0.867) balanced_accuracy: (train=0.746, test=0.738) f1: (train=0.790, test=0.781) total time=  14.4s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.735) f1: (train=0.779, test=0.778) total time=   2.1s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.733, test=0.743) f1: (train=0.777, test=0.786) total time=   2.1s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.786) total time=   4.1s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.786) total time=   1.2s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.735, test=0.735) f1: (train=0.778, test=0.778) total time=   1.4s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.786) total time=   1.9s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.780, test=0.772) total time=   4.1s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   4.2s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.744, test=0.741) f1: (train=0.787, test=0.783) total time=   4.8s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.787, test=0.779) total time=   8.2s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.783) total time=  16.7s\n",
      "[CV 1/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.778, test=0.776) total time=   1.4s\n",
      "[CV 1/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.777) total time=   1.5s\n",
      "[CV 2/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.737, test=0.731) f1: (train=0.780, test=0.773) total time=   1.5s\n",
      "[CV 4/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.779, test=0.776) total time=   2.5s\n",
      "[CV 3/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.779, test=0.776) total time=   2.4s\n",
      "[CV 2/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.780, test=0.773) total time=   4.6s\n",
      "[CV 5/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.866, test=0.871) balanced_accuracy: (train=0.733, test=0.742) f1: (train=0.776, test=0.785) total time=   1.4s\n",
      "[CV 4/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.778, test=0.775) total time=   1.4s\n",
      "[CV 5/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.866, test=0.870) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.785) total time=   2.1s\n",
      "[CV 2/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.780, test=0.773) total time=   4.4s\n",
      "[CV 1/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.744, test=0.741) f1: (train=0.787, test=0.783) total time=   5.5s\n",
      "[CV 2/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.744, test=0.736) f1: (train=0.787, test=0.779) total time=   8.3s\n",
      "[CV 3/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.785, test=0.783) total time=   9.5s\n",
      "[CV 1/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.744, test=0.741) f1: (train=0.787, test=0.784) total time=  18.6s\n",
      "[CV 5/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.866, test=0.870) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.785) total time=   2.4s\n",
      "[CV 3/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   3.7s\n",
      "[CV 5/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.733, test=0.743) f1: (train=0.777, test=0.786) total time=   3.3s\n",
      "[CV 3/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   2.1s\n",
      "[CV 5/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.866, test=0.871) balanced_accuracy: (train=0.733, test=0.742) f1: (train=0.776, test=0.786) total time=   2.2s\n",
      "[CV 2/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.780, test=0.773) total time=   4.2s\n",
      "[CV 3/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.785, test=0.782) total time=   5.6s\n",
      "[CV 1/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.745, test=0.741) f1: (train=0.787, test=0.784) total time=   9.1s\n",
      "[CV 3/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.785, test=0.783) total time=  15.1s\n",
      "[CV 4/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.741) f1: (train=0.786, test=0.783) total time=  16.7s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   4.0s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.737, test=0.731) f1: (train=0.780, test=0.773) total time=   2.0s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   4.0s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   4.3s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.744, test=0.741) f1: (train=0.787, test=0.783) total time=   5.2s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.871, test=0.870) balanced_accuracy: (train=0.743, test=0.741) f1: (train=0.786, test=0.784) total time=   7.9s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.744, test=0.740) f1: (train=0.787, test=0.783) total time=  18.2s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   1.5s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.776) total time=   2.3s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   2.3s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.780, test=0.773) total time=   4.0s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.777) total time=   4.2s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.866, test=0.870) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.785) total time=   2.2s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.780, test=0.773) total time=   4.2s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.787, test=0.779) total time=   5.8s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.744, test=0.740) f1: (train=0.786, test=0.783) total time=   9.1s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.741) f1: (train=0.786, test=0.783) total time=   9.5s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.744, test=0.741) f1: (train=0.787, test=0.784) total time=  18.4s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.779, test=0.776) total time=   2.4s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   4.2s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.778, test=0.776) total time=   1.3s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.737, test=0.731) f1: (train=0.780, test=0.773) total time=   1.4s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.737, test=0.731) f1: (train=0.780, test=0.773) total time=   2.1s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.779, test=0.776) total time=   4.1s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.745, test=0.741) f1: (train=0.787, test=0.783) total time=   6.2s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.744, test=0.740) f1: (train=0.786, test=0.783) total time=  10.0s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.741) f1: (train=0.786, test=0.783) total time=   6.7s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.870, test=0.874) balanced_accuracy: (train=0.742, test=0.751) f1: (train=0.785, test=0.794) total time=  17.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.865, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.732) f1: (train=0.779, test=0.775) total time=   1.3s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.735) f1: (train=0.779, test=0.778) total time=   2.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.735, test=0.732) f1: (train=0.779, test=0.775) total time=   2.8s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   3.6s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.735) f1: (train=0.779, test=0.778) total time=   1.9s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.779, test=0.776) total time=   2.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.744) f1: (train=0.777, test=0.787) total time=   4.1s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.872, test=0.870) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.790, test=0.785) total time=   4.7s\n",
      "[CV 2/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.872, test=0.868) balanced_accuracy: (train=0.747, test=0.739) f1: (train=0.790, test=0.781) total time=   7.1s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.872, test=0.870) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.789, test=0.784) total time=   8.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.747, test=0.742) f1: (train=0.790, test=0.785) total time=  16.1s\n",
      "[CV 2/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.737, test=0.730) f1: (train=0.780, test=0.773) total time=   2.3s\n",
      "[CV 1/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.735) f1: (train=0.779, test=0.778) total time=   4.3s\n",
      "[CV 5/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.786) total time=   3.7s\n",
      "[CV 4/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.737, test=0.734) f1: (train=0.780, test=0.777) total time=   2.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.733, test=0.743) f1: (train=0.777, test=0.786) total time=   4.1s\n",
      "[CV 2/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.873, test=0.868) balanced_accuracy: (train=0.747, test=0.739) f1: (train=0.791, test=0.781) total time=   5.2s\n",
      "[CV 5/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.871, test=0.875) balanced_accuracy: (train=0.745, test=0.753) f1: (train=0.788, test=0.796) total time=   5.4s\n",
      "[CV 2/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.873, test=0.867) balanced_accuracy: (train=0.747, test=0.738) f1: (train=0.790, test=0.780) total time=   8.7s\n",
      "[CV 4/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.873, test=0.869) balanced_accuracy: (train=0.747, test=0.742) f1: (train=0.790, test=0.784) total time=  17.6s\n",
      "[CV 2/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.737, test=0.730) f1: (train=0.780, test=0.773) total time=   2.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   2.3s\n",
      "[CV 3/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   4.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   1.2s\n",
      "[CV 3/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.732) f1: (train=0.779, test=0.775) total time=   1.2s\n",
      "[CV 2/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.737, test=0.731) f1: (train=0.780, test=0.774) total time=   2.1s\n",
      "[CV 5/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.866, test=0.871) balanced_accuracy: (train=0.733, test=0.742) f1: (train=0.776, test=0.785) total time=   2.2s\n",
      "[CV 2/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.737, test=0.731) f1: (train=0.780, test=0.773) total time=   4.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.872, test=0.870) balanced_accuracy: (train=0.747, test=0.742) f1: (train=0.790, test=0.785) total time=   5.1s\n",
      "[CV 5/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.871, test=0.875) balanced_accuracy: (train=0.744, test=0.753) f1: (train=0.787, test=0.795) total time=   8.6s\n",
      "[CV 2/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.873, test=0.868) balanced_accuracy: (train=0.747, test=0.739) f1: (train=0.790, test=0.781) total time=  16.4s\n",
      "[CV 5/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.872, test=0.875) balanced_accuracy: (train=0.746, test=0.754) f1: (train=0.788, test=0.796) total time=  16.1s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.732) f1: (train=0.779, test=0.775) total time=   1.3s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.737, test=0.730) f1: (train=0.780, test=0.772) total time=   2.1s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.777) total time=   2.2s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   4.1s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.745, test=0.737) f1: (train=0.788, test=0.779) total time=   5.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.783) total time=   8.5s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.744, test=0.740) f1: (train=0.787, test=0.783) total time=  16.9s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.783) total time=  11.7s\n",
      "[CV 4/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   4.2s\n",
      "[CV 4/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.778, test=0.776) total time=   1.4s\n",
      "[CV 2/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.737, test=0.731) f1: (train=0.780, test=0.773) total time=   1.2s\n",
      "[CV 2/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.737, test=0.731) f1: (train=0.780, test=0.773) total time=   2.2s\n",
      "[CV 3/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   4.1s\n",
      "[CV 3/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.777) total time=   4.4s\n",
      "[CV 5/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.870, test=0.874) balanced_accuracy: (train=0.742, test=0.752) f1: (train=0.785, test=0.794) total time=   5.2s\n",
      "[CV 3/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.786, test=0.783) total time=   6.8s\n",
      "[CV 4/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.787, test=0.783) total time=  17.6s\n",
      "[CV 1/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.778, test=0.776) total time=   1.4s\n",
      "[CV 2/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.864) balanced_accuracy: (train=0.735, test=0.729) f1: (train=0.778, test=0.771) total time=   1.4s\n",
      "[CV 5/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.866, test=0.871) balanced_accuracy: (train=0.733, test=0.742) f1: (train=0.776, test=0.785) total time=   1.4s\n",
      "[CV 1/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.776) total time=   1.4s\n",
      "[CV 3/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   2.2s\n",
      "[CV 1/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.778, test=0.776) total time=   2.5s\n",
      "[CV 1/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.778) total time=   4.6s\n",
      "[CV 4/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.778, test=0.776) total time=   1.5s\n",
      "[CV 2/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.737, test=0.731) f1: (train=0.780, test=0.773) total time=   1.3s\n",
      "[CV 3/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   2.2s\n",
      "[CV 5/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.776, test=0.786) total time=   4.2s\n",
      "[CV 2/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.787, test=0.779) total time=   5.5s\n",
      "[CV 3/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.785, test=0.782) total time=   5.8s\n",
      "[CV 1/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.744, test=0.741) f1: (train=0.787, test=0.783) total time=   9.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.785, test=0.782) total time=  18.4s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.737, test=0.730) f1: (train=0.780, test=0.772) total time=   2.2s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.779, test=0.776) total time=   2.0s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.778) total time=   4.0s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   4.0s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   2.0s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   2.1s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.786) total time=   4.2s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.745, test=0.737) f1: (train=0.788, test=0.779) total time=   5.3s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.783) total time=   8.2s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.744, test=0.740) f1: (train=0.787, test=0.783) total time=  18.2s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.864) balanced_accuracy: (train=0.735, test=0.729) f1: (train=0.778, test=0.771) total time=   1.2s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.777) total time=   1.7s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.776) total time=   1.5s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.735) f1: (train=0.779, test=0.778) total time=   2.2s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.779, test=0.777) total time=   2.5s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   4.1s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.778, test=0.776) total time=   1.4s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.866, test=0.870) balanced_accuracy: (train=0.733, test=0.742) f1: (train=0.776, test=0.785) total time=   1.3s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.779, test=0.776) total time=   2.1s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.866, test=0.871) balanced_accuracy: (train=0.733, test=0.742) f1: (train=0.776, test=0.786) total time=   2.4s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.780, test=0.773) total time=   3.9s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.785, test=0.782) total time=   5.2s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.741) f1: (train=0.786, test=0.784) total time=   7.1s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.785, test=0.783) total time=   9.3s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.870, test=0.874) balanced_accuracy: (train=0.742, test=0.751) f1: (train=0.785, test=0.794) total time=  18.6s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   2.5s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   4.2s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.733, test=0.743) f1: (train=0.777, test=0.786) total time=   4.0s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.780, test=0.772) total time=   2.0s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   4.2s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.744, test=0.741) f1: (train=0.787, test=0.783) total time=   6.0s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.785, test=0.782) total time=   9.8s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.870, test=0.874) balanced_accuracy: (train=0.742, test=0.751) f1: (train=0.785, test=0.794) total time=   8.5s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.787, test=0.778) total time=  15.7s\n",
      "[CV 4/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.741) f1: (train=0.786, test=0.783) total time=   5.8s\n",
      "[CV 3/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.785, test=0.782) total time=   9.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.741) f1: (train=0.786, test=0.783) total time=   9.1s\n",
      "[CV 1/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.744, test=0.741) f1: (train=0.787, test=0.784) total time=  18.6s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   2.4s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   3.9s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.786) total time=   1.2s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.786) total time=   1.2s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.779, test=0.776) total time=   2.0s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.777) total time=   2.1s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   4.2s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.739) f1: (train=0.786, test=0.782) total time=   5.5s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.870, test=0.874) balanced_accuracy: (train=0.741, test=0.751) f1: (train=0.784, test=0.794) total time=   8.0s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.787, test=0.778) total time=  18.1s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.732) f1: (train=0.779, test=0.775) total time=   1.3s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.779, test=0.776) total time=   1.4s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.778, test=0.775) total time=   1.4s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.866, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.776, test=0.787) total time=   2.1s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.778, test=0.776) total time=   2.3s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   4.3s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.732) f1: (train=0.779, test=0.775) total time=   1.4s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   1.4s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   2.4s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   4.1s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.777) total time=   4.3s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.870, test=0.874) balanced_accuracy: (train=0.742, test=0.752) f1: (train=0.785, test=0.794) total time=   5.6s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.872, test=0.867) balanced_accuracy: (train=0.745, test=0.737) f1: (train=0.788, test=0.779) total time=   8.6s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.787, test=0.783) total time=  18.5s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.777) total time=   1.5s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.776) total time=   1.5s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.779, test=0.773) total time=   2.2s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.866, test=0.870) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.785) total time=   2.3s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.780, test=0.773) total time=   4.3s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.777) total time=   1.3s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.778, test=0.775) total time=   1.3s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   2.1s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.776, test=0.786) total time=   4.2s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.786, test=0.783) total time=   6.2s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.744, test=0.736) f1: (train=0.787, test=0.779) total time=   8.5s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.785, test=0.783) total time=  10.2s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.744, test=0.741) f1: (train=0.787, test=0.784) total time=  16.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.780, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.737, test=0.736) f1: (train=0.780, test=0.778) total time=   1.3s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.732) f1: (train=0.779, test=0.775) total time=   1.9s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.735) f1: (train=0.779, test=0.778) total time=   4.2s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.737, test=0.734) f1: (train=0.780, test=0.777) total time=   1.1s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.779, test=0.778) total time=   1.1s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.866, test=0.870) balanced_accuracy: (train=0.732, test=0.741) f1: (train=0.775, test=0.785) total time=   1.2s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.737, test=0.734) f1: (train=0.780, test=0.777) total time=   1.8s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.786) total time=   3.8s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.872, test=0.870) balanced_accuracy: (train=0.748, test=0.743) f1: (train=0.790, test=0.785) total time=   5.1s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.871, test=0.875) balanced_accuracy: (train=0.744, test=0.753) f1: (train=0.787, test=0.796) total time=   4.8s\n",
      "[CV 2/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.872, test=0.867) balanced_accuracy: (train=0.746, test=0.738) f1: (train=0.789, test=0.780) total time=   8.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.746, test=0.741) f1: (train=0.789, test=0.784) total time=  15.5s\n",
      "[CV 3/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.732) f1: (train=0.779, test=0.775) total time=   1.1s\n",
      "[CV 4/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.737, test=0.735) f1: (train=0.779, test=0.778) total time=   1.3s\n",
      "[CV 1/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.737, test=0.734) f1: (train=0.779, test=0.777) total time=   1.9s\n",
      "[CV 5/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.866, test=0.871) balanced_accuracy: (train=0.733, test=0.742) f1: (train=0.776, test=0.785) total time=   2.2s\n",
      "[CV 3/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   4.1s\n",
      "[CV 4/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   1.2s\n",
      "[CV 1/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   1.3s\n",
      "[CV 5/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.787) total time=   2.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.737, test=0.730) f1: (train=0.780, test=0.773) total time=   4.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.780, test=0.776) total time=   4.4s\n",
      "[CV 1/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.873, test=0.869) balanced_accuracy: (train=0.748, test=0.742) f1: (train=0.791, test=0.784) total time=   4.9s\n",
      "[CV 3/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.873, test=0.870) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.790, test=0.785) total time=   6.7s\n",
      "[CV 4/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.872, test=0.870) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.789, test=0.784) total time=  13.8s\n",
      "[CV 3/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.872, test=0.870) balanced_accuracy: (train=0.746, test=0.743) f1: (train=0.789, test=0.785) total time=  16.4s\n",
      "[CV 1/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   1.2s\n",
      "[CV 5/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.787) total time=   1.2s\n",
      "[CV 5/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.787) total time=   2.1s\n",
      "[CV 3/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.735, test=0.732) f1: (train=0.779, test=0.775) total time=   3.9s\n",
      "[CV 5/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.786) total time=   4.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.873, test=0.869) balanced_accuracy: (train=0.748, test=0.742) f1: (train=0.791, test=0.784) total time=   3.8s\n",
      "[CV 3/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.873, test=0.870) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.790, test=0.785) total time=   8.2s\n",
      "[CV 1/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.873, test=0.870) balanced_accuracy: (train=0.748, test=0.744) f1: (train=0.791, test=0.786) total time=  16.5s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   1.2s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.737, test=0.730) f1: (train=0.780, test=0.772) total time=   1.3s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   1.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   2.3s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.777) total time=   2.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   4.2s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.732) f1: (train=0.779, test=0.775) total time=   1.3s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.786) total time=   1.1s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   2.1s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.733, test=0.743) f1: (train=0.777, test=0.786) total time=   2.1s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.737, test=0.730) f1: (train=0.780, test=0.773) total time=   4.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.739) f1: (train=0.786, test=0.782) total time=   5.2s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.870, test=0.874) balanced_accuracy: (train=0.741, test=0.751) f1: (train=0.784, test=0.794) total time=   8.4s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.787, test=0.778) total time=  12.8s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.785, test=0.782) total time=  13.5s\n",
      "[CV 2/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.780, test=0.773) total time=   4.5s\n",
      "[CV 4/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.779, test=0.777) total time=   4.2s\n",
      "[CV 3/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   2.1s\n",
      "[CV 5/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.776, test=0.786) total time=   4.3s\n",
      "[CV 2/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.787, test=0.779) total time=   5.5s\n",
      "[CV 1/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.744, test=0.740) f1: (train=0.786, test=0.783) total time=   8.9s\n",
      "[CV 5/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.870, test=0.874) balanced_accuracy: (train=0.742, test=0.751) f1: (train=0.785, test=0.794) total time=   9.5s\n",
      "[CV 2/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.787, test=0.778) total time=  18.4s\n",
      "[CV 2/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.780, test=0.772) total time=   2.4s\n",
      "[CV 5/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.776, test=0.786) total time=   4.6s\n",
      "[CV 3/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.732) f1: (train=0.779, test=0.775) total time=   1.2s\n",
      "[CV 1/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.776) total time=   1.3s\n",
      "[CV 5/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.866, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.776, test=0.787) total time=   2.1s\n",
      "[CV 2/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.780, test=0.773) total time=   4.3s\n",
      "[CV 1/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.745, test=0.741) f1: (train=0.787, test=0.783) total time=   5.9s\n",
      "[CV 4/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.783) total time=   5.8s\n",
      "[CV 5/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.870, test=0.874) balanced_accuracy: (train=0.742, test=0.751) f1: (train=0.785, test=0.794) total time=   8.7s\n",
      "[CV 2/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.872, test=0.867) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.787, test=0.779) total time=  14.5s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   1.3s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.732) f1: (train=0.779, test=0.775) total time=   1.2s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.864) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.779, test=0.772) total time=   1.3s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.779, test=0.776) total time=   2.0s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   2.2s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   4.0s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   4.0s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.786) total time=   2.0s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.778) total time=   4.2s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.786) total time=   4.2s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.870, test=0.874) balanced_accuracy: (train=0.742, test=0.751) f1: (train=0.784, test=0.793) total time=   3.6s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.787, test=0.779) total time=   8.5s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.783) total time=  18.2s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.866, test=0.871) balanced_accuracy: (train=0.733, test=0.742) f1: (train=0.776, test=0.785) total time=   1.3s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.776) total time=   1.4s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   2.1s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   2.3s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.779, test=0.776) total time=   3.9s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.779, test=0.777) total time=   4.1s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   1.9s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   4.2s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.733, test=0.743) f1: (train=0.777, test=0.786) total time=   4.2s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.872, test=0.867) balanced_accuracy: (train=0.744, test=0.736) f1: (train=0.787, test=0.779) total time=   5.5s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.783) total time=   8.5s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.870, test=0.874) balanced_accuracy: (train=0.742, test=0.750) f1: (train=0.785, test=0.793) total time=  13.5s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.870, test=0.874) balanced_accuracy: (train=0.742, test=0.751) f1: (train=0.785, test=0.794) total time=  15.5s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.780, test=0.773) total time=   4.1s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.779, test=0.773) total time=   2.3s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.779, test=0.777) total time=   2.2s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   4.2s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.783) total time=   6.1s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.745, test=0.741) f1: (train=0.787, test=0.784) total time=  10.3s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.785, test=0.783) total time=  14.0s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.785, test=0.782) total time=   9.6s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.865, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 2/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.780, test=0.773) total time=   1.3s\n",
      "[CV 2/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.737, test=0.731) f1: (train=0.780, test=0.773) total time=   1.8s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.786) total time=   4.5s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.732) f1: (train=0.779, test=0.775) total time=   1.2s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   1.6s\n",
      "[CV 2/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.738, test=0.731) f1: (train=0.781, test=0.773) total time=   1.9s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.779, test=0.776) total time=   4.2s\n",
      "[CV 2/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.872, test=0.867) balanced_accuracy: (train=0.747, test=0.739) f1: (train=0.790, test=0.781) total time=   4.9s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.871, test=0.875) balanced_accuracy: (train=0.745, test=0.753) f1: (train=0.787, test=0.796) total time=   8.6s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.873, test=0.870) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.790, test=0.785) total time=  13.3s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.746, test=0.741) f1: (train=0.789, test=0.784) total time=  12.3s\n",
      "[CV 5/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.787) total time=   4.3s\n",
      "[CV 3/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.732) f1: (train=0.779, test=0.775) total time=   1.3s\n",
      "[CV 1/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   1.9s\n",
      "[CV 3/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.779, test=0.776) total time=   2.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.787) total time=   3.9s\n",
      "[CV 2/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.873, test=0.868) balanced_accuracy: (train=0.747, test=0.739) f1: (train=0.790, test=0.781) total time=   4.9s\n",
      "[CV 4/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.872, test=0.870) balanced_accuracy: (train=0.747, test=0.742) f1: (train=0.790, test=0.785) total time=   8.4s\n",
      "[CV 1/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.872, test=0.870) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.790, test=0.785) total time=  17.1s\n",
      "[CV 5/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.872, test=0.875) balanced_accuracy: (train=0.746, test=0.754) f1: (train=0.788, test=0.796) total time=  13.3s\n",
      "[CV 3/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   3.1s\n",
      "[CV 1/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   1.1s\n",
      "[CV 1/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.737, test=0.734) f1: (train=0.779, test=0.777) total time=   2.1s\n",
      "[CV 4/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   4.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.872, test=0.870) balanced_accuracy: (train=0.748, test=0.743) f1: (train=0.791, test=0.785) total time=   5.2s\n",
      "[CV 4/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.872, test=0.870) balanced_accuracy: (train=0.746, test=0.743) f1: (train=0.789, test=0.786) total time=   3.8s\n",
      "[CV 4/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.872, test=0.870) balanced_accuracy: (train=0.747, test=0.742) f1: (train=0.790, test=0.785) total time=   6.6s\n",
      "[CV 5/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.871, test=0.875) balanced_accuracy: (train=0.744, test=0.752) f1: (train=0.787, test=0.795) total time=  16.5s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.776) total time=   1.4s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.786) total time=   1.2s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.786) total time=   1.3s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   2.3s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.867, test=0.870) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.786) total time=   2.1s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   4.1s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   4.2s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.737, test=0.731) f1: (train=0.780, test=0.773) total time=   2.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   4.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.870, test=0.875) balanced_accuracy: (train=0.741, test=0.751) f1: (train=0.784, test=0.794) total time=   5.1s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.786, test=0.778) total time=   8.3s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.785, test=0.782) total time=   8.7s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.870, test=0.874) balanced_accuracy: (train=0.741, test=0.750) f1: (train=0.784, test=0.793) total time=  15.3s\n",
      "[CV 3/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   2.5s\n",
      "[CV 5/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.866, test=0.870) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.785) total time=   2.3s\n",
      "[CV 5/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.776, test=0.786) total time=   3.4s\n",
      "[CV 5/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.733, test=0.743) f1: (train=0.777, test=0.786) total time=   4.3s\n",
      "[CV 1/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.778, test=0.776) total time=   2.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   4.2s\n",
      "[CV 5/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.870, test=0.874) balanced_accuracy: (train=0.741, test=0.750) f1: (train=0.784, test=0.793) total time=   5.5s\n",
      "[CV 5/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.870, test=0.875) balanced_accuracy: (train=0.742, test=0.752) f1: (train=0.785, test=0.795) total time=   5.8s\n",
      "[CV 1/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.744, test=0.741) f1: (train=0.787, test=0.783) total time=   8.7s\n",
      "[CV 2/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.872, test=0.867) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.787, test=0.779) total time=  16.2s\n",
      "[CV 4/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.778, test=0.776) total time=   1.4s\n",
      "[CV 4/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   1.4s\n",
      "[CV 1/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.776) total time=   2.2s\n",
      "[CV 3/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   2.4s\n",
      "[CV 2/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.780, test=0.773) total time=   4.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.779, test=0.777) total time=   4.3s\n",
      "[CV 5/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.866, test=0.870) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.785) total time=   2.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.778) total time=   4.3s\n",
      "[CV 3/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.786, test=0.783) total time=   5.5s\n",
      "[CV 5/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.870, test=0.875) balanced_accuracy: (train=0.742, test=0.752) f1: (train=0.785, test=0.795) total time=   5.8s\n",
      "[CV 2/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.787, test=0.779) total time=   8.8s\n",
      "[CV 4/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.783) total time=  18.1s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   1.3s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   2.2s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.867, test=0.870) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.786) total time=   2.2s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   3.8s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.786) total time=   4.0s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.867, test=0.870) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.786) total time=   2.2s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   4.1s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.783) total time=   5.2s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.870, test=0.874) balanced_accuracy: (train=0.741, test=0.751) f1: (train=0.784, test=0.794) total time=   5.5s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.744, test=0.736) f1: (train=0.787, test=0.779) total time=   8.1s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.785, test=0.782) total time=  13.1s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.870, test=0.874) balanced_accuracy: (train=0.741, test=0.751) f1: (train=0.784, test=0.794) total time=  16.1s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.736, test=0.729) f1: (train=0.779, test=0.772) total time=   1.4s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.778, test=0.775) total time=   1.4s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.778, test=0.776) total time=   2.1s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   4.1s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.870, test=0.874) balanced_accuracy: (train=0.741, test=0.750) f1: (train=0.784, test=0.793) total time=   5.5s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.744, test=0.736) f1: (train=0.787, test=0.779) total time=   9.0s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.870, test=0.874) balanced_accuracy: (train=0.742, test=0.751) f1: (train=0.785, test=0.794) total time=   9.7s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.787, test=0.778) total time=  18.5s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.866, test=0.871) balanced_accuracy: (train=0.733, test=0.742) f1: (train=0.776, test=0.786) total time=   2.5s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   4.2s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.779, test=0.776) total time=   1.3s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.866, test=0.869) balanced_accuracy: (train=0.732, test=0.741) f1: (train=0.775, test=0.784) total time=   1.3s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.778, test=0.776) total time=   2.1s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.780, test=0.773) total time=   4.5s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.870, test=0.874) balanced_accuracy: (train=0.741, test=0.750) f1: (train=0.784, test=0.793) total time=   4.5s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.783) total time=   5.8s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.744, test=0.741) f1: (train=0.787, test=0.783) total time=  10.2s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.783) total time=  11.8s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.741) f1: (train=0.786, test=0.783) total time=   9.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.870) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.786) total time=   1.2s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.737, test=0.735) f1: (train=0.780, test=0.778) total time=   1.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.867, test=0.872) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.787) total time=   1.9s\n",
      "[CV 2/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.737, test=0.731) f1: (train=0.780, test=0.773) total time=   4.3s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.870) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.786) total time=   1.3s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.737, test=0.735) f1: (train=0.780, test=0.778) total time=   1.3s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.867, test=0.872) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.787) total time=   2.1s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.737, test=0.735) f1: (train=0.780, test=0.778) total time=   3.7s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.873, test=0.870) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.790, test=0.786) total time=   4.9s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.746, test=0.741) f1: (train=0.788, test=0.783) total time=   4.6s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.872, test=0.870) balanced_accuracy: (train=0.747, test=0.742) f1: (train=0.790, test=0.785) total time=   7.1s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.872, test=0.870) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.789, test=0.785) total time=  16.2s\n",
      "[CV 5/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.786) total time=   1.1s\n",
      "[CV 1/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   1.3s\n",
      "[CV 3/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.780, test=0.776) total time=   2.1s\n",
      "[CV 2/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.737, test=0.730) f1: (train=0.780, test=0.773) total time=   2.4s\n",
      "[CV 1/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.737, test=0.735) f1: (train=0.780, test=0.777) total time=   4.2s\n",
      "[CV 1/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   1.3s\n",
      "[CV 2/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.738, test=0.731) f1: (train=0.781, test=0.774) total time=   1.2s\n",
      "[CV 2/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.737, test=0.730) f1: (train=0.780, test=0.773) total time=   1.9s\n",
      "[CV 3/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.735, test=0.732) f1: (train=0.779, test=0.775) total time=   4.1s\n",
      "[CV 5/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.786) total time=   4.2s\n",
      "[CV 2/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.873, test=0.868) balanced_accuracy: (train=0.747, test=0.739) f1: (train=0.791, test=0.781) total time=   4.9s\n",
      "[CV 4/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.872, test=0.870) balanced_accuracy: (train=0.747, test=0.742) f1: (train=0.790, test=0.785) total time=   6.7s\n",
      "[CV 5/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.871, test=0.875) balanced_accuracy: (train=0.744, test=0.752) f1: (train=0.787, test=0.795) total time=  17.5s\n",
      "[CV 1/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   1.5s\n",
      "[CV 2/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.738, test=0.731) f1: (train=0.781, test=0.774) total time=   1.2s\n",
      "[CV 3/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.780, test=0.776) total time=   2.4s\n",
      "[CV 5/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.866, test=0.871) balanced_accuracy: (train=0.733, test=0.742) f1: (train=0.776, test=0.785) total time=   2.2s\n",
      "[CV 2/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.780, test=0.773) total time=   3.9s\n",
      "[CV 2/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.737, test=0.730) f1: (train=0.780, test=0.773) total time=   1.3s\n",
      "[CV 2/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.779, test=0.772) total time=   1.2s\n",
      "[CV 3/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.780, test=0.776) total time=   2.1s\n",
      "[CV 1/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.735) f1: (train=0.779, test=0.778) total time=   4.1s\n",
      "[CV 3/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   4.1s\n",
      "[CV 5/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.871, test=0.875) balanced_accuracy: (train=0.746, test=0.753) f1: (train=0.788, test=0.796) total time=   3.7s\n",
      "[CV 2/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.873, test=0.868) balanced_accuracy: (train=0.747, test=0.739) f1: (train=0.790, test=0.781) total time=   8.2s\n",
      "[CV 3/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.873, test=0.870) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.790, test=0.786) total time=  16.8s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.863) balanced_accuracy: (train=0.736, test=0.729) f1: (train=0.778, test=0.771) total time=   1.4s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.777) total time=   1.3s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.864) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.779, test=0.772) total time=   1.1s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.737, test=0.730) f1: (train=0.780, test=0.772) total time=   2.3s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.737, test=0.731) f1: (train=0.780, test=0.773) total time=   2.1s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.778) total time=   4.1s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.786) total time=   3.2s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.737, test=0.731) f1: (train=0.780, test=0.773) total time=   1.9s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   4.3s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.744, test=0.736) f1: (train=0.787, test=0.778) total time=   5.3s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.785, test=0.782) total time=   5.1s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.744, test=0.740) f1: (train=0.786, test=0.783) total time=   8.4s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.783) total time=  17.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.736, test=0.729) f1: (train=0.779, test=0.772) total time=   1.5s\n",
      "[CV 3/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.776) total time=   1.6s\n",
      "[CV 1/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.735) f1: (train=0.779, test=0.778) total time=   2.3s\n",
      "[CV 4/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.779, test=0.777) total time=   2.3s\n",
      "[CV 5/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.866, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.786) total time=   4.5s\n",
      "[CV 5/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.866, test=0.870) balanced_accuracy: (train=0.733, test=0.742) f1: (train=0.776, test=0.785) total time=   1.3s\n",
      "[CV 3/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   2.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.779, test=0.777) total time=   2.1s\n",
      "[CV 1/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   4.3s\n",
      "[CV 3/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.785, test=0.782) total time=   5.4s\n",
      "[CV 5/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.870, test=0.874) balanced_accuracy: (train=0.742, test=0.751) f1: (train=0.785, test=0.794) total time=   8.6s\n",
      "[CV 2/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.744, test=0.736) f1: (train=0.787, test=0.779) total time=  17.7s\n",
      "[CV 3/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.785, test=0.782) total time=  13.3s\n",
      "[CV 5/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.866, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.786) total time=   4.5s\n",
      "[CV 3/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.779, test=0.776) total time=   1.4s\n",
      "[CV 2/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.779, test=0.773) total time=   2.2s\n",
      "[CV 1/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   4.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.777) total time=   4.4s\n",
      "[CV 5/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.870, test=0.874) balanced_accuracy: (train=0.742, test=0.752) f1: (train=0.785, test=0.794) total time=   5.4s\n",
      "[CV 4/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.783) total time=   7.3s\n",
      "[CV 5/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.870, test=0.874) balanced_accuracy: (train=0.742, test=0.750) f1: (train=0.785, test=0.793) total time=  13.1s\n",
      "[CV 3/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.785, test=0.782) total time=  17.6s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.786) total time=   4.0s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.866, test=0.870) balanced_accuracy: (train=0.733, test=0.742) f1: (train=0.776, test=0.785) total time=   1.3s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.737, test=0.731) f1: (train=0.780, test=0.773) total time=   1.9s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   4.1s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.744, test=0.740) f1: (train=0.786, test=0.783) total time=   5.1s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.786, test=0.778) total time=   8.8s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.870, test=0.874) balanced_accuracy: (train=0.741, test=0.751) f1: (train=0.784, test=0.794) total time=   9.0s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.744, test=0.736) f1: (train=0.787, test=0.778) total time=  16.4s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.780, test=0.772) total time=   2.3s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.780, test=0.773) total time=   3.7s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.733, test=0.743) f1: (train=0.777, test=0.786) total time=   4.0s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   2.1s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.778) total time=   4.3s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.786, test=0.783) total time=   5.5s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.783) total time=   5.5s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.870, test=0.874) balanced_accuracy: (train=0.742, test=0.751) f1: (train=0.785, test=0.794) total time=   8.6s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.872, test=0.867) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.787, test=0.779) total time=  13.3s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.778, test=0.776) total time=   1.4s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.732) f1: (train=0.779, test=0.775) total time=   1.5s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.866, test=0.871) balanced_accuracy: (train=0.733, test=0.742) f1: (train=0.776, test=0.785) total time=   1.3s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   1.4s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.776) total time=   1.8s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.737, test=0.731) f1: (train=0.780, test=0.773) total time=   2.3s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.780, test=0.773) total time=   4.3s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.779, test=0.777) total time=   4.1s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.866, test=0.870) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.785) total time=   2.0s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.778) total time=   4.2s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.787, test=0.779) total time=   4.5s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.870, test=0.874) balanced_accuracy: (train=0.742, test=0.752) f1: (train=0.785, test=0.794) total time=   5.7s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.872, test=0.867) balanced_accuracy: (train=0.745, test=0.737) f1: (train=0.788, test=0.779) total time=   8.7s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.787, test=0.783) total time=  14.1s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.870, test=0.874) balanced_accuracy: (train=0.742, test=0.751) f1: (train=0.785, test=0.794) total time=   8.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.749, test=0.745) f1: (train=0.790, test=0.786) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.746, test=0.738) f1: (train=0.788, test=0.780) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.789, test=0.785) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.788, test=0.784) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.870, test=0.873) balanced_accuracy: (train=0.746, test=0.754) f1: (train=0.788, test=0.795) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.749, test=0.745) f1: (train=0.790, test=0.786) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.746, test=0.738) f1: (train=0.788, test=0.780) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.789, test=0.785) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.788, test=0.784) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.870, test=0.873) balanced_accuracy: (train=0.746, test=0.754) f1: (train=0.788, test=0.795) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.749, test=0.745) f1: (train=0.790, test=0.786) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.746, test=0.738) f1: (train=0.788, test=0.780) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.789, test=0.785) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.788, test=0.784) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.870, test=0.873) balanced_accuracy: (train=0.746, test=0.754) f1: (train=0.788, test=0.795) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.749, test=0.745) f1: (train=0.790, test=0.786) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.746, test=0.738) f1: (train=0.788, test=0.780) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.789, test=0.785) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.788, test=0.784) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.870, test=0.873) balanced_accuracy: (train=0.746, test=0.754) f1: (train=0.788, test=0.795) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.749, test=0.745) f1: (train=0.790, test=0.786) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.746, test=0.738) f1: (train=0.788, test=0.780) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.789, test=0.785) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.788, test=0.784) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.870, test=0.873) balanced_accuracy: (train=0.746, test=0.754) f1: (train=0.788, test=0.795) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.749, test=0.745) f1: (train=0.790, test=0.786) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.746, test=0.738) f1: (train=0.788, test=0.780) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.789, test=0.785) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.788, test=0.784) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.870, test=0.873) balanced_accuracy: (train=0.746, test=0.754) f1: (train=0.788, test=0.795) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.870, test=0.865) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.784, test=0.781) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.872) balanced_accuracy: (train=0.744, test=0.752) f1: (train=0.785, test=0.793) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.870, test=0.865) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.784, test=0.781) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.872) balanced_accuracy: (train=0.744, test=0.752) f1: (train=0.785, test=0.793) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.870, test=0.865) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.784, test=0.781) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.872) balanced_accuracy: (train=0.744, test=0.752) f1: (train=0.785, test=0.793) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.870, test=0.865) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.784, test=0.781) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.872) balanced_accuracy: (train=0.744, test=0.752) f1: (train=0.785, test=0.793) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.870, test=0.865) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.784, test=0.781) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.872) balanced_accuracy: (train=0.744, test=0.752) f1: (train=0.785, test=0.793) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.870, test=0.865) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.784, test=0.781) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.872) balanced_accuracy: (train=0.744, test=0.752) f1: (train=0.785, test=0.793) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.737) f1: (train=0.781, test=0.779) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.738) f1: (train=0.783, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.740, test=0.749) f1: (train=0.781, test=0.789) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.737) f1: (train=0.781, test=0.779) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.738) f1: (train=0.783, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.740, test=0.749) f1: (train=0.781, test=0.789) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.737) f1: (train=0.781, test=0.779) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.738) f1: (train=0.783, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.740, test=0.749) f1: (train=0.781, test=0.789) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.737) f1: (train=0.781, test=0.779) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.738) f1: (train=0.783, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.740, test=0.749) f1: (train=0.781, test=0.789) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.737) f1: (train=0.781, test=0.779) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.738) f1: (train=0.783, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.740, test=0.749) f1: (train=0.781, test=0.789) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.737) f1: (train=0.781, test=0.779) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.738) f1: (train=0.783, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.740, test=0.749) f1: (train=0.781, test=0.789) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.780, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.865, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.780, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.865, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.780, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.865, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.780, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.865, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.780, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.865, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.780, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.865, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.749, test=0.745) f1: (train=0.790, test=0.786) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.746, test=0.738) f1: (train=0.788, test=0.780) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.789, test=0.785) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.788, test=0.784) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.870, test=0.873) balanced_accuracy: (train=0.746, test=0.754) f1: (train=0.788, test=0.795) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.749, test=0.745) f1: (train=0.790, test=0.786) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.746, test=0.738) f1: (train=0.788, test=0.780) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.789, test=0.785) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.788, test=0.784) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.870, test=0.873) balanced_accuracy: (train=0.746, test=0.754) f1: (train=0.788, test=0.795) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.749, test=0.745) f1: (train=0.790, test=0.786) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.746, test=0.738) f1: (train=0.788, test=0.780) total time=   0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.789, test=0.785) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.788, test=0.784) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.870, test=0.873) balanced_accuracy: (train=0.746, test=0.754) f1: (train=0.788, test=0.795) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.749, test=0.745) f1: (train=0.790, test=0.786) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.746, test=0.738) f1: (train=0.788, test=0.780) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.789, test=0.785) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.788, test=0.784) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.870, test=0.873) balanced_accuracy: (train=0.746, test=0.754) f1: (train=0.788, test=0.795) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.749, test=0.745) f1: (train=0.790, test=0.786) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.746, test=0.738) f1: (train=0.788, test=0.780) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.789, test=0.785) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.788, test=0.784) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.870, test=0.873) balanced_accuracy: (train=0.746, test=0.754) f1: (train=0.788, test=0.795) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.749, test=0.745) f1: (train=0.790, test=0.786) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.746, test=0.738) f1: (train=0.788, test=0.780) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.789, test=0.785) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.788, test=0.784) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.870, test=0.873) balanced_accuracy: (train=0.746, test=0.754) f1: (train=0.788, test=0.795) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.870, test=0.865) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.784, test=0.781) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.872) balanced_accuracy: (train=0.744, test=0.752) f1: (train=0.785, test=0.793) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.870, test=0.865) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.784, test=0.781) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.872) balanced_accuracy: (train=0.744, test=0.752) f1: (train=0.785, test=0.793) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.870, test=0.865) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.784, test=0.781) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.872) balanced_accuracy: (train=0.744, test=0.752) f1: (train=0.785, test=0.793) total time=   0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.870, test=0.865) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.784, test=0.781) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.872) balanced_accuracy: (train=0.744, test=0.752) f1: (train=0.785, test=0.793) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.870, test=0.865) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.784, test=0.781) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.872) balanced_accuracy: (train=0.744, test=0.752) f1: (train=0.785, test=0.793) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.870, test=0.865) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.784, test=0.781) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.872) balanced_accuracy: (train=0.744, test=0.752) f1: (train=0.785, test=0.793) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.737) f1: (train=0.781, test=0.779) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.738) f1: (train=0.783, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.740, test=0.749) f1: (train=0.781, test=0.789) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.783, test=0.776) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.737) f1: (train=0.781, test=0.779) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.738) f1: (train=0.783, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.740, test=0.749) f1: (train=0.781, test=0.789) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.737) f1: (train=0.781, test=0.779) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.738) f1: (train=0.783, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.740, test=0.749) f1: (train=0.781, test=0.789) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.737) f1: (train=0.781, test=0.779) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.738) f1: (train=0.783, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.740, test=0.749) f1: (train=0.781, test=0.789) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.737) f1: (train=0.781, test=0.779) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.738) f1: (train=0.783, test=0.780) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.740, test=0.749) f1: (train=0.781, test=0.789) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.737) f1: (train=0.781, test=0.779) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.738) f1: (train=0.783, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.740, test=0.749) f1: (train=0.781, test=0.789) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.780, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.865, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.780, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.865, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.780, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.865, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.780, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.865, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.780, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.865, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.780, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.865, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.746, test=0.743) f1: (train=0.787, test=0.784) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.870, test=0.866) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.786, test=0.778) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.782) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.871, test=0.868) balanced_accuracy: (train=0.744, test=0.741) f1: (train=0.787, test=0.783) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.873) balanced_accuracy: (train=0.744, test=0.752) f1: (train=0.785, test=0.793) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.746, test=0.743) f1: (train=0.787, test=0.784) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.870, test=0.866) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.786, test=0.778) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.782) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.871, test=0.868) balanced_accuracy: (train=0.744, test=0.741) f1: (train=0.787, test=0.783) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.873) balanced_accuracy: (train=0.744, test=0.752) f1: (train=0.785, test=0.793) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.746, test=0.743) f1: (train=0.787, test=0.784) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.870, test=0.866) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.786, test=0.778) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.782) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.871, test=0.868) balanced_accuracy: (train=0.744, test=0.741) f1: (train=0.787, test=0.783) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.873) balanced_accuracy: (train=0.744, test=0.752) f1: (train=0.785, test=0.793) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.746, test=0.743) f1: (train=0.787, test=0.784) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.870, test=0.866) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.786, test=0.778) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.782) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.871, test=0.868) balanced_accuracy: (train=0.744, test=0.741) f1: (train=0.787, test=0.783) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.873) balanced_accuracy: (train=0.744, test=0.752) f1: (train=0.785, test=0.793) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.746, test=0.743) f1: (train=0.787, test=0.784) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.870, test=0.866) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.786, test=0.778) total time=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.782) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.871, test=0.868) balanced_accuracy: (train=0.744, test=0.741) f1: (train=0.787, test=0.783) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.873) balanced_accuracy: (train=0.744, test=0.752) f1: (train=0.785, test=0.793) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.746, test=0.743) f1: (train=0.787, test=0.784) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.870, test=0.866) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.786, test=0.778) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.782) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.871, test=0.868) balanced_accuracy: (train=0.744, test=0.741) f1: (train=0.787, test=0.783) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.873) balanced_accuracy: (train=0.744, test=0.752) f1: (train=0.785, test=0.793) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.743, test=0.741) f1: (train=0.785, test=0.782) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.742, test=0.735) f1: (train=0.784, test=0.777) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.785, test=0.782) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.784, test=0.781) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.872) balanced_accuracy: (train=0.742, test=0.750) f1: (train=0.783, test=0.791) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.743, test=0.741) f1: (train=0.785, test=0.782) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.742, test=0.735) f1: (train=0.784, test=0.777) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.785, test=0.782) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.784, test=0.781) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.872) balanced_accuracy: (train=0.742, test=0.750) f1: (train=0.783, test=0.791) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.743, test=0.741) f1: (train=0.785, test=0.782) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.742, test=0.735) f1: (train=0.784, test=0.777) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.785, test=0.782) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.784, test=0.781) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.872) balanced_accuracy: (train=0.742, test=0.750) f1: (train=0.783, test=0.791) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.743, test=0.741) f1: (train=0.785, test=0.782) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.742, test=0.735) f1: (train=0.784, test=0.777) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.785, test=0.782) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.784, test=0.781) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.872) balanced_accuracy: (train=0.742, test=0.750) f1: (train=0.783, test=0.791) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.743, test=0.741) f1: (train=0.785, test=0.782) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.742, test=0.735) f1: (train=0.784, test=0.777) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.785, test=0.782) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.784, test=0.781) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.872) balanced_accuracy: (train=0.742, test=0.750) f1: (train=0.783, test=0.791) total time=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.743, test=0.741) f1: (train=0.785, test=0.782) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.742, test=0.735) f1: (train=0.784, test=0.777) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.785, test=0.782) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.784, test=0.781) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.872) balanced_accuracy: (train=0.742, test=0.750) f1: (train=0.783, test=0.791) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.737) f1: (train=0.781, test=0.779) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.738) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.740, test=0.749) f1: (train=0.781, test=0.789) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.737) f1: (train=0.781, test=0.779) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.738) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.740, test=0.749) f1: (train=0.781, test=0.789) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.737) f1: (train=0.781, test=0.779) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.738) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.740, test=0.749) f1: (train=0.781, test=0.789) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.737) f1: (train=0.781, test=0.779) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.738) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.740, test=0.749) f1: (train=0.781, test=0.789) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.737) f1: (train=0.781, test=0.779) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.738) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.740, test=0.749) f1: (train=0.781, test=0.789) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.737) f1: (train=0.781, test=0.779) total time=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.738) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.740, test=0.749) f1: (train=0.781, test=0.789) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.780, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.865, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.780, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.865, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.780, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.865, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.780, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.865, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.780, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.865, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.780, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.865, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.749, test=0.745) f1: (train=0.790, test=0.786) total time=   0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.746, test=0.738) f1: (train=0.788, test=0.780) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.789, test=0.785) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.788, test=0.784) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.870, test=0.873) balanced_accuracy: (train=0.746, test=0.754) f1: (train=0.788, test=0.795) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.749, test=0.745) f1: (train=0.790, test=0.786) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.746, test=0.738) f1: (train=0.788, test=0.780) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.789, test=0.785) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.788, test=0.784) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.870, test=0.873) balanced_accuracy: (train=0.746, test=0.754) f1: (train=0.788, test=0.795) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.749, test=0.745) f1: (train=0.790, test=0.786) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.746, test=0.738) f1: (train=0.788, test=0.780) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.789, test=0.785) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.788, test=0.784) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.870, test=0.873) balanced_accuracy: (train=0.746, test=0.754) f1: (train=0.788, test=0.795) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.749, test=0.745) f1: (train=0.790, test=0.786) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.746, test=0.738) f1: (train=0.788, test=0.780) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.789, test=0.785) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.788, test=0.784) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.870, test=0.873) balanced_accuracy: (train=0.746, test=0.754) f1: (train=0.788, test=0.795) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.749, test=0.745) f1: (train=0.790, test=0.786) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.746, test=0.738) f1: (train=0.788, test=0.780) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.789, test=0.785) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.788, test=0.784) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.870, test=0.873) balanced_accuracy: (train=0.746, test=0.754) f1: (train=0.788, test=0.795) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.749, test=0.745) f1: (train=0.790, test=0.786) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.746, test=0.738) f1: (train=0.788, test=0.780) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.789, test=0.785) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.788, test=0.784) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.870, test=0.873) balanced_accuracy: (train=0.746, test=0.754) f1: (train=0.788, test=0.795) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.870, test=0.865) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.784, test=0.781) total time=   0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.872) balanced_accuracy: (train=0.744, test=0.752) f1: (train=0.785, test=0.793) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.870, test=0.865) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.784, test=0.781) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.872) balanced_accuracy: (train=0.744, test=0.752) f1: (train=0.785, test=0.793) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.870, test=0.865) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.784, test=0.781) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.872) balanced_accuracy: (train=0.744, test=0.752) f1: (train=0.785, test=0.793) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.870, test=0.865) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.784, test=0.781) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.872) balanced_accuracy: (train=0.744, test=0.752) f1: (train=0.785, test=0.793) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.870, test=0.865) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.784, test=0.781) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.872) balanced_accuracy: (train=0.744, test=0.752) f1: (train=0.785, test=0.793) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.870, test=0.865) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.784, test=0.781) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.872) balanced_accuracy: (train=0.744, test=0.752) f1: (train=0.785, test=0.793) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.737) f1: (train=0.781, test=0.779) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.738) f1: (train=0.783, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.740, test=0.749) f1: (train=0.781, test=0.789) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.737) f1: (train=0.781, test=0.779) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.738) f1: (train=0.783, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.740, test=0.749) f1: (train=0.781, test=0.789) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.737) f1: (train=0.781, test=0.779) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.738) f1: (train=0.783, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.740, test=0.749) f1: (train=0.781, test=0.789) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.737) f1: (train=0.781, test=0.779) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.738) f1: (train=0.783, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.740, test=0.749) f1: (train=0.781, test=0.789) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.737) f1: (train=0.781, test=0.779) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.738) f1: (train=0.783, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.740, test=0.749) f1: (train=0.781, test=0.789) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.737) f1: (train=0.781, test=0.779) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.738) f1: (train=0.783, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.740, test=0.749) f1: (train=0.781, test=0.789) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.780, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.865, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.780, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.865, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.780, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.865, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.780, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.865, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.780, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.865, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.780, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.865, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.749, test=0.745) f1: (train=0.790, test=0.786) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.746, test=0.738) f1: (train=0.788, test=0.780) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.789, test=0.785) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.788, test=0.784) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.870, test=0.873) balanced_accuracy: (train=0.746, test=0.754) f1: (train=0.788, test=0.795) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.749, test=0.745) f1: (train=0.790, test=0.786) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.746, test=0.738) f1: (train=0.788, test=0.780) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.789, test=0.785) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.788, test=0.784) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.870, test=0.873) balanced_accuracy: (train=0.746, test=0.754) f1: (train=0.788, test=0.795) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.749, test=0.745) f1: (train=0.790, test=0.786) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.746, test=0.738) f1: (train=0.788, test=0.780) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.789, test=0.785) total time=   0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.788, test=0.784) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.870, test=0.873) balanced_accuracy: (train=0.746, test=0.754) f1: (train=0.788, test=0.795) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.749, test=0.745) f1: (train=0.790, test=0.786) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.746, test=0.738) f1: (train=0.788, test=0.780) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.789, test=0.785) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.788, test=0.784) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.870, test=0.873) balanced_accuracy: (train=0.746, test=0.754) f1: (train=0.788, test=0.795) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.749, test=0.745) f1: (train=0.790, test=0.786) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.746, test=0.738) f1: (train=0.788, test=0.780) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.789, test=0.785) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.788, test=0.784) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.870, test=0.873) balanced_accuracy: (train=0.746, test=0.754) f1: (train=0.788, test=0.795) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.749, test=0.745) f1: (train=0.790, test=0.786) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.746, test=0.738) f1: (train=0.788, test=0.780) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.789, test=0.785) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.788, test=0.784) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.870, test=0.873) balanced_accuracy: (train=0.746, test=0.754) f1: (train=0.788, test=0.795) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.870, test=0.865) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.784, test=0.781) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.872) balanced_accuracy: (train=0.744, test=0.752) f1: (train=0.785, test=0.793) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.870, test=0.865) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.784, test=0.781) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.872) balanced_accuracy: (train=0.744, test=0.752) f1: (train=0.785, test=0.793) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.870, test=0.865) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.784, test=0.781) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.872) balanced_accuracy: (train=0.744, test=0.752) f1: (train=0.785, test=0.793) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.870, test=0.865) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.784, test=0.781) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.872) balanced_accuracy: (train=0.744, test=0.752) f1: (train=0.785, test=0.793) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.870, test=0.865) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.784, test=0.781) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.872) balanced_accuracy: (train=0.744, test=0.752) f1: (train=0.785, test=0.793) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.870, test=0.865) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.784, test=0.781) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.872) balanced_accuracy: (train=0.744, test=0.752) f1: (train=0.785, test=0.793) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.737) f1: (train=0.781, test=0.779) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.738) f1: (train=0.783, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.740, test=0.749) f1: (train=0.781, test=0.789) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.737) f1: (train=0.781, test=0.779) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.738) f1: (train=0.783, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.740, test=0.749) f1: (train=0.781, test=0.789) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.737) f1: (train=0.781, test=0.779) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.738) f1: (train=0.783, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.740, test=0.749) f1: (train=0.781, test=0.789) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.737) f1: (train=0.781, test=0.779) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.738) f1: (train=0.783, test=0.780) total time=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.740, test=0.749) f1: (train=0.781, test=0.789) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.737) f1: (train=0.781, test=0.779) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.738) f1: (train=0.783, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.740, test=0.749) f1: (train=0.781, test=0.789) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.737) f1: (train=0.781, test=0.779) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.738) f1: (train=0.783, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.740, test=0.749) f1: (train=0.781, test=0.789) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.780, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.865, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.780, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.865, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.780, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.865, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.780, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.865, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.780, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.865, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.780, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.865, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.749, test=0.745) f1: (train=0.790, test=0.786) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.746, test=0.738) f1: (train=0.788, test=0.780) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.789, test=0.785) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.788, test=0.784) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.870, test=0.873) balanced_accuracy: (train=0.746, test=0.754) f1: (train=0.788, test=0.795) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.749, test=0.745) f1: (train=0.790, test=0.786) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.746, test=0.738) f1: (train=0.788, test=0.780) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.789, test=0.785) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.788, test=0.784) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.870, test=0.873) balanced_accuracy: (train=0.746, test=0.754) f1: (train=0.788, test=0.795) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.749, test=0.745) f1: (train=0.790, test=0.786) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.746, test=0.738) f1: (train=0.788, test=0.780) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.789, test=0.785) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.788, test=0.784) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.870, test=0.873) balanced_accuracy: (train=0.746, test=0.754) f1: (train=0.788, test=0.795) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.749, test=0.745) f1: (train=0.790, test=0.786) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.746, test=0.738) f1: (train=0.788, test=0.780) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.789, test=0.785) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.788, test=0.784) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.870, test=0.873) balanced_accuracy: (train=0.746, test=0.754) f1: (train=0.788, test=0.795) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.749, test=0.745) f1: (train=0.790, test=0.786) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.746, test=0.738) f1: (train=0.788, test=0.780) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.789, test=0.785) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.788, test=0.784) total time=   0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.870, test=0.873) balanced_accuracy: (train=0.746, test=0.754) f1: (train=0.788, test=0.795) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.749, test=0.745) f1: (train=0.790, test=0.786) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.746, test=0.738) f1: (train=0.788, test=0.780) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.789, test=0.785) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.788, test=0.784) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.870, test=0.873) balanced_accuracy: (train=0.746, test=0.754) f1: (train=0.788, test=0.795) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.870, test=0.865) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.784, test=0.781) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.872) balanced_accuracy: (train=0.744, test=0.752) f1: (train=0.785, test=0.793) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.870, test=0.865) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.784, test=0.781) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.872) balanced_accuracy: (train=0.744, test=0.752) f1: (train=0.785, test=0.793) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.870, test=0.865) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.784, test=0.781) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.872) balanced_accuracy: (train=0.744, test=0.752) f1: (train=0.785, test=0.793) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.870, test=0.865) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.784, test=0.781) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.872) balanced_accuracy: (train=0.744, test=0.752) f1: (train=0.785, test=0.793) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.870, test=0.865) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.784, test=0.781) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.872) balanced_accuracy: (train=0.744, test=0.752) f1: (train=0.785, test=0.793) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.870, test=0.865) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.784, test=0.781) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.872) balanced_accuracy: (train=0.744, test=0.752) f1: (train=0.785, test=0.793) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.737) f1: (train=0.781, test=0.779) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.738) f1: (train=0.783, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.740, test=0.749) f1: (train=0.781, test=0.789) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.737) f1: (train=0.781, test=0.779) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.738) f1: (train=0.783, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.740, test=0.749) f1: (train=0.781, test=0.789) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.737) f1: (train=0.781, test=0.779) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.738) f1: (train=0.783, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.740, test=0.749) f1: (train=0.781, test=0.789) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.737) f1: (train=0.781, test=0.779) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.738) f1: (train=0.783, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.740, test=0.749) f1: (train=0.781, test=0.789) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.737) f1: (train=0.781, test=0.779) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.738) f1: (train=0.783, test=0.780) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.740, test=0.749) f1: (train=0.781, test=0.789) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.737) f1: (train=0.781, test=0.779) total time=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.738) f1: (train=0.783, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.740, test=0.749) f1: (train=0.781, test=0.789) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.780, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.865, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.780, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.865, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.780, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.865, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.780, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.865, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.780, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.865, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.780, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.865, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False),\n",
       "             estimator=DecisionTreeClassifier(min_samples_leaf=50,\n",
       "                                              min_samples_split=50,\n",
       "                                              random_state=10),\n",
       "             param_grid={&#x27;ccp_alpha&#x27;: [0.0001],\n",
       "                         &#x27;criterion&#x27;: [&#x27;gini&#x27;, &#x27;entropy&#x27;, &#x27;log_loss&#x27;],\n",
       "                         &#x27;max_depth&#x27;: [10, 20, 30, None],\n",
       "                         &#x27;min_samples_leaf&#x27;: [20, 50, 100, 200],\n",
       "                         &#x27;min_samples_split&#x27;: [6, 8],\n",
       "                         &#x27;random_state&#x27;: [30, 50, None]},\n",
       "             refit=&#x27;balanced_accuracy&#x27;, return_train_score=True,\n",
       "             scoring={&#x27;accuracy&#x27;: &#x27;accuracy&#x27;,\n",
       "                      &#x27;balanced_accuracy&#x27;: &#x27;balanced_accuracy&#x27;,\n",
       "                      &#x27;f1&#x27;: &#x27;f1_macro&#x27;},\n",
       "             verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False),\n",
       "             estimator=DecisionTreeClassifier(min_samples_leaf=50,\n",
       "                                              min_samples_split=50,\n",
       "                                              random_state=10),\n",
       "             param_grid={&#x27;ccp_alpha&#x27;: [0.0001],\n",
       "                         &#x27;criterion&#x27;: [&#x27;gini&#x27;, &#x27;entropy&#x27;, &#x27;log_loss&#x27;],\n",
       "                         &#x27;max_depth&#x27;: [10, 20, 30, None],\n",
       "                         &#x27;min_samples_leaf&#x27;: [20, 50, 100, 200],\n",
       "                         &#x27;min_samples_split&#x27;: [6, 8],\n",
       "                         &#x27;random_state&#x27;: [30, 50, None]},\n",
       "             refit=&#x27;balanced_accuracy&#x27;, return_train_score=True,\n",
       "             scoring={&#x27;accuracy&#x27;: &#x27;accuracy&#x27;,\n",
       "                      &#x27;balanced_accuracy&#x27;: &#x27;balanced_accuracy&#x27;,\n",
       "                      &#x27;f1&#x27;: &#x27;f1_macro&#x27;},\n",
       "             verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(min_samples_leaf=50, min_samples_split=50,\n",
       "                       random_state=10)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(min_samples_leaf=50, min_samples_split=50,\n",
       "                       random_state=10)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False),\n",
       "             estimator=DecisionTreeClassifier(min_samples_leaf=50,\n",
       "                                              min_samples_split=50,\n",
       "                                              random_state=10),\n",
       "             param_grid={'ccp_alpha': [0.0001],\n",
       "                         'criterion': ['gini', 'entropy', 'log_loss'],\n",
       "                         'max_depth': [10, 20, 30, None],\n",
       "                         'min_samples_leaf': [20, 50, 100, 200],\n",
       "                         'min_samples_split': [6, 8],\n",
       "                         'random_state': [30, 50, None]},\n",
       "             refit='balanced_accuracy', return_train_score=True,\n",
       "             scoring={'accuracy': 'accuracy',\n",
       "                      'balanced_accuracy': 'balanced_accuracy',\n",
       "                      'f1': 'f1_macro'},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "#GRID SEARCH\n",
    "tree_clf = DecisionTreeClassifier(max_features=None,max_depth=None, random_state=10, min_samples_leaf=50,min_samples_split=50)\n",
    "\n",
    "parameter_grid = {\n",
    "    \"max_depth\": [10, 20, 30, None],\n",
    "    \"criterion\": ['gini', 'entropy', 'log_loss'],\n",
    "    'random_state': [30, 50, None],\n",
    "    'min_samples_leaf':[20, 50, 100, 200],\n",
    "    'ccp_alpha': [.0001],\n",
    "    'min_samples_split': [6, 8 ]\n",
    "}\n",
    "\n",
    "# Create Stratified folds\n",
    "cross_validation = StratifiedKFold(n_splits=5)\n",
    "cross_validation.get_n_splits(train_data, y_train)\n",
    "\n",
    "# Create the scoring dictionary\n",
    "SCORING = {\n",
    "    \"accuracy\": \"accuracy\",\n",
    "    \"balanced_accuracy\": \"balanced_accuracy\",\n",
    "    \"f1\": \"f1_macro\",\n",
    "}\n",
    "\n",
    "# Create and fit the GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=tree_clf,\n",
    "    param_grid=parameter_grid,\n",
    "    cv=cross_validation,\n",
    "    verbose=3,\n",
    "    scoring=SCORING,\n",
    "    return_train_score=True,\n",
    "    refit=\"balanced_accuracy\",\n",
    ")\n",
    "\n",
    "grid_search.fit(train_data,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "62d3ccd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.7443202990579671\n",
      "Best parameters: {'ccp_alpha': 0.0001, 'criterion': 'entropy', 'max_depth': 20, 'min_samples_leaf': 20, 'min_samples_split': 6, 'random_state': 30}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(ccp_alpha=0.0001, criterion=&#x27;entropy&#x27;, max_depth=20,\n",
       "                       min_samples_leaf=20, min_samples_split=6,\n",
       "                       random_state=30)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" checked><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(ccp_alpha=0.0001, criterion=&#x27;entropy&#x27;, max_depth=20,\n",
       "                       min_samples_leaf=20, min_samples_split=6,\n",
       "                       random_state=30)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.0001, criterion='entropy', max_depth=20,\n",
       "                       min_samples_leaf=20, min_samples_split=6,\n",
       "                       random_state=30)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Best score: {}\".format(grid_search.best_score_))\n",
    "print(\"Best parameters: {}\".format(grid_search.best_params_))\n",
    "\n",
    "best_dtc = grid_search.best_estimator_\n",
    "best_dtc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e0da7fcb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8686194494397566"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model =best_dtc\n",
    "my_model.fit(train_data, y_train)\n",
    "my_model.score(test_data,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5722cc90",
   "metadata": {},
   "source": [
    "RANDOM FOREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "07321942",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3b318752",
   "metadata": {},
   "outputs": [],
   "source": [
    "column = ['criterion', 'max_depth', 'max_features', 'n_estimators', 'random_state', 'accuracy']\n",
    "column_bar = ['try', 'Parameter_changed', 'Accuracy']\n",
    "\n",
    "### Create a single row equivalent to a single try for decision tree\n",
    "def create_bar_row(criterion, depth, feature, stimatori,random, attempt, parameter):\n",
    "  rf = RandomForestClassifier(criterion=criterion,max_depth=depth, max_features=feature,n_estimators=stimatori, random_state=random )\n",
    "  rf.fit(train_data, np.ravel(y_train))\n",
    "  testset_score = rf.score(test_data, y_test)\n",
    "  row = pd.DataFrame(data=[[attempt, parameter, testset_score]], columns=column_bar)\n",
    "  return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "080a26fd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  try Parameter_changed  Accuracy\n",
      "0   1             start  0.867029\n",
      "0   2         max_depth  0.867720\n",
      "0   3      max_features  0.867236\n",
      "0   4      n_estimators  0.868204\n",
      "0   5      n_estimators  0.867513\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'Score sul testset durante il tuning dei parametri'}, xlabel='Accuracy', ylabel='Parameter_changed'>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.DataFrame(columns=column_bar)\n",
    "df = pd.concat([df, create_bar_row('gini', None, 20, 40, 2,1, 'start')]) # try 1\n",
    "df = pd.concat([df, create_bar_row('gini', 40, 20, 40, 5,2, 'max_depth')]) # try 2\n",
    "df = pd.concat([df, create_bar_row('gini', 40, None, 40, 5,3, 'max_features')]) # try 3\n",
    "df = pd.concat([df, create_bar_row('gini', 40, None, 100, 5,4, 'n_estimators')]) # try 4\n",
    "df = pd.concat([df, create_bar_row('gini', 40, None, 100, 10,5, 'random_state')]) # try 5\n",
    "print(df)\n",
    "\n",
    "fig, axs = plt.subplots()\n",
    "axs.set_xlim([0.70,0.89])\n",
    "axs.set_title(\"Score sul testset durante il tuning dei parametri\")\n",
    "\n",
    "sns.barplot(data=df, x='Accuracy',y=\"Parameter_changed\",ax=axs, orient=\"h\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aada8db8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 243 candidates, totalling 1215 fits\n",
      "[CV 5/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.786) total time=   1.2s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.866, test=0.870) balanced_accuracy: (train=0.732, test=0.741) f1: (train=0.775, test=0.785) total time=   1.1s\n",
      "[CV 2/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.738, test=0.731) f1: (train=0.781, test=0.773) total time=   1.9s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.780, test=0.776) total time=   3.6s\n",
      "[CV 2/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.737, test=0.731) f1: (train=0.780, test=0.774) total time=   1.3s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.737, test=0.734) f1: (train=0.780, test=0.777) total time=   1.2s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   2.2s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.735, test=0.732) f1: (train=0.779, test=0.775) total time=   3.9s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.786) total time=   4.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.872, test=0.868) balanced_accuracy: (train=0.747, test=0.739) f1: (train=0.790, test=0.781) total time=   4.3s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.872, test=0.870) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.789, test=0.785) total time=   8.2s\n",
      "[CV 2/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.873, test=0.868) balanced_accuracy: (train=0.747, test=0.739) f1: (train=0.790, test=0.781) total time=  16.3s\n",
      "[CV 1/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   1.3s\n",
      "[CV 3/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.737, test=0.734) f1: (train=0.780, test=0.777) total time=   1.2s\n",
      "[CV 5/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.787) total time=   2.2s\n",
      "[CV 4/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   2.4s\n",
      "[CV 4/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   4.2s\n",
      "[CV 2/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.779, test=0.772) total time=   1.3s\n",
      "[CV 5/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.866, test=0.870) balanced_accuracy: (train=0.733, test=0.741) f1: (train=0.776, test=0.784) total time=   1.2s\n",
      "[CV 1/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   2.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   4.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.873, test=0.870) balanced_accuracy: (train=0.747, test=0.744) f1: (train=0.790, test=0.786) total time=   5.1s\n",
      "[CV 3/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.872, test=0.870) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.790, test=0.786) total time=   5.2s\n",
      "[CV 1/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.872, test=0.870) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.790, test=0.785) total time=   8.8s\n",
      "[CV 3/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.873, test=0.870) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.790, test=0.785) total time=  12.3s\n",
      "[CV 2/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.737, test=0.730) f1: (train=0.780, test=0.773) total time=   1.4s\n",
      "[CV 5/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.786) total time=   1.4s\n",
      "[CV 1/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   1.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.866, test=0.870) balanced_accuracy: (train=0.733, test=0.741) f1: (train=0.776, test=0.784) total time=   1.3s\n",
      "[CV 3/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   2.1s\n",
      "[CV 2/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.737, test=0.730) f1: (train=0.780, test=0.773) total time=   4.1s\n",
      "[CV 2/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.737, test=0.731) f1: (train=0.780, test=0.773) total time=   3.9s\n",
      "[CV 1/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   1.8s\n",
      "[CV 3/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.779, test=0.776) total time=   2.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   3.9s\n",
      "[CV 1/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.873, test=0.870) balanced_accuracy: (train=0.748, test=0.744) f1: (train=0.791, test=0.786) total time=   5.2s\n",
      "[CV 3/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.873, test=0.870) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.790, test=0.786) total time=   8.6s\n",
      "[CV 5/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.871, test=0.875) balanced_accuracy: (train=0.744, test=0.753) f1: (train=0.787, test=0.796) total time=   7.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.873, test=0.870) balanced_accuracy: (train=0.748, test=0.743) f1: (train=0.790, test=0.786) total time=  16.7s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.779, test=0.776) total time=   2.2s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.780, test=0.772) total time=   4.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.737, test=0.730) f1: (train=0.780, test=0.773) total time=   3.4s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.866, test=0.870) balanced_accuracy: (train=0.733, test=0.742) f1: (train=0.776, test=0.785) total time=   1.3s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.867, test=0.870) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.786) total time=   2.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.737, test=0.730) f1: (train=0.780, test=0.773) total time=   4.1s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.783) total time=   5.1s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.870, test=0.874) balanced_accuracy: (train=0.741, test=0.751) f1: (train=0.784, test=0.794) total time=   5.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.744, test=0.736) f1: (train=0.787, test=0.779) total time=   7.2s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.785, test=0.782) total time=  16.9s\n",
      "[CV 4/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.778, test=0.776) total time=   1.4s\n",
      "[CV 5/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.866, test=0.870) balanced_accuracy: (train=0.733, test=0.742) f1: (train=0.776, test=0.785) total time=   1.5s\n",
      "[CV 2/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.779, test=0.773) total time=   2.5s\n",
      "[CV 2/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.780, test=0.772) total time=   2.4s\n",
      "[CV 1/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.778) total time=   4.5s\n",
      "[CV 3/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.732) f1: (train=0.779, test=0.775) total time=   1.3s\n",
      "[CV 1/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.776) total time=   1.2s\n",
      "[CV 1/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.735) f1: (train=0.779, test=0.778) total time=   2.4s\n",
      "[CV 4/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.779, test=0.776) total time=   4.2s\n",
      "[CV 1/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.745, test=0.741) f1: (train=0.787, test=0.783) total time=   5.7s\n",
      "[CV 3/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.785, test=0.782) total time=   5.8s\n",
      "[CV 5/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.870, test=0.874) balanced_accuracy: (train=0.742, test=0.751) f1: (train=0.785, test=0.794) total time=  10.3s\n",
      "[CV 3/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.785, test=0.782) total time=  16.5s\n",
      "[CV 5/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.866, test=0.870) balanced_accuracy: (train=0.733, test=0.742) f1: (train=0.776, test=0.785) total time=   1.5s\n",
      "[CV 2/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.779, test=0.773) total time=   2.2s\n",
      "[CV 4/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   2.5s\n",
      "[CV 4/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.779, test=0.776) total time=   3.9s\n",
      "[CV 1/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.778, test=0.776) total time=   1.1s\n",
      "[CV 1/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.777) total time=   1.4s\n",
      "[CV 4/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.778, test=0.775) total time=   1.4s\n",
      "[CV 1/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.778, test=0.776) total time=   2.1s\n",
      "[CV 2/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.780, test=0.773) total time=   4.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.737, test=0.731) f1: (train=0.780, test=0.774) total time=   1.4s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.737, test=0.734) f1: (train=0.780, test=0.777) total time=   2.1s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.737, test=0.735) f1: (train=0.780, test=0.778) total time=   4.3s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   1.1s\n",
      "[CV 2/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.869, test=0.864) balanced_accuracy: (train=0.739, test=0.731) f1: (train=0.782, test=0.773) total time=   1.3s\n",
      "[CV 2/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.737, test=0.731) f1: (train=0.780, test=0.773) total time=   2.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   4.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.872, test=0.868) balanced_accuracy: (train=0.747, test=0.739) f1: (train=0.790, test=0.781) total time=   4.9s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.872, test=0.870) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.789, test=0.785) total time=   4.3s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.871, test=0.875) balanced_accuracy: (train=0.745, test=0.752) f1: (train=0.788, test=0.795) total time=   7.3s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.871, test=0.875) balanced_accuracy: (train=0.744, test=0.753) f1: (train=0.787, test=0.795) total time=  16.4s\n",
      "[CV 3/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.737, test=0.733) f1: (train=0.780, test=0.775) total time=   1.2s\n",
      "[CV 4/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   1.3s\n",
      "[CV 1/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   2.1s\n",
      "[CV 4/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.737, test=0.734) f1: (train=0.780, test=0.777) total time=   2.5s\n",
      "[CV 4/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   3.3s\n",
      "[CV 4/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.780, test=0.776) total time=   3.9s\n",
      "[CV 5/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.787) total time=   2.2s\n",
      "[CV 3/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   3.9s\n",
      "[CV 4/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.873, test=0.870) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.790, test=0.785) total time=   5.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.872, test=0.870) balanced_accuracy: (train=0.746, test=0.743) f1: (train=0.789, test=0.786) total time=   5.1s\n",
      "[CV 5/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.871, test=0.875) balanced_accuracy: (train=0.745, test=0.753) f1: (train=0.788, test=0.796) total time=   8.6s\n",
      "[CV 2/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.873, test=0.868) balanced_accuracy: (train=0.747, test=0.739) f1: (train=0.791, test=0.782) total time=  15.9s\n",
      "[CV 5/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.787) total time=   1.3s\n",
      "[CV 2/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.737, test=0.731) f1: (train=0.780, test=0.774) total time=   2.4s\n",
      "[CV 5/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.787) total time=   2.4s\n",
      "[CV 4/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   3.9s\n",
      "[CV 5/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.786) total time=   3.9s\n",
      "[CV 2/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.737, test=0.730) f1: (train=0.780, test=0.773) total time=   1.9s\n",
      "[CV 3/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   4.1s\n",
      "[CV 5/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.871, test=0.875) balanced_accuracy: (train=0.745, test=0.754) f1: (train=0.788, test=0.796) total time=   5.1s\n",
      "[CV 2/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.873, test=0.868) balanced_accuracy: (train=0.747, test=0.739) f1: (train=0.790, test=0.781) total time=   7.8s\n",
      "[CV 3/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.872, test=0.870) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.789, test=0.785) total time=   7.1s\n",
      "[CV 5/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.871, test=0.875) balanced_accuracy: (train=0.745, test=0.753) f1: (train=0.787, test=0.796) total time=  16.4s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.786) total time=   2.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   1.9s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.737, test=0.730) f1: (train=0.780, test=0.773) total time=   4.3s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.863) balanced_accuracy: (train=0.736, test=0.729) f1: (train=0.778, test=0.771) total time=   1.3s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   1.2s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.779, test=0.776) total time=   2.2s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.778) total time=   4.3s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   4.2s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.870, test=0.874) balanced_accuracy: (train=0.742, test=0.751) f1: (train=0.784, test=0.793) total time=   4.8s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.783) total time=   8.4s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.870, test=0.874) balanced_accuracy: (train=0.741, test=0.751) f1: (train=0.784, test=0.794) total time=  16.9s\n",
      "[CV 2/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.864) balanced_accuracy: (train=0.735, test=0.729) f1: (train=0.778, test=0.771) total time=   1.6s\n",
      "[CV 3/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.779, test=0.776) total time=   1.5s\n",
      "[CV 4/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.778, test=0.775) total time=   1.4s\n",
      "[CV 5/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.866, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.776, test=0.787) total time=   2.2s\n",
      "[CV 1/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   3.6s\n",
      "[CV 2/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.780, test=0.773) total time=   4.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.779, test=0.773) total time=   2.2s\n",
      "[CV 5/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.866, test=0.871) balanced_accuracy: (train=0.733, test=0.742) f1: (train=0.776, test=0.786) total time=   2.3s\n",
      "[CV 2/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.780, test=0.773) total time=   4.4s\n",
      "[CV 4/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.783) total time=   5.5s\n",
      "[CV 1/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.745, test=0.741) f1: (train=0.787, test=0.784) total time=   8.7s\n",
      "[CV 3/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.785, test=0.783) total time=  17.8s\n",
      "[CV 5/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.870, test=0.874) balanced_accuracy: (train=0.742, test=0.751) f1: (train=0.785, test=0.794) total time=  15.3s\n",
      "[CV 3/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.777) total time=   3.6s\n",
      "[CV 2/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.737, test=0.731) f1: (train=0.780, test=0.773) total time=   2.2s\n",
      "[CV 4/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.779, test=0.776) total time=   4.2s\n",
      "[CV 5/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.733, test=0.743) f1: (train=0.777, test=0.786) total time=   4.2s\n",
      "[CV 1/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.744, test=0.740) f1: (train=0.787, test=0.783) total time=   3.9s\n",
      "[CV 2/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.872, test=0.867) balanced_accuracy: (train=0.745, test=0.737) f1: (train=0.788, test=0.779) total time=   8.4s\n",
      "[CV 4/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.787, test=0.783) total time=  18.2s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.732) f1: (train=0.779, test=0.775) total time=   1.2s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.737, test=0.730) f1: (train=0.780, test=0.772) total time=   1.3s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.735, test=0.735) f1: (train=0.778, test=0.778) total time=   1.2s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.866, test=0.870) balanced_accuracy: (train=0.733, test=0.742) f1: (train=0.776, test=0.785) total time=   1.4s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.735) f1: (train=0.779, test=0.778) total time=   1.9s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.737, test=0.731) f1: (train=0.780, test=0.773) total time=   2.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.779, test=0.778) total time=   1.3s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.735) f1: (train=0.779, test=0.778) total time=   1.9s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.866, test=0.871) balanced_accuracy: (train=0.733, test=0.742) f1: (train=0.776, test=0.786) total time=   2.1s\n",
      "[CV 2/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.738, test=0.730) f1: (train=0.781, test=0.773) total time=   4.2s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.737, test=0.736) f1: (train=0.780, test=0.778) total time=   1.2s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.735) f1: (train=0.779, test=0.778) total time=   1.9s\n",
      "[CV 2/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.737, test=0.730) f1: (train=0.780, test=0.773) total time=   3.9s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.780, test=0.776) total time=   3.8s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.872, test=0.870) balanced_accuracy: (train=0.747, test=0.742) f1: (train=0.790, test=0.784) total time=   4.5s\n",
      "[CV 2/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.872, test=0.868) balanced_accuracy: (train=0.747, test=0.739) f1: (train=0.790, test=0.781) total time=   8.4s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.872, test=0.870) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.790, test=0.785) total time=  16.4s\n",
      "[CV 4/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   1.3s\n",
      "[CV 2/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.738, test=0.731) f1: (train=0.781, test=0.774) total time=   1.3s\n",
      "[CV 4/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.780, test=0.777) total time=   2.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   2.3s\n",
      "[CV 5/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.733, test=0.743) f1: (train=0.777, test=0.786) total time=   4.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   1.2s\n",
      "[CV 4/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   1.1s\n",
      "[CV 3/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.780, test=0.776) total time=   2.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   1.9s\n",
      "[CV 1/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.735) f1: (train=0.779, test=0.778) total time=   4.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.872, test=0.870) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.790, test=0.786) total time=   4.9s\n",
      "[CV 5/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.871, test=0.875) balanced_accuracy: (train=0.744, test=0.753) f1: (train=0.787, test=0.795) total time=   8.5s\n",
      "[CV 2/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.873, test=0.868) balanced_accuracy: (train=0.747, test=0.739) f1: (train=0.790, test=0.781) total time=  16.7s\n",
      "[CV 1/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   1.5s\n",
      "[CV 4/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   1.1s\n",
      "[CV 3/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.732) f1: (train=0.779, test=0.775) total time=   1.2s\n",
      "[CV 4/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.737, test=0.735) f1: (train=0.779, test=0.778) total time=   1.2s\n",
      "[CV 5/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.787) total time=   2.2s\n",
      "[CV 1/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.735) f1: (train=0.779, test=0.778) total time=   4.2s\n",
      "[CV 1/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.735) f1: (train=0.779, test=0.778) total time=   3.9s\n",
      "[CV 5/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.866, test=0.870) balanced_accuracy: (train=0.733, test=0.741) f1: (train=0.776, test=0.784) total time=   1.1s\n",
      "[CV 4/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.737, test=0.734) f1: (train=0.780, test=0.777) total time=   1.9s\n",
      "[CV 2/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.780, test=0.773) total time=   4.1s\n",
      "[CV 4/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.873, test=0.870) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.790, test=0.785) total time=   4.8s\n",
      "[CV 5/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.871, test=0.875) balanced_accuracy: (train=0.745, test=0.753) f1: (train=0.788, test=0.796) total time=   5.6s\n",
      "[CV 2/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.873, test=0.867) balanced_accuracy: (train=0.747, test=0.738) f1: (train=0.790, test=0.780) total time=   6.8s\n",
      "[CV 2/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.873, test=0.868) balanced_accuracy: (train=0.747, test=0.739) f1: (train=0.791, test=0.782) total time=  12.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.872, test=0.870) balanced_accuracy: (train=0.746, test=0.743) f1: (train=0.789, test=0.785) total time=  11.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   4.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   3.8s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.735) f1: (train=0.779, test=0.778) total time=   2.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   4.3s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.786) total time=   4.4s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.872, test=0.867) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.787, test=0.779) total time=   4.7s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.871, test=0.870) balanced_accuracy: (train=0.743, test=0.741) f1: (train=0.786, test=0.784) total time=   8.2s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.787, test=0.778) total time=  17.2s\n",
      "[CV 5/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.866, test=0.871) balanced_accuracy: (train=0.733, test=0.742) f1: (train=0.776, test=0.785) total time=   1.4s\n",
      "[CV 1/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.776) total time=   1.2s\n",
      "[CV 5/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.866, test=0.869) balanced_accuracy: (train=0.732, test=0.741) f1: (train=0.775, test=0.784) total time=   1.5s\n",
      "[CV 2/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.737, test=0.731) f1: (train=0.780, test=0.773) total time=   2.1s\n",
      "[CV 5/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.866, test=0.871) balanced_accuracy: (train=0.733, test=0.742) f1: (train=0.776, test=0.786) total time=   2.4s\n",
      "[CV 1/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   4.2s\n",
      "[CV 3/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.779, test=0.776) total time=   1.3s\n",
      "[CV 1/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.776) total time=   2.1s\n",
      "[CV 3/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.779, test=0.776) total time=   2.1s\n",
      "[CV 5/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.866, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.786) total time=   4.3s\n",
      "[CV 2/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.872, test=0.867) balanced_accuracy: (train=0.745, test=0.737) f1: (train=0.788, test=0.779) total time=   5.5s\n",
      "[CV 4/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.741) f1: (train=0.786, test=0.784) total time=   8.8s\n",
      "[CV 1/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.744, test=0.741) f1: (train=0.787, test=0.783) total time=  17.9s\n",
      "[CV 4/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.741) f1: (train=0.786, test=0.783) total time=  12.9s\n",
      "[CV 1/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   4.5s\n",
      "[CV 4/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   1.3s\n",
      "[CV 1/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.776) total time=   2.2s\n",
      "[CV 4/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.779, test=0.777) total time=   2.2s\n",
      "[CV 1/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   4.5s\n",
      "[CV 4/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.783) total time=   4.9s\n",
      "[CV 4/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.741) f1: (train=0.786, test=0.784) total time=   8.8s\n",
      "[CV 1/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.744, test=0.741) f1: (train=0.787, test=0.783) total time=  18.7s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.863) balanced_accuracy: (train=0.736, test=0.729) f1: (train=0.778, test=0.771) total time=   1.4s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.777) total time=   1.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.737, test=0.734) f1: (train=0.780, test=0.777) total time=   1.2s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   1.1s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.737, test=0.735) f1: (train=0.780, test=0.778) total time=   1.9s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.779, test=0.776) total time=   4.5s\n",
      "[CV 2/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.780, test=0.773) total time=   1.2s\n",
      "[CV 2/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.737, test=0.731) f1: (train=0.780, test=0.773) total time=   1.8s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   1.9s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.780, test=0.776) total time=   3.9s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.871, test=0.875) balanced_accuracy: (train=0.745, test=0.753) f1: (train=0.787, test=0.796) total time=   4.7s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.872, test=0.870) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.790, test=0.785) total time=   7.2s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.745, test=0.741) f1: (train=0.788, test=0.784) total time=   7.8s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.871, test=0.875) balanced_accuracy: (train=0.744, test=0.752) f1: (train=0.787, test=0.795) total time=  11.4s\n",
      "[CV 2/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.737, test=0.730) f1: (train=0.780, test=0.773) total time=   1.4s\n",
      "[CV 5/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.787) total time=   1.3s\n",
      "[CV 2/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.737, test=0.731) f1: (train=0.780, test=0.774) total time=   2.1s\n",
      "[CV 5/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.787) total time=   2.4s\n",
      "[CV 2/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.737, test=0.730) f1: (train=0.780, test=0.773) total time=   3.4s\n",
      "[CV 3/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   3.9s\n",
      "[CV 1/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.737, test=0.734) f1: (train=0.779, test=0.777) total time=   2.2s\n",
      "[CV 1/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.737, test=0.735) f1: (train=0.780, test=0.777) total time=   4.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.873, test=0.870) balanced_accuracy: (train=0.748, test=0.744) f1: (train=0.791, test=0.786) total time=   4.9s\n",
      "[CV 2/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.873, test=0.868) balanced_accuracy: (train=0.747, test=0.739) f1: (train=0.790, test=0.781) total time=   8.6s\n",
      "[CV 5/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.871, test=0.875) balanced_accuracy: (train=0.744, test=0.753) f1: (train=0.787, test=0.796) total time=   8.6s\n",
      "[CV 2/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.872, test=0.867) balanced_accuracy: (train=0.746, test=0.738) f1: (train=0.790, test=0.781) total time=  14.1s\n",
      "[CV 1/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.737, test=0.734) f1: (train=0.779, test=0.777) total time=   2.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.779, test=0.776) total time=   2.3s\n",
      "[CV 5/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.733, test=0.743) f1: (train=0.777, test=0.786) total time=   4.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.786) total time=   1.6s\n",
      "[CV 2/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.738, test=0.731) f1: (train=0.781, test=0.774) total time=   1.1s\n",
      "[CV 3/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   2.1s\n",
      "[CV 5/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.733, test=0.743) f1: (train=0.777, test=0.786) total time=   4.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.873, test=0.868) balanced_accuracy: (train=0.747, test=0.739) f1: (train=0.791, test=0.781) total time=   5.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.872, test=0.870) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.790, test=0.786) total time=   5.4s\n",
      "[CV 1/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.872, test=0.870) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.790, test=0.785) total time=   8.4s\n",
      "[CV 4/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.873, test=0.869) balanced_accuracy: (train=0.747, test=0.742) f1: (train=0.790, test=0.784) total time=  16.5s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.735, test=0.735) f1: (train=0.778, test=0.778) total time=   1.2s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.779, test=0.776) total time=   2.1s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   2.4s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   4.1s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.776) total time=   1.3s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.737, test=0.730) f1: (train=0.780, test=0.772) total time=   1.3s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   2.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   2.3s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.786) total time=   4.3s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.744, test=0.740) f1: (train=0.786, test=0.783) total time=   4.9s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.785, test=0.782) total time=   8.5s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.870, test=0.874) balanced_accuracy: (train=0.741, test=0.751) f1: (train=0.784, test=0.794) total time=   8.5s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.744, test=0.736) f1: (train=0.787, test=0.778) total time=  17.2s\n",
      "[CV 1/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.778, test=0.776) total time=   2.5s\n",
      "[CV 3/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   4.6s\n",
      "[CV 1/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.777) total time=   1.2s\n",
      "[CV 3/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.776) total time=   1.3s\n",
      "[CV 4/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   2.1s\n",
      "[CV 1/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.778) total time=   4.3s\n",
      "[CV 3/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.786, test=0.783) total time=   5.5s\n",
      "[CV 3/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.785, test=0.782) total time=   8.6s\n",
      "[CV 4/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.741) f1: (train=0.786, test=0.783) total time=   9.2s\n",
      "[CV 5/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.870, test=0.874) balanced_accuracy: (train=0.742, test=0.751) f1: (train=0.785, test=0.794) total time=  15.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.737, test=0.731) f1: (train=0.780, test=0.773) total time=   1.5s\n",
      "[CV 4/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.779, test=0.776) total time=   2.1s\n",
      "[CV 3/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.779, test=0.776) total time=   2.5s\n",
      "[CV 3/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   3.8s\n",
      "[CV 2/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.864) balanced_accuracy: (train=0.735, test=0.729) f1: (train=0.778, test=0.771) total time=   1.6s\n",
      "[CV 5/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.866, test=0.870) balanced_accuracy: (train=0.733, test=0.742) f1: (train=0.776, test=0.785) total time=   1.4s\n",
      "[CV 4/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.779, test=0.776) total time=   1.8s\n",
      "[CV 3/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.779, test=0.776) total time=   2.1s\n",
      "[CV 5/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.866, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.786) total time=   4.2s\n",
      "[CV 2/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.872, test=0.867) balanced_accuracy: (train=0.745, test=0.737) f1: (train=0.788, test=0.779) total time=   5.6s\n",
      "[CV 5/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.870, test=0.874) balanced_accuracy: (train=0.742, test=0.751) f1: (train=0.785, test=0.794) total time=   9.1s\n",
      "[CV 2/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.744, test=0.736) f1: (train=0.787, test=0.779) total time=  18.4s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.776) total time=   1.5s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False),\n",
       "             estimator=RandomForestClassifier(max_depth=100, max_features=None,\n",
       "                                              max_leaf_nodes=100,\n",
       "                                              n_estimators=50, n_jobs=-1,\n",
       "                                              random_state=100),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;criterion&#x27;: [&#x27;gini&#x27;, &#x27;entropy&#x27;, &#x27;log_loss&#x27;],\n",
       "                         &#x27;max_depth&#x27;: [10, 40, None],\n",
       "                         &#x27;max_features&#x27;: [&#x27;sqrt&#x27;, &#x27;log2&#x27;, None],\n",
       "                         &#x27;n_estimators&#x27;: [30, 50, 100],\n",
       "                         &#x27;random_state&#x27;: [10, 30, 100]},\n",
       "             refit=&#x27;balanced_accuracy&#x27;, return_train_score=True,\n",
       "             scoring={&#x27;accuracy&#x27;: &#x27;accuracy&#x27;,\n",
       "                      &#x27;balanced_accuracy&#x27;: &#x27;balanced_accuracy&#x27;,\n",
       "                      &#x27;f1&#x27;: &#x27;f1_macro&#x27;},\n",
       "             verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False),\n",
       "             estimator=RandomForestClassifier(max_depth=100, max_features=None,\n",
       "                                              max_leaf_nodes=100,\n",
       "                                              n_estimators=50, n_jobs=-1,\n",
       "                                              random_state=100),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;criterion&#x27;: [&#x27;gini&#x27;, &#x27;entropy&#x27;, &#x27;log_loss&#x27;],\n",
       "                         &#x27;max_depth&#x27;: [10, 40, None],\n",
       "                         &#x27;max_features&#x27;: [&#x27;sqrt&#x27;, &#x27;log2&#x27;, None],\n",
       "                         &#x27;n_estimators&#x27;: [30, 50, 100],\n",
       "                         &#x27;random_state&#x27;: [10, 30, 100]},\n",
       "             refit=&#x27;balanced_accuracy&#x27;, return_train_score=True,\n",
       "             scoring={&#x27;accuracy&#x27;: &#x27;accuracy&#x27;,\n",
       "                      &#x27;balanced_accuracy&#x27;: &#x27;balanced_accuracy&#x27;,\n",
       "                      &#x27;f1&#x27;: &#x27;f1_macro&#x27;},\n",
       "             verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=100, max_features=None, max_leaf_nodes=100,\n",
       "                       n_estimators=50, n_jobs=-1, random_state=100)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=100, max_features=None, max_leaf_nodes=100,\n",
       "                       n_estimators=50, n_jobs=-1, random_state=100)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False),\n",
       "             estimator=RandomForestClassifier(max_depth=100, max_features=None,\n",
       "                                              max_leaf_nodes=100,\n",
       "                                              n_estimators=50, n_jobs=-1,\n",
       "                                              random_state=100),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'criterion': ['gini', 'entropy', 'log_loss'],\n",
       "                         'max_depth': [10, 40, None],\n",
       "                         'max_features': ['sqrt', 'log2', None],\n",
       "                         'n_estimators': [30, 50, 100],\n",
       "                         'random_state': [10, 30, 100]},\n",
       "             refit='balanced_accuracy', return_train_score=True,\n",
       "             scoring={'accuracy': 'accuracy',\n",
       "                      'balanced_accuracy': 'balanced_accuracy',\n",
       "                      'f1': 'f1_macro'},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "rf = RandomForestClassifier( n_jobs=-1, n_estimators=50, max_depth=100,max_leaf_nodes=100, random_state=100, max_features=None)\n",
    "\n",
    "parameter_grid = {\n",
    "    \"n_estimators\": [30, 50, 100],\n",
    "    \"max_depth\": [10, 40, None],\n",
    "    \"max_features\": [\"sqrt\",\"log2\", None],\n",
    "    \"random_state\":[10,30,100],\n",
    "    \"criterion\": ['gini', 'entropy', 'log_loss']\n",
    "}\n",
    "\n",
    "cross_validation = StratifiedKFold(n_splits=5)\n",
    "cross_validation.get_n_splits(train_data, np.ravel(y_train))\n",
    "\n",
    "# Create the scoring dictionary\n",
    "SCORING = {\n",
    "    \"accuracy\": \"accuracy\",\n",
    "    \"balanced_accuracy\": \"balanced_accuracy\",\n",
    "    \"f1\": \"f1_macro\",\n",
    "}\n",
    "\n",
    "# Create and fit the GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=rf,\n",
    "    param_grid=parameter_grid,\n",
    "    n_jobs=-1,\n",
    "    cv=cross_validation,\n",
    "    verbose=3,\n",
    "    scoring=SCORING,\n",
    "    return_train_score=True,\n",
    "    refit=\"balanced_accuracy\",\n",
    ")\n",
    "\n",
    "grid_search.fit(train_data, np.ravel(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "35a074af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.7444008926792822\n",
      "Best parameters: {'criterion': 'gini', 'max_depth': 40, 'max_features': None, 'n_estimators': 30, 'random_state': 10}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_depth=40, max_features=None, max_leaf_nodes=100,\n",
       "                       n_estimators=30, n_jobs=-1, random_state=10)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=40, max_features=None, max_leaf_nodes=100,\n",
       "                       n_estimators=30, n_jobs=-1, random_state=10)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(max_depth=40, max_features=None, max_leaf_nodes=100,\n",
       "                       n_estimators=30, n_jobs=-1, random_state=10)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Best score: {}\".format(grid_search.best_score_))\n",
    "print(\"Best parameters: {}\".format(grid_search.best_params_))\n",
    "\n",
    "best_dtc = grid_search.best_estimator_\n",
    "best_dtc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "69089f07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8695186056162678"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model = best_dtc\n",
    "my_model.fit(train_data, np.ravel(y_train))\n",
    "my_model.score(test_data, np.ravel(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b587ca52",
   "metadata": {},
   "source": [
    "EXTRA TREE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "594e3215",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "47a73cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "column = ['criterion','max_features', 'n_estimators', 'random_state', 'accuracy']\n",
    "column_bar = ['try', 'Parameter_changed', 'Accuracy']\n",
    "\n",
    "### Create a single row equivalent to a single try for decision tree\n",
    "def create_bar_row(criterion,feature, stimatori,random, attempt, parameter):\n",
    "  xt = ExtraTreesClassifier(criterion=criterion,max_features=feature,n_estimators=stimatori, random_state=random, n_jobs=-1 )\n",
    "  xt.fit(train_data, np.ravel(y_train))\n",
    "  testset_score = xt.score(test_data, y_test)\n",
    "  row = pd.DataFrame(data=[[attempt, parameter, testset_score]], columns=column_bar)\n",
    "  return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5ae9c61a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  try Parameter_changed  Accuracy\n",
      "0   1             start  0.857587\n",
      "0   2      max_features  0.857587\n",
      "0   3       n_estimator  0.858556\n",
      "0   4      random_state  0.858902\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'Score sul testset durante il tuning dei parametri'}, xlabel='Accuracy', ylabel='Parameter_changed'>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.DataFrame(columns=column_bar)\n",
    "df = pd.concat([df, create_bar_row('gini', 'log2', 20, 4, 1, 'start')]) # try 1\n",
    "df = pd.concat([df, create_bar_row('gini', 'sqrt', 20, 4, 2, 'max_features')]) # try 2\n",
    "df = pd.concat([df, create_bar_row('gini', 'sqrt', 120, 4, 3, 'n_estimator')]) # try 3\n",
    "df = pd.concat([df, create_bar_row('gini', 'log2', 120, 30, 4, 'random_state')]) # try 4\n",
    "\n",
    "print(df)\n",
    "\n",
    "fig, axs = plt.subplots()\n",
    "axs.set_xlim([0.70,0.89])\n",
    "axs.set_title(\"Score sul testset durante il tuning dei parametri\")\n",
    "\n",
    "sns.barplot(data=df, x='Accuracy',y=\"Parameter_changed\",ax=axs, orient=\"h\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4b44ba0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 36 candidates, totalling 360 fits\n",
      "[CV 1/10] END criterion=gini, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.740) f1: (train=1.000, test=0.774) total time=   1.8s\n",
      "[CV 2/10] END criterion=gini, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.863) balanced_accuracy: (train=1.000, test=0.747) f1: (train=1.000, test=0.783) total time=   1.2s\n",
      "[CV 3/10] END criterion=gini, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.740) f1: (train=1.000, test=0.774) total time=   1.1s\n",
      "[CV 4/10] END criterion=gini, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.739) f1: (train=1.000, test=0.775) total time=   1.2s\n",
      "[CV 5/10] END criterion=gini, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.745) f1: (train=1.000, test=0.781) total time=   1.2s\n",
      "[CV 6/10] END criterion=gini, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.743) f1: (train=1.000, test=0.777) total time=   1.3s\n",
      "[CV 7/10] END criterion=gini, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.860) balanced_accuracy: (train=1.000, test=0.744) f1: (train=1.000, test=0.778) total time=   1.2s\n",
      "[CV 8/10] END criterion=gini, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.743) f1: (train=1.000, test=0.777) total time=   1.2s\n",
      "[CV 9/10] END criterion=gini, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.861) balanced_accuracy: (train=1.000, test=0.747) f1: (train=1.000, test=0.781) total time=   1.2s\n",
      "[CV 10/10] END criterion=gini, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.863) balanced_accuracy: (train=1.000, test=0.754) f1: (train=1.000, test=0.787) total time=   1.3s\n",
      "[CV 1/10] END criterion=gini, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.855) balanced_accuracy: (train=1.000, test=0.739) f1: (train=1.000, test=0.772) total time=   1.3s\n",
      "[CV 2/10] END criterion=gini, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.864) balanced_accuracy: (train=1.000, test=0.749) f1: (train=1.000, test=0.785) total time=   1.3s\n",
      "[CV 3/10] END criterion=gini, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.856) balanced_accuracy: (train=1.000, test=0.738) f1: (train=1.000, test=0.772) total time=   1.2s\n",
      "[CV 4/10] END criterion=gini, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.738) f1: (train=1.000, test=0.773) total time=   1.2s\n",
      "[CV 5/10] END criterion=gini, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.745) f1: (train=1.000, test=0.781) total time=   1.3s\n",
      "[CV 6/10] END criterion=gini, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.860) balanced_accuracy: (train=1.000, test=0.743) f1: (train=1.000, test=0.777) total time=   1.2s\n",
      "[CV 7/10] END criterion=gini, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.741) f1: (train=1.000, test=0.775) total time=   1.1s\n",
      "[CV 8/10] END criterion=gini, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.742) f1: (train=1.000, test=0.777) total time=   1.2s\n",
      "[CV 9/10] END criterion=gini, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.861) balanced_accuracy: (train=1.000, test=0.748) f1: (train=1.000, test=0.781) total time=   1.2s\n",
      "[CV 10/10] END criterion=gini, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.752) f1: (train=1.000, test=0.785) total time=   1.2s\n",
      "[CV 1/10] END criterion=gini, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.741) f1: (train=1.000, test=0.775) total time=   1.1s\n",
      "[CV 2/10] END criterion=gini, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.861) balanced_accuracy: (train=1.000, test=0.744) f1: (train=1.000, test=0.780) total time=   1.2s\n",
      "[CV 3/10] END criterion=gini, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.856) balanced_accuracy: (train=1.000, test=0.738) f1: (train=1.000, test=0.772) total time=   1.3s\n",
      "[CV 4/10] END criterion=gini, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.737) f1: (train=1.000, test=0.772) total time=   1.2s\n",
      "[CV 5/10] END criterion=gini, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.863) balanced_accuracy: (train=1.000, test=0.747) f1: (train=1.000, test=0.782) total time=   1.4s\n",
      "[CV 6/10] END criterion=gini, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.744) f1: (train=1.000, test=0.777) total time=   1.3s\n",
      "[CV 7/10] END criterion=gini, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.741) f1: (train=1.000, test=0.775) total time=   1.4s\n",
      "[CV 8/10] END criterion=gini, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.740) f1: (train=1.000, test=0.775) total time=   1.2s\n",
      "[CV 9/10] END criterion=gini, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.863) balanced_accuracy: (train=1.000, test=0.749) f1: (train=1.000, test=0.783) total time=   1.3s\n",
      "[CV 10/10] END criterion=gini, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.863) balanced_accuracy: (train=1.000, test=0.753) f1: (train=1.000, test=0.786) total time=   1.2s\n",
      "[CV 1/10] END criterion=gini, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.740) f1: (train=1.000, test=0.774) total time=   2.1s\n",
      "[CV 2/10] END criterion=gini, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.863) balanced_accuracy: (train=1.000, test=0.747) f1: (train=1.000, test=0.783) total time=   2.1s\n",
      "[CV 3/10] END criterion=gini, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.740) f1: (train=1.000, test=0.773) total time=   2.1s\n",
      "[CV 4/10] END criterion=gini, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.738) f1: (train=1.000, test=0.773) total time=   2.1s\n",
      "[CV 5/10] END criterion=gini, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.863) balanced_accuracy: (train=1.000, test=0.747) f1: (train=1.000, test=0.782) total time=   2.2s\n",
      "[CV 6/10] END criterion=gini, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.744) f1: (train=1.000, test=0.778) total time=   2.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 7/10] END criterion=gini, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.743) f1: (train=1.000, test=0.777) total time=   2.1s\n",
      "[CV 8/10] END criterion=gini, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.860) balanced_accuracy: (train=1.000, test=0.743) f1: (train=1.000, test=0.778) total time=   2.1s\n",
      "[CV 9/10] END criterion=gini, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.747) f1: (train=1.000, test=0.782) total time=   2.1s\n",
      "[CV 10/10] END criterion=gini, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.752) f1: (train=1.000, test=0.785) total time=   2.1s\n",
      "[CV 1/10] END criterion=gini, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.741) f1: (train=1.000, test=0.774) total time=   2.1s\n",
      "[CV 2/10] END criterion=gini, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.863) balanced_accuracy: (train=1.000, test=0.747) f1: (train=1.000, test=0.783) total time=   2.1s\n",
      "[CV 3/10] END criterion=gini, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.856) balanced_accuracy: (train=1.000, test=0.739) f1: (train=1.000, test=0.773) total time=   2.0s\n",
      "[CV 4/10] END criterion=gini, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.737) f1: (train=1.000, test=0.772) total time=   2.2s\n",
      "[CV 5/10] END criterion=gini, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.745) f1: (train=1.000, test=0.780) total time=   2.0s\n",
      "[CV 6/10] END criterion=gini, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.860) balanced_accuracy: (train=1.000, test=0.743) f1: (train=1.000, test=0.777) total time=   2.2s\n",
      "[CV 7/10] END criterion=gini, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.742) f1: (train=1.000, test=0.776) total time=   2.1s\n",
      "[CV 8/10] END criterion=gini, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.743) f1: (train=1.000, test=0.777) total time=   2.0s\n",
      "[CV 9/10] END criterion=gini, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.861) balanced_accuracy: (train=1.000, test=0.748) f1: (train=1.000, test=0.782) total time=   2.1s\n",
      "[CV 10/10] END criterion=gini, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.863) balanced_accuracy: (train=1.000, test=0.754) f1: (train=1.000, test=0.787) total time=   2.0s\n",
      "[CV 1/10] END criterion=gini, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.856) balanced_accuracy: (train=1.000, test=0.740) f1: (train=1.000, test=0.773) total time=   2.1s\n",
      "[CV 2/10] END criterion=gini, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.865) balanced_accuracy: (train=1.000, test=0.749) f1: (train=1.000, test=0.785) total time=   2.1s\n",
      "[CV 3/10] END criterion=gini, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.856) balanced_accuracy: (train=1.000, test=0.738) f1: (train=1.000, test=0.771) total time=   2.0s\n",
      "[CV 4/10] END criterion=gini, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.739) f1: (train=1.000, test=0.774) total time=   2.0s\n",
      "[CV 5/10] END criterion=gini, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.747) f1: (train=1.000, test=0.782) total time=   2.0s\n",
      "[CV 6/10] END criterion=gini, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.742) f1: (train=1.000, test=0.776) total time=   2.0s\n",
      "[CV 7/10] END criterion=gini, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.742) f1: (train=1.000, test=0.775) total time=   2.0s\n",
      "[CV 8/10] END criterion=gini, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.860) balanced_accuracy: (train=1.000, test=0.743) f1: (train=1.000, test=0.778) total time=   2.1s\n",
      "[CV 9/10] END criterion=gini, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.748) f1: (train=1.000, test=0.783) total time=   2.0s\n",
      "[CV 10/10] END criterion=gini, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.754) f1: (train=1.000, test=0.786) total time=   2.0s\n",
      "[CV 1/10] END criterion=gini, max_features=log2, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.740) f1: (train=1.000, test=0.774) total time=   1.2s\n",
      "[CV 2/10] END criterion=gini, max_features=log2, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.863) balanced_accuracy: (train=1.000, test=0.747) f1: (train=1.000, test=0.783) total time=   1.1s\n",
      "[CV 3/10] END criterion=gini, max_features=log2, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.740) f1: (train=1.000, test=0.774) total time=   1.1s\n",
      "[CV 4/10] END criterion=gini, max_features=log2, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.739) f1: (train=1.000, test=0.775) total time=   1.1s\n",
      "[CV 5/10] END criterion=gini, max_features=log2, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.745) f1: (train=1.000, test=0.781) total time=   1.1s\n",
      "[CV 6/10] END criterion=gini, max_features=log2, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.743) f1: (train=1.000, test=0.777) total time=   1.1s\n",
      "[CV 7/10] END criterion=gini, max_features=log2, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.860) balanced_accuracy: (train=1.000, test=0.744) f1: (train=1.000, test=0.778) total time=   1.1s\n",
      "[CV 8/10] END criterion=gini, max_features=log2, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.743) f1: (train=1.000, test=0.777) total time=   1.2s\n",
      "[CV 9/10] END criterion=gini, max_features=log2, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.861) balanced_accuracy: (train=1.000, test=0.747) f1: (train=1.000, test=0.781) total time=   1.1s\n",
      "[CV 10/10] END criterion=gini, max_features=log2, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.863) balanced_accuracy: (train=1.000, test=0.754) f1: (train=1.000, test=0.787) total time=   1.1s\n",
      "[CV 1/10] END criterion=gini, max_features=log2, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.855) balanced_accuracy: (train=1.000, test=0.739) f1: (train=1.000, test=0.772) total time=   1.1s\n",
      "[CV 2/10] END criterion=gini, max_features=log2, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.864) balanced_accuracy: (train=1.000, test=0.749) f1: (train=1.000, test=0.785) total time=   1.1s\n",
      "[CV 3/10] END criterion=gini, max_features=log2, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.856) balanced_accuracy: (train=1.000, test=0.738) f1: (train=1.000, test=0.772) total time=   1.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/10] END criterion=gini, max_features=log2, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.738) f1: (train=1.000, test=0.773) total time=   1.1s\n",
      "[CV 5/10] END criterion=gini, max_features=log2, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.745) f1: (train=1.000, test=0.781) total time=   1.1s\n",
      "[CV 6/10] END criterion=gini, max_features=log2, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.860) balanced_accuracy: (train=1.000, test=0.743) f1: (train=1.000, test=0.777) total time=   1.1s\n",
      "[CV 7/10] END criterion=gini, max_features=log2, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.741) f1: (train=1.000, test=0.775) total time=   1.1s\n",
      "[CV 8/10] END criterion=gini, max_features=log2, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.742) f1: (train=1.000, test=0.777) total time=   1.1s\n",
      "[CV 9/10] END criterion=gini, max_features=log2, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.861) balanced_accuracy: (train=1.000, test=0.748) f1: (train=1.000, test=0.781) total time=   1.2s\n",
      "[CV 10/10] END criterion=gini, max_features=log2, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.752) f1: (train=1.000, test=0.785) total time=   1.1s\n",
      "[CV 1/10] END criterion=gini, max_features=log2, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.740) f1: (train=1.000, test=0.774) total time=   1.1s\n",
      "[CV 2/10] END criterion=gini, max_features=log2, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.864) balanced_accuracy: (train=1.000, test=0.748) f1: (train=1.000, test=0.784) total time=   1.1s\n",
      "[CV 3/10] END criterion=gini, max_features=log2, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.739) f1: (train=1.000, test=0.773) total time=   1.1s\n",
      "[CV 4/10] END criterion=gini, max_features=log2, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.739) f1: (train=1.000, test=0.774) total time=   1.1s\n",
      "[CV 5/10] END criterion=gini, max_features=log2, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.861) balanced_accuracy: (train=1.000, test=0.745) f1: (train=1.000, test=0.780) total time=   1.1s\n",
      "[CV 6/10] END criterion=gini, max_features=log2, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.743) f1: (train=1.000, test=0.776) total time=   1.2s\n",
      "[CV 7/10] END criterion=gini, max_features=log2, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.743) f1: (train=1.000, test=0.777) total time=   1.2s\n",
      "[CV 8/10] END criterion=gini, max_features=log2, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.741) f1: (train=1.000, test=0.775) total time=   1.2s\n",
      "[CV 9/10] END criterion=gini, max_features=log2, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.863) balanced_accuracy: (train=1.000, test=0.750) f1: (train=1.000, test=0.784) total time=   1.2s\n",
      "[CV 10/10] END criterion=gini, max_features=log2, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.754) f1: (train=1.000, test=0.786) total time=   1.2s\n",
      "[CV 1/10] END criterion=gini, max_features=log2, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.740) f1: (train=1.000, test=0.774) total time=   2.1s\n",
      "[CV 2/10] END criterion=gini, max_features=log2, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.863) balanced_accuracy: (train=1.000, test=0.747) f1: (train=1.000, test=0.783) total time=   2.0s\n",
      "[CV 3/10] END criterion=gini, max_features=log2, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.740) f1: (train=1.000, test=0.773) total time=   2.1s\n",
      "[CV 4/10] END criterion=gini, max_features=log2, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.738) f1: (train=1.000, test=0.773) total time=   2.0s\n",
      "[CV 5/10] END criterion=gini, max_features=log2, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.863) balanced_accuracy: (train=1.000, test=0.747) f1: (train=1.000, test=0.782) total time=   2.1s\n",
      "[CV 6/10] END criterion=gini, max_features=log2, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.744) f1: (train=1.000, test=0.778) total time=   2.1s\n",
      "[CV 7/10] END criterion=gini, max_features=log2, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.743) f1: (train=1.000, test=0.777) total time=   2.1s\n",
      "[CV 8/10] END criterion=gini, max_features=log2, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.860) balanced_accuracy: (train=1.000, test=0.743) f1: (train=1.000, test=0.778) total time=   2.1s\n",
      "[CV 9/10] END criterion=gini, max_features=log2, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.747) f1: (train=1.000, test=0.782) total time=   2.1s\n",
      "[CV 10/10] END criterion=gini, max_features=log2, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.752) f1: (train=1.000, test=0.785) total time=   2.1s\n",
      "[CV 1/10] END criterion=gini, max_features=log2, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.741) f1: (train=1.000, test=0.774) total time=   2.1s\n",
      "[CV 2/10] END criterion=gini, max_features=log2, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.863) balanced_accuracy: (train=1.000, test=0.747) f1: (train=1.000, test=0.783) total time=   2.0s\n",
      "[CV 3/10] END criterion=gini, max_features=log2, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.856) balanced_accuracy: (train=1.000, test=0.739) f1: (train=1.000, test=0.773) total time=   2.0s\n",
      "[CV 4/10] END criterion=gini, max_features=log2, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.737) f1: (train=1.000, test=0.772) total time=   2.1s\n",
      "[CV 5/10] END criterion=gini, max_features=log2, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.745) f1: (train=1.000, test=0.780) total time=   2.0s\n",
      "[CV 6/10] END criterion=gini, max_features=log2, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.860) balanced_accuracy: (train=1.000, test=0.743) f1: (train=1.000, test=0.777) total time=   2.0s\n",
      "[CV 7/10] END criterion=gini, max_features=log2, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.742) f1: (train=1.000, test=0.776) total time=   2.0s\n",
      "[CV 8/10] END criterion=gini, max_features=log2, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.743) f1: (train=1.000, test=0.777) total time=   2.1s\n",
      "[CV 9/10] END criterion=gini, max_features=log2, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.861) balanced_accuracy: (train=1.000, test=0.748) f1: (train=1.000, test=0.782) total time=   2.1s\n",
      "[CV 10/10] END criterion=gini, max_features=log2, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.863) balanced_accuracy: (train=1.000, test=0.754) f1: (train=1.000, test=0.787) total time=   2.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/10] END criterion=gini, max_features=log2, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.741) f1: (train=1.000, test=0.774) total time=   2.2s\n",
      "[CV 2/10] END criterion=gini, max_features=log2, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.865) balanced_accuracy: (train=1.000, test=0.749) f1: (train=1.000, test=0.785) total time=   2.3s\n",
      "[CV 3/10] END criterion=gini, max_features=log2, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.740) f1: (train=1.000, test=0.773) total time=   2.4s\n",
      "[CV 4/10] END criterion=gini, max_features=log2, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.740) f1: (train=1.000, test=0.775) total time=   2.2s\n",
      "[CV 5/10] END criterion=gini, max_features=log2, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.746) f1: (train=1.000, test=0.781) total time=   2.3s\n",
      "[CV 6/10] END criterion=gini, max_features=log2, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.742) f1: (train=1.000, test=0.776) total time=   2.3s\n",
      "[CV 7/10] END criterion=gini, max_features=log2, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.856) balanced_accuracy: (train=1.000, test=0.740) f1: (train=1.000, test=0.773) total time=   2.2s\n",
      "[CV 8/10] END criterion=gini, max_features=log2, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.742) f1: (train=1.000, test=0.776) total time=   2.2s\n",
      "[CV 9/10] END criterion=gini, max_features=log2, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.861) balanced_accuracy: (train=1.000, test=0.747) f1: (train=1.000, test=0.782) total time=   2.1s\n",
      "[CV 10/10] END criterion=gini, max_features=log2, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.863) balanced_accuracy: (train=1.000, test=0.754) f1: (train=1.000, test=0.787) total time=   2.2s\n",
      "[CV 1/10] END criterion=entropy, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.855) balanced_accuracy: (train=1.000, test=0.738) f1: (train=1.000, test=0.771) total time=   1.2s\n",
      "[CV 2/10] END criterion=entropy, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.863) balanced_accuracy: (train=1.000, test=0.747) f1: (train=1.000, test=0.783) total time=   1.2s\n",
      "[CV 3/10] END criterion=entropy, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.856) balanced_accuracy: (train=1.000, test=0.739) f1: (train=1.000, test=0.772) total time=   1.2s\n",
      "[CV 4/10] END criterion=entropy, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.740) f1: (train=1.000, test=0.774) total time=   1.2s\n",
      "[CV 5/10] END criterion=entropy, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.861) balanced_accuracy: (train=1.000, test=0.745) f1: (train=1.000, test=0.779) total time=   1.2s\n",
      "[CV 6/10] END criterion=entropy, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.742) f1: (train=1.000, test=0.776) total time=   1.2s\n",
      "[CV 7/10] END criterion=entropy, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.741) f1: (train=1.000, test=0.775) total time=   1.2s\n",
      "[CV 8/10] END criterion=entropy, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.742) f1: (train=1.000, test=0.776) total time=   1.2s\n",
      "[CV 9/10] END criterion=entropy, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.861) balanced_accuracy: (train=1.000, test=0.747) f1: (train=1.000, test=0.781) total time=   1.2s\n",
      "[CV 10/10] END criterion=entropy, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.753) f1: (train=1.000, test=0.785) total time=   1.2s\n",
      "[CV 1/10] END criterion=entropy, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.856) balanced_accuracy: (train=1.000, test=0.739) f1: (train=1.000, test=0.772) total time=   1.3s\n",
      "[CV 2/10] END criterion=entropy, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.865) balanced_accuracy: (train=1.000, test=0.749) f1: (train=1.000, test=0.785) total time=   1.2s\n",
      "[CV 3/10] END criterion=entropy, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.740) f1: (train=1.000, test=0.774) total time=   1.2s\n",
      "[CV 4/10] END criterion=entropy, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.738) f1: (train=1.000, test=0.772) total time=   1.2s\n",
      "[CV 5/10] END criterion=entropy, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.861) balanced_accuracy: (train=1.000, test=0.745) f1: (train=1.000, test=0.780) total time=   1.2s\n",
      "[CV 6/10] END criterion=entropy, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.742) f1: (train=1.000, test=0.776) total time=   1.2s\n",
      "[CV 7/10] END criterion=entropy, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.855) balanced_accuracy: (train=1.000, test=0.739) f1: (train=1.000, test=0.771) total time=   1.2s\n",
      "[CV 8/10] END criterion=entropy, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.741) f1: (train=1.000, test=0.776) total time=   1.2s\n",
      "[CV 9/10] END criterion=entropy, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.860) balanced_accuracy: (train=1.000, test=0.746) f1: (train=1.000, test=0.779) total time=   1.1s\n",
      "[CV 10/10] END criterion=entropy, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.753) f1: (train=1.000, test=0.785) total time=   1.2s\n",
      "[CV 1/10] END criterion=entropy, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.740) f1: (train=1.000, test=0.774) total time=   1.1s\n",
      "[CV 2/10] END criterion=entropy, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.863) balanced_accuracy: (train=1.000, test=0.748) f1: (train=1.000, test=0.783) total time=   1.3s\n",
      "[CV 3/10] END criterion=entropy, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.856) balanced_accuracy: (train=1.000, test=0.739) f1: (train=1.000, test=0.772) total time=   1.2s\n",
      "[CV 4/10] END criterion=entropy, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.739) f1: (train=1.000, test=0.773) total time=   1.2s\n",
      "[CV 5/10] END criterion=entropy, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.746) f1: (train=1.000, test=0.782) total time=   1.2s\n",
      "[CV 6/10] END criterion=entropy, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.860) balanced_accuracy: (train=1.000, test=0.744) f1: (train=1.000, test=0.778) total time=   1.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 7/10] END criterion=entropy, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.740) f1: (train=1.000, test=0.774) total time=   1.2s\n",
      "[CV 8/10] END criterion=entropy, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.743) f1: (train=1.000, test=0.777) total time=   1.2s\n",
      "[CV 9/10] END criterion=entropy, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.860) balanced_accuracy: (train=1.000, test=0.746) f1: (train=1.000, test=0.780) total time=   1.2s\n",
      "[CV 10/10] END criterion=entropy, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.752) f1: (train=1.000, test=0.785) total time=   1.2s\n",
      "[CV 1/10] END criterion=entropy, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.855) balanced_accuracy: (train=1.000, test=0.738) f1: (train=1.000, test=0.771) total time=   2.2s\n",
      "[CV 2/10] END criterion=entropy, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.864) balanced_accuracy: (train=1.000, test=0.747) f1: (train=1.000, test=0.783) total time=   2.2s\n",
      "[CV 3/10] END criterion=entropy, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.856) balanced_accuracy: (train=1.000, test=0.739) f1: (train=1.000, test=0.772) total time=   2.2s\n",
      "[CV 4/10] END criterion=entropy, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.739) f1: (train=1.000, test=0.774) total time=   2.1s\n",
      "[CV 5/10] END criterion=entropy, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.861) balanced_accuracy: (train=1.000, test=0.745) f1: (train=1.000, test=0.780) total time=   2.2s\n",
      "[CV 6/10] END criterion=entropy, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.740) f1: (train=1.000, test=0.774) total time=   2.1s\n",
      "[CV 7/10] END criterion=entropy, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.742) f1: (train=1.000, test=0.776) total time=   2.2s\n",
      "[CV 8/10] END criterion=entropy, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.743) f1: (train=1.000, test=0.777) total time=   2.2s\n",
      "[CV 9/10] END criterion=entropy, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.748) f1: (train=1.000, test=0.782) total time=   2.2s\n",
      "[CV 10/10] END criterion=entropy, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.863) balanced_accuracy: (train=1.000, test=0.752) f1: (train=1.000, test=0.785) total time=   2.1s\n",
      "[CV 1/10] END criterion=entropy, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.856) balanced_accuracy: (train=1.000, test=0.739) f1: (train=1.000, test=0.772) total time=   2.2s\n",
      "[CV 2/10] END criterion=entropy, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.865) balanced_accuracy: (train=1.000, test=0.748) f1: (train=1.000, test=0.784) total time=   2.1s\n",
      "[CV 3/10] END criterion=entropy, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.856) balanced_accuracy: (train=1.000, test=0.739) f1: (train=1.000, test=0.772) total time=   2.1s\n",
      "[CV 4/10] END criterion=entropy, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.736) f1: (train=1.000, test=0.771) total time=   2.1s\n",
      "[CV 5/10] END criterion=entropy, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.861) balanced_accuracy: (train=1.000, test=0.744) f1: (train=1.000, test=0.779) total time=   2.1s\n",
      "[CV 6/10] END criterion=entropy, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.742) f1: (train=1.000, test=0.776) total time=   2.1s\n",
      "[CV 7/10] END criterion=entropy, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.856) balanced_accuracy: (train=1.000, test=0.740) f1: (train=1.000, test=0.773) total time=   2.1s\n",
      "[CV 8/10] END criterion=entropy, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.860) balanced_accuracy: (train=1.000, test=0.742) f1: (train=1.000, test=0.777) total time=   2.1s\n",
      "[CV 9/10] END criterion=entropy, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.861) balanced_accuracy: (train=1.000, test=0.747) f1: (train=1.000, test=0.781) total time=   2.1s\n",
      "[CV 10/10] END criterion=entropy, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.863) balanced_accuracy: (train=1.000, test=0.753) f1: (train=1.000, test=0.786) total time=   2.1s\n",
      "[CV 1/10] END criterion=entropy, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.740) f1: (train=1.000, test=0.774) total time=   2.1s\n",
      "[CV 2/10] END criterion=entropy, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.864) balanced_accuracy: (train=1.000, test=0.748) f1: (train=1.000, test=0.784) total time=   2.2s\n",
      "[CV 3/10] END criterion=entropy, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.740) f1: (train=1.000, test=0.774) total time=   2.1s\n",
      "[CV 4/10] END criterion=entropy, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.740) f1: (train=1.000, test=0.775) total time=   2.1s\n",
      "[CV 5/10] END criterion=entropy, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.863) balanced_accuracy: (train=1.000, test=0.747) f1: (train=1.000, test=0.782) total time=   2.1s\n",
      "[CV 6/10] END criterion=entropy, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.743) f1: (train=1.000, test=0.777) total time=   2.1s\n",
      "[CV 7/10] END criterion=entropy, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.740) f1: (train=1.000, test=0.773) total time=   2.1s\n",
      "[CV 8/10] END criterion=entropy, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.861) balanced_accuracy: (train=1.000, test=0.743) f1: (train=1.000, test=0.779) total time=   2.0s\n",
      "[CV 9/10] END criterion=entropy, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.748) f1: (train=1.000, test=0.782) total time=   2.0s\n",
      "[CV 10/10] END criterion=entropy, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.752) f1: (train=1.000, test=0.785) total time=   2.0s\n",
      "[CV 1/10] END criterion=entropy, max_features=log2, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.855) balanced_accuracy: (train=1.000, test=0.738) f1: (train=1.000, test=0.771) total time=   1.1s\n",
      "[CV 2/10] END criterion=entropy, max_features=log2, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.863) balanced_accuracy: (train=1.000, test=0.747) f1: (train=1.000, test=0.783) total time=   1.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/10] END criterion=entropy, max_features=log2, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.856) balanced_accuracy: (train=1.000, test=0.739) f1: (train=1.000, test=0.772) total time=   1.1s\n",
      "[CV 4/10] END criterion=entropy, max_features=log2, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.740) f1: (train=1.000, test=0.774) total time=   1.1s\n",
      "[CV 5/10] END criterion=entropy, max_features=log2, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.861) balanced_accuracy: (train=1.000, test=0.745) f1: (train=1.000, test=0.779) total time=   1.1s\n",
      "[CV 6/10] END criterion=entropy, max_features=log2, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.742) f1: (train=1.000, test=0.776) total time=   1.1s\n",
      "[CV 7/10] END criterion=entropy, max_features=log2, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.741) f1: (train=1.000, test=0.775) total time=   1.1s\n",
      "[CV 8/10] END criterion=entropy, max_features=log2, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.742) f1: (train=1.000, test=0.776) total time=   1.1s\n",
      "[CV 9/10] END criterion=entropy, max_features=log2, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.861) balanced_accuracy: (train=1.000, test=0.747) f1: (train=1.000, test=0.781) total time=   1.1s\n",
      "[CV 10/10] END criterion=entropy, max_features=log2, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.753) f1: (train=1.000, test=0.785) total time=   1.1s\n",
      "[CV 1/10] END criterion=entropy, max_features=log2, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.856) balanced_accuracy: (train=1.000, test=0.739) f1: (train=1.000, test=0.772) total time=   1.1s\n",
      "[CV 2/10] END criterion=entropy, max_features=log2, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.865) balanced_accuracy: (train=1.000, test=0.749) f1: (train=1.000, test=0.785) total time=   1.1s\n",
      "[CV 3/10] END criterion=entropy, max_features=log2, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.740) f1: (train=1.000, test=0.774) total time=   1.1s\n",
      "[CV 4/10] END criterion=entropy, max_features=log2, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.738) f1: (train=1.000, test=0.772) total time=   1.2s\n",
      "[CV 5/10] END criterion=entropy, max_features=log2, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.861) balanced_accuracy: (train=1.000, test=0.745) f1: (train=1.000, test=0.780) total time=   1.2s\n",
      "[CV 6/10] END criterion=entropy, max_features=log2, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.742) f1: (train=1.000, test=0.776) total time=   1.1s\n",
      "[CV 7/10] END criterion=entropy, max_features=log2, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.855) balanced_accuracy: (train=1.000, test=0.739) f1: (train=1.000, test=0.771) total time=   1.1s\n",
      "[CV 8/10] END criterion=entropy, max_features=log2, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.741) f1: (train=1.000, test=0.776) total time=   1.1s\n",
      "[CV 9/10] END criterion=entropy, max_features=log2, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.860) balanced_accuracy: (train=1.000, test=0.746) f1: (train=1.000, test=0.779) total time=   1.1s\n",
      "[CV 10/10] END criterion=entropy, max_features=log2, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.753) f1: (train=1.000, test=0.785) total time=   1.3s\n",
      "[CV 1/10] END criterion=entropy, max_features=log2, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.856) balanced_accuracy: (train=1.000, test=0.739) f1: (train=1.000, test=0.773) total time=   1.3s\n",
      "[CV 2/10] END criterion=entropy, max_features=log2, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.864) balanced_accuracy: (train=1.000, test=0.747) f1: (train=1.000, test=0.784) total time=   1.3s\n",
      "[CV 3/10] END criterion=entropy, max_features=log2, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.739) f1: (train=1.000, test=0.773) total time=   1.4s\n",
      "[CV 4/10] END criterion=entropy, max_features=log2, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.740) f1: (train=1.000, test=0.775) total time=   1.3s\n",
      "[CV 5/10] END criterion=entropy, max_features=log2, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.863) balanced_accuracy: (train=1.000, test=0.747) f1: (train=1.000, test=0.783) total time=   1.4s\n",
      "[CV 6/10] END criterion=entropy, max_features=log2, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.742) f1: (train=1.000, test=0.775) total time=   1.3s\n",
      "[CV 7/10] END criterion=entropy, max_features=log2, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.740) f1: (train=1.000, test=0.773) total time=   1.4s\n",
      "[CV 8/10] END criterion=entropy, max_features=log2, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.860) balanced_accuracy: (train=1.000, test=0.743) f1: (train=1.000, test=0.778) total time=   1.2s\n",
      "[CV 9/10] END criterion=entropy, max_features=log2, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.750) f1: (train=1.000, test=0.783) total time=   1.4s\n",
      "[CV 10/10] END criterion=entropy, max_features=log2, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.752) f1: (train=1.000, test=0.785) total time=   1.3s\n",
      "[CV 1/10] END criterion=entropy, max_features=log2, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.855) balanced_accuracy: (train=1.000, test=0.738) f1: (train=1.000, test=0.771) total time=   2.4s\n",
      "[CV 2/10] END criterion=entropy, max_features=log2, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.864) balanced_accuracy: (train=1.000, test=0.747) f1: (train=1.000, test=0.783) total time=   2.2s\n",
      "[CV 3/10] END criterion=entropy, max_features=log2, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.856) balanced_accuracy: (train=1.000, test=0.739) f1: (train=1.000, test=0.772) total time=   2.2s\n",
      "[CV 4/10] END criterion=entropy, max_features=log2, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.739) f1: (train=1.000, test=0.774) total time=   2.2s\n",
      "[CV 5/10] END criterion=entropy, max_features=log2, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.861) balanced_accuracy: (train=1.000, test=0.745) f1: (train=1.000, test=0.780) total time=   2.1s\n",
      "[CV 6/10] END criterion=entropy, max_features=log2, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.740) f1: (train=1.000, test=0.774) total time=   2.2s\n",
      "[CV 7/10] END criterion=entropy, max_features=log2, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.742) f1: (train=1.000, test=0.776) total time=   2.2s\n",
      "[CV 8/10] END criterion=entropy, max_features=log2, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.743) f1: (train=1.000, test=0.777) total time=   2.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 9/10] END criterion=entropy, max_features=log2, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.748) f1: (train=1.000, test=0.782) total time=   2.1s\n",
      "[CV 10/10] END criterion=entropy, max_features=log2, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.863) balanced_accuracy: (train=1.000, test=0.752) f1: (train=1.000, test=0.785) total time=   2.1s\n",
      "[CV 1/10] END criterion=entropy, max_features=log2, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.856) balanced_accuracy: (train=1.000, test=0.739) f1: (train=1.000, test=0.772) total time=   2.2s\n",
      "[CV 2/10] END criterion=entropy, max_features=log2, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.865) balanced_accuracy: (train=1.000, test=0.748) f1: (train=1.000, test=0.784) total time=   2.1s\n",
      "[CV 3/10] END criterion=entropy, max_features=log2, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.856) balanced_accuracy: (train=1.000, test=0.739) f1: (train=1.000, test=0.772) total time=   2.1s\n",
      "[CV 4/10] END criterion=entropy, max_features=log2, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.736) f1: (train=1.000, test=0.771) total time=   2.1s\n",
      "[CV 5/10] END criterion=entropy, max_features=log2, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.861) balanced_accuracy: (train=1.000, test=0.744) f1: (train=1.000, test=0.779) total time=   2.1s\n",
      "[CV 6/10] END criterion=entropy, max_features=log2, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.742) f1: (train=1.000, test=0.776) total time=   2.1s\n",
      "[CV 7/10] END criterion=entropy, max_features=log2, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.856) balanced_accuracy: (train=1.000, test=0.740) f1: (train=1.000, test=0.773) total time=   2.1s\n",
      "[CV 8/10] END criterion=entropy, max_features=log2, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.860) balanced_accuracy: (train=1.000, test=0.742) f1: (train=1.000, test=0.777) total time=   2.1s\n",
      "[CV 9/10] END criterion=entropy, max_features=log2, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.861) balanced_accuracy: (train=1.000, test=0.747) f1: (train=1.000, test=0.781) total time=   2.1s\n",
      "[CV 10/10] END criterion=entropy, max_features=log2, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.863) balanced_accuracy: (train=1.000, test=0.753) f1: (train=1.000, test=0.786) total time=   2.1s\n",
      "[CV 1/10] END criterion=entropy, max_features=log2, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.856) balanced_accuracy: (train=1.000, test=0.739) f1: (train=1.000, test=0.772) total time=   2.1s\n",
      "[CV 2/10] END criterion=entropy, max_features=log2, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.864) balanced_accuracy: (train=1.000, test=0.748) f1: (train=1.000, test=0.784) total time=   2.1s\n",
      "[CV 3/10] END criterion=entropy, max_features=log2, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.856) balanced_accuracy: (train=1.000, test=0.739) f1: (train=1.000, test=0.772) total time=   2.1s\n",
      "[CV 4/10] END criterion=entropy, max_features=log2, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.738) f1: (train=1.000, test=0.773) total time=   2.1s\n",
      "[CV 5/10] END criterion=entropy, max_features=log2, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.746) f1: (train=1.000, test=0.781) total time=   2.1s\n",
      "[CV 6/10] END criterion=entropy, max_features=log2, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.743) f1: (train=1.000, test=0.777) total time=   2.1s\n",
      "[CV 7/10] END criterion=entropy, max_features=log2, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.741) f1: (train=1.000, test=0.775) total time=   2.1s\n",
      "[CV 8/10] END criterion=entropy, max_features=log2, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.860) balanced_accuracy: (train=1.000, test=0.743) f1: (train=1.000, test=0.778) total time=   2.1s\n",
      "[CV 9/10] END criterion=entropy, max_features=log2, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.861) balanced_accuracy: (train=1.000, test=0.748) f1: (train=1.000, test=0.781) total time=   2.1s\n",
      "[CV 10/10] END criterion=entropy, max_features=log2, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.861) balanced_accuracy: (train=1.000, test=0.751) f1: (train=1.000, test=0.783) total time=   2.1s\n",
      "[CV 1/10] END criterion=log_loss, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.855) balanced_accuracy: (train=1.000, test=0.738) f1: (train=1.000, test=0.771) total time=   1.1s\n",
      "[CV 2/10] END criterion=log_loss, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.863) balanced_accuracy: (train=1.000, test=0.747) f1: (train=1.000, test=0.783) total time=   1.1s\n",
      "[CV 3/10] END criterion=log_loss, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.856) balanced_accuracy: (train=1.000, test=0.739) f1: (train=1.000, test=0.772) total time=   1.1s\n",
      "[CV 4/10] END criterion=log_loss, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.740) f1: (train=1.000, test=0.774) total time=   1.1s\n",
      "[CV 5/10] END criterion=log_loss, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.861) balanced_accuracy: (train=1.000, test=0.745) f1: (train=1.000, test=0.779) total time=   1.1s\n",
      "[CV 6/10] END criterion=log_loss, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.742) f1: (train=1.000, test=0.776) total time=   1.1s\n",
      "[CV 7/10] END criterion=log_loss, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.741) f1: (train=1.000, test=0.775) total time=   1.1s\n",
      "[CV 8/10] END criterion=log_loss, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.742) f1: (train=1.000, test=0.776) total time=   1.1s\n",
      "[CV 9/10] END criterion=log_loss, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.861) balanced_accuracy: (train=1.000, test=0.747) f1: (train=1.000, test=0.781) total time=   1.1s\n",
      "[CV 10/10] END criterion=log_loss, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.753) f1: (train=1.000, test=0.785) total time=   1.1s\n",
      "[CV 1/10] END criterion=log_loss, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.856) balanced_accuracy: (train=1.000, test=0.739) f1: (train=1.000, test=0.772) total time=   1.1s\n",
      "[CV 2/10] END criterion=log_loss, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.865) balanced_accuracy: (train=1.000, test=0.749) f1: (train=1.000, test=0.785) total time=   1.1s\n",
      "[CV 3/10] END criterion=log_loss, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.740) f1: (train=1.000, test=0.774) total time=   1.1s\n",
      "[CV 4/10] END criterion=log_loss, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.738) f1: (train=1.000, test=0.772) total time=   1.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/10] END criterion=log_loss, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.861) balanced_accuracy: (train=1.000, test=0.745) f1: (train=1.000, test=0.780) total time=   1.1s\n",
      "[CV 6/10] END criterion=log_loss, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.742) f1: (train=1.000, test=0.776) total time=   1.0s\n",
      "[CV 7/10] END criterion=log_loss, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.855) balanced_accuracy: (train=1.000, test=0.739) f1: (train=1.000, test=0.771) total time=   1.1s\n",
      "[CV 8/10] END criterion=log_loss, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.741) f1: (train=1.000, test=0.776) total time=   1.1s\n",
      "[CV 9/10] END criterion=log_loss, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.860) balanced_accuracy: (train=1.000, test=0.746) f1: (train=1.000, test=0.779) total time=   1.1s\n",
      "[CV 10/10] END criterion=log_loss, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.753) f1: (train=1.000, test=0.785) total time=   1.1s\n",
      "[CV 1/10] END criterion=log_loss, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.856) balanced_accuracy: (train=1.000, test=0.740) f1: (train=1.000, test=0.773) total time=   1.2s\n",
      "[CV 2/10] END criterion=log_loss, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.864) balanced_accuracy: (train=1.000, test=0.749) f1: (train=1.000, test=0.785) total time=   1.1s\n",
      "[CV 3/10] END criterion=log_loss, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.856) balanced_accuracy: (train=1.000, test=0.738) f1: (train=1.000, test=0.772) total time=   1.2s\n",
      "[CV 4/10] END criterion=log_loss, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.856) balanced_accuracy: (train=1.000, test=0.736) f1: (train=1.000, test=0.771) total time=   1.2s\n",
      "[CV 5/10] END criterion=log_loss, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.863) balanced_accuracy: (train=1.000, test=0.747) f1: (train=1.000, test=0.782) total time=   1.2s\n",
      "[CV 6/10] END criterion=log_loss, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.742) f1: (train=1.000, test=0.776) total time=   1.2s\n",
      "[CV 7/10] END criterion=log_loss, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.856) balanced_accuracy: (train=1.000, test=0.739) f1: (train=1.000, test=0.773) total time=   1.2s\n",
      "[CV 8/10] END criterion=log_loss, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.860) balanced_accuracy: (train=1.000, test=0.743) f1: (train=1.000, test=0.778) total time=   1.2s\n",
      "[CV 9/10] END criterion=log_loss, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.861) balanced_accuracy: (train=1.000, test=0.747) f1: (train=1.000, test=0.781) total time=   1.2s\n",
      "[CV 10/10] END criterion=log_loss, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.752) f1: (train=1.000, test=0.785) total time=   1.1s\n",
      "[CV 1/10] END criterion=log_loss, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.855) balanced_accuracy: (train=1.000, test=0.738) f1: (train=1.000, test=0.771) total time=   2.0s\n",
      "[CV 2/10] END criterion=log_loss, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.864) balanced_accuracy: (train=1.000, test=0.747) f1: (train=1.000, test=0.783) total time=   2.2s\n",
      "[CV 3/10] END criterion=log_loss, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.856) balanced_accuracy: (train=1.000, test=0.739) f1: (train=1.000, test=0.772) total time=   2.1s\n",
      "[CV 4/10] END criterion=log_loss, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.739) f1: (train=1.000, test=0.774) total time=   2.1s\n",
      "[CV 5/10] END criterion=log_loss, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.861) balanced_accuracy: (train=1.000, test=0.745) f1: (train=1.000, test=0.780) total time=   2.1s\n",
      "[CV 6/10] END criterion=log_loss, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.740) f1: (train=1.000, test=0.774) total time=   2.1s\n",
      "[CV 7/10] END criterion=log_loss, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.742) f1: (train=1.000, test=0.776) total time=   2.4s\n",
      "[CV 8/10] END criterion=log_loss, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.743) f1: (train=1.000, test=0.777) total time=   2.3s\n",
      "[CV 9/10] END criterion=log_loss, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.748) f1: (train=1.000, test=0.782) total time=   2.4s\n",
      "[CV 10/10] END criterion=log_loss, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.863) balanced_accuracy: (train=1.000, test=0.752) f1: (train=1.000, test=0.785) total time=   2.3s\n",
      "[CV 1/10] END criterion=log_loss, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.856) balanced_accuracy: (train=1.000, test=0.739) f1: (train=1.000, test=0.772) total time=   2.1s\n",
      "[CV 2/10] END criterion=log_loss, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.865) balanced_accuracy: (train=1.000, test=0.748) f1: (train=1.000, test=0.784) total time=   2.2s\n",
      "[CV 3/10] END criterion=log_loss, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.856) balanced_accuracy: (train=1.000, test=0.739) f1: (train=1.000, test=0.772) total time=   2.2s\n",
      "[CV 4/10] END criterion=log_loss, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.736) f1: (train=1.000, test=0.771) total time=   2.2s\n",
      "[CV 5/10] END criterion=log_loss, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.861) balanced_accuracy: (train=1.000, test=0.744) f1: (train=1.000, test=0.779) total time=   2.2s\n",
      "[CV 6/10] END criterion=log_loss, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.742) f1: (train=1.000, test=0.776) total time=   2.2s\n",
      "[CV 7/10] END criterion=log_loss, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.856) balanced_accuracy: (train=1.000, test=0.740) f1: (train=1.000, test=0.773) total time=   2.0s\n",
      "[CV 8/10] END criterion=log_loss, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.860) balanced_accuracy: (train=1.000, test=0.742) f1: (train=1.000, test=0.777) total time=   2.1s\n",
      "[CV 9/10] END criterion=log_loss, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.861) balanced_accuracy: (train=1.000, test=0.747) f1: (train=1.000, test=0.781) total time=   2.1s\n",
      "[CV 10/10] END criterion=log_loss, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.863) balanced_accuracy: (train=1.000, test=0.753) f1: (train=1.000, test=0.786) total time=   2.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/10] END criterion=log_loss, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.856) balanced_accuracy: (train=1.000, test=0.740) f1: (train=1.000, test=0.773) total time=   2.2s\n",
      "[CV 2/10] END criterion=log_loss, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.864) balanced_accuracy: (train=1.000, test=0.747) f1: (train=1.000, test=0.783) total time=   2.3s\n",
      "[CV 3/10] END criterion=log_loss, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.740) f1: (train=1.000, test=0.774) total time=   2.2s\n",
      "[CV 4/10] END criterion=log_loss, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.738) f1: (train=1.000, test=0.772) total time=   2.1s\n",
      "[CV 5/10] END criterion=log_loss, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.747) f1: (train=1.000, test=0.782) total time=   2.1s\n",
      "[CV 6/10] END criterion=log_loss, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.860) balanced_accuracy: (train=1.000, test=0.743) f1: (train=1.000, test=0.778) total time=   2.1s\n",
      "[CV 7/10] END criterion=log_loss, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.742) f1: (train=1.000, test=0.775) total time=   2.1s\n",
      "[CV 8/10] END criterion=log_loss, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.860) balanced_accuracy: (train=1.000, test=0.742) f1: (train=1.000, test=0.777) total time=   2.2s\n",
      "[CV 9/10] END criterion=log_loss, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.748) f1: (train=1.000, test=0.782) total time=   2.2s\n",
      "[CV 10/10] END criterion=log_loss, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.753) f1: (train=1.000, test=0.785) total time=   2.1s\n",
      "[CV 1/10] END criterion=log_loss, max_features=log2, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.855) balanced_accuracy: (train=1.000, test=0.738) f1: (train=1.000, test=0.771) total time=   1.2s\n",
      "[CV 2/10] END criterion=log_loss, max_features=log2, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.863) balanced_accuracy: (train=1.000, test=0.747) f1: (train=1.000, test=0.783) total time=   1.2s\n",
      "[CV 3/10] END criterion=log_loss, max_features=log2, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.856) balanced_accuracy: (train=1.000, test=0.739) f1: (train=1.000, test=0.772) total time=   1.2s\n",
      "[CV 4/10] END criterion=log_loss, max_features=log2, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.740) f1: (train=1.000, test=0.774) total time=   1.1s\n",
      "[CV 5/10] END criterion=log_loss, max_features=log2, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.861) balanced_accuracy: (train=1.000, test=0.745) f1: (train=1.000, test=0.779) total time=   1.2s\n",
      "[CV 6/10] END criterion=log_loss, max_features=log2, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.742) f1: (train=1.000, test=0.776) total time=   1.1s\n",
      "[CV 7/10] END criterion=log_loss, max_features=log2, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.741) f1: (train=1.000, test=0.775) total time=   1.2s\n",
      "[CV 8/10] END criterion=log_loss, max_features=log2, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.742) f1: (train=1.000, test=0.776) total time=   1.2s\n",
      "[CV 9/10] END criterion=log_loss, max_features=log2, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.861) balanced_accuracy: (train=1.000, test=0.747) f1: (train=1.000, test=0.781) total time=   1.2s\n",
      "[CV 10/10] END criterion=log_loss, max_features=log2, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.753) f1: (train=1.000, test=0.785) total time=   1.2s\n",
      "[CV 1/10] END criterion=log_loss, max_features=log2, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.856) balanced_accuracy: (train=1.000, test=0.739) f1: (train=1.000, test=0.772) total time=   1.2s\n",
      "[CV 2/10] END criterion=log_loss, max_features=log2, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.865) balanced_accuracy: (train=1.000, test=0.749) f1: (train=1.000, test=0.785) total time=   1.1s\n",
      "[CV 3/10] END criterion=log_loss, max_features=log2, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.740) f1: (train=1.000, test=0.774) total time=   1.2s\n",
      "[CV 4/10] END criterion=log_loss, max_features=log2, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.738) f1: (train=1.000, test=0.772) total time=   1.1s\n",
      "[CV 5/10] END criterion=log_loss, max_features=log2, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.861) balanced_accuracy: (train=1.000, test=0.745) f1: (train=1.000, test=0.780) total time=   1.2s\n",
      "[CV 6/10] END criterion=log_loss, max_features=log2, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.742) f1: (train=1.000, test=0.776) total time=   1.1s\n",
      "[CV 7/10] END criterion=log_loss, max_features=log2, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.855) balanced_accuracy: (train=1.000, test=0.739) f1: (train=1.000, test=0.771) total time=   1.2s\n",
      "[CV 8/10] END criterion=log_loss, max_features=log2, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.741) f1: (train=1.000, test=0.776) total time=   1.2s\n",
      "[CV 9/10] END criterion=log_loss, max_features=log2, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.860) balanced_accuracy: (train=1.000, test=0.746) f1: (train=1.000, test=0.779) total time=   1.2s\n",
      "[CV 10/10] END criterion=log_loss, max_features=log2, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.753) f1: (train=1.000, test=0.785) total time=   1.2s\n",
      "[CV 1/10] END criterion=log_loss, max_features=log2, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.740) f1: (train=1.000, test=0.773) total time=   1.2s\n",
      "[CV 2/10] END criterion=log_loss, max_features=log2, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.865) balanced_accuracy: (train=1.000, test=0.749) f1: (train=1.000, test=0.785) total time=   1.2s\n",
      "[CV 3/10] END criterion=log_loss, max_features=log2, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.856) balanced_accuracy: (train=1.000, test=0.738) f1: (train=1.000, test=0.771) total time=   1.2s\n",
      "[CV 4/10] END criterion=log_loss, max_features=log2, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.738) f1: (train=1.000, test=0.772) total time=   1.2s\n",
      "[CV 5/10] END criterion=log_loss, max_features=log2, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.746) f1: (train=1.000, test=0.781) total time=   1.2s\n",
      "[CV 6/10] END criterion=log_loss, max_features=log2, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.743) f1: (train=1.000, test=0.777) total time=   1.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 7/10] END criterion=log_loss, max_features=log2, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.742) f1: (train=1.000, test=0.775) total time=   1.2s\n",
      "[CV 8/10] END criterion=log_loss, max_features=log2, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.742) f1: (train=1.000, test=0.777) total time=   1.1s\n",
      "[CV 9/10] END criterion=log_loss, max_features=log2, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.863) balanced_accuracy: (train=1.000, test=0.749) f1: (train=1.000, test=0.784) total time=   1.1s\n",
      "[CV 10/10] END criterion=log_loss, max_features=log2, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.752) f1: (train=1.000, test=0.785) total time=   1.1s\n",
      "[CV 1/10] END criterion=log_loss, max_features=log2, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.855) balanced_accuracy: (train=1.000, test=0.738) f1: (train=1.000, test=0.771) total time=   2.0s\n",
      "[CV 2/10] END criterion=log_loss, max_features=log2, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.864) balanced_accuracy: (train=1.000, test=0.747) f1: (train=1.000, test=0.783) total time=   2.1s\n",
      "[CV 3/10] END criterion=log_loss, max_features=log2, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.856) balanced_accuracy: (train=1.000, test=0.739) f1: (train=1.000, test=0.772) total time=   2.1s\n",
      "[CV 4/10] END criterion=log_loss, max_features=log2, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.739) f1: (train=1.000, test=0.774) total time=   2.1s\n",
      "[CV 5/10] END criterion=log_loss, max_features=log2, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.861) balanced_accuracy: (train=1.000, test=0.745) f1: (train=1.000, test=0.780) total time=   2.1s\n",
      "[CV 6/10] END criterion=log_loss, max_features=log2, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.740) f1: (train=1.000, test=0.774) total time=   2.1s\n",
      "[CV 7/10] END criterion=log_loss, max_features=log2, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.742) f1: (train=1.000, test=0.776) total time=   2.1s\n",
      "[CV 8/10] END criterion=log_loss, max_features=log2, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.743) f1: (train=1.000, test=0.777) total time=   2.1s\n",
      "[CV 9/10] END criterion=log_loss, max_features=log2, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.748) f1: (train=1.000, test=0.782) total time=   2.1s\n",
      "[CV 10/10] END criterion=log_loss, max_features=log2, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.863) balanced_accuracy: (train=1.000, test=0.752) f1: (train=1.000, test=0.785) total time=   2.1s\n",
      "[CV 1/10] END criterion=log_loss, max_features=log2, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.856) balanced_accuracy: (train=1.000, test=0.739) f1: (train=1.000, test=0.772) total time=   2.1s\n",
      "[CV 2/10] END criterion=log_loss, max_features=log2, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.865) balanced_accuracy: (train=1.000, test=0.748) f1: (train=1.000, test=0.784) total time=   2.1s\n",
      "[CV 3/10] END criterion=log_loss, max_features=log2, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.856) balanced_accuracy: (train=1.000, test=0.739) f1: (train=1.000, test=0.772) total time=   2.0s\n",
      "[CV 4/10] END criterion=log_loss, max_features=log2, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.736) f1: (train=1.000, test=0.771) total time=   2.1s\n",
      "[CV 5/10] END criterion=log_loss, max_features=log2, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.861) balanced_accuracy: (train=1.000, test=0.744) f1: (train=1.000, test=0.779) total time=   2.1s\n",
      "[CV 6/10] END criterion=log_loss, max_features=log2, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.742) f1: (train=1.000, test=0.776) total time=   2.1s\n",
      "[CV 7/10] END criterion=log_loss, max_features=log2, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.856) balanced_accuracy: (train=1.000, test=0.740) f1: (train=1.000, test=0.773) total time=   2.0s\n",
      "[CV 8/10] END criterion=log_loss, max_features=log2, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.860) balanced_accuracy: (train=1.000, test=0.742) f1: (train=1.000, test=0.777) total time=   2.1s\n",
      "[CV 9/10] END criterion=log_loss, max_features=log2, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.861) balanced_accuracy: (train=1.000, test=0.747) f1: (train=1.000, test=0.781) total time=   1.9s\n",
      "[CV 10/10] END criterion=log_loss, max_features=log2, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.863) balanced_accuracy: (train=1.000, test=0.753) f1: (train=1.000, test=0.786) total time=   2.1s\n",
      "[CV 1/10] END criterion=log_loss, max_features=log2, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.856) balanced_accuracy: (train=1.000, test=0.739) f1: (train=1.000, test=0.772) total time=   2.1s\n",
      "[CV 2/10] END criterion=log_loss, max_features=log2, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.864) balanced_accuracy: (train=1.000, test=0.748) f1: (train=1.000, test=0.784) total time=   2.1s\n",
      "[CV 3/10] END criterion=log_loss, max_features=log2, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.856) balanced_accuracy: (train=1.000, test=0.738) f1: (train=1.000, test=0.772) total time=   2.1s\n",
      "[CV 4/10] END criterion=log_loss, max_features=log2, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.740) f1: (train=1.000, test=0.775) total time=   2.2s\n",
      "[CV 5/10] END criterion=log_loss, max_features=log2, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.745) f1: (train=1.000, test=0.780) total time=   2.4s\n",
      "[CV 6/10] END criterion=log_loss, max_features=log2, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.742) f1: (train=1.000, test=0.776) total time=   2.2s\n",
      "[CV 7/10] END criterion=log_loss, max_features=log2, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.741) f1: (train=1.000, test=0.775) total time=   2.4s\n",
      "[CV 8/10] END criterion=log_loss, max_features=log2, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.861) balanced_accuracy: (train=1.000, test=0.744) f1: (train=1.000, test=0.779) total time=   2.1s\n",
      "[CV 9/10] END criterion=log_loss, max_features=log2, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.863) balanced_accuracy: (train=1.000, test=0.749) f1: (train=1.000, test=0.783) total time=   2.2s\n",
      "[CV 10/10] END criterion=log_loss, max_features=log2, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.751) f1: (train=1.000, test=0.784) total time=   2.2s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=StratifiedKFold(n_splits=10, random_state=None, shuffle=False),\n",
       "             estimator=ExtraTreesClassifier(n_estimators=150, n_jobs=-1,\n",
       "                                            random_state=30),\n",
       "             param_grid={&#x27;criterion&#x27;: [&#x27;gini&#x27;, &#x27;entropy&#x27;, &#x27;log_loss&#x27;],\n",
       "                         &#x27;max_features&#x27;: [&#x27;sqrt&#x27;, &#x27;log2&#x27;],\n",
       "                         &#x27;n_estimators&#x27;: [100, 200], &#x27;n_jobs&#x27;: [-1],\n",
       "                         &#x27;random_state&#x27;: [50, 100, None]},\n",
       "             refit=&#x27;balanced_accuracy&#x27;, return_train_score=True,\n",
       "             scoring={&#x27;accuracy&#x27;: &#x27;accuracy&#x27;,\n",
       "                      &#x27;balanced_accuracy&#x27;: &#x27;balanced_accuracy&#x27;,\n",
       "                      &#x27;f1&#x27;: &#x27;f1_macro&#x27;},\n",
       "             verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=StratifiedKFold(n_splits=10, random_state=None, shuffle=False),\n",
       "             estimator=ExtraTreesClassifier(n_estimators=150, n_jobs=-1,\n",
       "                                            random_state=30),\n",
       "             param_grid={&#x27;criterion&#x27;: [&#x27;gini&#x27;, &#x27;entropy&#x27;, &#x27;log_loss&#x27;],\n",
       "                         &#x27;max_features&#x27;: [&#x27;sqrt&#x27;, &#x27;log2&#x27;],\n",
       "                         &#x27;n_estimators&#x27;: [100, 200], &#x27;n_jobs&#x27;: [-1],\n",
       "                         &#x27;random_state&#x27;: [50, 100, None]},\n",
       "             refit=&#x27;balanced_accuracy&#x27;, return_train_score=True,\n",
       "             scoring={&#x27;accuracy&#x27;: &#x27;accuracy&#x27;,\n",
       "                      &#x27;balanced_accuracy&#x27;: &#x27;balanced_accuracy&#x27;,\n",
       "                      &#x27;f1&#x27;: &#x27;f1_macro&#x27;},\n",
       "             verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: ExtraTreesClassifier</label><div class=\"sk-toggleable__content\"><pre>ExtraTreesClassifier(n_estimators=150, n_jobs=-1, random_state=30)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ExtraTreesClassifier</label><div class=\"sk-toggleable__content\"><pre>ExtraTreesClassifier(n_estimators=150, n_jobs=-1, random_state=30)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=10, random_state=None, shuffle=False),\n",
       "             estimator=ExtraTreesClassifier(n_estimators=150, n_jobs=-1,\n",
       "                                            random_state=30),\n",
       "             param_grid={'criterion': ['gini', 'entropy', 'log_loss'],\n",
       "                         'max_features': ['sqrt', 'log2'],\n",
       "                         'n_estimators': [100, 200], 'n_jobs': [-1],\n",
       "                         'random_state': [50, 100, None]},\n",
       "             refit='balanced_accuracy', return_train_score=True,\n",
       "             scoring={'accuracy': 'accuracy',\n",
       "                      'balanced_accuracy': 'balanced_accuracy',\n",
       "                      'f1': 'f1_macro'},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extra = ExtraTreesClassifier( n_jobs=-1, n_estimators=150, random_state=30)\n",
    "\n",
    "# Create the parameter grids\n",
    "parameter_grid = {\n",
    "    \"n_estimators\": [100, 200],\n",
    "    \"criterion\": ['gini', 'entropy', 'log_loss'],\n",
    "    \"max_features\": ['sqrt', 'log2'],\n",
    "    \"n_jobs\":[-1],\n",
    "   # \"bootstrap\":[True,False],\n",
    "    \"random_state\": [ 50, 100, None],\n",
    "   # \"warm_start\": [True, False],\n",
    "    \n",
    "}\n",
    "\n",
    "# Create Stratified folds\n",
    "# primi tentativi n_splits = 5 per limitare i tempi di esecuzione della gridSearch poi aumentato\n",
    "cross_validation = StratifiedKFold(n_splits=10)\n",
    "cross_validation.get_n_splits(train_data, np.ravel(y_train))\n",
    "\n",
    "# Create the scoring dictionary\n",
    "SCORING = {\n",
    "    \"accuracy\": \"accuracy\",\n",
    "    \"balanced_accuracy\": \"balanced_accuracy\",\n",
    "    \"f1\": \"f1_macro\",\n",
    "}\n",
    "\n",
    "# Create and fit the GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=extra,\n",
    "    param_grid=parameter_grid,\n",
    "    cv=cross_validation,\n",
    "    verbose=3,\n",
    "    scoring=SCORING,\n",
    "    return_train_score=True,\n",
    "    refit=\"balanced_accuracy\",\n",
    ")\n",
    "\n",
    "grid_search.fit(train_data, np.ravel(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e5c00f24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.7443125339355887\n",
      "Best parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 100, 'n_jobs': -1, 'random_state': 50}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>ExtraTreesClassifier(n_jobs=-1, random_state=50)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" checked><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ExtraTreesClassifier</label><div class=\"sk-toggleable__content\"><pre>ExtraTreesClassifier(n_jobs=-1, random_state=50)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "ExtraTreesClassifier(n_jobs=-1, random_state=50)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Best score: {}\".format(grid_search.best_score_))\n",
    "print(\"Best parameters: {}\".format(grid_search.best_params_))\n",
    "\n",
    "best_dtc = grid_search.best_estimator_\n",
    "best_dtc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "19c3a08d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.858244570480011"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model = best_dtc\n",
    "my_model.fit(train_data, np.ravel(y_train))\n",
    "my_model.score(test_data, np.ravel(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e54eb0a",
   "metadata": {},
   "source": [
    "Risultato accuracy su testSet in base all'algoritmo utilizzato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b9e27e5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "algoritmo=[\"Decision_Tree\",\"Random_forest\",\"Extra_Tree\"]\n",
    "accuracy=[0.8686,0.8695,0.8582]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(algoritmo, accuracy, marker='o', linestyle='-', color='r')\n",
    "plt.title(' Accuracy su testSet al Variare dell algoritmo')\n",
    "plt.xlabel('Algoritmo')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.grid(True)\n",
    "plt.xticks(algoritmo)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2cac543",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
