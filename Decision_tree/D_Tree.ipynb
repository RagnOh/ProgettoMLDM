{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86789fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "#importo libreria panda per leggere ed elaborare csv\n",
    "import pandas as pd\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"decision_trees\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
    "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)\n",
    "\n",
    "from sklearn.model_selection import (\n",
    "    GridSearchCV,\n",
    "    StratifiedKFold,\n",
    "    cross_val_score,\n",
    "    train_test_split,\n",
    ")\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ff2e821",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=pd.read_csv('/Users/ragno/Documents/Progetti/Mldm/ProgettoMLDM/Dataset/train_data.csv')\n",
    "test_data=pd.read_csv('/Users/ragno/Documents/Progetti/Mldm/ProgettoMLDM/Dataset/test_data.csv')\n",
    "y_train=pd.read_csv('/Users/ragno/Documents/Progetti/Mldm/ProgettoMLDM/Dataset/train_y.csv')\n",
    "y_test=pd.read_csv('/Users/ragno/Documents/Progetti/Mldm/ProgettoMLDM/Dataset/test_y.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34e752bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "column = ['criterion', 'max_depth', 'ccp_alpha', 'min_samples_leaf', 'min_samples_split', 'accuracy']\n",
    "column_bar = ['try', 'Parameter_changed', 'Accuracy']\n",
    "\n",
    "def plot_depthsVSaccuracy(depths, ccp_alpha, title):\n",
    "  accs = pd.DataFrame(columns=column)\n",
    "  for d in depths:\n",
    "    tree_clf = DecisionTreeClassifier(criterion='log_loss',max_depth=d, min_samples_leaf=4, ccp_alpha=ccp_alpha,min_samples_split=8 )\n",
    "    tree_clf.fit(train_data, y_train)\n",
    "    testset_score = tree_clf.score(test_data, y_test)\n",
    "    row = pd.DataFrame(data=[['log_loss', d, ccp_alpha, 4, 8 ,testset_score]], columns=column)\n",
    "    accs = pd.concat([accs, row])\n",
    "\n",
    "  # plot\n",
    "  fig, ax = plt.subplots()\n",
    "  ax.plot(accs.max_depth, accs.accuracy)\n",
    "\n",
    "  ax.set(xlabel='Max depth', ylabel='Accuracy',\n",
    "        title=title)\n",
    "  ax.grid()\n",
    "  plt.show()\n",
    "\n",
    "### Create a single row equivalent to a single try for decision tree\n",
    "def create_bar_row(criterion, depth, leaf, ccp, split, attempt, parameter):\n",
    "  tree_clf = DecisionTreeClassifier(criterion=criterion,max_depth=depth, min_samples_leaf=leaf, ccp_alpha=ccp,min_samples_split=split )\n",
    "  tree_clf.fit(train_data, y_train)\n",
    "  testset_score = tree_clf.score(test_data, y_test)\n",
    "  row = pd.DataFrame(data=[[attempt, parameter, testset_score]], columns=column_bar)\n",
    "  return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "efa3b0b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "depths = np.linspace(10, 40, 31, dtype=int)\n",
    "\n",
    "plot_depthsVSaccuracy(depths, 0.0001, 'Variazione accuracy CON PRUNING') # with pruning\n",
    "plot_depthsVSaccuracy(depths, 0.0, 'Variazione accuracy SENZA PRUNING') # without pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c0ef8e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  try  Parameter_changed  Accuracy\n",
      "0   5              start  0.831304\n",
      "0   5          max_depth  0.839916\n",
      "0   5   min_samples_leaf  0.858832\n",
      "0  40  min_samples_split  0.858729\n",
      "0   5          ccp_alpha  0.868965\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'Score sul testset durante il tuning dei parametri'}, xlabel='Accuracy', ylabel='Parameter_changed'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "df = pd.DataFrame(columns=column_bar)\n",
    "df = pd.concat([df, create_bar_row('entropy', 50, 1, 0.0, 20, 5, 'start')]) # try 1\n",
    "df = pd.concat([df, create_bar_row('entropy', 25, 1, 0.0, 20, 5, 'max_depth')]) # try 2\n",
    "df = pd.concat([df, create_bar_row('entropy', 25, 10, 0.0, 40, 5, 'min_samples_leaf')]) # try 3\n",
    "df = pd.concat([df, create_bar_row('entropy', 25, 10, 0.0, 40, 5, 'min_samples_split')]) # try 4\n",
    "df = pd.concat([df, create_bar_row('entropy', 25, 10, 0.0001, 40, 5, 'ccp_alpha')]) # try 5\n",
    "print(df)\n",
    "\n",
    "fig, axs = plt.subplots()\n",
    "axs.set_xlim([0.70,0.89])\n",
    "axs.set_title(\"Score sul testset durante il tuning dei parametri\")\n",
    "\n",
    "sns.barplot(data=df, x='Accuracy',y=\"Parameter_changed\",ax=axs, orient=\"h\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "328fa9b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 288 candidates, totalling 1440 fits\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.787, test=0.782) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.870, test=0.866) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.870) balanced_accuracy: (train=0.739, test=0.741) f1: (train=0.782, test=0.784) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.745, test=0.743) f1: (train=0.786, test=0.784) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.869) balanced_accuracy: (train=0.745, test=0.745) f1: (train=0.786, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.787, test=0.782) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.870, test=0.866) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.870) balanced_accuracy: (train=0.739, test=0.741) f1: (train=0.782, test=0.784) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.745, test=0.743) f1: (train=0.786, test=0.784) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.869) balanced_accuracy: (train=0.745, test=0.745) f1: (train=0.786, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.787, test=0.782) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.870, test=0.866) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.870) balanced_accuracy: (train=0.739, test=0.741) f1: (train=0.782, test=0.784) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.745, test=0.743) f1: (train=0.786, test=0.784) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.869) balanced_accuracy: (train=0.745, test=0.745) f1: (train=0.786, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.787, test=0.782) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.870, test=0.866) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.870) balanced_accuracy: (train=0.739, test=0.741) f1: (train=0.782, test=0.784) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.745, test=0.743) f1: (train=0.786, test=0.784) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.869) balanced_accuracy: (train=0.745, test=0.745) f1: (train=0.786, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.787, test=0.782) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.870, test=0.866) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.870) balanced_accuracy: (train=0.739, test=0.741) f1: (train=0.782, test=0.784) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.745, test=0.743) f1: (train=0.786, test=0.784) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.869) balanced_accuracy: (train=0.745, test=0.745) f1: (train=0.786, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.787, test=0.782) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.870, test=0.866) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.870) balanced_accuracy: (train=0.739, test=0.741) f1: (train=0.782, test=0.784) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.745, test=0.743) f1: (train=0.786, test=0.784) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.869) balanced_accuracy: (train=0.745, test=0.745) f1: (train=0.786, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.782) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.742, test=0.735) f1: (train=0.784, test=0.777) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.869) balanced_accuracy: (train=0.738, test=0.740) f1: (train=0.780, test=0.783) total time=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.784, test=0.783) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.868) balanced_accuracy: (train=0.742, test=0.742) f1: (train=0.783, test=0.783) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.782) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.742, test=0.735) f1: (train=0.784, test=0.777) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.869) balanced_accuracy: (train=0.738, test=0.740) f1: (train=0.780, test=0.783) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.784, test=0.783) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.868) balanced_accuracy: (train=0.742, test=0.742) f1: (train=0.783, test=0.783) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.782) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.742, test=0.735) f1: (train=0.784, test=0.777) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.869) balanced_accuracy: (train=0.738, test=0.740) f1: (train=0.780, test=0.783) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.784, test=0.783) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.868) balanced_accuracy: (train=0.742, test=0.742) f1: (train=0.783, test=0.783) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.782) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.742, test=0.735) f1: (train=0.784, test=0.777) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.869) balanced_accuracy: (train=0.738, test=0.740) f1: (train=0.780, test=0.783) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.784, test=0.783) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.868) balanced_accuracy: (train=0.742, test=0.742) f1: (train=0.783, test=0.783) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.782) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.742, test=0.735) f1: (train=0.784, test=0.777) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.869) balanced_accuracy: (train=0.738, test=0.740) f1: (train=0.780, test=0.783) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.784, test=0.783) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.868) balanced_accuracy: (train=0.742, test=0.742) f1: (train=0.783, test=0.783) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.782) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.742, test=0.735) f1: (train=0.784, test=0.777) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.869) balanced_accuracy: (train=0.738, test=0.740) f1: (train=0.780, test=0.783) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.784, test=0.783) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.868) balanced_accuracy: (train=0.742, test=0.742) f1: (train=0.783, test=0.783) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.783, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.784, test=0.777) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.869) balanced_accuracy: (train=0.736, test=0.739) f1: (train=0.779, test=0.782) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.737, test=0.736) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.736, test=0.736) f1: (train=0.778, test=0.779) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.783, test=0.780) total time=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.784, test=0.777) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.869) balanced_accuracy: (train=0.736, test=0.739) f1: (train=0.779, test=0.782) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.737, test=0.736) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.736, test=0.736) f1: (train=0.778, test=0.779) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.783, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.784, test=0.777) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.869) balanced_accuracy: (train=0.736, test=0.739) f1: (train=0.779, test=0.782) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.737, test=0.736) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.736, test=0.736) f1: (train=0.778, test=0.779) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.783, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.784, test=0.777) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.869) balanced_accuracy: (train=0.736, test=0.739) f1: (train=0.779, test=0.782) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.737, test=0.736) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.736, test=0.736) f1: (train=0.778, test=0.779) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.783, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.784, test=0.777) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.869) balanced_accuracy: (train=0.736, test=0.739) f1: (train=0.779, test=0.782) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.737, test=0.736) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.736, test=0.736) f1: (train=0.778, test=0.779) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.783, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.784, test=0.777) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.869) balanced_accuracy: (train=0.736, test=0.739) f1: (train=0.779, test=0.782) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.737, test=0.736) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.736, test=0.736) f1: (train=0.778, test=0.779) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.866, test=0.864) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.782, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.864) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.782, test=0.775) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.866, test=0.868) balanced_accuracy: (train=0.734, test=0.737) f1: (train=0.776, test=0.780) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.866, test=0.866) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.777, test=0.777) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.866, test=0.867) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.777, test=0.778) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.866, test=0.864) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.782, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.864) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.782, test=0.775) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.866, test=0.868) balanced_accuracy: (train=0.734, test=0.737) f1: (train=0.776, test=0.780) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.866, test=0.866) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.777, test=0.777) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.866, test=0.867) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.777, test=0.778) total time=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.866, test=0.864) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.782, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.864) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.782, test=0.775) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.866, test=0.868) balanced_accuracy: (train=0.734, test=0.737) f1: (train=0.776, test=0.780) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.866, test=0.866) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.777, test=0.777) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.866, test=0.867) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.777, test=0.778) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.866, test=0.864) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.782, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.864) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.782, test=0.775) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.866, test=0.868) balanced_accuracy: (train=0.734, test=0.737) f1: (train=0.776, test=0.780) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.866, test=0.866) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.777, test=0.777) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.866, test=0.867) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.777, test=0.778) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.866, test=0.864) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.782, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.864) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.782, test=0.775) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.866, test=0.868) balanced_accuracy: (train=0.734, test=0.737) f1: (train=0.776, test=0.780) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.866, test=0.866) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.777, test=0.777) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.866, test=0.867) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.777, test=0.778) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.866, test=0.864) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.782, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.864) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.782, test=0.775) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.866, test=0.868) balanced_accuracy: (train=0.734, test=0.737) f1: (train=0.776, test=0.780) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.866, test=0.866) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.777, test=0.777) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.866, test=0.867) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.777, test=0.778) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.870, test=0.867) balanced_accuracy: (train=0.748, test=0.743) f1: (train=0.788, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.870, test=0.867) balanced_accuracy: (train=0.745, test=0.738) f1: (train=0.787, test=0.780) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.870) balanced_accuracy: (train=0.739, test=0.742) f1: (train=0.782, test=0.785) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.747, test=0.745) f1: (train=0.788, test=0.785) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.870, test=0.870) balanced_accuracy: (train=0.747, test=0.747) f1: (train=0.788, test=0.788) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.870, test=0.867) balanced_accuracy: (train=0.748, test=0.743) f1: (train=0.788, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.870, test=0.867) balanced_accuracy: (train=0.745, test=0.738) f1: (train=0.787, test=0.780) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.870) balanced_accuracy: (train=0.739, test=0.742) f1: (train=0.782, test=0.785) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.747, test=0.745) f1: (train=0.788, test=0.785) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.870, test=0.870) balanced_accuracy: (train=0.747, test=0.747) f1: (train=0.788, test=0.788) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.870, test=0.867) balanced_accuracy: (train=0.748, test=0.743) f1: (train=0.788, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.870, test=0.867) balanced_accuracy: (train=0.745, test=0.738) f1: (train=0.787, test=0.780) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.870) balanced_accuracy: (train=0.739, test=0.742) f1: (train=0.782, test=0.785) total time=   0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.747, test=0.745) f1: (train=0.788, test=0.785) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.870, test=0.870) balanced_accuracy: (train=0.747, test=0.747) f1: (train=0.788, test=0.788) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.870, test=0.867) balanced_accuracy: (train=0.748, test=0.743) f1: (train=0.788, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.870, test=0.867) balanced_accuracy: (train=0.745, test=0.738) f1: (train=0.787, test=0.780) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.870) balanced_accuracy: (train=0.739, test=0.742) f1: (train=0.782, test=0.785) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.747, test=0.745) f1: (train=0.788, test=0.785) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.870, test=0.870) balanced_accuracy: (train=0.747, test=0.747) f1: (train=0.788, test=0.788) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.870, test=0.867) balanced_accuracy: (train=0.748, test=0.743) f1: (train=0.788, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.870, test=0.867) balanced_accuracy: (train=0.745, test=0.738) f1: (train=0.787, test=0.780) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.870) balanced_accuracy: (train=0.739, test=0.742) f1: (train=0.782, test=0.785) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.747, test=0.745) f1: (train=0.788, test=0.785) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.870, test=0.870) balanced_accuracy: (train=0.747, test=0.747) f1: (train=0.788, test=0.788) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.870, test=0.867) balanced_accuracy: (train=0.748, test=0.743) f1: (train=0.788, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.870, test=0.867) balanced_accuracy: (train=0.745, test=0.738) f1: (train=0.787, test=0.780) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.870) balanced_accuracy: (train=0.739, test=0.742) f1: (train=0.782, test=0.785) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.747, test=0.745) f1: (train=0.788, test=0.785) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.870, test=0.870) balanced_accuracy: (train=0.747, test=0.747) f1: (train=0.788, test=0.788) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.785, test=0.777) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.869) balanced_accuracy: (train=0.738, test=0.740) f1: (train=0.780, test=0.783) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.745, test=0.743) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.868) balanced_accuracy: (train=0.743, test=0.743) f1: (train=0.784, test=0.784) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.785, test=0.777) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.869) balanced_accuracy: (train=0.738, test=0.740) f1: (train=0.780, test=0.783) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.745, test=0.743) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.868) balanced_accuracy: (train=0.743, test=0.743) f1: (train=0.784, test=0.784) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.785, test=0.777) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.869) balanced_accuracy: (train=0.738, test=0.740) f1: (train=0.780, test=0.783) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.745, test=0.743) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.868) balanced_accuracy: (train=0.743, test=0.743) f1: (train=0.784, test=0.784) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.786, test=0.783) total time=   0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.785, test=0.777) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.869) balanced_accuracy: (train=0.738, test=0.740) f1: (train=0.780, test=0.783) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.745, test=0.743) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.868) balanced_accuracy: (train=0.743, test=0.743) f1: (train=0.784, test=0.784) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.785, test=0.777) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.869) balanced_accuracy: (train=0.738, test=0.740) f1: (train=0.780, test=0.783) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.745, test=0.743) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.868) balanced_accuracy: (train=0.743, test=0.743) f1: (train=0.784, test=0.784) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.785, test=0.777) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.869) balanced_accuracy: (train=0.738, test=0.740) f1: (train=0.780, test=0.783) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.745, test=0.743) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.868) balanced_accuracy: (train=0.743, test=0.743) f1: (train=0.784, test=0.784) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.783, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.784, test=0.777) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.869) balanced_accuracy: (train=0.736, test=0.739) f1: (train=0.779, test=0.782) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.737, test=0.736) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.736, test=0.736) f1: (train=0.778, test=0.779) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.783, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.784, test=0.777) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.869) balanced_accuracy: (train=0.736, test=0.739) f1: (train=0.779, test=0.782) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.737, test=0.736) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.736, test=0.736) f1: (train=0.778, test=0.779) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.783, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.784, test=0.777) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.869) balanced_accuracy: (train=0.736, test=0.739) f1: (train=0.779, test=0.782) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.737, test=0.736) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.736, test=0.736) f1: (train=0.778, test=0.779) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.783, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.784, test=0.777) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.869) balanced_accuracy: (train=0.736, test=0.739) f1: (train=0.779, test=0.782) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.737, test=0.736) f1: (train=0.779, test=0.778) total time=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.736, test=0.736) f1: (train=0.778, test=0.779) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.783, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.784, test=0.777) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.869) balanced_accuracy: (train=0.736, test=0.739) f1: (train=0.779, test=0.782) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.737, test=0.736) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.736, test=0.736) f1: (train=0.778, test=0.779) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.783, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.784, test=0.777) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.869) balanced_accuracy: (train=0.736, test=0.739) f1: (train=0.779, test=0.782) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.737, test=0.736) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.736, test=0.736) f1: (train=0.778, test=0.779) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.866, test=0.864) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.782, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.864) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.782, test=0.775) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.866, test=0.868) balanced_accuracy: (train=0.734, test=0.737) f1: (train=0.776, test=0.780) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.866, test=0.866) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.777, test=0.777) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.866, test=0.867) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.777, test=0.778) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.866, test=0.864) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.782, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.864) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.782, test=0.775) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.866, test=0.868) balanced_accuracy: (train=0.734, test=0.737) f1: (train=0.776, test=0.780) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.866, test=0.866) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.777, test=0.777) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.866, test=0.867) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.777, test=0.778) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.866, test=0.864) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.782, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.864) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.782, test=0.775) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.866, test=0.868) balanced_accuracy: (train=0.734, test=0.737) f1: (train=0.776, test=0.780) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.866, test=0.866) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.777, test=0.777) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.866, test=0.867) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.777, test=0.778) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.866, test=0.864) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.782, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.864) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.782, test=0.775) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.866, test=0.868) balanced_accuracy: (train=0.734, test=0.737) f1: (train=0.776, test=0.780) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.866, test=0.866) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.777, test=0.777) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.866, test=0.867) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.777, test=0.778) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.866, test=0.864) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.782, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.864) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.782, test=0.775) total time=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.866, test=0.868) balanced_accuracy: (train=0.734, test=0.737) f1: (train=0.776, test=0.780) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.866, test=0.866) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.777, test=0.777) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.866, test=0.867) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.777, test=0.778) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.866, test=0.864) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.782, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.864) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.782, test=0.775) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.866, test=0.868) balanced_accuracy: (train=0.734, test=0.737) f1: (train=0.776, test=0.780) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.866, test=0.866) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.777, test=0.777) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.866, test=0.867) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.777, test=0.778) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.870, test=0.867) balanced_accuracy: (train=0.748, test=0.743) f1: (train=0.788, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.870, test=0.867) balanced_accuracy: (train=0.745, test=0.738) f1: (train=0.787, test=0.780) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.870) balanced_accuracy: (train=0.739, test=0.742) f1: (train=0.782, test=0.785) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.747, test=0.745) f1: (train=0.788, test=0.785) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.870, test=0.870) balanced_accuracy: (train=0.747, test=0.747) f1: (train=0.788, test=0.788) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.870, test=0.867) balanced_accuracy: (train=0.748, test=0.743) f1: (train=0.788, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.870, test=0.867) balanced_accuracy: (train=0.745, test=0.738) f1: (train=0.787, test=0.780) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.870) balanced_accuracy: (train=0.739, test=0.742) f1: (train=0.782, test=0.785) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.747, test=0.745) f1: (train=0.788, test=0.785) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.870, test=0.870) balanced_accuracy: (train=0.747, test=0.747) f1: (train=0.788, test=0.788) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.870, test=0.867) balanced_accuracy: (train=0.748, test=0.743) f1: (train=0.788, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.870, test=0.867) balanced_accuracy: (train=0.745, test=0.738) f1: (train=0.787, test=0.780) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.870) balanced_accuracy: (train=0.739, test=0.742) f1: (train=0.782, test=0.785) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.747, test=0.745) f1: (train=0.788, test=0.785) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.870, test=0.870) balanced_accuracy: (train=0.747, test=0.747) f1: (train=0.788, test=0.788) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.870, test=0.867) balanced_accuracy: (train=0.748, test=0.743) f1: (train=0.788, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.870, test=0.867) balanced_accuracy: (train=0.745, test=0.738) f1: (train=0.787, test=0.780) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.870) balanced_accuracy: (train=0.739, test=0.742) f1: (train=0.782, test=0.785) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.747, test=0.745) f1: (train=0.788, test=0.785) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.870, test=0.870) balanced_accuracy: (train=0.747, test=0.747) f1: (train=0.788, test=0.788) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.870, test=0.867) balanced_accuracy: (train=0.748, test=0.743) f1: (train=0.788, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.870, test=0.867) balanced_accuracy: (train=0.745, test=0.738) f1: (train=0.787, test=0.780) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.870) balanced_accuracy: (train=0.739, test=0.742) f1: (train=0.782, test=0.785) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.747, test=0.745) f1: (train=0.788, test=0.785) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.870, test=0.870) balanced_accuracy: (train=0.747, test=0.747) f1: (train=0.788, test=0.788) total time=   0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.870, test=0.867) balanced_accuracy: (train=0.748, test=0.743) f1: (train=0.788, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.870, test=0.867) balanced_accuracy: (train=0.745, test=0.738) f1: (train=0.787, test=0.780) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.870) balanced_accuracy: (train=0.739, test=0.742) f1: (train=0.782, test=0.785) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.747, test=0.745) f1: (train=0.788, test=0.785) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.870, test=0.870) balanced_accuracy: (train=0.747, test=0.747) f1: (train=0.788, test=0.788) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.785, test=0.777) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.869) balanced_accuracy: (train=0.738, test=0.740) f1: (train=0.780, test=0.783) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.745, test=0.743) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.868) balanced_accuracy: (train=0.743, test=0.743) f1: (train=0.784, test=0.784) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.785, test=0.777) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.869) balanced_accuracy: (train=0.738, test=0.740) f1: (train=0.780, test=0.783) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.745, test=0.743) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.868) balanced_accuracy: (train=0.743, test=0.743) f1: (train=0.784, test=0.784) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.785, test=0.777) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.869) balanced_accuracy: (train=0.738, test=0.740) f1: (train=0.780, test=0.783) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.745, test=0.743) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.868) balanced_accuracy: (train=0.743, test=0.743) f1: (train=0.784, test=0.784) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.785, test=0.777) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.869) balanced_accuracy: (train=0.738, test=0.740) f1: (train=0.780, test=0.783) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.745, test=0.743) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.868) balanced_accuracy: (train=0.743, test=0.743) f1: (train=0.784, test=0.784) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.785, test=0.777) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.869) balanced_accuracy: (train=0.738, test=0.740) f1: (train=0.780, test=0.783) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.745, test=0.743) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.868) balanced_accuracy: (train=0.743, test=0.743) f1: (train=0.784, test=0.784) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.785, test=0.777) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.869) balanced_accuracy: (train=0.738, test=0.740) f1: (train=0.780, test=0.783) total time=   0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.745, test=0.743) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.868) balanced_accuracy: (train=0.743, test=0.743) f1: (train=0.784, test=0.784) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.783, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.784, test=0.777) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.869) balanced_accuracy: (train=0.736, test=0.739) f1: (train=0.779, test=0.782) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.737, test=0.736) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.736, test=0.736) f1: (train=0.778, test=0.779) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.783, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.784, test=0.777) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.869) balanced_accuracy: (train=0.736, test=0.739) f1: (train=0.779, test=0.782) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.737, test=0.736) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.736, test=0.736) f1: (train=0.778, test=0.779) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.783, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.784, test=0.777) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.869) balanced_accuracy: (train=0.736, test=0.739) f1: (train=0.779, test=0.782) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.737, test=0.736) f1: (train=0.779, test=0.778) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.736, test=0.736) f1: (train=0.778, test=0.779) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.783, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.784, test=0.777) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.869) balanced_accuracy: (train=0.736, test=0.739) f1: (train=0.779, test=0.782) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.737, test=0.736) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.736, test=0.736) f1: (train=0.778, test=0.779) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.783, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.784, test=0.777) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.869) balanced_accuracy: (train=0.736, test=0.739) f1: (train=0.779, test=0.782) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.737, test=0.736) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.736, test=0.736) f1: (train=0.778, test=0.779) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.783, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.784, test=0.777) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.869) balanced_accuracy: (train=0.736, test=0.739) f1: (train=0.779, test=0.782) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.737, test=0.736) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.736, test=0.736) f1: (train=0.778, test=0.779) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.866, test=0.864) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.782, test=0.778) total time=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.864) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.782, test=0.775) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.866, test=0.868) balanced_accuracy: (train=0.734, test=0.737) f1: (train=0.776, test=0.780) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.866, test=0.866) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.777, test=0.777) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.866, test=0.867) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.777, test=0.778) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.866, test=0.864) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.782, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.864) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.782, test=0.775) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.866, test=0.868) balanced_accuracy: (train=0.734, test=0.737) f1: (train=0.776, test=0.780) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.866, test=0.866) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.777, test=0.777) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.866, test=0.867) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.777, test=0.778) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.866, test=0.864) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.782, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.864) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.782, test=0.775) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.866, test=0.868) balanced_accuracy: (train=0.734, test=0.737) f1: (train=0.776, test=0.780) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.866, test=0.866) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.777, test=0.777) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.866, test=0.867) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.777, test=0.778) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.866, test=0.864) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.782, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.864) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.782, test=0.775) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.866, test=0.868) balanced_accuracy: (train=0.734, test=0.737) f1: (train=0.776, test=0.780) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.866, test=0.866) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.777, test=0.777) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.866, test=0.867) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.777, test=0.778) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.866, test=0.864) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.782, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.864) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.782, test=0.775) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.866, test=0.868) balanced_accuracy: (train=0.734, test=0.737) f1: (train=0.776, test=0.780) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.866, test=0.866) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.777, test=0.777) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.866, test=0.867) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.777, test=0.778) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.866, test=0.864) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.782, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.864) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.782, test=0.775) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.866, test=0.868) balanced_accuracy: (train=0.734, test=0.737) f1: (train=0.776, test=0.780) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.866, test=0.866) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.777, test=0.777) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.866, test=0.867) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.777, test=0.778) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.870, test=0.867) balanced_accuracy: (train=0.748, test=0.743) f1: (train=0.788, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.870, test=0.867) balanced_accuracy: (train=0.745, test=0.738) f1: (train=0.787, test=0.780) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.870) balanced_accuracy: (train=0.739, test=0.742) f1: (train=0.782, test=0.785) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.747, test=0.745) f1: (train=0.788, test=0.785) total time=   0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.870, test=0.870) balanced_accuracy: (train=0.747, test=0.747) f1: (train=0.788, test=0.788) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.870, test=0.867) balanced_accuracy: (train=0.748, test=0.743) f1: (train=0.788, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.870, test=0.867) balanced_accuracy: (train=0.745, test=0.738) f1: (train=0.787, test=0.780) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.870) balanced_accuracy: (train=0.739, test=0.742) f1: (train=0.782, test=0.785) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.747, test=0.745) f1: (train=0.788, test=0.785) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.870, test=0.870) balanced_accuracy: (train=0.747, test=0.747) f1: (train=0.788, test=0.788) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.870, test=0.867) balanced_accuracy: (train=0.748, test=0.743) f1: (train=0.788, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.870, test=0.867) balanced_accuracy: (train=0.745, test=0.738) f1: (train=0.787, test=0.780) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.870) balanced_accuracy: (train=0.739, test=0.742) f1: (train=0.782, test=0.785) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.747, test=0.745) f1: (train=0.788, test=0.785) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.870, test=0.870) balanced_accuracy: (train=0.747, test=0.747) f1: (train=0.788, test=0.788) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.870, test=0.867) balanced_accuracy: (train=0.748, test=0.743) f1: (train=0.788, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.870, test=0.867) balanced_accuracy: (train=0.745, test=0.738) f1: (train=0.787, test=0.780) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.870) balanced_accuracy: (train=0.739, test=0.742) f1: (train=0.782, test=0.785) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.747, test=0.745) f1: (train=0.788, test=0.785) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.870, test=0.870) balanced_accuracy: (train=0.747, test=0.747) f1: (train=0.788, test=0.788) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.870, test=0.867) balanced_accuracy: (train=0.748, test=0.743) f1: (train=0.788, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.870, test=0.867) balanced_accuracy: (train=0.745, test=0.738) f1: (train=0.787, test=0.780) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.870) balanced_accuracy: (train=0.739, test=0.742) f1: (train=0.782, test=0.785) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.747, test=0.745) f1: (train=0.788, test=0.785) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.870, test=0.870) balanced_accuracy: (train=0.747, test=0.747) f1: (train=0.788, test=0.788) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.870, test=0.867) balanced_accuracy: (train=0.748, test=0.743) f1: (train=0.788, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.870, test=0.867) balanced_accuracy: (train=0.745, test=0.738) f1: (train=0.787, test=0.780) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.870) balanced_accuracy: (train=0.739, test=0.742) f1: (train=0.782, test=0.785) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.747, test=0.745) f1: (train=0.788, test=0.785) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.870, test=0.870) balanced_accuracy: (train=0.747, test=0.747) f1: (train=0.788, test=0.788) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.785, test=0.777) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.869) balanced_accuracy: (train=0.738, test=0.740) f1: (train=0.780, test=0.783) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.745, test=0.743) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.868) balanced_accuracy: (train=0.743, test=0.743) f1: (train=0.784, test=0.784) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.785, test=0.777) total time=   0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.869) balanced_accuracy: (train=0.738, test=0.740) f1: (train=0.780, test=0.783) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.745, test=0.743) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.868) balanced_accuracy: (train=0.743, test=0.743) f1: (train=0.784, test=0.784) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.785, test=0.777) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.869) balanced_accuracy: (train=0.738, test=0.740) f1: (train=0.780, test=0.783) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.745, test=0.743) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.868) balanced_accuracy: (train=0.743, test=0.743) f1: (train=0.784, test=0.784) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.785, test=0.777) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.869) balanced_accuracy: (train=0.738, test=0.740) f1: (train=0.780, test=0.783) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.745, test=0.743) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.868) balanced_accuracy: (train=0.743, test=0.743) f1: (train=0.784, test=0.784) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.785, test=0.777) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.869) balanced_accuracy: (train=0.738, test=0.740) f1: (train=0.780, test=0.783) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.745, test=0.743) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.868) balanced_accuracy: (train=0.743, test=0.743) f1: (train=0.784, test=0.784) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.785, test=0.777) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.869) balanced_accuracy: (train=0.738, test=0.740) f1: (train=0.780, test=0.783) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.745, test=0.743) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.868) balanced_accuracy: (train=0.743, test=0.743) f1: (train=0.784, test=0.784) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.783, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.784, test=0.777) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.869) balanced_accuracy: (train=0.736, test=0.739) f1: (train=0.779, test=0.782) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.737, test=0.736) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.736, test=0.736) f1: (train=0.778, test=0.779) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.783, test=0.780) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.784, test=0.777) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.869) balanced_accuracy: (train=0.736, test=0.739) f1: (train=0.779, test=0.782) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.737, test=0.736) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.736, test=0.736) f1: (train=0.778, test=0.779) total time=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.783, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.784, test=0.777) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.869) balanced_accuracy: (train=0.736, test=0.739) f1: (train=0.779, test=0.782) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.737, test=0.736) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.736, test=0.736) f1: (train=0.778, test=0.779) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.783, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.784, test=0.777) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.869) balanced_accuracy: (train=0.736, test=0.739) f1: (train=0.779, test=0.782) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.737, test=0.736) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.736, test=0.736) f1: (train=0.778, test=0.779) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.783, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.784, test=0.777) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.869) balanced_accuracy: (train=0.736, test=0.739) f1: (train=0.779, test=0.782) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.737, test=0.736) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.736, test=0.736) f1: (train=0.778, test=0.779) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.783, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.784, test=0.777) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.869) balanced_accuracy: (train=0.736, test=0.739) f1: (train=0.779, test=0.782) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.737, test=0.736) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.736, test=0.736) f1: (train=0.778, test=0.779) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.866, test=0.864) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.782, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.864) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.782, test=0.775) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.866, test=0.868) balanced_accuracy: (train=0.734, test=0.737) f1: (train=0.776, test=0.780) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.866, test=0.866) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.777, test=0.777) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.866, test=0.867) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.777, test=0.778) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.866, test=0.864) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.782, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.864) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.782, test=0.775) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.866, test=0.868) balanced_accuracy: (train=0.734, test=0.737) f1: (train=0.776, test=0.780) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.866, test=0.866) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.777, test=0.777) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.866, test=0.867) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.777, test=0.778) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.866, test=0.864) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.782, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.864) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.782, test=0.775) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.866, test=0.868) balanced_accuracy: (train=0.734, test=0.737) f1: (train=0.776, test=0.780) total time=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.866, test=0.866) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.777, test=0.777) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.866, test=0.867) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.777, test=0.778) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.866, test=0.864) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.782, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.864) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.782, test=0.775) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.866, test=0.868) balanced_accuracy: (train=0.734, test=0.737) f1: (train=0.776, test=0.780) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.866, test=0.866) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.777, test=0.777) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.866, test=0.867) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.777, test=0.778) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.866, test=0.864) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.782, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.864) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.782, test=0.775) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.866, test=0.868) balanced_accuracy: (train=0.734, test=0.737) f1: (train=0.776, test=0.780) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.866, test=0.866) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.777, test=0.777) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.866, test=0.867) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.777, test=0.778) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.866, test=0.864) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.782, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.864) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.782, test=0.775) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.866, test=0.868) balanced_accuracy: (train=0.734, test=0.737) f1: (train=0.776, test=0.780) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.866, test=0.866) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.777, test=0.777) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.866, test=0.867) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.777, test=0.778) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.749, test=0.743) f1: (train=0.790, test=0.783) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.870, test=0.866) balanced_accuracy: (train=0.748, test=0.742) f1: (train=0.788, test=0.782) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.871) balanced_accuracy: (train=0.744, test=0.745) f1: (train=0.785, test=0.787) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.749, test=0.746) f1: (train=0.789, test=0.786) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.744, test=0.743) f1: (train=0.787, test=0.785) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.749, test=0.743) f1: (train=0.790, test=0.783) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.870, test=0.866) balanced_accuracy: (train=0.748, test=0.742) f1: (train=0.788, test=0.782) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.871) balanced_accuracy: (train=0.744, test=0.745) f1: (train=0.785, test=0.787) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.749, test=0.746) f1: (train=0.789, test=0.786) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.744, test=0.743) f1: (train=0.787, test=0.785) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.749, test=0.743) f1: (train=0.790, test=0.783) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.870, test=0.866) balanced_accuracy: (train=0.748, test=0.742) f1: (train=0.788, test=0.782) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.871) balanced_accuracy: (train=0.744, test=0.745) f1: (train=0.785, test=0.787) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.749, test=0.746) f1: (train=0.789, test=0.786) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.744, test=0.743) f1: (train=0.787, test=0.785) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.749, test=0.743) f1: (train=0.790, test=0.783) total time=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.870, test=0.866) balanced_accuracy: (train=0.748, test=0.742) f1: (train=0.788, test=0.782) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.871) balanced_accuracy: (train=0.744, test=0.745) f1: (train=0.785, test=0.787) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.749, test=0.746) f1: (train=0.789, test=0.786) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.744, test=0.743) f1: (train=0.787, test=0.785) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.749, test=0.743) f1: (train=0.790, test=0.783) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.870, test=0.866) balanced_accuracy: (train=0.748, test=0.742) f1: (train=0.788, test=0.782) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.871) balanced_accuracy: (train=0.744, test=0.745) f1: (train=0.785, test=0.787) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.749, test=0.746) f1: (train=0.789, test=0.786) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.744, test=0.743) f1: (train=0.787, test=0.785) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.749, test=0.743) f1: (train=0.790, test=0.783) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.870, test=0.866) balanced_accuracy: (train=0.748, test=0.742) f1: (train=0.788, test=0.782) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.871) balanced_accuracy: (train=0.744, test=0.745) f1: (train=0.785, test=0.787) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.749, test=0.746) f1: (train=0.789, test=0.786) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.744, test=0.743) f1: (train=0.787, test=0.785) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.866) balanced_accuracy: (train=0.747, test=0.742) f1: (train=0.788, test=0.782) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.745, test=0.739) f1: (train=0.786, test=0.779) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.869) balanced_accuracy: (train=0.744, test=0.746) f1: (train=0.785, test=0.787) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.746, test=0.744) f1: (train=0.786, test=0.784) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.745, test=0.743) f1: (train=0.786, test=0.784) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.866) balanced_accuracy: (train=0.747, test=0.742) f1: (train=0.788, test=0.782) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.745, test=0.739) f1: (train=0.786, test=0.779) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.869) balanced_accuracy: (train=0.744, test=0.746) f1: (train=0.785, test=0.787) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.746, test=0.744) f1: (train=0.786, test=0.784) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.745, test=0.743) f1: (train=0.786, test=0.784) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.866) balanced_accuracy: (train=0.747, test=0.742) f1: (train=0.788, test=0.782) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.745, test=0.739) f1: (train=0.786, test=0.779) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.869) balanced_accuracy: (train=0.744, test=0.746) f1: (train=0.785, test=0.787) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.746, test=0.744) f1: (train=0.786, test=0.784) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.745, test=0.743) f1: (train=0.786, test=0.784) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.866) balanced_accuracy: (train=0.747, test=0.742) f1: (train=0.788, test=0.782) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.745, test=0.739) f1: (train=0.786, test=0.779) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.869) balanced_accuracy: (train=0.744, test=0.746) f1: (train=0.785, test=0.787) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.746, test=0.744) f1: (train=0.786, test=0.784) total time=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.745, test=0.743) f1: (train=0.786, test=0.784) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.866) balanced_accuracy: (train=0.747, test=0.742) f1: (train=0.788, test=0.782) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.745, test=0.739) f1: (train=0.786, test=0.779) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.869) balanced_accuracy: (train=0.744, test=0.746) f1: (train=0.785, test=0.787) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.746, test=0.744) f1: (train=0.786, test=0.784) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.745, test=0.743) f1: (train=0.786, test=0.784) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.866) balanced_accuracy: (train=0.747, test=0.742) f1: (train=0.788, test=0.782) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.745, test=0.739) f1: (train=0.786, test=0.779) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.869) balanced_accuracy: (train=0.744, test=0.746) f1: (train=0.785, test=0.787) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.746, test=0.744) f1: (train=0.786, test=0.784) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.745, test=0.743) f1: (train=0.786, test=0.784) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.786, test=0.781) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.744, test=0.738) f1: (train=0.784, test=0.778) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.869) balanced_accuracy: (train=0.739, test=0.742) f1: (train=0.781, test=0.784) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.740) f1: (train=0.782, test=0.782) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.786, test=0.781) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.744, test=0.738) f1: (train=0.784, test=0.778) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.869) balanced_accuracy: (train=0.739, test=0.742) f1: (train=0.781, test=0.784) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.740) f1: (train=0.782, test=0.782) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.786, test=0.781) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.744, test=0.738) f1: (train=0.784, test=0.778) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.869) balanced_accuracy: (train=0.739, test=0.742) f1: (train=0.781, test=0.784) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.740) f1: (train=0.782, test=0.782) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.786, test=0.781) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.744, test=0.738) f1: (train=0.784, test=0.778) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.869) balanced_accuracy: (train=0.739, test=0.742) f1: (train=0.781, test=0.784) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.740) f1: (train=0.782, test=0.782) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.786, test=0.781) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.744, test=0.738) f1: (train=0.784, test=0.778) total time=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.869) balanced_accuracy: (train=0.739, test=0.742) f1: (train=0.781, test=0.784) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.740) f1: (train=0.782, test=0.782) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.786, test=0.781) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.744, test=0.738) f1: (train=0.784, test=0.778) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.869) balanced_accuracy: (train=0.739, test=0.742) f1: (train=0.781, test=0.784) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.740) f1: (train=0.782, test=0.782) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.865) balanced_accuracy: (train=0.741, test=0.738) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.864) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.782, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.866, test=0.867) balanced_accuracy: (train=0.737, test=0.739) f1: (train=0.778, test=0.781) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.866, test=0.866) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.777, test=0.777) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.866, test=0.867) balanced_accuracy: (train=0.739, test=0.739) f1: (train=0.780, test=0.781) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.865) balanced_accuracy: (train=0.741, test=0.738) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.864) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.782, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.866, test=0.867) balanced_accuracy: (train=0.737, test=0.739) f1: (train=0.778, test=0.781) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.866, test=0.866) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.777, test=0.777) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.866, test=0.867) balanced_accuracy: (train=0.739, test=0.739) f1: (train=0.780, test=0.781) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.865) balanced_accuracy: (train=0.741, test=0.738) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.864) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.782, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.866, test=0.867) balanced_accuracy: (train=0.737, test=0.739) f1: (train=0.778, test=0.781) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.866, test=0.866) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.777, test=0.777) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.866, test=0.867) balanced_accuracy: (train=0.739, test=0.739) f1: (train=0.780, test=0.781) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.865) balanced_accuracy: (train=0.741, test=0.738) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.864) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.782, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.866, test=0.867) balanced_accuracy: (train=0.737, test=0.739) f1: (train=0.778, test=0.781) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.866, test=0.866) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.777, test=0.777) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.866, test=0.867) balanced_accuracy: (train=0.739, test=0.739) f1: (train=0.780, test=0.781) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.865) balanced_accuracy: (train=0.741, test=0.738) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.864) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.782, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.866, test=0.867) balanced_accuracy: (train=0.737, test=0.739) f1: (train=0.778, test=0.781) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.866, test=0.866) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.777, test=0.777) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.866, test=0.867) balanced_accuracy: (train=0.739, test=0.739) f1: (train=0.780, test=0.781) total time=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.865) balanced_accuracy: (train=0.741, test=0.738) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.864) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.782, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.866, test=0.867) balanced_accuracy: (train=0.737, test=0.739) f1: (train=0.778, test=0.781) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.866, test=0.866) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.777, test=0.777) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.866, test=0.867) balanced_accuracy: (train=0.739, test=0.739) f1: (train=0.780, test=0.781) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.871, test=0.866) balanced_accuracy: (train=0.752, test=0.745) f1: (train=0.792, test=0.784) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.751, test=0.745) f1: (train=0.791, test=0.784) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.870, test=0.870) balanced_accuracy: (train=0.746, test=0.746) f1: (train=0.788, test=0.788) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.751, test=0.748) f1: (train=0.791, test=0.788) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.871, test=0.870) balanced_accuracy: (train=0.750, test=0.747) f1: (train=0.791, test=0.787) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.871, test=0.866) balanced_accuracy: (train=0.752, test=0.745) f1: (train=0.792, test=0.784) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.751, test=0.745) f1: (train=0.791, test=0.784) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.870, test=0.870) balanced_accuracy: (train=0.746, test=0.746) f1: (train=0.788, test=0.788) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.751, test=0.748) f1: (train=0.791, test=0.788) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.871, test=0.870) balanced_accuracy: (train=0.750, test=0.747) f1: (train=0.791, test=0.787) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.871, test=0.866) balanced_accuracy: (train=0.752, test=0.745) f1: (train=0.792, test=0.784) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.751, test=0.745) f1: (train=0.791, test=0.784) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.870, test=0.870) balanced_accuracy: (train=0.746, test=0.746) f1: (train=0.788, test=0.788) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.751, test=0.748) f1: (train=0.791, test=0.788) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.871, test=0.870) balanced_accuracy: (train=0.750, test=0.747) f1: (train=0.791, test=0.787) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.871, test=0.866) balanced_accuracy: (train=0.752, test=0.745) f1: (train=0.792, test=0.784) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.751, test=0.745) f1: (train=0.791, test=0.784) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.870, test=0.870) balanced_accuracy: (train=0.746, test=0.746) f1: (train=0.788, test=0.788) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.751, test=0.748) f1: (train=0.791, test=0.788) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.871, test=0.870) balanced_accuracy: (train=0.750, test=0.747) f1: (train=0.791, test=0.787) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.871, test=0.866) balanced_accuracy: (train=0.752, test=0.745) f1: (train=0.792, test=0.784) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.751, test=0.745) f1: (train=0.791, test=0.784) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.870, test=0.870) balanced_accuracy: (train=0.746, test=0.746) f1: (train=0.788, test=0.788) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.751, test=0.748) f1: (train=0.791, test=0.788) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.871, test=0.870) balanced_accuracy: (train=0.750, test=0.747) f1: (train=0.791, test=0.787) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.871, test=0.866) balanced_accuracy: (train=0.752, test=0.745) f1: (train=0.792, test=0.784) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.751, test=0.745) f1: (train=0.791, test=0.784) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.870, test=0.870) balanced_accuracy: (train=0.746, test=0.746) f1: (train=0.788, test=0.788) total time=   0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.751, test=0.748) f1: (train=0.791, test=0.788) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.871, test=0.870) balanced_accuracy: (train=0.750, test=0.747) f1: (train=0.791, test=0.787) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.866) balanced_accuracy: (train=0.747, test=0.741) f1: (train=0.787, test=0.781) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.866) balanced_accuracy: (train=0.747, test=0.741) f1: (train=0.787, test=0.781) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.870) balanced_accuracy: (train=0.745, test=0.746) f1: (train=0.786, test=0.787) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.748, test=0.745) f1: (train=0.788, test=0.784) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.746, test=0.744) f1: (train=0.787, test=0.785) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.866) balanced_accuracy: (train=0.747, test=0.741) f1: (train=0.787, test=0.781) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.866) balanced_accuracy: (train=0.747, test=0.741) f1: (train=0.787, test=0.781) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.870) balanced_accuracy: (train=0.745, test=0.746) f1: (train=0.786, test=0.787) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.748, test=0.745) f1: (train=0.788, test=0.784) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.746, test=0.744) f1: (train=0.787, test=0.785) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.866) balanced_accuracy: (train=0.747, test=0.741) f1: (train=0.787, test=0.781) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.866) balanced_accuracy: (train=0.747, test=0.741) f1: (train=0.787, test=0.781) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.870) balanced_accuracy: (train=0.745, test=0.746) f1: (train=0.786, test=0.787) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.748, test=0.745) f1: (train=0.788, test=0.784) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.746, test=0.744) f1: (train=0.787, test=0.785) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.866) balanced_accuracy: (train=0.747, test=0.741) f1: (train=0.787, test=0.781) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.866) balanced_accuracy: (train=0.747, test=0.741) f1: (train=0.787, test=0.781) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.870) balanced_accuracy: (train=0.745, test=0.746) f1: (train=0.786, test=0.787) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.748, test=0.745) f1: (train=0.788, test=0.784) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.746, test=0.744) f1: (train=0.787, test=0.785) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.866) balanced_accuracy: (train=0.747, test=0.741) f1: (train=0.787, test=0.781) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.866) balanced_accuracy: (train=0.747, test=0.741) f1: (train=0.787, test=0.781) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.870) balanced_accuracy: (train=0.745, test=0.746) f1: (train=0.786, test=0.787) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.748, test=0.745) f1: (train=0.788, test=0.784) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.746, test=0.744) f1: (train=0.787, test=0.785) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.866) balanced_accuracy: (train=0.747, test=0.741) f1: (train=0.787, test=0.781) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.866) balanced_accuracy: (train=0.747, test=0.741) f1: (train=0.787, test=0.781) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.870) balanced_accuracy: (train=0.745, test=0.746) f1: (train=0.786, test=0.787) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.748, test=0.745) f1: (train=0.788, test=0.784) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.746, test=0.744) f1: (train=0.787, test=0.785) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.786, test=0.781) total time=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.745, test=0.739) f1: (train=0.785, test=0.779) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.869) balanced_accuracy: (train=0.739, test=0.742) f1: (train=0.781, test=0.784) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.740) f1: (train=0.782, test=0.782) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.786, test=0.781) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.745, test=0.739) f1: (train=0.785, test=0.779) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.869) balanced_accuracy: (train=0.739, test=0.742) f1: (train=0.781, test=0.784) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.740) f1: (train=0.782, test=0.782) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.786, test=0.781) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.745, test=0.739) f1: (train=0.785, test=0.779) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.869) balanced_accuracy: (train=0.739, test=0.742) f1: (train=0.781, test=0.784) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.740) f1: (train=0.782, test=0.782) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.786, test=0.781) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.745, test=0.739) f1: (train=0.785, test=0.779) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.869) balanced_accuracy: (train=0.739, test=0.742) f1: (train=0.781, test=0.784) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.740) f1: (train=0.782, test=0.782) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.786, test=0.781) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.745, test=0.739) f1: (train=0.785, test=0.779) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.869) balanced_accuracy: (train=0.739, test=0.742) f1: (train=0.781, test=0.784) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.740) f1: (train=0.782, test=0.782) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.786, test=0.781) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.745, test=0.739) f1: (train=0.785, test=0.779) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.869) balanced_accuracy: (train=0.739, test=0.742) f1: (train=0.781, test=0.784) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.740) f1: (train=0.782, test=0.782) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.865) balanced_accuracy: (train=0.741, test=0.738) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.864) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.782, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.866, test=0.867) balanced_accuracy: (train=0.737, test=0.739) f1: (train=0.778, test=0.781) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.866, test=0.866) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.777, test=0.777) total time=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.866, test=0.867) balanced_accuracy: (train=0.739, test=0.739) f1: (train=0.780, test=0.781) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.865) balanced_accuracy: (train=0.741, test=0.738) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.864) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.782, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.866, test=0.867) balanced_accuracy: (train=0.737, test=0.739) f1: (train=0.778, test=0.781) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.866, test=0.866) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.777, test=0.777) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.866, test=0.867) balanced_accuracy: (train=0.739, test=0.739) f1: (train=0.780, test=0.781) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.865) balanced_accuracy: (train=0.741, test=0.738) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.864) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.782, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.866, test=0.867) balanced_accuracy: (train=0.737, test=0.739) f1: (train=0.778, test=0.781) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.866, test=0.866) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.777, test=0.777) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.866, test=0.867) balanced_accuracy: (train=0.739, test=0.739) f1: (train=0.780, test=0.781) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.865) balanced_accuracy: (train=0.741, test=0.738) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.864) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.782, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.866, test=0.867) balanced_accuracy: (train=0.737, test=0.739) f1: (train=0.778, test=0.781) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.866, test=0.866) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.777, test=0.777) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.866, test=0.867) balanced_accuracy: (train=0.739, test=0.739) f1: (train=0.780, test=0.781) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.865) balanced_accuracy: (train=0.741, test=0.738) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.864) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.782, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.866, test=0.867) balanced_accuracy: (train=0.737, test=0.739) f1: (train=0.778, test=0.781) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.866, test=0.866) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.777, test=0.777) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.866, test=0.867) balanced_accuracy: (train=0.739, test=0.739) f1: (train=0.780, test=0.781) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.865) balanced_accuracy: (train=0.741, test=0.738) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.864) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.782, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.866, test=0.867) balanced_accuracy: (train=0.737, test=0.739) f1: (train=0.778, test=0.781) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.866, test=0.866) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.777, test=0.777) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.866, test=0.867) balanced_accuracy: (train=0.739, test=0.739) f1: (train=0.780, test=0.781) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.871, test=0.866) balanced_accuracy: (train=0.752, test=0.745) f1: (train=0.792, test=0.784) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.751, test=0.745) f1: (train=0.791, test=0.784) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.870, test=0.870) balanced_accuracy: (train=0.746, test=0.746) f1: (train=0.788, test=0.788) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.751, test=0.748) f1: (train=0.791, test=0.788) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.871, test=0.870) balanced_accuracy: (train=0.750, test=0.747) f1: (train=0.791, test=0.787) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.871, test=0.866) balanced_accuracy: (train=0.752, test=0.745) f1: (train=0.792, test=0.784) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.751, test=0.745) f1: (train=0.791, test=0.784) total time=   0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.870, test=0.870) balanced_accuracy: (train=0.746, test=0.746) f1: (train=0.788, test=0.788) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.751, test=0.748) f1: (train=0.791, test=0.788) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.871, test=0.870) balanced_accuracy: (train=0.750, test=0.747) f1: (train=0.791, test=0.787) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.871, test=0.866) balanced_accuracy: (train=0.752, test=0.745) f1: (train=0.792, test=0.784) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.751, test=0.745) f1: (train=0.791, test=0.784) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.870, test=0.870) balanced_accuracy: (train=0.746, test=0.746) f1: (train=0.788, test=0.788) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.751, test=0.748) f1: (train=0.791, test=0.788) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.871, test=0.870) balanced_accuracy: (train=0.750, test=0.747) f1: (train=0.791, test=0.787) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.871, test=0.866) balanced_accuracy: (train=0.752, test=0.745) f1: (train=0.792, test=0.784) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.751, test=0.745) f1: (train=0.791, test=0.784) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.870, test=0.870) balanced_accuracy: (train=0.746, test=0.746) f1: (train=0.788, test=0.788) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.751, test=0.748) f1: (train=0.791, test=0.788) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.871, test=0.870) balanced_accuracy: (train=0.750, test=0.747) f1: (train=0.791, test=0.787) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.871, test=0.866) balanced_accuracy: (train=0.752, test=0.745) f1: (train=0.792, test=0.784) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.751, test=0.745) f1: (train=0.791, test=0.784) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.870, test=0.870) balanced_accuracy: (train=0.746, test=0.746) f1: (train=0.788, test=0.788) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.751, test=0.748) f1: (train=0.791, test=0.788) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.871, test=0.870) balanced_accuracy: (train=0.750, test=0.747) f1: (train=0.791, test=0.787) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.871, test=0.866) balanced_accuracy: (train=0.752, test=0.745) f1: (train=0.792, test=0.784) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.751, test=0.745) f1: (train=0.791, test=0.784) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.870, test=0.870) balanced_accuracy: (train=0.746, test=0.746) f1: (train=0.788, test=0.788) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.751, test=0.748) f1: (train=0.791, test=0.788) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.871, test=0.870) balanced_accuracy: (train=0.750, test=0.747) f1: (train=0.791, test=0.787) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.866) balanced_accuracy: (train=0.747, test=0.741) f1: (train=0.787, test=0.781) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.866) balanced_accuracy: (train=0.747, test=0.741) f1: (train=0.787, test=0.781) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.870) balanced_accuracy: (train=0.745, test=0.746) f1: (train=0.786, test=0.787) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.748, test=0.745) f1: (train=0.788, test=0.784) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.746, test=0.744) f1: (train=0.787, test=0.785) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.866) balanced_accuracy: (train=0.747, test=0.741) f1: (train=0.787, test=0.781) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.866) balanced_accuracy: (train=0.747, test=0.741) f1: (train=0.787, test=0.781) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.870) balanced_accuracy: (train=0.745, test=0.746) f1: (train=0.786, test=0.787) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.748, test=0.745) f1: (train=0.788, test=0.784) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.746, test=0.744) f1: (train=0.787, test=0.785) total time=   0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.866) balanced_accuracy: (train=0.747, test=0.741) f1: (train=0.787, test=0.781) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.866) balanced_accuracy: (train=0.747, test=0.741) f1: (train=0.787, test=0.781) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.870) balanced_accuracy: (train=0.745, test=0.746) f1: (train=0.786, test=0.787) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.748, test=0.745) f1: (train=0.788, test=0.784) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.746, test=0.744) f1: (train=0.787, test=0.785) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.866) balanced_accuracy: (train=0.747, test=0.741) f1: (train=0.787, test=0.781) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.866) balanced_accuracy: (train=0.747, test=0.741) f1: (train=0.787, test=0.781) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.870) balanced_accuracy: (train=0.745, test=0.746) f1: (train=0.786, test=0.787) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.748, test=0.745) f1: (train=0.788, test=0.784) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.746, test=0.744) f1: (train=0.787, test=0.785) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.866) balanced_accuracy: (train=0.747, test=0.741) f1: (train=0.787, test=0.781) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.866) balanced_accuracy: (train=0.747, test=0.741) f1: (train=0.787, test=0.781) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.870) balanced_accuracy: (train=0.745, test=0.746) f1: (train=0.786, test=0.787) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.748, test=0.745) f1: (train=0.788, test=0.784) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.746, test=0.744) f1: (train=0.787, test=0.785) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.866) balanced_accuracy: (train=0.747, test=0.741) f1: (train=0.787, test=0.781) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.866) balanced_accuracy: (train=0.747, test=0.741) f1: (train=0.787, test=0.781) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.870) balanced_accuracy: (train=0.745, test=0.746) f1: (train=0.786, test=0.787) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.748, test=0.745) f1: (train=0.788, test=0.784) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.746, test=0.744) f1: (train=0.787, test=0.785) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.786, test=0.781) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.745, test=0.739) f1: (train=0.785, test=0.779) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.869) balanced_accuracy: (train=0.739, test=0.742) f1: (train=0.781, test=0.784) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.740) f1: (train=0.782, test=0.782) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.786, test=0.781) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.745, test=0.739) f1: (train=0.785, test=0.779) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.869) balanced_accuracy: (train=0.739, test=0.742) f1: (train=0.781, test=0.784) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.740) f1: (train=0.782, test=0.782) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.786, test=0.781) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.745, test=0.739) f1: (train=0.785, test=0.779) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.869) balanced_accuracy: (train=0.739, test=0.742) f1: (train=0.781, test=0.784) total time=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.740) f1: (train=0.782, test=0.782) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.786, test=0.781) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.745, test=0.739) f1: (train=0.785, test=0.779) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.869) balanced_accuracy: (train=0.739, test=0.742) f1: (train=0.781, test=0.784) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.740) f1: (train=0.782, test=0.782) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.786, test=0.781) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.745, test=0.739) f1: (train=0.785, test=0.779) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.869) balanced_accuracy: (train=0.739, test=0.742) f1: (train=0.781, test=0.784) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.740) f1: (train=0.782, test=0.782) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.786, test=0.781) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.745, test=0.739) f1: (train=0.785, test=0.779) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.869) balanced_accuracy: (train=0.739, test=0.742) f1: (train=0.781, test=0.784) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.740) f1: (train=0.782, test=0.782) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.865) balanced_accuracy: (train=0.741, test=0.738) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.864) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.782, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.866, test=0.867) balanced_accuracy: (train=0.737, test=0.739) f1: (train=0.778, test=0.781) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.866, test=0.866) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.777, test=0.777) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.866, test=0.867) balanced_accuracy: (train=0.739, test=0.739) f1: (train=0.780, test=0.781) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.865) balanced_accuracy: (train=0.741, test=0.738) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.864) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.782, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.866, test=0.867) balanced_accuracy: (train=0.737, test=0.739) f1: (train=0.778, test=0.781) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.866, test=0.866) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.777, test=0.777) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.866, test=0.867) balanced_accuracy: (train=0.739, test=0.739) f1: (train=0.780, test=0.781) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.865) balanced_accuracy: (train=0.741, test=0.738) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.864) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.782, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.866, test=0.867) balanced_accuracy: (train=0.737, test=0.739) f1: (train=0.778, test=0.781) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.866, test=0.866) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.777, test=0.777) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.866, test=0.867) balanced_accuracy: (train=0.739, test=0.739) f1: (train=0.780, test=0.781) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.865) balanced_accuracy: (train=0.741, test=0.738) f1: (train=0.781, test=0.778) total time=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.864) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.782, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.866, test=0.867) balanced_accuracy: (train=0.737, test=0.739) f1: (train=0.778, test=0.781) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.866, test=0.866) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.777, test=0.777) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.866, test=0.867) balanced_accuracy: (train=0.739, test=0.739) f1: (train=0.780, test=0.781) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.865) balanced_accuracy: (train=0.741, test=0.738) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.864) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.782, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.866, test=0.867) balanced_accuracy: (train=0.737, test=0.739) f1: (train=0.778, test=0.781) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.866, test=0.866) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.777, test=0.777) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.866, test=0.867) balanced_accuracy: (train=0.739, test=0.739) f1: (train=0.780, test=0.781) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.865) balanced_accuracy: (train=0.741, test=0.738) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.864) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.782, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.866, test=0.867) balanced_accuracy: (train=0.737, test=0.739) f1: (train=0.778, test=0.781) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.866, test=0.866) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.777, test=0.777) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.866, test=0.867) balanced_accuracy: (train=0.739, test=0.739) f1: (train=0.780, test=0.781) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.871, test=0.866) balanced_accuracy: (train=0.752, test=0.745) f1: (train=0.792, test=0.784) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.751, test=0.745) f1: (train=0.791, test=0.784) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.870, test=0.870) balanced_accuracy: (train=0.746, test=0.746) f1: (train=0.788, test=0.788) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.751, test=0.748) f1: (train=0.791, test=0.788) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.871, test=0.870) balanced_accuracy: (train=0.750, test=0.747) f1: (train=0.791, test=0.787) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.871, test=0.866) balanced_accuracy: (train=0.752, test=0.745) f1: (train=0.792, test=0.784) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.751, test=0.745) f1: (train=0.791, test=0.784) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.870, test=0.870) balanced_accuracy: (train=0.746, test=0.746) f1: (train=0.788, test=0.788) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.751, test=0.748) f1: (train=0.791, test=0.788) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.871, test=0.870) balanced_accuracy: (train=0.750, test=0.747) f1: (train=0.791, test=0.787) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.871, test=0.866) balanced_accuracy: (train=0.752, test=0.745) f1: (train=0.792, test=0.784) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.751, test=0.745) f1: (train=0.791, test=0.784) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.870, test=0.870) balanced_accuracy: (train=0.746, test=0.746) f1: (train=0.788, test=0.788) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.751, test=0.748) f1: (train=0.791, test=0.788) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.871, test=0.870) balanced_accuracy: (train=0.750, test=0.747) f1: (train=0.791, test=0.787) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.871, test=0.866) balanced_accuracy: (train=0.752, test=0.745) f1: (train=0.792, test=0.784) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.751, test=0.745) f1: (train=0.791, test=0.784) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.870, test=0.870) balanced_accuracy: (train=0.746, test=0.746) f1: (train=0.788, test=0.788) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.751, test=0.748) f1: (train=0.791, test=0.788) total time=   0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.871, test=0.870) balanced_accuracy: (train=0.750, test=0.747) f1: (train=0.791, test=0.787) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.871, test=0.866) balanced_accuracy: (train=0.752, test=0.745) f1: (train=0.792, test=0.784) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.751, test=0.745) f1: (train=0.791, test=0.784) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.870, test=0.870) balanced_accuracy: (train=0.746, test=0.746) f1: (train=0.788, test=0.788) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.751, test=0.748) f1: (train=0.791, test=0.788) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.871, test=0.870) balanced_accuracy: (train=0.750, test=0.747) f1: (train=0.791, test=0.787) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.871, test=0.866) balanced_accuracy: (train=0.752, test=0.745) f1: (train=0.792, test=0.784) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.751, test=0.745) f1: (train=0.791, test=0.784) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.870, test=0.870) balanced_accuracy: (train=0.746, test=0.746) f1: (train=0.788, test=0.788) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.751, test=0.748) f1: (train=0.791, test=0.788) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.871, test=0.870) balanced_accuracy: (train=0.750, test=0.747) f1: (train=0.791, test=0.787) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.866) balanced_accuracy: (train=0.747, test=0.741) f1: (train=0.787, test=0.781) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.866) balanced_accuracy: (train=0.747, test=0.741) f1: (train=0.787, test=0.781) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.870) balanced_accuracy: (train=0.745, test=0.746) f1: (train=0.786, test=0.787) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.748, test=0.745) f1: (train=0.788, test=0.784) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.746, test=0.744) f1: (train=0.787, test=0.785) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.866) balanced_accuracy: (train=0.747, test=0.741) f1: (train=0.787, test=0.781) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.866) balanced_accuracy: (train=0.747, test=0.741) f1: (train=0.787, test=0.781) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.870) balanced_accuracy: (train=0.745, test=0.746) f1: (train=0.786, test=0.787) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.748, test=0.745) f1: (train=0.788, test=0.784) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.746, test=0.744) f1: (train=0.787, test=0.785) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.866) balanced_accuracy: (train=0.747, test=0.741) f1: (train=0.787, test=0.781) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.866) balanced_accuracy: (train=0.747, test=0.741) f1: (train=0.787, test=0.781) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.870) balanced_accuracy: (train=0.745, test=0.746) f1: (train=0.786, test=0.787) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.748, test=0.745) f1: (train=0.788, test=0.784) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.746, test=0.744) f1: (train=0.787, test=0.785) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.866) balanced_accuracy: (train=0.747, test=0.741) f1: (train=0.787, test=0.781) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.866) balanced_accuracy: (train=0.747, test=0.741) f1: (train=0.787, test=0.781) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.870) balanced_accuracy: (train=0.745, test=0.746) f1: (train=0.786, test=0.787) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.748, test=0.745) f1: (train=0.788, test=0.784) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.746, test=0.744) f1: (train=0.787, test=0.785) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.866) balanced_accuracy: (train=0.747, test=0.741) f1: (train=0.787, test=0.781) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.866) balanced_accuracy: (train=0.747, test=0.741) f1: (train=0.787, test=0.781) total time=   0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.870) balanced_accuracy: (train=0.745, test=0.746) f1: (train=0.786, test=0.787) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.748, test=0.745) f1: (train=0.788, test=0.784) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.746, test=0.744) f1: (train=0.787, test=0.785) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.866) balanced_accuracy: (train=0.747, test=0.741) f1: (train=0.787, test=0.781) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.866) balanced_accuracy: (train=0.747, test=0.741) f1: (train=0.787, test=0.781) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.870) balanced_accuracy: (train=0.745, test=0.746) f1: (train=0.786, test=0.787) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.748, test=0.745) f1: (train=0.788, test=0.784) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.746, test=0.744) f1: (train=0.787, test=0.785) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.786, test=0.781) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.745, test=0.739) f1: (train=0.785, test=0.779) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.869) balanced_accuracy: (train=0.739, test=0.742) f1: (train=0.781, test=0.784) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.740) f1: (train=0.782, test=0.782) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.786, test=0.781) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.745, test=0.739) f1: (train=0.785, test=0.779) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.869) balanced_accuracy: (train=0.739, test=0.742) f1: (train=0.781, test=0.784) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.740) f1: (train=0.782, test=0.782) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.786, test=0.781) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.745, test=0.739) f1: (train=0.785, test=0.779) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.869) balanced_accuracy: (train=0.739, test=0.742) f1: (train=0.781, test=0.784) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.740) f1: (train=0.782, test=0.782) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.786, test=0.781) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.745, test=0.739) f1: (train=0.785, test=0.779) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.869) balanced_accuracy: (train=0.739, test=0.742) f1: (train=0.781, test=0.784) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.740) f1: (train=0.782, test=0.782) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.786, test=0.781) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.745, test=0.739) f1: (train=0.785, test=0.779) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.869) balanced_accuracy: (train=0.739, test=0.742) f1: (train=0.781, test=0.784) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.740) f1: (train=0.782, test=0.782) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.786, test=0.781) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.745, test=0.739) f1: (train=0.785, test=0.779) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.869) balanced_accuracy: (train=0.739, test=0.742) f1: (train=0.781, test=0.784) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.740) f1: (train=0.782, test=0.782) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.865) balanced_accuracy: (train=0.741, test=0.738) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.864) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.782, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.866, test=0.867) balanced_accuracy: (train=0.737, test=0.739) f1: (train=0.778, test=0.781) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.866, test=0.866) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.777, test=0.777) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.866, test=0.867) balanced_accuracy: (train=0.739, test=0.739) f1: (train=0.780, test=0.781) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.865) balanced_accuracy: (train=0.741, test=0.738) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.864) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.782, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.866, test=0.867) balanced_accuracy: (train=0.737, test=0.739) f1: (train=0.778, test=0.781) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.866, test=0.866) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.777, test=0.777) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.866, test=0.867) balanced_accuracy: (train=0.739, test=0.739) f1: (train=0.780, test=0.781) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.865) balanced_accuracy: (train=0.741, test=0.738) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.864) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.782, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.866, test=0.867) balanced_accuracy: (train=0.737, test=0.739) f1: (train=0.778, test=0.781) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.866, test=0.866) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.777, test=0.777) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.866, test=0.867) balanced_accuracy: (train=0.739, test=0.739) f1: (train=0.780, test=0.781) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.865) balanced_accuracy: (train=0.741, test=0.738) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.864) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.782, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.866, test=0.867) balanced_accuracy: (train=0.737, test=0.739) f1: (train=0.778, test=0.781) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.866, test=0.866) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.777, test=0.777) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.866, test=0.867) balanced_accuracy: (train=0.739, test=0.739) f1: (train=0.780, test=0.781) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.865) balanced_accuracy: (train=0.741, test=0.738) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.864) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.782, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.866, test=0.867) balanced_accuracy: (train=0.737, test=0.739) f1: (train=0.778, test=0.781) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.866, test=0.866) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.777, test=0.777) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.866, test=0.867) balanced_accuracy: (train=0.739, test=0.739) f1: (train=0.780, test=0.781) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.865) balanced_accuracy: (train=0.741, test=0.738) f1: (train=0.781, test=0.778) total time=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.864) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.782, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.866, test=0.867) balanced_accuracy: (train=0.737, test=0.739) f1: (train=0.778, test=0.781) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.866, test=0.866) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.777, test=0.777) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.866, test=0.867) balanced_accuracy: (train=0.739, test=0.739) f1: (train=0.780, test=0.781) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.749, test=0.743) f1: (train=0.790, test=0.783) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.870, test=0.866) balanced_accuracy: (train=0.748, test=0.742) f1: (train=0.788, test=0.782) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.871) balanced_accuracy: (train=0.744, test=0.745) f1: (train=0.785, test=0.787) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.749, test=0.746) f1: (train=0.789, test=0.786) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.744, test=0.743) f1: (train=0.787, test=0.785) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.749, test=0.743) f1: (train=0.790, test=0.783) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.870, test=0.866) balanced_accuracy: (train=0.748, test=0.742) f1: (train=0.788, test=0.782) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.871) balanced_accuracy: (train=0.744, test=0.745) f1: (train=0.785, test=0.787) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.749, test=0.746) f1: (train=0.789, test=0.786) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.744, test=0.743) f1: (train=0.787, test=0.785) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.749, test=0.743) f1: (train=0.790, test=0.783) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.870, test=0.866) balanced_accuracy: (train=0.748, test=0.742) f1: (train=0.788, test=0.782) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.871) balanced_accuracy: (train=0.744, test=0.745) f1: (train=0.785, test=0.787) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.749, test=0.746) f1: (train=0.789, test=0.786) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.744, test=0.743) f1: (train=0.787, test=0.785) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.749, test=0.743) f1: (train=0.790, test=0.783) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.870, test=0.866) balanced_accuracy: (train=0.748, test=0.742) f1: (train=0.788, test=0.782) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.871) balanced_accuracy: (train=0.744, test=0.745) f1: (train=0.785, test=0.787) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.749, test=0.746) f1: (train=0.789, test=0.786) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.744, test=0.743) f1: (train=0.787, test=0.785) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.749, test=0.743) f1: (train=0.790, test=0.783) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.870, test=0.866) balanced_accuracy: (train=0.748, test=0.742) f1: (train=0.788, test=0.782) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.871) balanced_accuracy: (train=0.744, test=0.745) f1: (train=0.785, test=0.787) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.749, test=0.746) f1: (train=0.789, test=0.786) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.744, test=0.743) f1: (train=0.787, test=0.785) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.749, test=0.743) f1: (train=0.790, test=0.783) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.870, test=0.866) balanced_accuracy: (train=0.748, test=0.742) f1: (train=0.788, test=0.782) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.871) balanced_accuracy: (train=0.744, test=0.745) f1: (train=0.785, test=0.787) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.749, test=0.746) f1: (train=0.789, test=0.786) total time=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.744, test=0.743) f1: (train=0.787, test=0.785) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.866) balanced_accuracy: (train=0.747, test=0.742) f1: (train=0.788, test=0.782) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.745, test=0.739) f1: (train=0.786, test=0.779) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.869) balanced_accuracy: (train=0.744, test=0.746) f1: (train=0.785, test=0.787) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.746, test=0.744) f1: (train=0.786, test=0.784) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.745, test=0.743) f1: (train=0.786, test=0.784) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.866) balanced_accuracy: (train=0.747, test=0.742) f1: (train=0.788, test=0.782) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.745, test=0.739) f1: (train=0.786, test=0.779) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.869) balanced_accuracy: (train=0.744, test=0.746) f1: (train=0.785, test=0.787) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.746, test=0.744) f1: (train=0.786, test=0.784) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.745, test=0.743) f1: (train=0.786, test=0.784) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.866) balanced_accuracy: (train=0.747, test=0.742) f1: (train=0.788, test=0.782) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.745, test=0.739) f1: (train=0.786, test=0.779) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.869) balanced_accuracy: (train=0.744, test=0.746) f1: (train=0.785, test=0.787) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.746, test=0.744) f1: (train=0.786, test=0.784) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.745, test=0.743) f1: (train=0.786, test=0.784) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.866) balanced_accuracy: (train=0.747, test=0.742) f1: (train=0.788, test=0.782) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.745, test=0.739) f1: (train=0.786, test=0.779) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.869) balanced_accuracy: (train=0.744, test=0.746) f1: (train=0.785, test=0.787) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.746, test=0.744) f1: (train=0.786, test=0.784) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.745, test=0.743) f1: (train=0.786, test=0.784) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.866) balanced_accuracy: (train=0.747, test=0.742) f1: (train=0.788, test=0.782) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.745, test=0.739) f1: (train=0.786, test=0.779) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.869) balanced_accuracy: (train=0.744, test=0.746) f1: (train=0.785, test=0.787) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.746, test=0.744) f1: (train=0.786, test=0.784) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.745, test=0.743) f1: (train=0.786, test=0.784) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.866) balanced_accuracy: (train=0.747, test=0.742) f1: (train=0.788, test=0.782) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.745, test=0.739) f1: (train=0.786, test=0.779) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.869) balanced_accuracy: (train=0.744, test=0.746) f1: (train=0.785, test=0.787) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.746, test=0.744) f1: (train=0.786, test=0.784) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.745, test=0.743) f1: (train=0.786, test=0.784) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.786, test=0.781) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.744, test=0.738) f1: (train=0.784, test=0.778) total time=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.869) balanced_accuracy: (train=0.739, test=0.742) f1: (train=0.781, test=0.784) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.740) f1: (train=0.782, test=0.782) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.786, test=0.781) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.744, test=0.738) f1: (train=0.784, test=0.778) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.869) balanced_accuracy: (train=0.739, test=0.742) f1: (train=0.781, test=0.784) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.740) f1: (train=0.782, test=0.782) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.786, test=0.781) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.744, test=0.738) f1: (train=0.784, test=0.778) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.869) balanced_accuracy: (train=0.739, test=0.742) f1: (train=0.781, test=0.784) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.740) f1: (train=0.782, test=0.782) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.786, test=0.781) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.744, test=0.738) f1: (train=0.784, test=0.778) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.869) balanced_accuracy: (train=0.739, test=0.742) f1: (train=0.781, test=0.784) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.740) f1: (train=0.782, test=0.782) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.786, test=0.781) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.744, test=0.738) f1: (train=0.784, test=0.778) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.869) balanced_accuracy: (train=0.739, test=0.742) f1: (train=0.781, test=0.784) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.740) f1: (train=0.782, test=0.782) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.786, test=0.781) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.744, test=0.738) f1: (train=0.784, test=0.778) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.869) balanced_accuracy: (train=0.739, test=0.742) f1: (train=0.781, test=0.784) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.740) f1: (train=0.782, test=0.782) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.865) balanced_accuracy: (train=0.741, test=0.738) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.864) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.782, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.866, test=0.867) balanced_accuracy: (train=0.737, test=0.739) f1: (train=0.778, test=0.781) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.866, test=0.866) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.777, test=0.777) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.866, test=0.867) balanced_accuracy: (train=0.739, test=0.739) f1: (train=0.780, test=0.781) total time=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.865) balanced_accuracy: (train=0.741, test=0.738) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.864) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.782, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.866, test=0.867) balanced_accuracy: (train=0.737, test=0.739) f1: (train=0.778, test=0.781) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.866, test=0.866) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.777, test=0.777) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.866, test=0.867) balanced_accuracy: (train=0.739, test=0.739) f1: (train=0.780, test=0.781) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.865) balanced_accuracy: (train=0.741, test=0.738) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.864) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.782, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.866, test=0.867) balanced_accuracy: (train=0.737, test=0.739) f1: (train=0.778, test=0.781) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.866, test=0.866) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.777, test=0.777) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.866, test=0.867) balanced_accuracy: (train=0.739, test=0.739) f1: (train=0.780, test=0.781) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.865) balanced_accuracy: (train=0.741, test=0.738) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.864) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.782, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.866, test=0.867) balanced_accuracy: (train=0.737, test=0.739) f1: (train=0.778, test=0.781) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.866, test=0.866) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.777, test=0.777) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.866, test=0.867) balanced_accuracy: (train=0.739, test=0.739) f1: (train=0.780, test=0.781) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.865) balanced_accuracy: (train=0.741, test=0.738) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.864) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.782, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.866, test=0.867) balanced_accuracy: (train=0.737, test=0.739) f1: (train=0.778, test=0.781) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.866, test=0.866) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.777, test=0.777) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.866, test=0.867) balanced_accuracy: (train=0.739, test=0.739) f1: (train=0.780, test=0.781) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.865) balanced_accuracy: (train=0.741, test=0.738) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.864) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.782, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.866, test=0.867) balanced_accuracy: (train=0.737, test=0.739) f1: (train=0.778, test=0.781) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.866, test=0.866) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.777, test=0.777) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.866, test=0.867) balanced_accuracy: (train=0.739, test=0.739) f1: (train=0.780, test=0.781) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.871, test=0.866) balanced_accuracy: (train=0.752, test=0.745) f1: (train=0.792, test=0.784) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.751, test=0.745) f1: (train=0.791, test=0.784) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.870, test=0.870) balanced_accuracy: (train=0.746, test=0.746) f1: (train=0.788, test=0.788) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.751, test=0.748) f1: (train=0.791, test=0.788) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.871, test=0.870) balanced_accuracy: (train=0.750, test=0.747) f1: (train=0.791, test=0.787) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.871, test=0.866) balanced_accuracy: (train=0.752, test=0.745) f1: (train=0.792, test=0.784) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.751, test=0.745) f1: (train=0.791, test=0.784) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.870, test=0.870) balanced_accuracy: (train=0.746, test=0.746) f1: (train=0.788, test=0.788) total time=   0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.751, test=0.748) f1: (train=0.791, test=0.788) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.871, test=0.870) balanced_accuracy: (train=0.750, test=0.747) f1: (train=0.791, test=0.787) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.871, test=0.866) balanced_accuracy: (train=0.752, test=0.745) f1: (train=0.792, test=0.784) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.751, test=0.745) f1: (train=0.791, test=0.784) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.870, test=0.870) balanced_accuracy: (train=0.746, test=0.746) f1: (train=0.788, test=0.788) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.751, test=0.748) f1: (train=0.791, test=0.788) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.871, test=0.870) balanced_accuracy: (train=0.750, test=0.747) f1: (train=0.791, test=0.787) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.871, test=0.866) balanced_accuracy: (train=0.752, test=0.745) f1: (train=0.792, test=0.784) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.751, test=0.745) f1: (train=0.791, test=0.784) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.870, test=0.870) balanced_accuracy: (train=0.746, test=0.746) f1: (train=0.788, test=0.788) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.751, test=0.748) f1: (train=0.791, test=0.788) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.871, test=0.870) balanced_accuracy: (train=0.750, test=0.747) f1: (train=0.791, test=0.787) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.871, test=0.866) balanced_accuracy: (train=0.752, test=0.745) f1: (train=0.792, test=0.784) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.751, test=0.745) f1: (train=0.791, test=0.784) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.870, test=0.870) balanced_accuracy: (train=0.746, test=0.746) f1: (train=0.788, test=0.788) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.751, test=0.748) f1: (train=0.791, test=0.788) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.871, test=0.870) balanced_accuracy: (train=0.750, test=0.747) f1: (train=0.791, test=0.787) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.871, test=0.866) balanced_accuracy: (train=0.752, test=0.745) f1: (train=0.792, test=0.784) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.751, test=0.745) f1: (train=0.791, test=0.784) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.870, test=0.870) balanced_accuracy: (train=0.746, test=0.746) f1: (train=0.788, test=0.788) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.751, test=0.748) f1: (train=0.791, test=0.788) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.871, test=0.870) balanced_accuracy: (train=0.750, test=0.747) f1: (train=0.791, test=0.787) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.866) balanced_accuracy: (train=0.747, test=0.741) f1: (train=0.787, test=0.781) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.866) balanced_accuracy: (train=0.747, test=0.741) f1: (train=0.787, test=0.781) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.870) balanced_accuracy: (train=0.745, test=0.746) f1: (train=0.786, test=0.787) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.748, test=0.745) f1: (train=0.788, test=0.784) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.746, test=0.744) f1: (train=0.787, test=0.785) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.866) balanced_accuracy: (train=0.747, test=0.741) f1: (train=0.787, test=0.781) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.866) balanced_accuracy: (train=0.747, test=0.741) f1: (train=0.787, test=0.781) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.870) balanced_accuracy: (train=0.745, test=0.746) f1: (train=0.786, test=0.787) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.748, test=0.745) f1: (train=0.788, test=0.784) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.746, test=0.744) f1: (train=0.787, test=0.785) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.866) balanced_accuracy: (train=0.747, test=0.741) f1: (train=0.787, test=0.781) total time=   0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.866) balanced_accuracy: (train=0.747, test=0.741) f1: (train=0.787, test=0.781) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.870) balanced_accuracy: (train=0.745, test=0.746) f1: (train=0.786, test=0.787) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.748, test=0.745) f1: (train=0.788, test=0.784) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.746, test=0.744) f1: (train=0.787, test=0.785) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.866) balanced_accuracy: (train=0.747, test=0.741) f1: (train=0.787, test=0.781) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.866) balanced_accuracy: (train=0.747, test=0.741) f1: (train=0.787, test=0.781) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.870) balanced_accuracy: (train=0.745, test=0.746) f1: (train=0.786, test=0.787) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.748, test=0.745) f1: (train=0.788, test=0.784) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.746, test=0.744) f1: (train=0.787, test=0.785) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.866) balanced_accuracy: (train=0.747, test=0.741) f1: (train=0.787, test=0.781) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.866) balanced_accuracy: (train=0.747, test=0.741) f1: (train=0.787, test=0.781) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.870) balanced_accuracy: (train=0.745, test=0.746) f1: (train=0.786, test=0.787) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.748, test=0.745) f1: (train=0.788, test=0.784) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.746, test=0.744) f1: (train=0.787, test=0.785) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.866) balanced_accuracy: (train=0.747, test=0.741) f1: (train=0.787, test=0.781) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.866) balanced_accuracy: (train=0.747, test=0.741) f1: (train=0.787, test=0.781) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.870) balanced_accuracy: (train=0.745, test=0.746) f1: (train=0.786, test=0.787) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.748, test=0.745) f1: (train=0.788, test=0.784) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.746, test=0.744) f1: (train=0.787, test=0.785) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.786, test=0.781) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.745, test=0.739) f1: (train=0.785, test=0.779) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.869) balanced_accuracy: (train=0.739, test=0.742) f1: (train=0.781, test=0.784) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.740) f1: (train=0.782, test=0.782) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.786, test=0.781) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.745, test=0.739) f1: (train=0.785, test=0.779) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.869) balanced_accuracy: (train=0.739, test=0.742) f1: (train=0.781, test=0.784) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.740) f1: (train=0.782, test=0.782) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.786, test=0.781) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.745, test=0.739) f1: (train=0.785, test=0.779) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.869) balanced_accuracy: (train=0.739, test=0.742) f1: (train=0.781, test=0.784) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.740) f1: (train=0.782, test=0.782) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.786, test=0.781) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.745, test=0.739) f1: (train=0.785, test=0.779) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.869) balanced_accuracy: (train=0.739, test=0.742) f1: (train=0.781, test=0.784) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.740) f1: (train=0.782, test=0.782) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.786, test=0.781) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.745, test=0.739) f1: (train=0.785, test=0.779) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.869) balanced_accuracy: (train=0.739, test=0.742) f1: (train=0.781, test=0.784) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.740) f1: (train=0.782, test=0.782) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.786, test=0.781) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.745, test=0.739) f1: (train=0.785, test=0.779) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.869) balanced_accuracy: (train=0.739, test=0.742) f1: (train=0.781, test=0.784) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.740) f1: (train=0.782, test=0.782) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.865) balanced_accuracy: (train=0.741, test=0.738) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.864) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.782, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.866, test=0.867) balanced_accuracy: (train=0.737, test=0.739) f1: (train=0.778, test=0.781) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.866, test=0.866) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.777, test=0.777) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.866, test=0.867) balanced_accuracy: (train=0.739, test=0.739) f1: (train=0.780, test=0.781) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.865) balanced_accuracy: (train=0.741, test=0.738) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.864) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.782, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.866, test=0.867) balanced_accuracy: (train=0.737, test=0.739) f1: (train=0.778, test=0.781) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.866, test=0.866) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.777, test=0.777) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.866, test=0.867) balanced_accuracy: (train=0.739, test=0.739) f1: (train=0.780, test=0.781) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.865) balanced_accuracy: (train=0.741, test=0.738) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.864) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.782, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.866, test=0.867) balanced_accuracy: (train=0.737, test=0.739) f1: (train=0.778, test=0.781) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.866, test=0.866) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.777, test=0.777) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.866, test=0.867) balanced_accuracy: (train=0.739, test=0.739) f1: (train=0.780, test=0.781) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.865) balanced_accuracy: (train=0.741, test=0.738) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.864) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.782, test=0.776) total time=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.866, test=0.867) balanced_accuracy: (train=0.737, test=0.739) f1: (train=0.778, test=0.781) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.866, test=0.866) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.777, test=0.777) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.866, test=0.867) balanced_accuracy: (train=0.739, test=0.739) f1: (train=0.780, test=0.781) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.865) balanced_accuracy: (train=0.741, test=0.738) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.864) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.782, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.866, test=0.867) balanced_accuracy: (train=0.737, test=0.739) f1: (train=0.778, test=0.781) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.866, test=0.866) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.777, test=0.777) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.866, test=0.867) balanced_accuracy: (train=0.739, test=0.739) f1: (train=0.780, test=0.781) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.865) balanced_accuracy: (train=0.741, test=0.738) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.864) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.782, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.866, test=0.867) balanced_accuracy: (train=0.737, test=0.739) f1: (train=0.778, test=0.781) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.866, test=0.866) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.777, test=0.777) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.866, test=0.867) balanced_accuracy: (train=0.739, test=0.739) f1: (train=0.780, test=0.781) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.871, test=0.866) balanced_accuracy: (train=0.752, test=0.745) f1: (train=0.792, test=0.784) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.751, test=0.745) f1: (train=0.791, test=0.784) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.870, test=0.870) balanced_accuracy: (train=0.746, test=0.746) f1: (train=0.788, test=0.788) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.751, test=0.748) f1: (train=0.791, test=0.788) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.871, test=0.870) balanced_accuracy: (train=0.750, test=0.747) f1: (train=0.791, test=0.787) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.871, test=0.866) balanced_accuracy: (train=0.752, test=0.745) f1: (train=0.792, test=0.784) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.751, test=0.745) f1: (train=0.791, test=0.784) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.870, test=0.870) balanced_accuracy: (train=0.746, test=0.746) f1: (train=0.788, test=0.788) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.751, test=0.748) f1: (train=0.791, test=0.788) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.871, test=0.870) balanced_accuracy: (train=0.750, test=0.747) f1: (train=0.791, test=0.787) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.871, test=0.866) balanced_accuracy: (train=0.752, test=0.745) f1: (train=0.792, test=0.784) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.751, test=0.745) f1: (train=0.791, test=0.784) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.870, test=0.870) balanced_accuracy: (train=0.746, test=0.746) f1: (train=0.788, test=0.788) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.751, test=0.748) f1: (train=0.791, test=0.788) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.871, test=0.870) balanced_accuracy: (train=0.750, test=0.747) f1: (train=0.791, test=0.787) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.871, test=0.866) balanced_accuracy: (train=0.752, test=0.745) f1: (train=0.792, test=0.784) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.751, test=0.745) f1: (train=0.791, test=0.784) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.870, test=0.870) balanced_accuracy: (train=0.746, test=0.746) f1: (train=0.788, test=0.788) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.751, test=0.748) f1: (train=0.791, test=0.788) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.871, test=0.870) balanced_accuracy: (train=0.750, test=0.747) f1: (train=0.791, test=0.787) total time=   0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.871, test=0.866) balanced_accuracy: (train=0.752, test=0.745) f1: (train=0.792, test=0.784) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.751, test=0.745) f1: (train=0.791, test=0.784) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.870, test=0.870) balanced_accuracy: (train=0.746, test=0.746) f1: (train=0.788, test=0.788) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.751, test=0.748) f1: (train=0.791, test=0.788) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.871, test=0.870) balanced_accuracy: (train=0.750, test=0.747) f1: (train=0.791, test=0.787) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.871, test=0.866) balanced_accuracy: (train=0.752, test=0.745) f1: (train=0.792, test=0.784) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.751, test=0.745) f1: (train=0.791, test=0.784) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.870, test=0.870) balanced_accuracy: (train=0.746, test=0.746) f1: (train=0.788, test=0.788) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.751, test=0.748) f1: (train=0.791, test=0.788) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.871, test=0.870) balanced_accuracy: (train=0.750, test=0.747) f1: (train=0.791, test=0.787) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.866) balanced_accuracy: (train=0.747, test=0.741) f1: (train=0.787, test=0.781) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.866) balanced_accuracy: (train=0.747, test=0.741) f1: (train=0.787, test=0.781) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.870) balanced_accuracy: (train=0.745, test=0.746) f1: (train=0.786, test=0.787) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.748, test=0.745) f1: (train=0.788, test=0.784) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.746, test=0.744) f1: (train=0.787, test=0.785) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.866) balanced_accuracy: (train=0.747, test=0.741) f1: (train=0.787, test=0.781) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.866) balanced_accuracy: (train=0.747, test=0.741) f1: (train=0.787, test=0.781) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.870) balanced_accuracy: (train=0.745, test=0.746) f1: (train=0.786, test=0.787) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.748, test=0.745) f1: (train=0.788, test=0.784) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.746, test=0.744) f1: (train=0.787, test=0.785) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.866) balanced_accuracy: (train=0.747, test=0.741) f1: (train=0.787, test=0.781) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.866) balanced_accuracy: (train=0.747, test=0.741) f1: (train=0.787, test=0.781) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.870) balanced_accuracy: (train=0.745, test=0.746) f1: (train=0.786, test=0.787) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.748, test=0.745) f1: (train=0.788, test=0.784) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.746, test=0.744) f1: (train=0.787, test=0.785) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.866) balanced_accuracy: (train=0.747, test=0.741) f1: (train=0.787, test=0.781) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.866) balanced_accuracy: (train=0.747, test=0.741) f1: (train=0.787, test=0.781) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.870) balanced_accuracy: (train=0.745, test=0.746) f1: (train=0.786, test=0.787) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.748, test=0.745) f1: (train=0.788, test=0.784) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.746, test=0.744) f1: (train=0.787, test=0.785) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.866) balanced_accuracy: (train=0.747, test=0.741) f1: (train=0.787, test=0.781) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.866) balanced_accuracy: (train=0.747, test=0.741) f1: (train=0.787, test=0.781) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.870) balanced_accuracy: (train=0.745, test=0.746) f1: (train=0.786, test=0.787) total time=   0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.748, test=0.745) f1: (train=0.788, test=0.784) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.746, test=0.744) f1: (train=0.787, test=0.785) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.866) balanced_accuracy: (train=0.747, test=0.741) f1: (train=0.787, test=0.781) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.866) balanced_accuracy: (train=0.747, test=0.741) f1: (train=0.787, test=0.781) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.870) balanced_accuracy: (train=0.745, test=0.746) f1: (train=0.786, test=0.787) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.748, test=0.745) f1: (train=0.788, test=0.784) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.746, test=0.744) f1: (train=0.787, test=0.785) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.786, test=0.781) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.745, test=0.739) f1: (train=0.785, test=0.779) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.869) balanced_accuracy: (train=0.739, test=0.742) f1: (train=0.781, test=0.784) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.740) f1: (train=0.782, test=0.782) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.786, test=0.781) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.745, test=0.739) f1: (train=0.785, test=0.779) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.869) balanced_accuracy: (train=0.739, test=0.742) f1: (train=0.781, test=0.784) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.740) f1: (train=0.782, test=0.782) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.786, test=0.781) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.745, test=0.739) f1: (train=0.785, test=0.779) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.869) balanced_accuracy: (train=0.739, test=0.742) f1: (train=0.781, test=0.784) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.740) f1: (train=0.782, test=0.782) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.786, test=0.781) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.745, test=0.739) f1: (train=0.785, test=0.779) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.869) balanced_accuracy: (train=0.739, test=0.742) f1: (train=0.781, test=0.784) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.740) f1: (train=0.782, test=0.782) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.786, test=0.781) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.745, test=0.739) f1: (train=0.785, test=0.779) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.869) balanced_accuracy: (train=0.739, test=0.742) f1: (train=0.781, test=0.784) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.740) f1: (train=0.782, test=0.782) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.786, test=0.781) total time=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.745, test=0.739) f1: (train=0.785, test=0.779) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.869) balanced_accuracy: (train=0.739, test=0.742) f1: (train=0.781, test=0.784) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.740) f1: (train=0.782, test=0.782) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.865) balanced_accuracy: (train=0.741, test=0.738) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.864) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.782, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.866, test=0.867) balanced_accuracy: (train=0.737, test=0.739) f1: (train=0.778, test=0.781) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.866, test=0.866) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.777, test=0.777) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.866, test=0.867) balanced_accuracy: (train=0.739, test=0.739) f1: (train=0.780, test=0.781) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.865) balanced_accuracy: (train=0.741, test=0.738) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.864) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.782, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.866, test=0.867) balanced_accuracy: (train=0.737, test=0.739) f1: (train=0.778, test=0.781) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.866, test=0.866) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.777, test=0.777) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.866, test=0.867) balanced_accuracy: (train=0.739, test=0.739) f1: (train=0.780, test=0.781) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.865) balanced_accuracy: (train=0.741, test=0.738) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.864) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.782, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.866, test=0.867) balanced_accuracy: (train=0.737, test=0.739) f1: (train=0.778, test=0.781) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.866, test=0.866) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.777, test=0.777) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.866, test=0.867) balanced_accuracy: (train=0.739, test=0.739) f1: (train=0.780, test=0.781) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.865) balanced_accuracy: (train=0.741, test=0.738) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.864) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.782, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.866, test=0.867) balanced_accuracy: (train=0.737, test=0.739) f1: (train=0.778, test=0.781) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.866, test=0.866) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.777, test=0.777) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.866, test=0.867) balanced_accuracy: (train=0.739, test=0.739) f1: (train=0.780, test=0.781) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.865) balanced_accuracy: (train=0.741, test=0.738) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.864) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.782, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.866, test=0.867) balanced_accuracy: (train=0.737, test=0.739) f1: (train=0.778, test=0.781) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.866, test=0.866) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.777, test=0.777) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.866, test=0.867) balanced_accuracy: (train=0.739, test=0.739) f1: (train=0.780, test=0.781) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.865) balanced_accuracy: (train=0.741, test=0.738) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.864) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.782, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.866, test=0.867) balanced_accuracy: (train=0.737, test=0.739) f1: (train=0.778, test=0.781) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.866, test=0.866) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.777, test=0.777) total time=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.866, test=0.867) balanced_accuracy: (train=0.739, test=0.739) f1: (train=0.780, test=0.781) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.871, test=0.866) balanced_accuracy: (train=0.752, test=0.745) f1: (train=0.792, test=0.784) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.751, test=0.745) f1: (train=0.791, test=0.784) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.870, test=0.870) balanced_accuracy: (train=0.746, test=0.746) f1: (train=0.788, test=0.788) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.751, test=0.748) f1: (train=0.791, test=0.788) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.871, test=0.870) balanced_accuracy: (train=0.750, test=0.747) f1: (train=0.791, test=0.787) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.871, test=0.866) balanced_accuracy: (train=0.752, test=0.745) f1: (train=0.792, test=0.784) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.751, test=0.745) f1: (train=0.791, test=0.784) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.870, test=0.870) balanced_accuracy: (train=0.746, test=0.746) f1: (train=0.788, test=0.788) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.751, test=0.748) f1: (train=0.791, test=0.788) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.871, test=0.870) balanced_accuracy: (train=0.750, test=0.747) f1: (train=0.791, test=0.787) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.871, test=0.866) balanced_accuracy: (train=0.752, test=0.745) f1: (train=0.792, test=0.784) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.751, test=0.745) f1: (train=0.791, test=0.784) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.870, test=0.870) balanced_accuracy: (train=0.746, test=0.746) f1: (train=0.788, test=0.788) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.751, test=0.748) f1: (train=0.791, test=0.788) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.871, test=0.870) balanced_accuracy: (train=0.750, test=0.747) f1: (train=0.791, test=0.787) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.871, test=0.866) balanced_accuracy: (train=0.752, test=0.745) f1: (train=0.792, test=0.784) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.751, test=0.745) f1: (train=0.791, test=0.784) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.870, test=0.870) balanced_accuracy: (train=0.746, test=0.746) f1: (train=0.788, test=0.788) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.751, test=0.748) f1: (train=0.791, test=0.788) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.871, test=0.870) balanced_accuracy: (train=0.750, test=0.747) f1: (train=0.791, test=0.787) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.871, test=0.866) balanced_accuracy: (train=0.752, test=0.745) f1: (train=0.792, test=0.784) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.751, test=0.745) f1: (train=0.791, test=0.784) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.870, test=0.870) balanced_accuracy: (train=0.746, test=0.746) f1: (train=0.788, test=0.788) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.751, test=0.748) f1: (train=0.791, test=0.788) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.871, test=0.870) balanced_accuracy: (train=0.750, test=0.747) f1: (train=0.791, test=0.787) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.871, test=0.866) balanced_accuracy: (train=0.752, test=0.745) f1: (train=0.792, test=0.784) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.751, test=0.745) f1: (train=0.791, test=0.784) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.870, test=0.870) balanced_accuracy: (train=0.746, test=0.746) f1: (train=0.788, test=0.788) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.751, test=0.748) f1: (train=0.791, test=0.788) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.871, test=0.870) balanced_accuracy: (train=0.750, test=0.747) f1: (train=0.791, test=0.787) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.866) balanced_accuracy: (train=0.747, test=0.741) f1: (train=0.787, test=0.781) total time=   0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.866) balanced_accuracy: (train=0.747, test=0.741) f1: (train=0.787, test=0.781) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.870) balanced_accuracy: (train=0.745, test=0.746) f1: (train=0.786, test=0.787) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.748, test=0.745) f1: (train=0.788, test=0.784) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.746, test=0.744) f1: (train=0.787, test=0.785) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.866) balanced_accuracy: (train=0.747, test=0.741) f1: (train=0.787, test=0.781) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.866) balanced_accuracy: (train=0.747, test=0.741) f1: (train=0.787, test=0.781) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.870) balanced_accuracy: (train=0.745, test=0.746) f1: (train=0.786, test=0.787) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.748, test=0.745) f1: (train=0.788, test=0.784) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.746, test=0.744) f1: (train=0.787, test=0.785) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.866) balanced_accuracy: (train=0.747, test=0.741) f1: (train=0.787, test=0.781) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.866) balanced_accuracy: (train=0.747, test=0.741) f1: (train=0.787, test=0.781) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.870) balanced_accuracy: (train=0.745, test=0.746) f1: (train=0.786, test=0.787) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.748, test=0.745) f1: (train=0.788, test=0.784) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.746, test=0.744) f1: (train=0.787, test=0.785) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.866) balanced_accuracy: (train=0.747, test=0.741) f1: (train=0.787, test=0.781) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.866) balanced_accuracy: (train=0.747, test=0.741) f1: (train=0.787, test=0.781) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.870) balanced_accuracy: (train=0.745, test=0.746) f1: (train=0.786, test=0.787) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.748, test=0.745) f1: (train=0.788, test=0.784) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.746, test=0.744) f1: (train=0.787, test=0.785) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.866) balanced_accuracy: (train=0.747, test=0.741) f1: (train=0.787, test=0.781) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.866) balanced_accuracy: (train=0.747, test=0.741) f1: (train=0.787, test=0.781) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.870) balanced_accuracy: (train=0.745, test=0.746) f1: (train=0.786, test=0.787) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.748, test=0.745) f1: (train=0.788, test=0.784) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.746, test=0.744) f1: (train=0.787, test=0.785) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.866) balanced_accuracy: (train=0.747, test=0.741) f1: (train=0.787, test=0.781) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.866) balanced_accuracy: (train=0.747, test=0.741) f1: (train=0.787, test=0.781) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.870) balanced_accuracy: (train=0.745, test=0.746) f1: (train=0.786, test=0.787) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.748, test=0.745) f1: (train=0.788, test=0.784) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.746, test=0.744) f1: (train=0.787, test=0.785) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.786, test=0.781) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.745, test=0.739) f1: (train=0.785, test=0.779) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.869) balanced_accuracy: (train=0.739, test=0.742) f1: (train=0.781, test=0.784) total time=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.740) f1: (train=0.782, test=0.782) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.786, test=0.781) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.745, test=0.739) f1: (train=0.785, test=0.779) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.869) balanced_accuracy: (train=0.739, test=0.742) f1: (train=0.781, test=0.784) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.740) f1: (train=0.782, test=0.782) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.786, test=0.781) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.745, test=0.739) f1: (train=0.785, test=0.779) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.869) balanced_accuracy: (train=0.739, test=0.742) f1: (train=0.781, test=0.784) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.740) f1: (train=0.782, test=0.782) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.786, test=0.781) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.745, test=0.739) f1: (train=0.785, test=0.779) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.869) balanced_accuracy: (train=0.739, test=0.742) f1: (train=0.781, test=0.784) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.740) f1: (train=0.782, test=0.782) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.786, test=0.781) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.745, test=0.739) f1: (train=0.785, test=0.779) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.869) balanced_accuracy: (train=0.739, test=0.742) f1: (train=0.781, test=0.784) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.740) f1: (train=0.782, test=0.782) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.786, test=0.781) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.745, test=0.739) f1: (train=0.785, test=0.779) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.869) balanced_accuracy: (train=0.739, test=0.742) f1: (train=0.781, test=0.784) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.740) f1: (train=0.782, test=0.782) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.865) balanced_accuracy: (train=0.741, test=0.738) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.864) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.782, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.866, test=0.867) balanced_accuracy: (train=0.737, test=0.739) f1: (train=0.778, test=0.781) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.866, test=0.866) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.777, test=0.777) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.866, test=0.867) balanced_accuracy: (train=0.739, test=0.739) f1: (train=0.780, test=0.781) total time=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.865) balanced_accuracy: (train=0.741, test=0.738) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.864) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.782, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.866, test=0.867) balanced_accuracy: (train=0.737, test=0.739) f1: (train=0.778, test=0.781) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.866, test=0.866) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.777, test=0.777) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.866, test=0.867) balanced_accuracy: (train=0.739, test=0.739) f1: (train=0.780, test=0.781) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.865) balanced_accuracy: (train=0.741, test=0.738) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.864) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.782, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.866, test=0.867) balanced_accuracy: (train=0.737, test=0.739) f1: (train=0.778, test=0.781) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.866, test=0.866) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.777, test=0.777) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.866, test=0.867) balanced_accuracy: (train=0.739, test=0.739) f1: (train=0.780, test=0.781) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.865) balanced_accuracy: (train=0.741, test=0.738) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.864) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.782, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.866, test=0.867) balanced_accuracy: (train=0.737, test=0.739) f1: (train=0.778, test=0.781) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.866, test=0.866) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.777, test=0.777) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.866, test=0.867) balanced_accuracy: (train=0.739, test=0.739) f1: (train=0.780, test=0.781) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.865) balanced_accuracy: (train=0.741, test=0.738) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.864) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.782, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.866, test=0.867) balanced_accuracy: (train=0.737, test=0.739) f1: (train=0.778, test=0.781) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.866, test=0.866) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.777, test=0.777) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.866, test=0.867) balanced_accuracy: (train=0.739, test=0.739) f1: (train=0.780, test=0.781) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.865) balanced_accuracy: (train=0.741, test=0.738) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.864) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.782, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.866, test=0.867) balanced_accuracy: (train=0.737, test=0.739) f1: (train=0.778, test=0.781) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.866, test=0.866) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.777, test=0.777) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.866, test=0.867) balanced_accuracy: (train=0.739, test=0.739) f1: (train=0.780, test=0.781) total time=   0.2s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-68 {color: black;background-color: white;}#sk-container-id-68 pre{padding: 0;}#sk-container-id-68 div.sk-toggleable {background-color: white;}#sk-container-id-68 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-68 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-68 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-68 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-68 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-68 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-68 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-68 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-68 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-68 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-68 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-68 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-68 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-68 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-68 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-68 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-68 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-68 div.sk-item {position: relative;z-index: 1;}#sk-container-id-68 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-68 div.sk-item::before, #sk-container-id-68 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-68 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-68 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-68 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-68 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-68 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-68 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-68 div.sk-label-container {text-align: center;}#sk-container-id-68 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-68 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-68\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False),\n",
       "             estimator=DecisionTreeClassifier(min_samples_leaf=50,\n",
       "                                              min_samples_split=50,\n",
       "                                              random_state=10),\n",
       "             param_grid={&#x27;ccp_alpha&#x27;: [0.0001],\n",
       "                         &#x27;criterion&#x27;: [&#x27;gini&#x27;, &#x27;entropy&#x27;, &#x27;log_loss&#x27;],\n",
       "                         &#x27;max_depth&#x27;: [10, 20, 30, None],\n",
       "                         &#x27;min_samples_leaf&#x27;: [20, 50, 100, 200],\n",
       "                         &#x27;min_samples_split&#x27;: [6, 8],\n",
       "                         &#x27;random_state&#x27;: [30, 50, None]},\n",
       "             refit=&#x27;balanced_accuracy&#x27;, return_train_score=True,\n",
       "             scoring={&#x27;accuracy&#x27;: &#x27;accuracy&#x27;,\n",
       "                      &#x27;balanced_accuracy&#x27;: &#x27;balanced_accuracy&#x27;,\n",
       "                      &#x27;f1&#x27;: &#x27;f1_macro&#x27;},\n",
       "             verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-80\" type=\"checkbox\" ><label for=\"sk-estimator-id-80\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False),\n",
       "             estimator=DecisionTreeClassifier(min_samples_leaf=50,\n",
       "                                              min_samples_split=50,\n",
       "                                              random_state=10),\n",
       "             param_grid={&#x27;ccp_alpha&#x27;: [0.0001],\n",
       "                         &#x27;criterion&#x27;: [&#x27;gini&#x27;, &#x27;entropy&#x27;, &#x27;log_loss&#x27;],\n",
       "                         &#x27;max_depth&#x27;: [10, 20, 30, None],\n",
       "                         &#x27;min_samples_leaf&#x27;: [20, 50, 100, 200],\n",
       "                         &#x27;min_samples_split&#x27;: [6, 8],\n",
       "                         &#x27;random_state&#x27;: [30, 50, None]},\n",
       "             refit=&#x27;balanced_accuracy&#x27;, return_train_score=True,\n",
       "             scoring={&#x27;accuracy&#x27;: &#x27;accuracy&#x27;,\n",
       "                      &#x27;balanced_accuracy&#x27;: &#x27;balanced_accuracy&#x27;,\n",
       "                      &#x27;f1&#x27;: &#x27;f1_macro&#x27;},\n",
       "             verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-81\" type=\"checkbox\" ><label for=\"sk-estimator-id-81\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(min_samples_leaf=50, min_samples_split=50,\n",
       "                       random_state=10)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-82\" type=\"checkbox\" ><label for=\"sk-estimator-id-82\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(min_samples_leaf=50, min_samples_split=50,\n",
       "                       random_state=10)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False),\n",
       "             estimator=DecisionTreeClassifier(min_samples_leaf=50,\n",
       "                                              min_samples_split=50,\n",
       "                                              random_state=10),\n",
       "             param_grid={'ccp_alpha': [0.0001],\n",
       "                         'criterion': ['gini', 'entropy', 'log_loss'],\n",
       "                         'max_depth': [10, 20, 30, None],\n",
       "                         'min_samples_leaf': [20, 50, 100, 200],\n",
       "                         'min_samples_split': [6, 8],\n",
       "                         'random_state': [30, 50, None]},\n",
       "             refit='balanced_accuracy', return_train_score=True,\n",
       "             scoring={'accuracy': 'accuracy',\n",
       "                      'balanced_accuracy': 'balanced_accuracy',\n",
       "                      'f1': 'f1_macro'},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "#GRID SEARCH\n",
    "tree_clf = DecisionTreeClassifier(max_features=None,max_depth=None, random_state=10, min_samples_leaf=50,min_samples_split=50)\n",
    "\n",
    "parameter_grid = {\n",
    "    \"max_depth\": [10, 20, 30, None],\n",
    "    \"criterion\": ['gini', 'entropy', 'log_loss'],\n",
    "    'random_state': [30, 50, None],\n",
    "    'min_samples_leaf':[20, 50, 100, 200],\n",
    "    'ccp_alpha': [.0001],\n",
    "    'min_samples_split': [6, 8 ]\n",
    "}\n",
    "\n",
    "# Create Stratified folds\n",
    "cross_validation = StratifiedKFold(n_splits=5)\n",
    "cross_validation.get_n_splits(train_data, y_train)\n",
    "\n",
    "# Create the scoring dictionary\n",
    "SCORING = {\n",
    "    \"accuracy\": \"accuracy\",\n",
    "    \"balanced_accuracy\": \"balanced_accuracy\",\n",
    "    \"f1\": \"f1_macro\",\n",
    "}\n",
    "\n",
    "# Create and fit the GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=tree_clf,\n",
    "    param_grid=parameter_grid,\n",
    "    cv=cross_validation,\n",
    "    verbose=3,\n",
    "    scoring=SCORING,\n",
    "    return_train_score=True,\n",
    "    refit=\"balanced_accuracy\",\n",
    ")\n",
    "\n",
    "grid_search.fit(train_data,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "62d3ccd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.7461108177372227\n",
      "Best parameters: {'ccp_alpha': 0.0001, 'criterion': 'entropy', 'max_depth': 20, 'min_samples_leaf': 20, 'min_samples_split': 6, 'random_state': 30}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-69 {color: black;background-color: white;}#sk-container-id-69 pre{padding: 0;}#sk-container-id-69 div.sk-toggleable {background-color: white;}#sk-container-id-69 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-69 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-69 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-69 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-69 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-69 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-69 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-69 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-69 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-69 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-69 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-69 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-69 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-69 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-69 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-69 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-69 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-69 div.sk-item {position: relative;z-index: 1;}#sk-container-id-69 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-69 div.sk-item::before, #sk-container-id-69 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-69 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-69 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-69 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-69 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-69 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-69 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-69 div.sk-label-container {text-align: center;}#sk-container-id-69 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-69 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-69\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(ccp_alpha=0.0001, criterion=&#x27;entropy&#x27;, max_depth=20,\n",
       "                       min_samples_leaf=20, min_samples_split=6,\n",
       "                       random_state=30)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-83\" type=\"checkbox\" checked><label for=\"sk-estimator-id-83\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(ccp_alpha=0.0001, criterion=&#x27;entropy&#x27;, max_depth=20,\n",
       "                       min_samples_leaf=20, min_samples_split=6,\n",
       "                       random_state=30)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.0001, criterion='entropy', max_depth=20,\n",
       "                       min_samples_leaf=20, min_samples_split=6,\n",
       "                       random_state=30)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Best score: {}\".format(grid_search.best_score_))\n",
    "print(\"Best parameters: {}\".format(grid_search.best_params_))\n",
    "\n",
    "best_dtc = grid_search.best_estimator_\n",
    "best_dtc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "e0da7fcb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8691727763176096"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model =best_dtc\n",
    "my_model.fit(train_data, y_train)\n",
    "my_model.score(test_data,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5722cc90",
   "metadata": {},
   "source": [
    "RANDOM FOREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "07321942",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3b318752",
   "metadata": {},
   "outputs": [],
   "source": [
    "column = ['criterion', 'max_depth', 'max_features', 'n_estimators', 'random_state', 'accuracy']\n",
    "column_bar = ['try', 'Parameter_changed', 'Accuracy']\n",
    "\n",
    "### Create a single row equivalent to a single try for decision tree\n",
    "def create_bar_row(criterion, depth, feature, stimatori,random, attempt, parameter):\n",
    "  rf = RandomForestClassifier(criterion=criterion,max_depth=depth, max_features=feature,n_estimators=stimatori, random_state=random )\n",
    "  rf.fit(train_data, np.ravel(y_train))\n",
    "  testset_score = rf.score(test_data, y_test)\n",
    "  row = pd.DataFrame(data=[[attempt, parameter, testset_score]], columns=column_bar)\n",
    "  return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "080a26fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  try Parameter_changed  Accuracy\n",
      "0   1             start  0.867029\n",
      "0   2         max_depth  0.867720\n",
      "0   3      max_features  0.867236\n",
      "0   4      n_estimators  0.868204\n",
      "0   5      n_estimators  0.867513\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'Score sul testset durante il tuning dei parametri'}, xlabel='Accuracy', ylabel='Parameter_changed'>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.DataFrame(columns=column_bar)\n",
    "df = pd.concat([df, create_bar_row('gini', None, 20, 40, 2,1, 'start')]) # try 1\n",
    "df = pd.concat([df, create_bar_row('gini', 40, 20, 40, 5,2, 'max_depth')]) # try 1\n",
    "df = pd.concat([df, create_bar_row('gini', 40, None, 40, 5,3, 'max_features')]) # try 1\n",
    "df = pd.concat([df, create_bar_row('gini', 40, None, 100, 5,4, 'n_estimators')]) # try 1\n",
    "df = pd.concat([df, create_bar_row('gini', 40, None, 100, 10,5, 'n_estimators')]) # try 1\n",
    "print(df)\n",
    "\n",
    "fig, axs = plt.subplots()\n",
    "axs.set_xlim([0.70,0.89])\n",
    "axs.set_title(\"Score sul testset durante il tuning dei parametri\")\n",
    "\n",
    "sns.barplot(data=df, x='Accuracy',y=\"Parameter_changed\",ax=axs, orient=\"h\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "aada8db8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 243 candidates, totalling 1215 fits\n",
      "[CV 2/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.737, test=0.731) f1: (train=0.780, test=0.774) total time=   1.3s\n",
      "[CV 2/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.731) f1: (train=0.779, test=0.774) total time=   1.9s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.735, test=0.736) f1: (train=0.778, test=0.778) total time=   2.1s\n",
      "[CV 2/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.737, test=0.733) f1: (train=0.780, test=0.776) total time=   4.4s\n",
      "[CV 2/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.864) balanced_accuracy: (train=0.737, test=0.731) f1: (train=0.779, test=0.773) total time=   1.4s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.868) balanced_accuracy: (train=0.735, test=0.735) f1: (train=0.779, test=0.779) total time=   2.2s\n",
      "[CV 2/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.732) f1: (train=0.779, test=0.775) total time=   4.4s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.871, test=0.871) balanced_accuracy: (train=0.745, test=0.745) f1: (train=0.787, test=0.788) total time=   4.8s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.872, test=0.870) balanced_accuracy: (train=0.746, test=0.743) f1: (train=0.788, test=0.785) total time=   4.8s\n",
      "[CV 2/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.746, test=0.741) f1: (train=0.789, test=0.784) total time=   7.6s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.871, test=0.871) balanced_accuracy: (train=0.744, test=0.745) f1: (train=0.787, test=0.788) total time=  14.6s\n",
      "[CV 3/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.869) balanced_accuracy: (train=0.736, test=0.739) f1: (train=0.779, test=0.781) total time=   1.4s\n",
      "[CV 1/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.735) f1: (train=0.779, test=0.778) total time=   1.1s\n",
      "[CV 4/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   2.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.777) total time=   1.9s\n",
      "[CV 2/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.732) f1: (train=0.779, test=0.775) total time=   3.9s\n",
      "[CV 3/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.869) balanced_accuracy: (train=0.736, test=0.739) f1: (train=0.779, test=0.781) total time=   1.3s\n",
      "[CV 1/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.735) f1: (train=0.779, test=0.778) total time=   1.3s\n",
      "[CV 3/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.867, test=0.869) balanced_accuracy: (train=0.735, test=0.738) f1: (train=0.778, test=0.781) total time=   2.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.735) f1: (train=0.779, test=0.777) total time=   3.9s\n",
      "[CV 4/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.779, test=0.777) total time=   3.6s\n",
      "[CV 5/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.872, test=0.871) balanced_accuracy: (train=0.746, test=0.745) f1: (train=0.789, test=0.787) total time=   4.9s\n",
      "[CV 2/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.872, test=0.868) balanced_accuracy: (train=0.746, test=0.740) f1: (train=0.789, test=0.782) total time=   8.2s\n",
      "[CV 5/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.872, test=0.871) balanced_accuracy: (train=0.747, test=0.745) f1: (train=0.789, test=0.787) total time=  16.1s\n",
      "[CV 1/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   1.2s\n",
      "[CV 1/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.778) total time=   1.3s\n",
      "[CV 1/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.735) f1: (train=0.779, test=0.778) total time=   1.3s\n",
      "[CV 2/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.867, test=0.865) balanced_accuracy: (train=0.735, test=0.731) f1: (train=0.778, test=0.773) total time=   2.5s\n",
      "[CV 2/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.737, test=0.732) f1: (train=0.780, test=0.774) total time=   2.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   4.1s\n",
      "[CV 1/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   1.4s\n",
      "[CV 3/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.867, test=0.869) balanced_accuracy: (train=0.734, test=0.737) f1: (train=0.778, test=0.781) total time=   1.4s\n",
      "[CV 4/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.735) f1: (train=0.779, test=0.778) total time=   1.1s\n",
      "[CV 1/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   1.9s\n",
      "[CV 3/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.734, test=0.737) f1: (train=0.778, test=0.780) total time=   4.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.872, test=0.871) balanced_accuracy: (train=0.745, test=0.745) f1: (train=0.788, test=0.788) total time=   5.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.872, test=0.870) balanced_accuracy: (train=0.746, test=0.743) f1: (train=0.788, test=0.785) total time=   5.1s\n",
      "[CV 2/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.746, test=0.741) f1: (train=0.789, test=0.783) total time=   7.9s\n",
      "[CV 3/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.871, test=0.871) balanced_accuracy: (train=0.745, test=0.745) f1: (train=0.788, test=0.788) total time=  15.6s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.777) total time=   1.4s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.735, test=0.731) f1: (train=0.778, test=0.774) total time=   1.3s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.734, test=0.738) f1: (train=0.777, test=0.781) total time=   2.1s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.735, test=0.730) f1: (train=0.778, test=0.773) total time=   2.4s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.776) total time=   3.9s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.736, test=0.738) f1: (train=0.778, test=0.781) total time=   1.3s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.732, test=0.736) f1: (train=0.776, test=0.779) total time=   1.2s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.735, test=0.737) f1: (train=0.778, test=0.780) total time=   1.1s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.735, test=0.730) f1: (train=0.778, test=0.773) total time=   2.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.735, test=0.731) f1: (train=0.778, test=0.775) total time=   4.1s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.870, test=0.870) balanced_accuracy: (train=0.743, test=0.742) f1: (train=0.786, test=0.785) total time=   5.4s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.871, test=0.868) balanced_accuracy: (train=0.743, test=0.738) f1: (train=0.786, test=0.781) total time=   7.1s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.870, test=0.871) balanced_accuracy: (train=0.743, test=0.744) f1: (train=0.785, test=0.787) total time=   8.1s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.870, test=0.870) balanced_accuracy: (train=0.743, test=0.742) f1: (train=0.786, test=0.784) total time=  16.3s\n",
      "[CV 1/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.778, test=0.776) total time=   2.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.777) total time=   2.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.777) total time=   4.2s\n",
      "[CV 4/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.779, test=0.777) total time=   3.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.866, test=0.865) balanced_accuracy: (train=0.734, test=0.732) f1: (train=0.777, test=0.774) total time=   1.3s\n",
      "[CV 5/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.778, test=0.779) total time=   2.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.732) f1: (train=0.778, test=0.775) total time=   4.3s\n",
      "[CV 4/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.741) f1: (train=0.786, test=0.783) total time=   4.4s\n",
      "[CV 3/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.870, test=0.871) balanced_accuracy: (train=0.743, test=0.744) f1: (train=0.786, test=0.787) total time=   5.3s\n",
      "[CV 1/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.782) total time=   9.9s\n",
      "[CV 3/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.870, test=0.871) balanced_accuracy: (train=0.742, test=0.743) f1: (train=0.785, test=0.786) total time=  18.2s\n",
      "[CV 5/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.736, test=0.735) f1: (train=0.778, test=0.778) total time=   1.2s\n",
      "[CV 5/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.778, test=0.778) total time=   1.4s\n",
      "[CV 3/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.734, test=0.737) f1: (train=0.777, test=0.781) total time=   2.1s\n",
      "[CV 2/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.867, test=0.865) balanced_accuracy: (train=0.735, test=0.731) f1: (train=0.778, test=0.774) total time=   2.1s\n",
      "[CV 2/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.732) f1: (train=0.778, test=0.775) total time=   4.5s\n",
      "[CV 4/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.777) total time=   1.5s\n",
      "[CV 5/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.778, test=0.778) total time=   1.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.736, test=0.731) f1: (train=0.779, test=0.773) total time=   1.3s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.735) f1: (train=0.779, test=0.778) total time=   0.9s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.868) balanced_accuracy: (train=0.735, test=0.735) f1: (train=0.779, test=0.779) total time=   1.9s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.867, test=0.869) balanced_accuracy: (train=0.735, test=0.737) f1: (train=0.778, test=0.781) total time=   3.5s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   1.2s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.867, test=0.869) balanced_accuracy: (train=0.735, test=0.737) f1: (train=0.778, test=0.781) total time=   1.5s\n",
      "[CV 2/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.737, test=0.733) f1: (train=0.780, test=0.775) total time=   1.9s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.869) balanced_accuracy: (train=0.735, test=0.737) f1: (train=0.778, test=0.780) total time=   4.6s\n",
      "[CV 2/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.746, test=0.741) f1: (train=0.788, test=0.783) total time=   4.9s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.872, test=0.868) balanced_accuracy: (train=0.747, test=0.741) f1: (train=0.789, test=0.783) total time=   7.9s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.871, test=0.871) balanced_accuracy: (train=0.745, test=0.744) f1: (train=0.787, test=0.786) total time=   7.9s\n",
      "[CV 2/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.746, test=0.741) f1: (train=0.789, test=0.783) total time=  13.4s\n",
      "[CV 5/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.735, test=0.736) f1: (train=0.778, test=0.779) total time=   1.3s\n",
      "[CV 4/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.779, test=0.777) total time=   2.1s\n",
      "[CV 4/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.779, test=0.777) total time=   4.1s\n",
      "[CV 5/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.868) balanced_accuracy: (train=0.735, test=0.736) f1: (train=0.778, test=0.779) total time=   3.7s\n",
      "[CV 1/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   2.1s\n",
      "[CV 3/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.734, test=0.737) f1: (train=0.778, test=0.780) total time=   4.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.872, test=0.871) balanced_accuracy: (train=0.747, test=0.745) f1: (train=0.790, test=0.787) total time=   5.1s\n",
      "[CV 2/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.746, test=0.741) f1: (train=0.789, test=0.784) total time=   8.3s\n",
      "[CV 4/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.744, test=0.741) f1: (train=0.787, test=0.783) total time=   8.7s\n",
      "[CV 1/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.747, test=0.741) f1: (train=0.789, test=0.783) total time=  16.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.735, test=0.736) f1: (train=0.778, test=0.779) total time=   2.5s\n",
      "[CV 4/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.779, test=0.777) total time=   4.3s\n",
      "[CV 2/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.865) balanced_accuracy: (train=0.735, test=0.731) f1: (train=0.778, test=0.774) total time=   1.3s\n",
      "[CV 2/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.732) f1: (train=0.779, test=0.775) total time=   1.5s\n",
      "[CV 1/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.778) total time=   1.9s\n",
      "[CV 3/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.734, test=0.737) f1: (train=0.778, test=0.780) total time=   1.7s\n",
      "[CV 5/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.735, test=0.736) f1: (train=0.778, test=0.779) total time=   4.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.746, test=0.741) f1: (train=0.789, test=0.783) total time=   4.9s\n",
      "[CV 2/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.746, test=0.741) f1: (train=0.789, test=0.784) total time=   8.3s\n",
      "[CV 4/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.744, test=0.741) f1: (train=0.787, test=0.783) total time=   8.2s\n",
      "[CV 1/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.747, test=0.741) f1: (train=0.789, test=0.783) total time=  15.9s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.867, test=0.869) balanced_accuracy: (train=0.734, test=0.737) f1: (train=0.777, test=0.780) total time=   2.5s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.735, test=0.731) f1: (train=0.778, test=0.774) total time=   4.2s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.868) balanced_accuracy: (train=0.735, test=0.736) f1: (train=0.778, test=0.779) total time=   4.1s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.735, test=0.732) f1: (train=0.778, test=0.775) total time=   2.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.778, test=0.776) total time=   4.1s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.867, test=0.869) balanced_accuracy: (train=0.734, test=0.738) f1: (train=0.778, test=0.781) total time=   4.1s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.785, test=0.781) total time=   3.5s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.871, test=0.868) balanced_accuracy: (train=0.742, test=0.738) f1: (train=0.786, test=0.781) total time=   8.3s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.783) total time=  16.1s\n",
      "[CV 1/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.734, test=0.733) f1: (train=0.777, test=0.775) total time=   1.3s\n",
      "[CV 3/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.734, test=0.737) f1: (train=0.777, test=0.780) total time=   1.1s\n",
      "[CV 1/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.777) total time=   1.3s\n",
      "[CV 1/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.776) total time=   1.3s\n",
      "[CV 3/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.734, test=0.737) f1: (train=0.777, test=0.781) total time=   2.2s\n",
      "[CV 2/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.867, test=0.865) balanced_accuracy: (train=0.735, test=0.731) f1: (train=0.778, test=0.774) total time=   2.4s\n",
      "[CV 4/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.777) total time=   3.6s\n",
      "[CV 1/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.734, test=0.733) f1: (train=0.777, test=0.775) total time=   1.4s\n",
      "[CV 4/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.734, test=0.733) f1: (train=0.778, test=0.777) total time=   1.4s\n",
      "[CV 5/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.735, test=0.735) f1: (train=0.778, test=0.778) total time=   2.3s\n",
      "[CV 5/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.778, test=0.778) total time=   4.6s\n",
      "[CV 2/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.744, test=0.739) f1: (train=0.787, test=0.782) total time=   5.8s\n",
      "[CV 5/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.870, test=0.870) balanced_accuracy: (train=0.743, test=0.742) f1: (train=0.785, test=0.785) total time=   3.8s\n",
      "[CV 4/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.741) f1: (train=0.786, test=0.783) total time=  10.2s\n",
      "[CV 2/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.871, test=0.868) balanced_accuracy: (train=0.742, test=0.737) f1: (train=0.785, test=0.780) total time=  18.5s\n",
      "[CV 2/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.731) f1: (train=0.778, test=0.774) total time=   1.2s\n",
      "[CV 2/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.865) balanced_accuracy: (train=0.735, test=0.731) f1: (train=0.778, test=0.773) total time=   1.5s\n",
      "[CV 5/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.735, test=0.735) f1: (train=0.778, test=0.778) total time=   2.1s\n",
      "[CV 5/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.777, test=0.778) total time=   2.2s\n",
      "[CV 5/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.778, test=0.779) total time=   4.2s\n",
      "[CV 2/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.731) f1: (train=0.778, test=0.774) total time=   1.5s\n",
      "[CV 4/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.866, test=0.865) balanced_accuracy: (train=0.734, test=0.732) f1: (train=0.777, test=0.774) total time=   1.2s\n",
      "[CV 5/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.778, test=0.779) total time=   2.1s\n",
      "[CV 2/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.732) f1: (train=0.778, test=0.775) total time=   3.3s\n",
      "[CV 1/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.744, test=0.741) f1: (train=0.787, test=0.783) total time=   5.9s\n",
      "[CV 3/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.870, test=0.871) balanced_accuracy: (train=0.743, test=0.744) f1: (train=0.786, test=0.787) total time=   5.3s\n",
      "[CV 5/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.871, test=0.870) balanced_accuracy: (train=0.743, test=0.742) f1: (train=0.786, test=0.785) total time=   9.7s\n",
      "[CV 3/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.870, test=0.871) balanced_accuracy: (train=0.742, test=0.743) f1: (train=0.785, test=0.786) total time=  17.3s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.778, test=0.776) total time=   1.4s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.867, test=0.869) balanced_accuracy: (train=0.735, test=0.737) f1: (train=0.778, test=0.781) total time=   1.6s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.867, test=0.869) balanced_accuracy: (train=0.734, test=0.737) f1: (train=0.778, test=0.781) total time=   1.8s\n",
      "[CV 2/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.731) f1: (train=0.779, test=0.774) total time=   3.8s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.868) balanced_accuracy: (train=0.735, test=0.737) f1: (train=0.778, test=0.780) total time=   3.5s\n",
      "[CV 2/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.731) f1: (train=0.779, test=0.774) total time=   1.8s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.777) total time=   1.9s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   3.8s\n",
      "[CV 2/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.745, test=0.741) f1: (train=0.788, test=0.783) total time=   4.5s\n",
      "[CV 2/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.745, test=0.741) f1: (train=0.788, test=0.783) total time=   8.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.788, test=0.784) total time=   7.5s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.872, test=0.868) balanced_accuracy: (train=0.747, test=0.741) f1: (train=0.789, test=0.782) total time=  15.3s\n",
      "[CV 1/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.778) total time=   2.1s\n",
      "[CV 3/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.734, test=0.737) f1: (train=0.778, test=0.780) total time=   1.9s\n",
      "[CV 1/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   3.9s\n",
      "[CV 2/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.865) balanced_accuracy: (train=0.735, test=0.731) f1: (train=0.778, test=0.774) total time=   1.2s\n",
      "[CV 5/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.777, test=0.779) total time=   1.1s\n",
      "[CV 2/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.867, test=0.865) balanced_accuracy: (train=0.735, test=0.731) f1: (train=0.778, test=0.773) total time=   1.9s\n",
      "[CV 4/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.777) total time=   2.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.735, test=0.736) f1: (train=0.778, test=0.779) total time=   4.1s\n",
      "[CV 3/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.871, test=0.871) balanced_accuracy: (train=0.745, test=0.745) f1: (train=0.788, test=0.788) total time=   5.2s\n",
      "[CV 5/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.872, test=0.871) balanced_accuracy: (train=0.747, test=0.745) f1: (train=0.790, test=0.787) total time=   7.9s\n",
      "[CV 5/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.872, test=0.870) balanced_accuracy: (train=0.745, test=0.743) f1: (train=0.788, test=0.786) total time=   8.5s\n",
      "[CV 2/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.746, test=0.741) f1: (train=0.789, test=0.783) total time=  15.7s\n",
      "[CV 4/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.779, test=0.777) total time=   2.4s\n",
      "[CV 3/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.867, test=0.869) balanced_accuracy: (train=0.735, test=0.738) f1: (train=0.778, test=0.781) total time=   4.4s\n",
      "[CV 5/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.868) balanced_accuracy: (train=0.735, test=0.736) f1: (train=0.778, test=0.779) total time=   3.5s\n",
      "[CV 2/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.737, test=0.733) f1: (train=0.780, test=0.775) total time=   2.1s\n",
      "[CV 3/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.867, test=0.869) balanced_accuracy: (train=0.735, test=0.738) f1: (train=0.778, test=0.781) total time=   4.1s\n",
      "[CV 5/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.868) balanced_accuracy: (train=0.735, test=0.736) f1: (train=0.778, test=0.779) total time=   4.1s\n",
      "[CV 2/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.746, test=0.741) f1: (train=0.789, test=0.783) total time=   5.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.872, test=0.871) balanced_accuracy: (train=0.746, test=0.745) f1: (train=0.789, test=0.787) total time=   7.9s\n",
      "[CV 2/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.872, test=0.868) balanced_accuracy: (train=0.745, test=0.739) f1: (train=0.788, test=0.782) total time=  15.9s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.735) f1: (train=0.778, test=0.777) total time=   1.3s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.777, test=0.778) total time=   1.3s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.777) total time=   2.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.777) total time=   2.6s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.867, test=0.869) balanced_accuracy: (train=0.734, test=0.737) f1: (train=0.777, test=0.780) total time=   4.1s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.779, test=0.777) total time=   3.9s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.735, test=0.735) f1: (train=0.778, test=0.778) total time=   2.2s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.867, test=0.869) balanced_accuracy: (train=0.734, test=0.737) f1: (train=0.777, test=0.781) total time=   4.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.871, test=0.868) balanced_accuracy: (train=0.743, test=0.738) f1: (train=0.786, test=0.781) total time=   5.2s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.785, test=0.783) total time=   5.3s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.743, test=0.739) f1: (train=0.785, test=0.782) total time=   8.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.871, test=0.868) balanced_accuracy: (train=0.742, test=0.737) f1: (train=0.785, test=0.780) total time=  16.4s\n",
      "[CV 5/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.736, test=0.735) f1: (train=0.778, test=0.778) total time=   1.5s\n",
      "[CV 2/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.865) balanced_accuracy: (train=0.735, test=0.731) f1: (train=0.778, test=0.773) total time=   1.4s\n",
      "[CV 5/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.735, test=0.735) f1: (train=0.778, test=0.778) total time=   2.4s\n",
      "[CV 5/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.777, test=0.778) total time=   2.2s\n",
      "[CV 5/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.778, test=0.779) total time=   3.9s\n",
      "[CV 3/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.734, test=0.737) f1: (train=0.777, test=0.780) total time=   1.2s\n",
      "[CV 5/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.778, test=0.778) total time=   1.3s\n",
      "[CV 4/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.777) total time=   1.8s\n",
      "[CV 3/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.734, test=0.737) f1: (train=0.777, test=0.780) total time=   2.2s\n",
      "[CV 5/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.778, test=0.779) total time=   4.5s\n",
      "[CV 2/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.871, test=0.868) balanced_accuracy: (train=0.742, test=0.737) f1: (train=0.785, test=0.780) total time=   5.6s\n",
      "[CV 4/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.741) f1: (train=0.786, test=0.783) total time=  10.2s\n",
      "[CV 3/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.870, test=0.871) balanced_accuracy: (train=0.742, test=0.744) f1: (train=0.785, test=0.787) total time=  18.5s\n",
      "[CV 2/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.865) balanced_accuracy: (train=0.736, test=0.732) f1: (train=0.778, test=0.774) total time=   1.1s\n",
      "[CV 4/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.777) total time=   1.4s\n",
      "[CV 4/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.734, test=0.733) f1: (train=0.778, test=0.777) total time=   1.3s\n",
      "[CV 5/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.734, test=0.736) f1: (train=0.777, test=0.779) total time=   1.1s\n",
      "[CV 3/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.867, test=0.869) balanced_accuracy: (train=0.733, test=0.737) f1: (train=0.777, test=0.780) total time=   2.2s\n",
      "[CV 3/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.867, test=0.869) balanced_accuracy: (train=0.734, test=0.737) f1: (train=0.777, test=0.781) total time=   3.7s\n",
      "[CV 1/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.777) total time=   4.4s\n",
      "[CV 2/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.867, test=0.865) balanced_accuracy: (train=0.736, test=0.731) f1: (train=0.779, test=0.774) total time=   2.3s\n",
      "[CV 4/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.734, test=0.732) f1: (train=0.777, test=0.775) total time=   2.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.777) total time=   4.4s\n",
      "[CV 3/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.870, test=0.871) balanced_accuracy: (train=0.742, test=0.744) f1: (train=0.785, test=0.787) total time=   5.7s\n",
      "[CV 5/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.870, test=0.871) balanced_accuracy: (train=0.742, test=0.743) f1: (train=0.785, test=0.786) total time=   9.5s\n",
      "[CV 4/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.741) f1: (train=0.786, test=0.783) total time=  17.3s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.736, test=0.731) f1: (train=0.779, test=0.774) total time=   1.4s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-91 {color: black;background-color: white;}#sk-container-id-91 pre{padding: 0;}#sk-container-id-91 div.sk-toggleable {background-color: white;}#sk-container-id-91 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-91 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-91 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-91 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-91 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-91 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-91 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-91 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-91 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-91 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-91 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-91 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-91 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-91 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-91 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-91 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-91 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-91 div.sk-item {position: relative;z-index: 1;}#sk-container-id-91 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-91 div.sk-item::before, #sk-container-id-91 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-91 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-91 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-91 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-91 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-91 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-91 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-91 div.sk-label-container {text-align: center;}#sk-container-id-91 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-91 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-91\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False),\n",
       "             estimator=RandomForestClassifier(max_depth=100, max_features=None,\n",
       "                                              max_leaf_nodes=100,\n",
       "                                              n_estimators=50, n_jobs=-1,\n",
       "                                              random_state=100),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;criterion&#x27;: [&#x27;gini&#x27;, &#x27;entropy&#x27;, &#x27;log_loss&#x27;],\n",
       "                         &#x27;max_depth&#x27;: [10, 40, None],\n",
       "                         &#x27;max_features&#x27;: [&#x27;sqrt&#x27;, &#x27;log2&#x27;, None],\n",
       "                         &#x27;n_estimators&#x27;: [30, 50, 100],\n",
       "                         &#x27;random_state&#x27;: [10, 30, 100]},\n",
       "             refit=&#x27;balanced_accuracy&#x27;, return_train_score=True,\n",
       "             scoring={&#x27;accuracy&#x27;: &#x27;accuracy&#x27;,\n",
       "                      &#x27;balanced_accuracy&#x27;: &#x27;balanced_accuracy&#x27;,\n",
       "                      &#x27;f1&#x27;: &#x27;f1_macro&#x27;},\n",
       "             verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-105\" type=\"checkbox\" ><label for=\"sk-estimator-id-105\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False),\n",
       "             estimator=RandomForestClassifier(max_depth=100, max_features=None,\n",
       "                                              max_leaf_nodes=100,\n",
       "                                              n_estimators=50, n_jobs=-1,\n",
       "                                              random_state=100),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;criterion&#x27;: [&#x27;gini&#x27;, &#x27;entropy&#x27;, &#x27;log_loss&#x27;],\n",
       "                         &#x27;max_depth&#x27;: [10, 40, None],\n",
       "                         &#x27;max_features&#x27;: [&#x27;sqrt&#x27;, &#x27;log2&#x27;, None],\n",
       "                         &#x27;n_estimators&#x27;: [30, 50, 100],\n",
       "                         &#x27;random_state&#x27;: [10, 30, 100]},\n",
       "             refit=&#x27;balanced_accuracy&#x27;, return_train_score=True,\n",
       "             scoring={&#x27;accuracy&#x27;: &#x27;accuracy&#x27;,\n",
       "                      &#x27;balanced_accuracy&#x27;: &#x27;balanced_accuracy&#x27;,\n",
       "                      &#x27;f1&#x27;: &#x27;f1_macro&#x27;},\n",
       "             verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-106\" type=\"checkbox\" ><label for=\"sk-estimator-id-106\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=100, max_features=None, max_leaf_nodes=100,\n",
       "                       n_estimators=50, n_jobs=-1, random_state=100)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-107\" type=\"checkbox\" ><label for=\"sk-estimator-id-107\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=100, max_features=None, max_leaf_nodes=100,\n",
       "                       n_estimators=50, n_jobs=-1, random_state=100)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False),\n",
       "             estimator=RandomForestClassifier(max_depth=100, max_features=None,\n",
       "                                              max_leaf_nodes=100,\n",
       "                                              n_estimators=50, n_jobs=-1,\n",
       "                                              random_state=100),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'criterion': ['gini', 'entropy', 'log_loss'],\n",
       "                         'max_depth': [10, 40, None],\n",
       "                         'max_features': ['sqrt', 'log2', None],\n",
       "                         'n_estimators': [30, 50, 100],\n",
       "                         'random_state': [10, 30, 100]},\n",
       "             refit='balanced_accuracy', return_train_score=True,\n",
       "             scoring={'accuracy': 'accuracy',\n",
       "                      'balanced_accuracy': 'balanced_accuracy',\n",
       "                      'f1': 'f1_macro'},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "rf = RandomForestClassifier( n_jobs=-1, n_estimators=50, max_depth=100,max_leaf_nodes=100, random_state=100, max_features=None)\n",
    "\n",
    "parameter_grid = {\n",
    "    \"n_estimators\": [30, 50, 100],\n",
    "    \"max_depth\": [10, 40, None],\n",
    "    \"max_features\": [\"sqrt\",\"log2\", None],\n",
    "    \"random_state\":[10,30,100],\n",
    "    \"criterion\": ['gini', 'entropy', 'log_loss']\n",
    "}\n",
    "\n",
    "cross_validation = StratifiedKFold(n_splits=5)\n",
    "cross_validation.get_n_splits(train_data, np.ravel(y_train))\n",
    "\n",
    "# Create the scoring dictionary\n",
    "SCORING = {\n",
    "    \"accuracy\": \"accuracy\",\n",
    "    \"balanced_accuracy\": \"balanced_accuracy\",\n",
    "    \"f1\": \"f1_macro\",\n",
    "}\n",
    "\n",
    "# Create and fit the GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=rf,\n",
    "    param_grid=parameter_grid,\n",
    "    n_jobs=-1,\n",
    "    cv=cross_validation,\n",
    "    verbose=3,\n",
    "    scoring=SCORING,\n",
    "    return_train_score=True,\n",
    "    refit=\"balanced_accuracy\",\n",
    ")\n",
    "\n",
    "grid_search.fit(train_data, np.ravel(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "35a074af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.742978958465423\n",
      "Best parameters: {'criterion': 'gini', 'max_depth': 40, 'max_features': None, 'n_estimators': 100, 'random_state': 10}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-92 {color: black;background-color: white;}#sk-container-id-92 pre{padding: 0;}#sk-container-id-92 div.sk-toggleable {background-color: white;}#sk-container-id-92 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-92 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-92 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-92 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-92 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-92 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-92 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-92 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-92 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-92 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-92 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-92 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-92 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-92 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-92 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-92 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-92 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-92 div.sk-item {position: relative;z-index: 1;}#sk-container-id-92 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-92 div.sk-item::before, #sk-container-id-92 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-92 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-92 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-92 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-92 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-92 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-92 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-92 div.sk-label-container {text-align: center;}#sk-container-id-92 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-92 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-92\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_depth=40, max_features=None, max_leaf_nodes=100,\n",
       "                       n_jobs=-1, random_state=10)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-108\" type=\"checkbox\" checked><label for=\"sk-estimator-id-108\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=40, max_features=None, max_leaf_nodes=100,\n",
       "                       n_jobs=-1, random_state=10)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(max_depth=40, max_features=None, max_leaf_nodes=100,\n",
       "                       n_jobs=-1, random_state=10)"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Best score: {}\".format(grid_search.best_score_))\n",
    "print(\"Best parameters: {}\".format(grid_search.best_params_))\n",
    "\n",
    "best_dtc = grid_search.best_estimator_\n",
    "best_dtc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "69089f07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8701756812837184"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.777, test=0.778) total time=   1.2s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.735, test=0.737) f1: (train=0.778, test=0.780) total time=   1.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   2.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.732) f1: (train=0.779, test=0.775) total time=   3.9s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.868, test=0.869) balanced_accuracy: (train=0.736, test=0.739) f1: (train=0.779, test=0.782) total time=   1.3s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.777) total time=   1.4s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.779, test=0.777) total time=   2.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.777) total time=   2.7s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.868) balanced_accuracy: (train=0.735, test=0.737) f1: (train=0.778, test=0.780) total time=   4.1s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.872, test=0.871) balanced_accuracy: (train=0.746, test=0.745) f1: (train=0.789, test=0.787) total time=   4.5s\n",
      "[CV 2/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.872, test=0.868) balanced_accuracy: (train=0.745, test=0.740) f1: (train=0.788, test=0.782) total time=   7.6s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.745, test=0.741) f1: (train=0.788, test=0.784) total time=  15.9s\n",
      "[CV 2/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.865) balanced_accuracy: (train=0.735, test=0.731) f1: (train=0.778, test=0.774) total time=   1.4s\n",
      "[CV 2/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.732) f1: (train=0.779, test=0.775) total time=   1.3s\n",
      "[CV 4/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.735) f1: (train=0.779, test=0.778) total time=   1.2s\n",
      "[CV 3/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.734, test=0.737) f1: (train=0.777, test=0.780) total time=   2.3s\n",
      "[CV 3/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.867, test=0.869) balanced_accuracy: (train=0.735, test=0.738) f1: (train=0.778, test=0.781) total time=   3.6s\n",
      "[CV 1/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   3.6s\n",
      "[CV 4/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   2.2s\n",
      "[CV 4/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.779, test=0.777) total time=   4.1s\n",
      "[CV 1/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.747, test=0.741) f1: (train=0.789, test=0.783) total time=   5.4s\n",
      "[CV 5/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.872, test=0.870) balanced_accuracy: (train=0.746, test=0.743) f1: (train=0.788, test=0.785) total time=   5.1s\n",
      "[CV 2/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.746, test=0.741) f1: (train=0.789, test=0.783) total time=   7.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.871, test=0.871) balanced_accuracy: (train=0.745, test=0.745) f1: (train=0.788, test=0.788) total time=  15.8s\n",
      "[CV 2/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.732) f1: (train=0.779, test=0.775) total time=   1.5s\n",
      "[CV 5/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.735, test=0.736) f1: (train=0.778, test=0.779) total time=   1.3s\n",
      "[CV 1/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.778) total time=   2.9s\n",
      "[CV 2/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.735, test=0.731) f1: (train=0.778, test=0.774) total time=   3.9s\n",
      "[CV 1/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   3.5s\n",
      "[CV 2/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.867, test=0.865) balanced_accuracy: (train=0.735, test=0.731) f1: (train=0.778, test=0.773) total time=   2.4s\n",
      "[CV 2/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.732) f1: (train=0.779, test=0.775) total time=   4.7s\n",
      "[CV 1/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.746, test=0.741) f1: (train=0.788, test=0.783) total time=   5.4s\n",
      "[CV 1/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.746, test=0.741) f1: (train=0.789, test=0.783) total time=   8.4s\n",
      "[CV 3/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.871, test=0.872) balanced_accuracy: (train=0.745, test=0.746) f1: (train=0.788, test=0.789) total time=  15.6s\n",
      "[CV 4/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.745, test=0.741) f1: (train=0.787, test=0.784) total time=  14.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.867, test=0.869) balanced_accuracy: (train=0.734, test=0.738) f1: (train=0.778, test=0.781) total time=   4.3s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.735, test=0.735) f1: (train=0.778, test=0.778) total time=   2.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.777, test=0.778) total time=   2.4s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.735, test=0.731) f1: (train=0.779, test=0.774) total time=   3.6s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.785, test=0.783) total time=   5.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.782) total time=   8.3s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.870, test=0.871) balanced_accuracy: (train=0.742, test=0.743) f1: (train=0.785, test=0.786) total time=  12.8s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.870, test=0.871) balanced_accuracy: (train=0.743, test=0.744) f1: (train=0.785, test=0.787) total time=  12.5s\n",
      "[CV 2/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.735, test=0.731) f1: (train=0.778, test=0.774) total time=   4.4s\n",
      "[CV 2/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.735, test=0.731) f1: (train=0.778, test=0.774) total time=   4.1s\n",
      "[CV 1/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.778, test=0.776) total time=   2.2s\n",
      "[CV 4/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.734, test=0.732) f1: (train=0.777, test=0.775) total time=   2.2s\n",
      "[CV 1/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.777) total time=   4.3s\n",
      "[CV 4/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.743, test=0.741) f1: (train=0.786, test=0.783) total time=   5.5s\n",
      "[CV 1/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.783) total time=   8.8s\n",
      "[CV 2/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.871, test=0.868) balanced_accuracy: (train=0.743, test=0.738) f1: (train=0.786, test=0.781) total time=  10.7s\n",
      "[CV 3/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.870, test=0.871) balanced_accuracy: (train=0.742, test=0.743) f1: (train=0.785, test=0.786) total time=  15.5s\n",
      "[CV 1/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.778, test=0.776) total time=   2.2s\n",
      "[CV 5/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.778, test=0.778) total time=   4.4s\n",
      "[CV 2/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.865) balanced_accuracy: (train=0.736, test=0.732) f1: (train=0.778, test=0.774) total time=   1.4s\n",
      "[CV 4/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.734, test=0.733) f1: (train=0.778, test=0.777) total time=   1.4s\n",
      "[CV 1/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.778, test=0.776) total time=   2.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.734, test=0.737) f1: (train=0.777, test=0.780) total time=   2.1s\n",
      "[CV 5/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.778, test=0.779) total time=   4.6s\n",
      "[CV 2/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.871, test=0.868) balanced_accuracy: (train=0.742, test=0.737) f1: (train=0.785, test=0.780) total time=   5.6s\n",
      "[CV 4/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.741) f1: (train=0.786, test=0.783) total time=   8.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.870, test=0.871) balanced_accuracy: (train=0.742, test=0.743) f1: (train=0.785, test=0.786) total time=   8.9s\n",
      "[CV 2/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.871, test=0.868) balanced_accuracy: (train=0.742, test=0.737) f1: (train=0.785, test=0.780) total time=  16.9s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.777) total time=   2.1s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.867, test=0.869) balanced_accuracy: (train=0.734, test=0.737) f1: (train=0.777, test=0.780) total time=   4.3s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.779, test=0.777) total time=   4.1s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.735, test=0.735) f1: (train=0.778, test=0.778) total time=   2.2s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.776) total time=   4.1s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.871, test=0.868) balanced_accuracy: (train=0.743, test=0.738) f1: (train=0.786, test=0.781) total time=   5.4s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.785, test=0.783) total time=   5.5s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.743, test=0.739) f1: (train=0.785, test=0.782) total time=   8.5s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.870, test=0.871) balanced_accuracy: (train=0.742, test=0.743) f1: (train=0.785, test=0.787) total time=  16.2s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.733, test=0.736) f1: (train=0.776, test=0.779) total time=   1.6s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.734, test=0.736) f1: (train=0.777, test=0.779) total time=   1.4s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.867, test=0.869) balanced_accuracy: (train=0.733, test=0.737) f1: (train=0.777, test=0.780) total time=   2.0s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.735, test=0.731) f1: (train=0.778, test=0.774) total time=   4.2s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.777) total time=   4.0s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.778, test=0.776) total time=   2.3s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.734, test=0.737) f1: (train=0.777, test=0.780) total time=   2.3s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.777) total time=   4.2s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.871, test=0.868) balanced_accuracy: (train=0.742, test=0.737) f1: (train=0.785, test=0.780) total time=   5.7s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.741) f1: (train=0.786, test=0.783) total time=  10.6s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.870, test=0.871) balanced_accuracy: (train=0.742, test=0.744) f1: (train=0.785, test=0.787) total time=  16.2s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.870, test=0.871) balanced_accuracy: (train=0.742, test=0.743) f1: (train=0.785, test=0.786) total time=  12.3s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.867, test=0.869) balanced_accuracy: (train=0.734, test=0.737) f1: (train=0.777, test=0.781) total time=   4.1s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.779, test=0.777) total time=   3.9s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.735, test=0.735) f1: (train=0.778, test=0.778) total time=   2.1s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.867, test=0.869) balanced_accuracy: (train=0.734, test=0.737) f1: (train=0.777, test=0.781) total time=   4.4s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.744, test=0.739) f1: (train=0.787, test=0.782) total time=   4.5s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.870, test=0.871) balanced_accuracy: (train=0.743, test=0.744) f1: (train=0.786, test=0.787) total time=   5.2s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.871, test=0.870) balanced_accuracy: (train=0.743, test=0.742) f1: (train=0.786, test=0.785) total time=   8.9s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.871, test=0.868) balanced_accuracy: (train=0.742, test=0.737) f1: (train=0.785, test=0.780) total time=  18.6s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.735, test=0.737) f1: (train=0.778, test=0.780) total time=   1.2s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.777) total time=   2.2s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.777, test=0.778) total time=   2.3s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.777) total time=   3.9s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.735) f1: (train=0.778, test=0.777) total time=   1.3s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.777, test=0.778) total time=   1.5s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.777) total time=   2.2s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.735, test=0.735) f1: (train=0.778, test=0.777) total time=   4.1s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.868) balanced_accuracy: (train=0.735, test=0.736) f1: (train=0.778, test=0.779) total time=   4.4s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.870, test=0.871) balanced_accuracy: (train=0.743, test=0.744) f1: (train=0.786, test=0.787) total time=   5.2s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.870, test=0.870) balanced_accuracy: (train=0.743, test=0.743) f1: (train=0.785, test=0.785) total time=   9.0s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.871, test=0.868) balanced_accuracy: (train=0.742, test=0.737) f1: (train=0.785, test=0.780) total time=  16.0s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.731) f1: (train=0.778, test=0.774) total time=   1.4s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.866, test=0.865) balanced_accuracy: (train=0.734, test=0.732) f1: (train=0.777, test=0.774) total time=   1.5s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.777) total time=   2.1s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.778, test=0.776) total time=   4.3s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.778, test=0.779) total time=   3.9s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.734, test=0.736) f1: (train=0.777, test=0.779) total time=   1.3s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.777) total time=   2.4s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.867, test=0.869) balanced_accuracy: (train=0.734, test=0.737) f1: (train=0.777, test=0.781) total time=   4.5s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.744, test=0.741) f1: (train=0.787, test=0.783) total time=   5.8s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.870, test=0.871) balanced_accuracy: (train=0.743, test=0.744) f1: (train=0.786, test=0.787) total time=   4.0s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.871, test=0.870) balanced_accuracy: (train=0.743, test=0.742) f1: (train=0.786, test=0.785) total time=   8.4s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.783) total time=  20.0s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.865) balanced_accuracy: (train=0.736, test=0.732) f1: (train=0.778, test=0.774) total time=   1.5s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.731) f1: (train=0.778, test=0.774) total time=   1.7s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.865) balanced_accuracy: (train=0.735, test=0.731) f1: (train=0.778, test=0.773) total time=   2.0s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.867, test=0.869) balanced_accuracy: (train=0.733, test=0.737) f1: (train=0.777, test=0.780) total time=   1.9s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.778, test=0.776) total time=   4.0s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.735, test=0.731) f1: (train=0.778, test=0.774) total time=   4.1s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.777) total time=   2.2s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.735, test=0.731) f1: (train=0.778, test=0.774) total time=   4.5s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.744, test=0.741) f1: (train=0.787, test=0.783) total time=   4.6s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.871, test=0.868) balanced_accuracy: (train=0.743, test=0.738) f1: (train=0.786, test=0.781) total time=   5.0s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.870, test=0.871) balanced_accuracy: (train=0.742, test=0.743) f1: (train=0.785, test=0.786) total time=   8.8s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.783) total time=  15.4s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.870, test=0.871) balanced_accuracy: (train=0.742, test=0.743) f1: (train=0.785, test=0.786) total time=   7.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.868, test=0.869) balanced_accuracy: (train=0.736, test=0.739) f1: (train=0.779, test=0.782) total time=   1.4s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.777, test=0.778) total time=   1.2s\n",
      "[CV 2/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.736, test=0.732) f1: (train=0.779, test=0.774) total time=   2.1s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.868) balanced_accuracy: (train=0.735, test=0.736) f1: (train=0.778, test=0.779) total time=   4.3s\n",
      "[CV 2/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.737, test=0.731) f1: (train=0.780, test=0.774) total time=   1.3s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.779, test=0.777) total time=   2.2s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   4.3s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.872, test=0.868) balanced_accuracy: (train=0.746, test=0.741) f1: (train=0.789, test=0.783) total time=   4.9s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.871, test=0.871) balanced_accuracy: (train=0.745, test=0.746) f1: (train=0.788, test=0.788) total time=   4.9s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.872, test=0.868) balanced_accuracy: (train=0.747, test=0.741) f1: (train=0.790, test=0.783) total time=   7.8s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.788, test=0.784) total time=  15.9s\n",
      "[CV 3/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.867, test=0.869) balanced_accuracy: (train=0.734, test=0.737) f1: (train=0.778, test=0.781) total time=   1.3s\n",
      "[CV 2/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.867, test=0.865) balanced_accuracy: (train=0.735, test=0.731) f1: (train=0.778, test=0.773) total time=   2.2s\n",
      "[CV 2/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.737, test=0.732) f1: (train=0.780, test=0.774) total time=   2.1s\n",
      "[CV 4/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.779, test=0.777) total time=   3.8s\n",
      "[CV 1/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.778) total time=   1.2s\n",
      "[CV 2/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.865) balanced_accuracy: (train=0.736, test=0.732) f1: (train=0.779, test=0.774) total time=   1.2s\n",
      "[CV 1/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.778) total time=   2.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.867, test=0.869) balanced_accuracy: (train=0.735, test=0.738) f1: (train=0.778, test=0.781) total time=   3.3s\n",
      "[CV 3/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.734, test=0.737) f1: (train=0.778, test=0.780) total time=   4.1s\n",
      "[CV 1/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.872, test=0.868) balanced_accuracy: (train=0.747, test=0.741) f1: (train=0.789, test=0.783) total time=   4.9s\n",
      "[CV 3/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.871, test=0.871) balanced_accuracy: (train=0.745, test=0.745) f1: (train=0.788, test=0.787) total time=   8.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.787, test=0.784) total time=  16.1s\n",
      "[CV 2/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.865) balanced_accuracy: (train=0.735, test=0.731) f1: (train=0.778, test=0.774) total time=   1.2s\n",
      "[CV 5/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.777, test=0.778) total time=   1.4s\n",
      "[CV 2/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.865) balanced_accuracy: (train=0.736, test=0.732) f1: (train=0.779, test=0.774) total time=   1.2s\n",
      "[CV 1/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.778) total time=   1.3s\n",
      "[CV 3/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.734, test=0.737) f1: (train=0.777, test=0.780) total time=   2.3s\n",
      "[CV 1/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.735) f1: (train=0.779, test=0.777) total time=   4.3s\n",
      "[CV 2/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.737, test=0.732) f1: (train=0.780, test=0.774) total time=   4.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.779, test=0.777) total time=   2.1s\n",
      "[CV 1/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   3.9s\n",
      "[CV 1/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.747, test=0.741) f1: (train=0.789, test=0.783) total time=   5.1s\n",
      "[CV 4/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.788, test=0.784) total time=   5.3s\n",
      "[CV 1/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.872, test=0.868) balanced_accuracy: (train=0.747, test=0.741) f1: (train=0.789, test=0.783) total time=   8.1s\n",
      "[CV 4/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.872, test=0.870) balanced_accuracy: (train=0.745, test=0.743) f1: (train=0.788, test=0.785) total time=  15.9s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.778, test=0.776) total time=   1.3s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.735, test=0.737) f1: (train=0.778, test=0.780) total time=   1.2s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.777) total time=   2.5s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.777, test=0.778) total time=   2.6s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.867, test=0.869) balanced_accuracy: (train=0.734, test=0.737) f1: (train=0.777, test=0.781) total time=   3.9s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.735, test=0.736) f1: (train=0.778, test=0.778) total time=   1.2s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.777, test=0.778) total time=   1.3s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.734, test=0.733) f1: (train=0.777, test=0.776) total time=   1.8s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.735, test=0.735) f1: (train=0.778, test=0.777) total time=   4.2s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.870, test=0.871) balanced_accuracy: (train=0.742, test=0.743) f1: (train=0.785, test=0.786) total time=   5.3s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.870, test=0.870) balanced_accuracy: (train=0.742, test=0.742) f1: (train=0.785, test=0.785) total time=   5.4s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.871, test=0.868) balanced_accuracy: (train=0.743, test=0.738) f1: (train=0.786, test=0.781) total time=   8.2s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.785, test=0.782) total time=  16.4s\n",
      "[CV 4/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.734, test=0.733) f1: (train=0.778, test=0.777) total time=   1.3s\n",
      "[CV 5/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.734, test=0.736) f1: (train=0.777, test=0.779) total time=   1.2s\n",
      "[CV 2/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.867, test=0.865) balanced_accuracy: (train=0.735, test=0.731) f1: (train=0.778, test=0.774) total time=   2.1s\n",
      "[CV 1/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.778, test=0.776) total time=   4.4s\n",
      "[CV 1/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.777) total time=   4.2s\n",
      "[CV 3/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.734, test=0.737) f1: (train=0.777, test=0.781) total time=   2.3s\n",
      "[CV 1/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.778, test=0.776) total time=   4.3s\n",
      "[CV 4/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.779, test=0.777) total time=   3.9s\n",
      "[CV 5/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.871, test=0.870) balanced_accuracy: (train=0.743, test=0.743) f1: (train=0.786, test=0.785) total time=   5.4s\n",
      "[CV 2/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.871, test=0.868) balanced_accuracy: (train=0.742, test=0.738) f1: (train=0.786, test=0.781) total time=  10.2s\n",
      "[CV 1/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.783) total time=  18.6s\n",
      "[CV 1/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.777) total time=   1.3s\n",
      "[CV 1/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.776) total time=   1.4s\n",
      "[CV 4/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.777) total time=   2.2s\n",
      "[CV 4/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.734, test=0.732) f1: (train=0.777, test=0.775) total time=   2.2s\n",
      "[CV 4/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.777) total time=   3.4s\n",
      "[CV 5/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.734, test=0.736) f1: (train=0.778, test=0.779) total time=   4.3s\n",
      "[CV 2/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.867, test=0.865) balanced_accuracy: (train=0.735, test=0.731) f1: (train=0.778, test=0.774) total time=   2.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.777) total time=   4.7s\n",
      "[CV 1/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.782) total time=   5.5s\n",
      "[CV 2/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.871, test=0.868) balanced_accuracy: (train=0.744, test=0.739) f1: (train=0.787, test=0.781) total time=   9.6s\n",
      "[CV 2/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.871, test=0.868) balanced_accuracy: (train=0.743, test=0.738) f1: (train=0.786, test=0.781) total time=  17.1s\n",
      "[CV 4/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.742, test=0.741) f1: (train=0.785, test=0.783) total time=  17.2s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.735, test=0.736) f1: (train=0.778, test=0.778) total time=   1.3s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.735, test=0.731) f1: (train=0.778, test=0.774) total time=   1.3s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.735, test=0.732) f1: (train=0.778, test=0.775) total time=   1.9s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.735, test=0.731) f1: (train=0.778, test=0.774) total time=   4.1s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.779, test=0.777) total time=   4.1s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.871, test=0.868) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.785, test=0.781) total time=   4.9s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.870, test=0.871) balanced_accuracy: (train=0.742, test=0.744) f1: (train=0.785, test=0.787) total time=   7.5s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.783) total time=  16.2s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.734, test=0.733) f1: (train=0.777, test=0.775) total time=   1.3s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.777) total time=   1.2s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.734, test=0.733) f1: (train=0.778, test=0.777) total time=   1.4s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.778, test=0.776) total time=   2.2s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.777) total time=   2.3s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.867, test=0.869) balanced_accuracy: (train=0.734, test=0.737) f1: (train=0.777, test=0.781) total time=   4.2s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.735, test=0.731) f1: (train=0.778, test=0.774) total time=   4.5s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.778, test=0.779) total time=   2.1s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.777) total time=   4.6s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.871, test=0.871) balanced_accuracy: (train=0.743, test=0.744) f1: (train=0.786, test=0.787) total time=   5.7s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.870, test=0.870) balanced_accuracy: (train=0.743, test=0.742) f1: (train=0.785, test=0.785) total time=   6.0s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.871, test=0.868) balanced_accuracy: (train=0.743, test=0.738) f1: (train=0.786, test=0.781) total time=  11.0s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.783) total time=  20.1s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.777) total time=   2.2s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.734, test=0.732) f1: (train=0.777, test=0.775) total time=   2.1s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.777) total time=   4.0s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.777) total time=   1.3s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.776) total time=   1.3s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.867, test=0.869) balanced_accuracy: (train=0.733, test=0.737) f1: (train=0.777, test=0.780) total time=   2.0s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.777) total time=   4.6s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.871, test=0.871) balanced_accuracy: (train=0.743, test=0.744) f1: (train=0.786, test=0.787) total time=   4.5s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.870, test=0.870) balanced_accuracy: (train=0.743, test=0.742) f1: (train=0.785, test=0.785) total time=   5.1s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.782) total time=   8.8s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.870, test=0.871) balanced_accuracy: (train=0.742, test=0.743) f1: (train=0.785, test=0.786) total time=  18.6s\n",
      "[CV 3/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.867, test=0.869) balanced_accuracy: (train=0.733, test=0.737) f1: (train=0.777, test=0.780) total time=   2.1s\n",
      "[CV 1/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.777) total time=   3.8s\n",
      "[CV 2/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.744, test=0.739) f1: (train=0.787, test=0.782) total time=   5.7s\n",
      "[CV 4/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.785, test=0.783) total time=   5.4s\n",
      "[CV 1/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.782) total time=   9.5s\n",
      "[CV 2/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.871, test=0.868) balanced_accuracy: (train=0.742, test=0.737) f1: (train=0.785, test=0.780) total time=  17.1s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.732, test=0.736) f1: (train=0.776, test=0.779) total time=   1.3s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.866, test=0.865) balanced_accuracy: (train=0.734, test=0.732) f1: (train=0.777, test=0.774) total time=   1.1s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.735, test=0.735) f1: (train=0.778, test=0.778) total time=   2.2s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.867, test=0.869) balanced_accuracy: (train=0.734, test=0.737) f1: (train=0.777, test=0.780) total time=   2.4s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.867, test=0.869) balanced_accuracy: (train=0.734, test=0.737) f1: (train=0.777, test=0.781) total time=   4.1s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.736, test=0.731) f1: (train=0.779, test=0.774) total time=   1.3s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.778, test=0.776) total time=   1.3s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.735, test=0.735) f1: (train=0.778, test=0.778) total time=   2.2s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.778, test=0.776) total time=   4.1s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.867, test=0.869) balanced_accuracy: (train=0.734, test=0.738) f1: (train=0.778, test=0.781) total time=   4.2s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.785, test=0.781) total time=   5.1s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.785, test=0.783) total time=   7.8s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.870, test=0.870) balanced_accuracy: (train=0.742, test=0.743) f1: (train=0.785, test=0.785) total time=  16.2s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.865) balanced_accuracy: (train=0.736, test=0.732) f1: (train=0.778, test=0.774) total time=   1.2s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.736, test=0.735) f1: (train=0.778, test=0.778) total time=   1.2s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.778, test=0.778) total time=   1.3s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.734, test=0.737) f1: (train=0.777, test=0.781) total time=   2.2s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.867, test=0.865) balanced_accuracy: (train=0.735, test=0.731) f1: (train=0.778, test=0.774) total time=   2.2s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.778, test=0.778) total time=   4.0s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.779, test=0.777) total time=   4.0s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.867, test=0.869) balanced_accuracy: (train=0.733, test=0.737) f1: (train=0.777, test=0.780) total time=   2.2s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.732) f1: (train=0.778, test=0.775) total time=   4.7s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.870, test=0.870) balanced_accuracy: (train=0.742, test=0.742) f1: (train=0.785, test=0.785) total time=   5.6s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.744, test=0.741) f1: (train=0.787, test=0.783) total time=   6.1s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.871, test=0.871) balanced_accuracy: (train=0.742, test=0.744) f1: (train=0.785, test=0.787) total time=  11.3s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.871, test=0.870) balanced_accuracy: (train=0.743, test=0.743) f1: (train=0.786, test=0.785) total time=  16.0s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.733, test=0.736) f1: (train=0.776, test=0.779) total time=   1.6s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.866, test=0.865) balanced_accuracy: (train=0.734, test=0.732) f1: (train=0.777, test=0.774) total time=   1.8s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.777) total time=   2.1s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.777, test=0.778) total time=   2.3s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.778, test=0.779) total time=   4.1s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.733, test=0.736) f1: (train=0.776, test=0.779) total time=   1.4s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.778, test=0.776) total time=   2.4s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.734, test=0.737) f1: (train=0.777, test=0.780) total time=   2.2s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.777) total time=   4.4s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.870, test=0.871) balanced_accuracy: (train=0.742, test=0.744) f1: (train=0.785, test=0.787) total time=   5.8s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.741) f1: (train=0.786, test=0.783) total time=   7.8s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.871, test=0.871) balanced_accuracy: (train=0.742, test=0.744) f1: (train=0.785, test=0.787) total time=   9.4s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.871, test=0.870) balanced_accuracy: (train=0.743, test=0.743) f1: (train=0.786, test=0.785) total time=  15.2s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.779, test=0.777) total time=   1.5s\n",
      "[CV 2/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.737, test=0.733) f1: (train=0.780, test=0.775) total time=   2.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.869) balanced_accuracy: (train=0.735, test=0.737) f1: (train=0.778, test=0.780) total time=   3.9s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.868) balanced_accuracy: (train=0.735, test=0.736) f1: (train=0.778, test=0.779) total time=   3.6s\n",
      "[CV 2/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.736, test=0.732) f1: (train=0.779, test=0.774) total time=   2.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.779, test=0.777) total time=   4.3s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.744, test=0.741) f1: (train=0.787, test=0.783) total time=   4.9s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.871, test=0.870) balanced_accuracy: (train=0.745, test=0.744) f1: (train=0.788, test=0.787) total time=   4.8s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.872, test=0.871) balanced_accuracy: (train=0.746, test=0.745) f1: (train=0.789, test=0.787) total time=   7.6s\n",
      "[CV 2/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.872, test=0.868) balanced_accuracy: (train=0.744, test=0.739) f1: (train=0.788, test=0.782) total time=  15.8s\n",
      "[CV 1/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.778) total time=   1.1s\n",
      "[CV 3/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.735, test=0.737) f1: (train=0.778, test=0.780) total time=   1.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.777, test=0.778) total time=   2.3s\n",
      "[CV 5/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.735, test=0.735) f1: (train=0.778, test=0.778) total time=   1.8s\n",
      "[CV 3/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.734, test=0.737) f1: (train=0.778, test=0.780) total time=   3.9s\n",
      "[CV 4/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.865) balanced_accuracy: (train=0.735, test=0.732) f1: (train=0.778, test=0.775) total time=   1.1s\n",
      "[CV 4/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.777) total time=   1.1s\n",
      "[CV 1/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.778) total time=   1.8s\n",
      "[CV 3/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.734, test=0.737) f1: (train=0.778, test=0.780) total time=   2.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.779, test=0.777) total time=   4.1s\n",
      "[CV 1/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.746, test=0.741) f1: (train=0.788, test=0.783) total time=   5.2s\n",
      "[CV 3/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.871, test=0.871) balanced_accuracy: (train=0.745, test=0.745) f1: (train=0.788, test=0.788) total time=   8.2s\n",
      "[CV 2/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.746, test=0.741) f1: (train=0.789, test=0.783) total time=  16.2s\n",
      "[CV 3/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.872, test=0.872) balanced_accuracy: (train=0.746, test=0.746) f1: (train=0.789, test=0.789) total time=  16.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.865) balanced_accuracy: (train=0.735, test=0.732) f1: (train=0.778, test=0.775) total time=   1.2s\n",
      "[CV 1/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.735) f1: (train=0.779, test=0.778) total time=   1.3s\n",
      "[CV 4/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   2.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.777) total time=   2.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   3.8s\n",
      "[CV 4/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.787, test=0.784) total time=   5.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.872, test=0.871) balanced_accuracy: (train=0.747, test=0.745) f1: (train=0.790, test=0.787) total time=   8.1s\n",
      "[CV 5/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.872, test=0.870) balanced_accuracy: (train=0.745, test=0.743) f1: (train=0.788, test=0.786) total time=   8.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.746, test=0.741) f1: (train=0.789, test=0.783) total time=  15.8s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.778, test=0.779) total time=   2.5s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.735, test=0.735) f1: (train=0.778, test=0.777) total time=   4.1s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.777, test=0.776) total time=   1.4s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.778, test=0.776) total time=   1.3s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.777) total time=   1.9s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.867, test=0.869) balanced_accuracy: (train=0.734, test=0.737) f1: (train=0.777, test=0.780) total time=   1.8s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.735, test=0.735) f1: (train=0.778, test=0.778) total time=   4.2s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.871, test=0.868) balanced_accuracy: (train=0.742, test=0.738) f1: (train=0.785, test=0.781) total time=   5.2s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.870, test=0.871) balanced_accuracy: (train=0.742, test=0.743) f1: (train=0.785, test=0.786) total time=   8.6s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.870, test=0.870) balanced_accuracy: (train=0.742, test=0.742) f1: (train=0.785, test=0.785) total time=   8.7s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.871, test=0.868) balanced_accuracy: (train=0.742, test=0.738) f1: (train=0.785, test=0.781) total time=  16.1s\n",
      "[CV 5/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.778, test=0.779) total time=   2.3s\n",
      "[CV 5/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.778, test=0.778) total time=   4.1s\n",
      "[CV 5/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.734, test=0.736) f1: (train=0.778, test=0.779) total time=   4.2s\n",
      "[CV 1/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.778, test=0.776) total time=   2.2s\n",
      "[CV 4/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.777) total time=   4.1s\n",
      "[CV 5/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.870, test=0.870) balanced_accuracy: (train=0.742, test=0.742) f1: (train=0.785, test=0.785) total time=   5.9s\n",
      "[CV 2/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.871, test=0.868) balanced_accuracy: (train=0.744, test=0.739) f1: (train=0.787, test=0.781) total time=   6.5s\n",
      "[CV 3/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.871, test=0.871) balanced_accuracy: (train=0.742, test=0.744) f1: (train=0.785, test=0.787) total time=   9.7s\n",
      "[CV 1/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.785, test=0.782) total time=  18.1s\n",
      "[CV 2/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.867, test=0.865) balanced_accuracy: (train=0.736, test=0.731) f1: (train=0.779, test=0.774) total time=   2.1s\n",
      "[CV 3/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.734, test=0.737) f1: (train=0.777, test=0.780) total time=   2.2s\n",
      "[CV 3/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.867, test=0.869) balanced_accuracy: (train=0.734, test=0.737) f1: (train=0.777, test=0.780) total time=   4.5s\n",
      "[CV 5/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.736, test=0.735) f1: (train=0.778, test=0.778) total time=   1.3s\n",
      "[CV 2/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.865) balanced_accuracy: (train=0.735, test=0.731) f1: (train=0.778, test=0.773) total time=   1.2s\n",
      "[CV 4/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.777) total time=   2.1s\n",
      "[CV 1/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.778, test=0.776) total time=   4.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.779, test=0.777) total time=   4.4s\n",
      "[CV 2/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.871, test=0.868) balanced_accuracy: (train=0.743, test=0.738) f1: (train=0.786, test=0.781) total time=   5.2s\n",
      "[CV 4/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.741) f1: (train=0.786, test=0.783) total time=   9.9s\n",
      "[CV 1/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.783) total time=  17.1s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.735, test=0.736) f1: (train=0.778, test=0.778) total time=   1.1s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.777, test=0.778) total time=   1.4s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.777) total time=   2.0s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.778, test=0.779) total time=   2.3s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.735, test=0.735) f1: (train=0.778, test=0.777) total time=   3.4s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.735, test=0.731) f1: (train=0.779, test=0.774) total time=   3.9s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.735, test=0.737) f1: (train=0.778, test=0.780) total time=   1.3s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.735, test=0.730) f1: (train=0.778, test=0.773) total time=   2.0s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.777) total time=   4.0s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.782) total time=   5.3s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.871, test=0.868) balanced_accuracy: (train=0.743, test=0.738) f1: (train=0.786, test=0.781) total time=   7.3s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.785, test=0.783) total time=   6.8s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.870, test=0.870) balanced_accuracy: (train=0.743, test=0.742) f1: (train=0.786, test=0.784) total time=  15.8s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.865) balanced_accuracy: (train=0.735, test=0.731) f1: (train=0.778, test=0.773) total time=   1.4s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.777) total time=   2.1s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.734, test=0.737) f1: (train=0.777, test=0.780) total time=   2.2s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.777) total time=   4.1s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.734, test=0.733) f1: (train=0.777, test=0.775) total time=   1.0s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.731) f1: (train=0.778, test=0.774) total time=   1.5s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.866, test=0.865) balanced_accuracy: (train=0.734, test=0.732) f1: (train=0.777, test=0.774) total time=   1.3s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.777) total time=   2.1s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.778, test=0.778) total time=   4.5s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.744, test=0.739) f1: (train=0.787, test=0.782) total time=   5.8s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.785, test=0.783) total time=   5.5s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.782) total time=   6.8s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.870, test=0.870) balanced_accuracy: (train=0.742, test=0.743) f1: (train=0.785, test=0.786) total time=  13.9s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.742, test=0.741) f1: (train=0.785, test=0.783) total time=  18.4s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.734, test=0.737) f1: (train=0.777, test=0.780) total time=   4.2s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.777) total time=   2.1s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.778, test=0.776) total time=   4.3s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.734, test=0.736) f1: (train=0.778, test=0.779) total time=   4.6s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.785, test=0.783) total time=   5.5s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.871, test=0.868) balanced_accuracy: (train=0.743, test=0.738) f1: (train=0.786, test=0.781) total time=   8.9s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.783) total time=  18.3s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   1.4s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.867, test=0.869) balanced_accuracy: (train=0.735, test=0.737) f1: (train=0.778, test=0.781) total time=   1.7s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.735, test=0.737) f1: (train=0.778, test=0.780) total time=   2.1s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   4.3s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.735, test=0.735) f1: (train=0.778, test=0.778) total time=   1.1s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.735) f1: (train=0.779, test=0.777) total time=   1.8s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.735, test=0.736) f1: (train=0.778, test=0.778) total time=   2.4s\n",
      "[CV 2/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.737, test=0.733) f1: (train=0.780, test=0.776) total time=   4.3s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.871, test=0.868) balanced_accuracy: (train=0.744, test=0.741) f1: (train=0.787, test=0.783) total time=   4.6s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.746, test=0.741) f1: (train=0.789, test=0.783) total time=   8.2s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.871, test=0.871) balanced_accuracy: (train=0.744, test=0.745) f1: (train=0.787, test=0.788) total time=  12.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.871, test=0.871) balanced_accuracy: (train=0.745, test=0.745) f1: (train=0.788, test=0.788) total time=  12.6s\n",
      "[CV 5/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.735, test=0.736) f1: (train=0.778, test=0.779) total time=   4.1s\n",
      "[CV 2/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.732) f1: (train=0.779, test=0.775) total time=   1.5s\n",
      "[CV 5/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.735, test=0.736) f1: (train=0.778, test=0.779) total time=   1.3s\n",
      "[CV 2/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.737, test=0.732) f1: (train=0.780, test=0.774) total time=   2.3s\n",
      "[CV 2/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.737, test=0.732) f1: (train=0.780, test=0.774) total time=   4.5s\n",
      "[CV 4/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.787, test=0.784) total time=   5.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.746, test=0.741) f1: (train=0.789, test=0.783) total time=   7.9s\n",
      "[CV 3/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.871, test=0.872) balanced_accuracy: (train=0.745, test=0.746) f1: (train=0.788, test=0.789) total time=  16.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.872, test=0.871) balanced_accuracy: (train=0.745, test=0.744) f1: (train=0.788, test=0.786) total time=  11.1s\n",
      "[CV 3/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.734, test=0.737) f1: (train=0.778, test=0.780) total time=   4.1s\n",
      "[CV 5/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.777, test=0.778) total time=   1.2s\n",
      "[CV 2/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.865) balanced_accuracy: (train=0.736, test=0.732) f1: (train=0.779, test=0.774) total time=   1.2s\n",
      "[CV 3/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.867, test=0.869) balanced_accuracy: (train=0.735, test=0.738) f1: (train=0.778, test=0.781) total time=   2.2s\n",
      "[CV 5/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.735, test=0.735) f1: (train=0.778, test=0.778) total time=   2.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.737, test=0.732) f1: (train=0.780, test=0.774) total time=   3.9s\n",
      "[CV 3/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.871, test=0.871) balanced_accuracy: (train=0.745, test=0.745) f1: (train=0.788, test=0.788) total time=   5.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.787, test=0.784) total time=   8.5s\n",
      "[CV 2/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.746, test=0.741) f1: (train=0.789, test=0.783) total time=  15.5s\n",
      "[CV 3/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.872, test=0.872) balanced_accuracy: (train=0.746, test=0.746) f1: (train=0.789, test=0.789) total time=  13.9s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.735, test=0.735) f1: (train=0.778, test=0.778) total time=   3.9s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.735, test=0.731) f1: (train=0.778, test=0.774) total time=   1.3s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.867, test=0.869) balanced_accuracy: (train=0.734, test=0.737) f1: (train=0.777, test=0.780) total time=   1.9s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.867, test=0.869) balanced_accuracy: (train=0.734, test=0.737) f1: (train=0.777, test=0.780) total time=   4.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.868) balanced_accuracy: (train=0.735, test=0.736) f1: (train=0.778, test=0.779) total time=   3.4s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.871, test=0.870) balanced_accuracy: (train=0.743, test=0.743) f1: (train=0.786, test=0.785) total time=   4.9s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.870, test=0.871) balanced_accuracy: (train=0.742, test=0.744) f1: (train=0.785, test=0.787) total time=   8.5s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.870, test=0.870) balanced_accuracy: (train=0.742, test=0.743) f1: (train=0.785, test=0.785) total time=  16.5s\n",
      "[CV 2/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.865) balanced_accuracy: (train=0.736, test=0.732) f1: (train=0.778, test=0.774) total time=   1.3s\n",
      "[CV 3/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.733, test=0.736) f1: (train=0.776, test=0.779) total time=   1.3s\n",
      "[CV 4/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.866, test=0.865) balanced_accuracy: (train=0.734, test=0.732) f1: (train=0.777, test=0.774) total time=   1.4s\n",
      "[CV 1/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.777) total time=   2.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.734, test=0.732) f1: (train=0.777, test=0.775) total time=   2.2s\n",
      "[CV 3/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.867, test=0.869) balanced_accuracy: (train=0.734, test=0.737) f1: (train=0.777, test=0.780) total time=   4.2s\n",
      "[CV 4/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.777) total time=   1.3s\n",
      "[CV 1/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.776) total time=   1.2s\n",
      "[CV 1/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.777) total time=   2.2s\n",
      "[CV 2/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.735, test=0.731) f1: (train=0.778, test=0.774) total time=   3.7s\n",
      "[CV 3/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.734, test=0.737) f1: (train=0.777, test=0.780) total time=   4.6s\n",
      "[CV 1/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.783) total time=   5.5s\n",
      "[CV 3/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.870, test=0.871) balanced_accuracy: (train=0.742, test=0.743) f1: (train=0.785, test=0.786) total time=   8.1s\n",
      "[CV 4/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.741) f1: (train=0.786, test=0.783) total time=  18.3s\n",
      "[CV 1/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.734, test=0.733) f1: (train=0.777, test=0.775) total time=   1.1s\n",
      "[CV 3/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.734, test=0.737) f1: (train=0.777, test=0.780) total time=   1.3s\n",
      "[CV 3/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.733, test=0.736) f1: (train=0.776, test=0.779) total time=   1.2s\n",
      "[CV 3/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.734, test=0.736) f1: (train=0.777, test=0.779) total time=   1.2s\n",
      "[CV 1/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.777) total time=   2.2s\n",
      "[CV 1/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.778, test=0.776) total time=   4.4s\n",
      "[CV 3/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.734, test=0.737) f1: (train=0.777, test=0.780) total time=   4.3s\n",
      "[CV 2/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.867, test=0.865) balanced_accuracy: (train=0.735, test=0.731) f1: (train=0.778, test=0.774) total time=   2.1s\n",
      "[CV 4/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.777) total time=   4.6s\n",
      "[CV 4/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.741) f1: (train=0.786, test=0.783) total time=   5.8s\n",
      "[CV 1/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.744, test=0.741) f1: (train=0.787, test=0.783) total time=   8.3s\n",
      "[CV 3/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.871, test=0.871) balanced_accuracy: (train=0.742, test=0.744) f1: (train=0.785, test=0.787) total time=   8.8s\n",
      "[CV 5/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.871, test=0.870) balanced_accuracy: (train=0.743, test=0.743) f1: (train=0.786, test=0.785) total time=  17.4s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.867, test=0.869) balanced_accuracy: (train=0.734, test=0.737) f1: (train=0.777, test=0.780) total time=   2.1s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.778, test=0.776) total time=   3.4s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.777) total time=   3.9s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.734, test=0.737) f1: (train=0.777, test=0.780) total time=   1.3s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.777) total time=   2.0s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.735, test=0.736) f1: (train=0.778, test=0.779) total time=   4.1s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.744, test=0.741) f1: (train=0.787, test=0.783) total time=   3.9s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.871, test=0.870) balanced_accuracy: (train=0.743, test=0.743) f1: (train=0.786, test=0.785) total time=   5.0s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.871, test=0.868) balanced_accuracy: (train=0.742, test=0.738) f1: (train=0.786, test=0.781) total time=   8.7s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.782) total time=  15.7s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.734, test=0.737) f1: (train=0.777, test=0.780) total time=   1.0s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.777) total time=   1.1s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.776) total time=   1.3s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.867, test=0.865) balanced_accuracy: (train=0.736, test=0.731) f1: (train=0.779, test=0.774) total time=   2.1s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.778, test=0.779) total time=   2.3s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.777) total time=   4.3s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.734, test=0.737) f1: (train=0.777, test=0.780) total time=   4.5s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.867, test=0.865) balanced_accuracy: (train=0.735, test=0.731) f1: (train=0.778, test=0.774) total time=   2.1s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.777) total time=   4.6s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.782) total time=   5.7s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.870, test=0.871) balanced_accuracy: (train=0.742, test=0.744) f1: (train=0.785, test=0.787) total time=  10.6s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.871, test=0.868) balanced_accuracy: (train=0.743, test=0.738) f1: (train=0.786, test=0.781) total time=  14.3s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.870, test=0.871) balanced_accuracy: (train=0.742, test=0.743) f1: (train=0.785, test=0.786) total time=  18.3s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.777) total time=   4.2s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.734, test=0.736) f1: (train=0.777, test=0.779) total time=   1.5s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.778, test=0.776) total time=   2.2s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.732) f1: (train=0.778, test=0.775) total time=   4.7s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.870, test=0.870) balanced_accuracy: (train=0.742, test=0.742) f1: (train=0.785, test=0.785) total time=   6.1s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.870, test=0.871) balanced_accuracy: (train=0.742, test=0.744) f1: (train=0.785, test=0.787) total time=   9.0s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.785, test=0.783) total time=   9.4s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.785, test=0.782) total time=  13.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   1.3s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.735) f1: (train=0.779, test=0.777) total time=   1.7s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.777) total time=   1.9s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.779, test=0.777) total time=   4.2s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.779, test=0.777) total time=   1.2s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.777, test=0.778) total time=   0.8s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.867, test=0.869) balanced_accuracy: (train=0.734, test=0.737) f1: (train=0.778, test=0.781) total time=   1.7s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   4.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.779, test=0.777) total time=   4.1s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.872, test=0.868) balanced_accuracy: (train=0.746, test=0.740) f1: (train=0.789, test=0.782) total time=   4.4s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.871, test=0.871) balanced_accuracy: (train=0.745, test=0.745) f1: (train=0.787, test=0.788) total time=   7.8s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.872, test=0.871) balanced_accuracy: (train=0.747, test=0.745) f1: (train=0.789, test=0.787) total time=  15.6s\n",
      "[CV 1/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   1.2s\n",
      "[CV 5/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.777, test=0.778) total time=   1.1s\n",
      "[CV 4/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.777) total time=   1.1s\n",
      "[CV 1/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.778) total time=   1.6s\n",
      "[CV 5/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.735, test=0.736) f1: (train=0.778, test=0.779) total time=   2.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.735, test=0.731) f1: (train=0.778, test=0.774) total time=   4.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.737, test=0.732) f1: (train=0.780, test=0.774) total time=   3.7s\n",
      "[CV 5/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.777, test=0.778) total time=   1.4s\n",
      "[CV 5/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.735, test=0.735) f1: (train=0.778, test=0.778) total time=   2.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   4.1s\n",
      "[CV 2/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.746, test=0.741) f1: (train=0.789, test=0.783) total time=   5.2s\n",
      "[CV 4/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.787, test=0.784) total time=   7.9s\n",
      "[CV 1/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.746, test=0.741) f1: (train=0.789, test=0.784) total time=  16.4s\n",
      "[CV 4/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.745, test=0.741) f1: (train=0.787, test=0.784) total time=  14.8s\n",
      "[CV 4/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.779, test=0.777) total time=   3.9s\n",
      "[CV 3/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.734, test=0.737) f1: (train=0.777, test=0.780) total time=   2.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.734, test=0.734) f1: (train=0.777, test=0.778) total time=   3.9s\n",
      "[CV 4/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.779, test=0.777) total time=   4.2s\n",
      "[CV 1/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.872, test=0.868) balanced_accuracy: (train=0.747, test=0.741) f1: (train=0.789, test=0.783) total time=   4.6s\n",
      "[CV 3/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.871, test=0.871) balanced_accuracy: (train=0.745, test=0.745) f1: (train=0.788, test=0.787) total time=   7.9s\n",
      "[CV 5/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.872, test=0.871) balanced_accuracy: (train=0.747, test=0.745) f1: (train=0.789, test=0.787) total time=  15.8s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.736, test=0.731) f1: (train=0.779, test=0.774) total time=   1.5s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.732, test=0.736) f1: (train=0.776, test=0.779) total time=   1.3s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.866, test=0.865) balanced_accuracy: (train=0.734, test=0.732) f1: (train=0.777, test=0.774) total time=   1.2s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.735, test=0.735) f1: (train=0.778, test=0.778) total time=   2.3s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.867, test=0.869) balanced_accuracy: (train=0.734, test=0.737) f1: (train=0.777, test=0.780) total time=   2.5s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.735, test=0.731) f1: (train=0.778, test=0.775) total time=   4.2s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.735) f1: (train=0.778, test=0.777) total time=   1.3s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.734, test=0.733) f1: (train=0.777, test=0.776) total time=   1.2s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.777) total time=   2.1s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.735, test=0.731) f1: (train=0.778, test=0.774) total time=   4.1s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.779, test=0.777) total time=   4.5s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.871, test=0.868) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.785, test=0.781) total time=   5.2s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.785, test=0.783) total time=   8.1s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.782) total time=  16.6s\n",
      "[CV 4/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.777) total time=   1.4s\n",
      "[CV 5/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.778, test=0.778) total time=   1.5s\n",
      "[CV 2/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.867, test=0.865) balanced_accuracy: (train=0.736, test=0.731) f1: (train=0.779, test=0.774) total time=   2.1s\n",
      "[CV 1/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.778, test=0.776) total time=   2.3s\n",
      "[CV 1/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.777) total time=   4.1s\n",
      "[CV 2/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.865) balanced_accuracy: (train=0.736, test=0.732) f1: (train=0.778, test=0.774) total time=   1.3s\n",
      "[CV 3/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.733, test=0.736) f1: (train=0.776, test=0.779) total time=   1.3s\n",
      "[CV 5/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.734, test=0.736) f1: (train=0.777, test=0.779) total time=   1.5s\n",
      "[CV 2/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.867, test=0.865) balanced_accuracy: (train=0.735, test=0.731) f1: (train=0.778, test=0.774) total time=   2.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.867, test=0.869) balanced_accuracy: (train=0.734, test=0.737) f1: (train=0.777, test=0.780) total time=   4.4s\n",
      "[CV 1/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.782) total time=   5.7s\n",
      "[CV 3/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.870, test=0.871) balanced_accuracy: (train=0.742, test=0.744) f1: (train=0.785, test=0.787) total time=   8.5s\n",
      "[CV 5/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.870, test=0.871) balanced_accuracy: (train=0.742, test=0.743) f1: (train=0.785, test=0.786) total time=   9.8s\n",
      "[CV 2/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.871, test=0.868) balanced_accuracy: (train=0.742, test=0.737) f1: (train=0.785, test=0.780) total time=  17.8s\n",
      "[CV 4/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.777) total time=   2.1s\n",
      "[CV 4/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.777) total time=   4.5s\n",
      "[CV 1/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.734, test=0.733) f1: (train=0.777, test=0.775) total time=   1.5s\n",
      "[CV 3/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.733, test=0.736) f1: (train=0.776, test=0.779) total time=   1.4s\n",
      "[CV 5/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.734, test=0.736) f1: (train=0.777, test=0.779) total time=   1.2s\n",
      "[CV 1/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.778, test=0.776) total time=   2.1s\n",
      "[CV 3/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.867, test=0.869) balanced_accuracy: (train=0.734, test=0.737) f1: (train=0.777, test=0.780) total time=   4.5s\n",
      "[CV 5/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.870, test=0.870) balanced_accuracy: (train=0.742, test=0.742) f1: (train=0.785, test=0.785) total time=   5.7s\n",
      "[CV 3/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.870, test=0.871) balanced_accuracy: (train=0.742, test=0.744) f1: (train=0.785, test=0.787) total time=   8.2s\n",
      "[CV 4/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.785, test=0.783) total time=   8.9s\n",
      "[CV 1/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.785, test=0.782) total time=  17.2s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.735, test=0.732) f1: (train=0.778, test=0.775) total time=   2.4s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.735, test=0.731) f1: (train=0.778, test=0.774) total time=   4.4s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.867, test=0.869) balanced_accuracy: (train=0.734, test=0.738) f1: (train=0.778, test=0.781) total time=   4.1s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.867, test=0.869) balanced_accuracy: (train=0.734, test=0.737) f1: (train=0.777, test=0.780) total time=   1.9s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.867, test=0.869) balanced_accuracy: (train=0.734, test=0.737) f1: (train=0.777, test=0.780) total time=   4.3s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.870, test=0.871) balanced_accuracy: (train=0.742, test=0.743) f1: (train=0.785, test=0.786) total time=   5.7s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.870, test=0.871) balanced_accuracy: (train=0.742, test=0.743) f1: (train=0.785, test=0.786) total time=   7.3s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.870, test=0.871) balanced_accuracy: (train=0.743, test=0.744) f1: (train=0.785, test=0.787) total time=   8.8s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.785, test=0.782) total time=  16.3s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.867, test=0.865) balanced_accuracy: (train=0.735, test=0.731) f1: (train=0.778, test=0.774) total time=   2.0s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.777, test=0.778) total time=   2.3s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.777) total time=   3.9s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.777) total time=   1.3s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.778, test=0.778) total time=   1.5s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.734, test=0.737) f1: (train=0.777, test=0.781) total time=   2.3s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.777, test=0.778) total time=   2.2s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.735, test=0.731) f1: (train=0.778, test=0.774) total time=   4.3s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.743, test=0.741) f1: (train=0.786, test=0.783) total time=   5.6s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.783) total time=   8.9s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.870, test=0.871) balanced_accuracy: (train=0.742, test=0.743) f1: (train=0.785, test=0.786) total time=  11.0s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.871, test=0.868) balanced_accuracy: (train=0.742, test=0.737) f1: (train=0.785, test=0.780) total time=  17.9s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.778, test=0.779) total time=   2.1s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.778, test=0.778) total time=   4.2s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.865) balanced_accuracy: (train=0.736, test=0.732) f1: (train=0.778, test=0.774) total time=   1.3s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.734, test=0.733) f1: (train=0.778, test=0.777) total time=   1.4s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.867, test=0.865) balanced_accuracy: (train=0.736, test=0.731) f1: (train=0.779, test=0.774) total time=   2.2s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.734, test=0.732) f1: (train=0.777, test=0.775) total time=   2.5s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.735, test=0.731) f1: (train=0.778, test=0.774) total time=   4.4s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.743, test=0.741) f1: (train=0.786, test=0.783) total time=   5.6s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.783) total time=   8.9s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.870, test=0.871) balanced_accuracy: (train=0.742, test=0.744) f1: (train=0.785, test=0.787) total time=  12.8s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.742, test=0.741) f1: (train=0.785, test=0.783) total time=  11.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.777) total time=   1.6s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.778, test=0.778) total time=   2.2s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   4.5s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   1.4s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.735, test=0.737) f1: (train=0.778, test=0.780) total time=   1.1s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   2.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.731) f1: (train=0.779, test=0.774) total time=   4.3s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.868) balanced_accuracy: (train=0.735, test=0.736) f1: (train=0.778, test=0.779) total time=   4.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.746, test=0.741) f1: (train=0.789, test=0.783) total time=   4.5s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.787, test=0.784) total time=   7.6s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.746, test=0.741) f1: (train=0.789, test=0.783) total time=  15.9s\n",
      "[CV 4/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.865) balanced_accuracy: (train=0.735, test=0.732) f1: (train=0.778, test=0.775) total time=   1.3s\n",
      "[CV 2/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.865) balanced_accuracy: (train=0.736, test=0.732) f1: (train=0.779, test=0.774) total time=   1.3s\n",
      "[CV 2/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.737, test=0.733) f1: (train=0.780, test=0.775) total time=   2.1s\n",
      "[CV 1/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.735) f1: (train=0.779, test=0.777) total time=   4.2s\n",
      "[CV 4/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.779, test=0.777) total time=   4.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.779, test=0.777) total time=   2.1s\n",
      "[CV 5/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.734, test=0.734) f1: (train=0.777, test=0.778) total time=   4.1s\n",
      "[CV 2/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.747, test=0.742) f1: (train=0.789, test=0.784) total time=   5.3s\n",
      "[CV 4/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.788, test=0.784) total time=   4.9s\n",
      "[CV 5/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.872, test=0.871) balanced_accuracy: (train=0.746, test=0.745) f1: (train=0.789, test=0.787) total time=   6.7s\n",
      "[CV 2/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.872, test=0.868) balanced_accuracy: (train=0.745, test=0.739) f1: (train=0.788, test=0.782) total time=  15.8s\n",
      "[CV 3/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.869) balanced_accuracy: (train=0.736, test=0.739) f1: (train=0.779, test=0.781) total time=   1.3s\n",
      "[CV 4/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.777) total time=   1.1s\n",
      "[CV 3/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.735, test=0.737) f1: (train=0.778, test=0.780) total time=   1.1s\n",
      "[CV 3/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.867, test=0.869) balanced_accuracy: (train=0.735, test=0.738) f1: (train=0.778, test=0.781) total time=   2.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   2.3s\n",
      "[CV 5/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.734, test=0.734) f1: (train=0.777, test=0.778) total time=   4.3s\n",
      "[CV 3/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.869) balanced_accuracy: (train=0.736, test=0.739) f1: (train=0.779, test=0.781) total time=   1.4s\n",
      "[CV 4/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.777) total time=   1.2s\n",
      "[CV 5/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.735, test=0.736) f1: (train=0.778, test=0.779) total time=   1.5s\n",
      "[CV 2/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.737, test=0.732) f1: (train=0.780, test=0.774) total time=   1.8s\n",
      "[CV 4/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.779, test=0.777) total time=   3.9s\n",
      "[CV 4/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.744, test=0.741) f1: (train=0.787, test=0.783) total time=   5.1s\n",
      "[CV 1/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.746, test=0.741) f1: (train=0.789, test=0.783) total time=   8.6s\n",
      "[CV 3/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.872, test=0.871) balanced_accuracy: (train=0.746, test=0.746) f1: (train=0.788, test=0.788) total time=   8.1s\n",
      "[CV 5/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.872, test=0.871) balanced_accuracy: (train=0.746, test=0.745) f1: (train=0.789, test=0.787) total time=  15.7s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.735, test=0.732) f1: (train=0.778, test=0.775) total time=   2.1s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.778, test=0.776) total time=   4.2s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.735, test=0.731) f1: (train=0.779, test=0.774) total time=   4.1s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.732) f1: (train=0.779, test=0.775) total time=   2.1s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.734, test=0.733) f1: (train=0.777, test=0.776) total time=   1.8s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.777) total time=   3.9s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.870, test=0.871) balanced_accuracy: (train=0.743, test=0.744) f1: (train=0.785, test=0.787) total time=   5.2s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.742, test=0.741) f1: (train=0.785, test=0.783) total time=   8.6s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.782) total time=  16.4s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.742, test=0.741) f1: (train=0.785, test=0.783) total time=  16.2s\n",
      "[CV 1/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.777) total time=   1.3s\n",
      "[CV 3/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.734, test=0.736) f1: (train=0.777, test=0.779) total time=   1.4s\n",
      "[CV 4/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.777) total time=   2.2s\n",
      "[CV 1/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.777) total time=   4.2s\n",
      "[CV 3/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.871, test=0.871) balanced_accuracy: (train=0.743, test=0.744) f1: (train=0.786, test=0.787) total time=   6.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.744, test=0.741) f1: (train=0.787, test=0.783) total time=   8.3s\n",
      "[CV 4/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.785, test=0.783) total time=   7.8s\n",
      "[CV 5/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.871, test=0.870) balanced_accuracy: (train=0.743, test=0.743) f1: (train=0.786, test=0.785) total time=  18.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.778, test=0.776) total time=   2.1s\n",
      "[CV 5/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.778, test=0.779) total time=   2.2s\n",
      "[CV 1/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.777) total time=   4.6s\n",
      "[CV 3/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.734, test=0.737) f1: (train=0.777, test=0.780) total time=   1.5s\n",
      "[CV 1/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.776) total time=   1.3s\n",
      "[CV 3/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.734, test=0.737) f1: (train=0.777, test=0.781) total time=   2.2s\n",
      "[CV 3/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.867, test=0.869) balanced_accuracy: (train=0.734, test=0.737) f1: (train=0.777, test=0.781) total time=   3.8s\n",
      "[CV 3/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.734, test=0.737) f1: (train=0.777, test=0.780) total time=   4.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.871, test=0.870) balanced_accuracy: (train=0.743, test=0.743) f1: (train=0.786, test=0.785) total time=   5.2s\n",
      "[CV 2/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.871, test=0.868) balanced_accuracy: (train=0.742, test=0.738) f1: (train=0.786, test=0.781) total time=   8.2s\n",
      "[CV 5/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.870, test=0.870) balanced_accuracy: (train=0.742, test=0.743) f1: (train=0.785, test=0.786) total time=  16.8s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.777, test=0.776) total time=   1.2s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.736, test=0.738) f1: (train=0.778, test=0.781) total time=   1.1s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.777) total time=   1.4s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.734, test=0.733) f1: (train=0.777, test=0.776) total time=   1.2s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.732) f1: (train=0.779, test=0.775) total time=   2.1s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.734, test=0.733) f1: (train=0.777, test=0.776) total time=   2.2s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.735, test=0.736) f1: (train=0.778, test=0.779) total time=   4.1s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.868) balanced_accuracy: (train=0.735, test=0.736) f1: (train=0.778, test=0.779) total time=   4.1s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.778, test=0.779) total time=   1.8s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.867, test=0.869) balanced_accuracy: (train=0.734, test=0.737) f1: (train=0.777, test=0.781) total time=   4.1s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.783) total time=   5.4s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.870, test=0.870) balanced_accuracy: (train=0.742, test=0.742) f1: (train=0.785, test=0.785) total time=   5.6s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.871, test=0.868) balanced_accuracy: (train=0.743, test=0.738) f1: (train=0.786, test=0.781) total time=   8.5s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.785, test=0.782) total time=  16.3s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.734, test=0.736) f1: (train=0.777, test=0.779) total time=   1.3s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.735, test=0.735) f1: (train=0.778, test=0.778) total time=   2.2s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.734, test=0.732) f1: (train=0.777, test=0.775) total time=   2.1s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.732) f1: (train=0.778, test=0.775) total time=   4.2s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.734, test=0.737) f1: (train=0.777, test=0.780) total time=   1.1s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.733, test=0.736) f1: (train=0.776, test=0.779) total time=   1.4s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.734, test=0.736) f1: (train=0.777, test=0.779) total time=   1.3s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.867, test=0.865) balanced_accuracy: (train=0.735, test=0.731) f1: (train=0.778, test=0.774) total time=   2.2s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.777) total time=   3.6s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.734, test=0.736) f1: (train=0.778, test=0.779) total time=   4.2s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.871, test=0.868) balanced_accuracy: (train=0.743, test=0.738) f1: (train=0.786, test=0.781) total time=   5.6s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.741) f1: (train=0.786, test=0.783) total time=   8.6s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.741) f1: (train=0.786, test=0.783) total time=  20.4s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.734, test=0.737) f1: (train=0.777, test=0.780) total time=   1.5s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.734, test=0.733) f1: (train=0.778, test=0.777) total time=   1.6s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.734, test=0.736) f1: (train=0.777, test=0.779) total time=   1.7s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.867, test=0.865) balanced_accuracy: (train=0.735, test=0.731) f1: (train=0.778, test=0.774) total time=   2.2s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.735, test=0.731) f1: (train=0.778, test=0.774) total time=   4.1s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.734, test=0.736) f1: (train=0.778, test=0.779) total time=   4.0s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.867, test=0.865) balanced_accuracy: (train=0.735, test=0.731) f1: (train=0.778, test=0.774) total time=   2.3s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.778, test=0.778) total time=   3.5s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.734, test=0.737) f1: (train=0.777, test=0.780) total time=   4.6s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.783) total time=   5.4s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.741) f1: (train=0.786, test=0.783) total time=   8.5s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.870, test=0.870) balanced_accuracy: (train=0.742, test=0.743) f1: (train=0.785, test=0.786) total time=  18.8s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.735, test=0.735) f1: (train=0.778, test=0.778) total time=   1.6s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.779, test=0.777) total time=   2.2s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.778, test=0.778) total time=   4.7s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.777, test=0.778) total time=   1.3s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.735) f1: (train=0.779, test=0.778) total time=   1.2s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   2.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.867, test=0.869) balanced_accuracy: (train=0.735, test=0.737) f1: (train=0.778, test=0.781) total time=   4.5s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.746, test=0.741) f1: (train=0.788, test=0.783) total time=   4.8s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.745, test=0.741) f1: (train=0.788, test=0.783) total time=   8.1s\n",
      "[CV 2/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.745, test=0.740) f1: (train=0.788, test=0.782) total time=  15.7s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.872, test=0.871) balanced_accuracy: (train=0.745, test=0.744) f1: (train=0.788, test=0.787) total time=  14.4s\n",
      "[CV 5/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.777, test=0.778) total time=   1.1s\n",
      "[CV 3/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.735, test=0.737) f1: (train=0.778, test=0.780) total time=   1.4s\n",
      "[CV 3/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.734, test=0.737) f1: (train=0.777, test=0.780) total time=   2.2s\n",
      "[CV 2/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.732) f1: (train=0.779, test=0.775) total time=   4.4s\n",
      "[CV 4/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.744, test=0.741) f1: (train=0.787, test=0.783) total time=   4.2s\n",
      "[CV 3/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.871, test=0.871) balanced_accuracy: (train=0.746, test=0.745) f1: (train=0.788, test=0.788) total time=   5.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.872, test=0.868) balanced_accuracy: (train=0.747, test=0.741) f1: (train=0.789, test=0.783) total time=   8.3s\n",
      "[CV 4/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.872, test=0.870) balanced_accuracy: (train=0.745, test=0.743) f1: (train=0.788, test=0.785) total time=  16.3s\n",
      "[CV 5/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.777, test=0.779) total time=   1.5s\n",
      "[CV 5/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.777, test=0.778) total time=   2.1s\n",
      "[CV 4/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.777) total time=   2.9s\n",
      "[CV 5/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.735, test=0.736) f1: (train=0.778, test=0.779) total time=   4.1s\n",
      "[CV 5/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.777, test=0.779) total time=   1.6s\n",
      "[CV 1/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.778) total time=   2.1s\n",
      "[CV 2/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.735, test=0.731) f1: (train=0.778, test=0.774) total time=   4.4s\n",
      "[CV 5/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.872, test=0.871) balanced_accuracy: (train=0.747, test=0.745) f1: (train=0.790, test=0.787) total time=   5.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.871, test=0.871) balanced_accuracy: (train=0.745, test=0.745) f1: (train=0.788, test=0.788) total time=   8.3s\n",
      "[CV 1/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.746, test=0.741) f1: (train=0.789, test=0.784) total time=  16.3s\n",
      "[CV 5/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.872, test=0.871) balanced_accuracy: (train=0.745, test=0.744) f1: (train=0.788, test=0.786) total time=  13.2s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.777) total time=   4.2s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.734, test=0.738) f1: (train=0.777, test=0.781) total time=   2.5s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.777) total time=   4.2s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.782) total time=   5.3s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.870, test=0.870) balanced_accuracy: (train=0.743, test=0.743) f1: (train=0.785, test=0.786) total time=   8.6s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.871, test=0.868) balanced_accuracy: (train=0.743, test=0.738) f1: (train=0.786, test=0.781) total time=  16.7s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.870, test=0.870) balanced_accuracy: (train=0.742, test=0.742) f1: (train=0.785, test=0.785) total time=  16.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.731) f1: (train=0.778, test=0.774) total time=   1.4s\n",
      "[CV 2/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.867, test=0.865) balanced_accuracy: (train=0.736, test=0.731) f1: (train=0.779, test=0.774) total time=   2.1s\n",
      "[CV 5/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.777, test=0.778) total time=   2.3s\n",
      "[CV 2/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.735, test=0.731) f1: (train=0.778, test=0.774) total time=   4.2s\n",
      "[CV 3/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.870, test=0.871) balanced_accuracy: (train=0.742, test=0.744) f1: (train=0.785, test=0.787) total time=   5.6s\n",
      "[CV 5/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.870, test=0.871) balanced_accuracy: (train=0.742, test=0.743) f1: (train=0.785, test=0.786) total time=   8.4s\n",
      "[CV 1/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.744, test=0.740) f1: (train=0.786, test=0.783) total time=  18.8s\n",
      "[CV 5/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.870, test=0.871) balanced_accuracy: (train=0.742, test=0.743) f1: (train=0.785, test=0.786) total time=  15.8s\n",
      "[CV 1/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.777) total time=   1.3s\n",
      "[CV 3/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.734, test=0.736) f1: (train=0.777, test=0.779) total time=   1.1s\n",
      "[CV 5/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.735, test=0.735) f1: (train=0.778, test=0.778) total time=   2.1s\n",
      "[CV 5/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.777, test=0.778) total time=   2.3s\n",
      "[CV 2/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.735, test=0.731) f1: (train=0.778, test=0.774) total time=   4.3s\n",
      "[CV 4/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.743, test=0.741) f1: (train=0.786, test=0.783) total time=   5.3s\n",
      "[CV 1/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.783) total time=   8.1s\n",
      "[CV 1/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.744, test=0.740) f1: (train=0.786, test=0.783) total time=  17.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.870, test=0.871) balanced_accuracy: (train=0.742, test=0.743) f1: (train=0.785, test=0.786) total time=  13.4s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.735, test=0.735) f1: (train=0.778, test=0.778) total time=   4.1s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.735, test=0.731) f1: (train=0.778, test=0.774) total time=   1.4s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.777) total time=   2.0s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.867, test=0.869) balanced_accuracy: (train=0.734, test=0.737) f1: (train=0.777, test=0.780) total time=   2.2s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.735, test=0.735) f1: (train=0.778, test=0.778) total time=   4.1s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.870, test=0.871) balanced_accuracy: (train=0.743, test=0.744) f1: (train=0.785, test=0.787) total time=   5.3s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.870, test=0.870) balanced_accuracy: (train=0.743, test=0.743) f1: (train=0.785, test=0.786) total time=   8.6s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.871, test=0.868) balanced_accuracy: (train=0.743, test=0.738) f1: (train=0.786, test=0.781) total time=  16.1s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.742, test=0.741) f1: (train=0.785, test=0.783) total time=  15.6s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.736, test=0.735) f1: (train=0.778, test=0.778) total time=   1.6s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.776) total time=   1.4s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.735, test=0.735) f1: (train=0.778, test=0.778) total time=   2.4s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.735, test=0.731) f1: (train=0.778, test=0.774) total time=   3.5s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.779, test=0.777) total time=   4.3s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.783) total time=   5.6s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.870, test=0.871) balanced_accuracy: (train=0.742, test=0.743) f1: (train=0.785, test=0.786) total time=  10.3s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.870, test=0.871) balanced_accuracy: (train=0.742, test=0.743) f1: (train=0.785, test=0.786) total time=  19.8s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.777) total time=   1.7s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.734, test=0.736) f1: (train=0.777, test=0.779) total time=   1.7s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.735, test=0.735) f1: (train=0.778, test=0.778) total time=   2.1s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.734, test=0.737) f1: (train=0.777, test=0.780) total time=   2.3s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.867, test=0.869) balanced_accuracy: (train=0.734, test=0.737) f1: (train=0.777, test=0.780) total time=   4.2s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.736, test=0.735) f1: (train=0.778, test=0.778) total time=   1.4s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.865) balanced_accuracy: (train=0.735, test=0.731) f1: (train=0.778, test=0.773) total time=   1.4s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.777) total time=   2.0s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.777) total time=   3.3s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.779, test=0.777) total time=   3.9s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.871, test=0.870) balanced_accuracy: (train=0.743, test=0.743) f1: (train=0.786, test=0.785) total time=   5.5s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.871, test=0.868) balanced_accuracy: (train=0.742, test=0.738) f1: (train=0.786, test=0.781) total time=   8.8s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.741) f1: (train=0.786, test=0.783) total time=  18.8s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.735) f1: (train=0.779, test=0.777) total time=   1.4s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.779, test=0.777) total time=   2.3s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.777) total time=   4.4s\n",
      "[CV 2/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.736, test=0.731) f1: (train=0.779, test=0.773) total time=   1.4s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.735) f1: (train=0.779, test=0.777) total time=   1.3s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.778, test=0.778) total time=   2.3s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.778, test=0.778) total time=   4.5s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.872, test=0.871) balanced_accuracy: (train=0.747, test=0.745) f1: (train=0.789, test=0.787) total time=   4.9s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.871, test=0.871) balanced_accuracy: (train=0.744, test=0.745) f1: (train=0.787, test=0.788) total time=   7.1s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.871, test=0.871) balanced_accuracy: (train=0.745, test=0.746) f1: (train=0.788, test=0.788) total time=   7.5s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.872, test=0.870) balanced_accuracy: (train=0.746, test=0.744) f1: (train=0.789, test=0.787) total time=  13.9s\n",
      "[CV 5/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.777, test=0.779) total time=   1.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.867, test=0.869) balanced_accuracy: (train=0.735, test=0.738) f1: (train=0.778, test=0.781) total time=   2.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   1.9s\n",
      "[CV 5/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.734, test=0.734) f1: (train=0.777, test=0.778) total time=   4.2s\n",
      "[CV 1/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   1.2s\n",
      "[CV 3/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.867, test=0.869) balanced_accuracy: (train=0.734, test=0.737) f1: (train=0.778, test=0.781) total time=   1.2s\n",
      "[CV 4/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.735) f1: (train=0.779, test=0.778) total time=   1.2s\n",
      "[CV 5/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.735, test=0.736) f1: (train=0.778, test=0.779) total time=   2.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   4.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.872, test=0.871) balanced_accuracy: (train=0.745, test=0.745) f1: (train=0.788, test=0.788) total time=   5.3s\n",
      "[CV 1/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.746, test=0.741) f1: (train=0.789, test=0.783) total time=   8.2s\n",
      "[CV 3/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.872, test=0.871) balanced_accuracy: (train=0.746, test=0.746) f1: (train=0.788, test=0.788) total time=   8.3s\n",
      "[CV 5/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.872, test=0.871) balanced_accuracy: (train=0.746, test=0.745) f1: (train=0.789, test=0.787) total time=  15.8s\n",
      "[CV 2/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.737, test=0.733) f1: (train=0.780, test=0.775) total time=   2.1s\n",
      "[CV 5/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.735, test=0.735) f1: (train=0.778, test=0.778) total time=   2.3s\n",
      "[CV 4/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.779, test=0.777) total time=   4.1s\n",
      "[CV 1/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.778) total time=   1.3s\n",
      "[CV 3/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.735, test=0.737) f1: (train=0.778, test=0.780) total time=   1.1s\n",
      "[CV 5/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.777, test=0.778) total time=   2.1s\n",
      "[CV 1/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.735) f1: (train=0.779, test=0.777) total time=   3.9s\n",
      "[CV 3/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.734, test=0.737) f1: (train=0.778, test=0.780) total time=   4.2s\n",
      "[CV 5/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.872, test=0.871) balanced_accuracy: (train=0.746, test=0.745) f1: (train=0.789, test=0.787) total time=   5.1s\n",
      "[CV 4/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.871, test=0.870) balanced_accuracy: (train=0.745, test=0.743) f1: (train=0.788, test=0.785) total time=   7.8s\n",
      "[CV 1/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.746, test=0.741) f1: (train=0.789, test=0.783) total time=  15.7s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.736, test=0.738) f1: (train=0.778, test=0.781) total time=   1.1s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.735, test=0.731) f1: (train=0.778, test=0.774) total time=   1.3s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.734, test=0.737) f1: (train=0.777, test=0.780) total time=   1.2s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.735, test=0.735) f1: (train=0.778, test=0.778) total time=   2.3s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.734, test=0.733) f1: (train=0.777, test=0.776) total time=   2.9s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.777) total time=   3.8s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.777) total time=   1.3s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.734, test=0.737) f1: (train=0.777, test=0.780) total time=   1.2s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.777) total time=   1.9s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.776) total time=   4.2s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.783) total time=   5.3s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.744, test=0.740) f1: (train=0.786, test=0.783) total time=   8.7s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.785, test=0.783) total time=   8.3s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.785, test=0.782) total time=  16.2s\n",
      "[CV 3/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.867, test=0.869) balanced_accuracy: (train=0.733, test=0.737) f1: (train=0.777, test=0.780) total time=   2.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.867, test=0.869) balanced_accuracy: (train=0.734, test=0.737) f1: (train=0.777, test=0.781) total time=   4.4s\n",
      "[CV 3/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.734, test=0.737) f1: (train=0.777, test=0.780) total time=   4.2s\n",
      "[CV 2/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.867, test=0.865) balanced_accuracy: (train=0.735, test=0.731) f1: (train=0.778, test=0.774) total time=   2.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.867, test=0.869) balanced_accuracy: (train=0.734, test=0.737) f1: (train=0.777, test=0.781) total time=   4.3s\n",
      "[CV 5/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.734, test=0.736) f1: (train=0.778, test=0.779) total time=   4.7s\n",
      "[CV 2/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.871, test=0.868) balanced_accuracy: (train=0.743, test=0.738) f1: (train=0.786, test=0.781) total time=   5.3s\n",
      "[CV 5/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.871, test=0.870) balanced_accuracy: (train=0.743, test=0.742) f1: (train=0.786, test=0.785) total time=   8.3s\n",
      "[CV 5/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.870, test=0.870) balanced_accuracy: (train=0.742, test=0.743) f1: (train=0.785, test=0.786) total time=  13.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.742, test=0.741) f1: (train=0.785, test=0.783) total time=  17.2s\n",
      "[CV 2/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.735, test=0.731) f1: (train=0.778, test=0.774) total time=   4.2s\n",
      "[CV 4/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.777) total time=   2.1s\n",
      "[CV 5/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.778, test=0.778) total time=   3.8s\n",
      "[CV 5/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.734, test=0.736) f1: (train=0.778, test=0.779) total time=   4.4s\n",
      "[CV 1/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.783) total time=   5.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.870, test=0.871) balanced_accuracy: (train=0.742, test=0.743) f1: (train=0.785, test=0.786) total time=   7.7s\n",
      "[CV 3/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.870, test=0.871) balanced_accuracy: (train=0.742, test=0.744) f1: (train=0.785, test=0.787) total time=  17.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.870, test=0.871) balanced_accuracy: (train=0.742, test=0.743) f1: (train=0.785, test=0.786) total time=  17.3s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.734, test=0.733) f1: (train=0.777, test=0.776) total time=   1.1s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.734, test=0.738) f1: (train=0.777, test=0.781) total time=   2.1s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.777, test=0.778) total time=   2.3s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.735, test=0.731) f1: (train=0.779, test=0.774) total time=   4.1s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.785, test=0.783) total time=   5.2s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.782) total time=   7.3s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.782) total time=  16.4s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.870, test=0.871) balanced_accuracy: (train=0.743, test=0.744) f1: (train=0.785, test=0.787) total time=  15.7s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.734, test=0.736) f1: (train=0.778, test=0.779) total time=   4.2s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.778, test=0.776) total time=   2.4s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.867, test=0.869) balanced_accuracy: (train=0.734, test=0.737) f1: (train=0.777, test=0.780) total time=   4.4s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.741) f1: (train=0.786, test=0.783) total time=   5.8s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.871, test=0.868) balanced_accuracy: (train=0.744, test=0.739) f1: (train=0.787, test=0.781) total time=  10.6s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.744, test=0.740) f1: (train=0.786, test=0.783) total time=  20.0s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.734, test=0.733) f1: (train=0.777, test=0.775) total time=   1.3s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.777) total time=   1.6s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.778, test=0.778) total time=   1.7s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.778, test=0.776) total time=   2.5s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.777) total time=   2.0s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.777) total time=   4.1s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.734, test=0.733) f1: (train=0.777, test=0.775) total time=   1.2s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.731) f1: (train=0.778, test=0.774) total time=   1.4s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.734, test=0.736) f1: (train=0.777, test=0.779) total time=   1.6s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.867, test=0.865) balanced_accuracy: (train=0.735, test=0.731) f1: (train=0.778, test=0.774) total time=   2.2s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.777) total time=   4.7s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.782) total time=   6.1s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.871, test=0.868) balanced_accuracy: (train=0.744, test=0.739) f1: (train=0.787, test=0.781) total time=   9.6s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.871, test=0.868) balanced_accuracy: (train=0.743, test=0.738) f1: (train=0.786, test=0.781) total time=  12.7s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.870, test=0.871) balanced_accuracy: (train=0.742, test=0.743) f1: (train=0.785, test=0.786) total time=  10.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.864) balanced_accuracy: (train=0.737, test=0.731) f1: (train=0.779, test=0.773) total time=   1.5s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   1.8s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   4.1s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.779, test=0.777) total time=   3.6s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.867, test=0.869) balanced_accuracy: (train=0.735, test=0.737) f1: (train=0.778, test=0.781) total time=   1.6s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.735, test=0.737) f1: (train=0.778, test=0.780) total time=   1.9s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.868) balanced_accuracy: (train=0.735, test=0.736) f1: (train=0.778, test=0.779) total time=   4.1s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.871, test=0.871) balanced_accuracy: (train=0.744, test=0.745) f1: (train=0.787, test=0.787) total time=   4.7s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.872, test=0.871) balanced_accuracy: (train=0.746, test=0.745) f1: (train=0.789, test=0.788) total time=   8.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.746, test=0.741) f1: (train=0.789, test=0.783) total time=  15.2s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.872, test=0.870) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.789, test=0.785) total time=  14.8s\n",
      "[CV 3/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.734, test=0.737) f1: (train=0.778, test=0.780) total time=   3.6s\n",
      "[CV 2/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.737, test=0.733) f1: (train=0.780, test=0.775) total time=   1.8s\n",
      "[CV 2/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.735, test=0.731) f1: (train=0.778, test=0.774) total time=   4.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.868) balanced_accuracy: (train=0.735, test=0.736) f1: (train=0.778, test=0.779) total time=   4.2s\n",
      "[CV 2/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.746, test=0.741) f1: (train=0.789, test=0.783) total time=   4.8s\n",
      "[CV 4/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.871, test=0.870) balanced_accuracy: (train=0.745, test=0.743) f1: (train=0.788, test=0.785) total time=   7.7s\n",
      "[CV 1/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.746, test=0.741) f1: (train=0.789, test=0.783) total time=  16.3s\n",
      "[CV 4/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.865) balanced_accuracy: (train=0.735, test=0.732) f1: (train=0.778, test=0.775) total time=   1.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.867, test=0.869) balanced_accuracy: (train=0.734, test=0.737) f1: (train=0.778, test=0.781) total time=   1.3s\n",
      "[CV 4/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.735) f1: (train=0.779, test=0.778) total time=   1.1s\n",
      "[CV 4/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   2.2s\n",
      "[CV 3/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.734, test=0.737) f1: (train=0.778, test=0.780) total time=   2.5s\n",
      "[CV 2/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.732) f1: (train=0.779, test=0.775) total time=   3.1s\n",
      "[CV 3/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.734, test=0.737) f1: (train=0.778, test=0.780) total time=   3.9s\n",
      "[CV 5/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.735, test=0.736) f1: (train=0.778, test=0.779) total time=   1.9s\n",
      "[CV 4/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.779, test=0.777) total time=   4.1s\n",
      "[CV 2/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.747, test=0.742) f1: (train=0.789, test=0.784) total time=   4.7s\n",
      "[CV 3/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.871, test=0.871) balanced_accuracy: (train=0.746, test=0.745) f1: (train=0.788, test=0.788) total time=   3.4s\n",
      "[CV 2/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.872, test=0.868) balanced_accuracy: (train=0.746, test=0.740) f1: (train=0.789, test=0.782) total time=   8.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.787, test=0.784) total time=  15.9s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.777, test=0.776) total time=   1.2s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.735, test=0.736) f1: (train=0.778, test=0.778) total time=   1.3s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.734, test=0.733) f1: (train=0.777, test=0.776) total time=   1.4s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.732) f1: (train=0.779, test=0.775) total time=   2.1s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.734, test=0.733) f1: (train=0.777, test=0.776) total time=   2.5s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.735, test=0.736) f1: (train=0.778, test=0.779) total time=   4.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.736, test=0.731) f1: (train=0.779, test=0.774) total time=   1.3s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.735, test=0.731) f1: (train=0.778, test=0.774) total time=   1.1s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.866, test=0.865) balanced_accuracy: (train=0.734, test=0.732) f1: (train=0.777, test=0.774) total time=   1.1s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.778, test=0.779) total time=   2.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.735, test=0.736) f1: (train=0.778, test=0.779) total time=   4.2s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.744, test=0.741) f1: (train=0.787, test=0.783) total time=   5.2s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.870, test=0.871) balanced_accuracy: (train=0.743, test=0.744) f1: (train=0.786, test=0.787) total time=   5.3s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.870, test=0.870) balanced_accuracy: (train=0.743, test=0.743) f1: (train=0.785, test=0.785) total time=   8.3s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.870, test=0.871) balanced_accuracy: (train=0.742, test=0.743) f1: (train=0.785, test=0.787) total time=  16.3s\n",
      "[CV 2/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.731) f1: (train=0.778, test=0.774) total time=   1.3s\n",
      "[CV 3/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.734, test=0.736) f1: (train=0.777, test=0.779) total time=   1.4s\n",
      "[CV 4/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.777) total time=   2.1s\n",
      "[CV 3/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.734, test=0.737) f1: (train=0.777, test=0.780) total time=   2.2s\n",
      "[CV 2/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.732) f1: (train=0.778, test=0.775) total time=   4.4s\n",
      "[CV 5/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.736, test=0.735) f1: (train=0.778, test=0.778) total time=   1.3s\n",
      "[CV 2/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.865) balanced_accuracy: (train=0.735, test=0.731) f1: (train=0.778, test=0.773) total time=   1.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.867, test=0.869) balanced_accuracy: (train=0.733, test=0.737) f1: (train=0.777, test=0.780) total time=   2.1s\n",
      "[CV 4/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.777) total time=   4.4s\n",
      "[CV 1/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.744, test=0.741) f1: (train=0.787, test=0.783) total time=   6.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.785, test=0.783) total time=   6.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.871, test=0.868) balanced_accuracy: (train=0.743, test=0.738) f1: (train=0.786, test=0.781) total time=  10.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.783) total time=  18.3s\n",
      "[CV 4/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.866, test=0.865) balanced_accuracy: (train=0.734, test=0.732) f1: (train=0.777, test=0.774) total time=   1.3s\n",
      "[CV 2/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.867, test=0.865) balanced_accuracy: (train=0.735, test=0.731) f1: (train=0.778, test=0.774) total time=   2.1s\n",
      "[CV 2/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.735, test=0.731) f1: (train=0.778, test=0.774) total time=   4.7s\n",
      "[CV 4/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.779, test=0.777) total time=   4.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.777) total time=   2.1s\n",
      "[CV 2/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.735, test=0.731) f1: (train=0.778, test=0.774) total time=   4.8s\n",
      "[CV 3/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.871, test=0.871) balanced_accuracy: (train=0.743, test=0.744) f1: (train=0.786, test=0.787) total time=   5.7s\n",
      "[CV 5/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.870, test=0.870) balanced_accuracy: (train=0.743, test=0.742) f1: (train=0.785, test=0.785) total time=   5.5s\n",
      "[CV 2/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.871, test=0.868) balanced_accuracy: (train=0.743, test=0.738) f1: (train=0.786, test=0.781) total time=   9.5s\n",
      "[CV 4/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.783) total time=  17.2s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.735, test=0.731) f1: (train=0.778, test=0.774) total time=   1.4s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.734, test=0.738) f1: (train=0.777, test=0.781) total time=   2.3s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.735, test=0.730) f1: (train=0.778, test=0.773) total time=   2.3s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.776) total time=   4.2s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.777, test=0.776) total time=   1.5s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.777) total time=   1.3s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.866, test=0.865) balanced_accuracy: (train=0.734, test=0.732) f1: (train=0.777, test=0.774) total time=   1.3s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.734, test=0.733) f1: (train=0.777, test=0.776) total time=   1.7s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.735, test=0.731) f1: (train=0.778, test=0.775) total time=   4.1s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.870, test=0.870) balanced_accuracy: (train=0.743, test=0.742) f1: (train=0.786, test=0.785) total time=   5.4s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.744, test=0.740) f1: (train=0.786, test=0.783) total time=   8.9s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.870, test=0.870) balanced_accuracy: (train=0.742, test=0.742) f1: (train=0.785, test=0.785) total time=   8.7s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.871, test=0.868) balanced_accuracy: (train=0.742, test=0.738) f1: (train=0.785, test=0.781) total time=  16.1s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.778, test=0.776) total time=   2.4s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.867, test=0.869) balanced_accuracy: (train=0.734, test=0.737) f1: (train=0.777, test=0.780) total time=   4.1s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.865) balanced_accuracy: (train=0.736, test=0.732) f1: (train=0.778, test=0.774) total time=   1.4s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.734, test=0.733) f1: (train=0.778, test=0.777) total time=   1.4s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.867, test=0.865) balanced_accuracy: (train=0.736, test=0.731) f1: (train=0.779, test=0.774) total time=   2.1s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.734, test=0.732) f1: (train=0.777, test=0.775) total time=   2.1s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.778, test=0.779) total time=   4.5s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.870, test=0.871) balanced_accuracy: (train=0.742, test=0.744) f1: (train=0.785, test=0.787) total time=   5.6s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.870, test=0.871) balanced_accuracy: (train=0.742, test=0.743) f1: (train=0.785, test=0.786) total time=   9.1s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.785, test=0.783) total time=   8.4s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.785, test=0.782) total time=  18.1s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.734, test=0.737) f1: (train=0.777, test=0.781) total time=   2.2s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.867, test=0.865) balanced_accuracy: (train=0.735, test=0.731) f1: (train=0.778, test=0.774) total time=   2.3s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.732) f1: (train=0.778, test=0.775) total time=   4.4s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.777) total time=   1.4s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.866, test=0.865) balanced_accuracy: (train=0.734, test=0.732) f1: (train=0.777, test=0.774) total time=   1.4s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.778, test=0.779) total time=   2.2s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.867, test=0.869) balanced_accuracy: (train=0.734, test=0.737) f1: (train=0.777, test=0.780) total time=   4.5s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.741) f1: (train=0.786, test=0.783) total time=   6.1s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.744, test=0.741) f1: (train=0.787, test=0.783) total time=   9.1s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.870, test=0.871) balanced_accuracy: (train=0.742, test=0.743) f1: (train=0.785, test=0.786) total time=   9.5s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.871, test=0.868) balanced_accuracy: (train=0.742, test=0.737) f1: (train=0.785, test=0.780) total time=  14.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.735) f1: (train=0.778, test=0.777) total time=   1.2s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.735, test=0.731) f1: (train=0.778, test=0.774) total time=   1.3s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.734, test=0.737) f1: (train=0.777, test=0.780) total time=   1.2s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.735, test=0.735) f1: (train=0.778, test=0.778) total time=   2.4s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.734, test=0.733) f1: (train=0.777, test=0.776) total time=   2.3s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.735, test=0.731) f1: (train=0.778, test=0.775) total time=   4.1s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.736, test=0.738) f1: (train=0.778, test=0.781) total time=   1.1s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.732, test=0.736) f1: (train=0.776, test=0.779) total time=   1.3s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.732) f1: (train=0.779, test=0.775) total time=   2.1s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.734, test=0.733) f1: (train=0.777, test=0.776) total time=   2.1s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.777) total time=   3.9s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.871, test=0.868) balanced_accuracy: (train=0.742, test=0.738) f1: (train=0.785, test=0.781) total time=   5.1s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.742, test=0.741) f1: (train=0.785, test=0.783) total time=   8.9s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.870, test=0.871) balanced_accuracy: (train=0.742, test=0.743) f1: (train=0.785, test=0.786) total time=  16.1s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.870, test=0.870) balanced_accuracy: (train=0.742, test=0.742) f1: (train=0.785, test=0.785) total time=  15.5s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.777) total time=   1.3s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.865) balanced_accuracy: (train=0.735, test=0.731) f1: (train=0.778, test=0.773) total time=   1.3s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.777) total time=   2.3s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.778, test=0.776) total time=   3.5s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.734, test=0.737) f1: (train=0.777, test=0.780) total time=   4.2s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.871, test=0.870) balanced_accuracy: (train=0.743, test=0.743) f1: (train=0.786, test=0.785) total time=   5.7s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.871, test=0.868) balanced_accuracy: (train=0.742, test=0.738) f1: (train=0.786, test=0.781) total time=  10.3s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.871, test=0.868) balanced_accuracy: (train=0.742, test=0.737) f1: (train=0.785, test=0.780) total time=  19.9s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.736, test=0.735) f1: (train=0.778, test=0.778) total time=   1.8s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.776) total time=   1.4s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.867, test=0.865) balanced_accuracy: (train=0.736, test=0.731) f1: (train=0.779, test=0.774) total time=   2.7s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.778, test=0.776) total time=   2.2s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.777) total time=   4.3s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.734, test=0.737) f1: (train=0.777, test=0.780) total time=   1.2s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.778, test=0.778) total time=   1.4s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.734, test=0.737) f1: (train=0.777, test=0.781) total time=   2.3s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.777, test=0.778) total time=   1.6s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.867, test=0.868) balanced_accuracy: (train=0.734, test=0.735) f1: (train=0.778, test=0.779) total time=   4.2s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.871, test=0.868) balanced_accuracy: (train=0.742, test=0.737) f1: (train=0.785, test=0.780) total time=   5.9s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.870, test=0.871) balanced_accuracy: (train=0.742, test=0.743) f1: (train=0.785, test=0.786) total time=   9.0s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.744, test=0.740) f1: (train=0.786, test=0.783) total time=  17.1s\n"
     ]
    }
   ],
   "source": [
    "my_model = best_dtc\n",
    "my_model.fit(train_data, np.ravel(y_train))\n",
    "my_model.score(test_data, np.ravel(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b587ca52",
   "metadata": {},
   "source": [
    "EXTRA TREE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "594e3215",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "47a73cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "column = ['criterion','max_features', 'n_estimators', 'random_state', 'accuracy']\n",
    "column_bar = ['try', 'Parameter_changed', 'Accuracy']\n",
    "\n",
    "### Create a single row equivalent to a single try for decision tree\n",
    "def create_bar_row(criterion,feature, stimatori,random, attempt, parameter):\n",
    "  xt = ExtraTreesClassifier(criterion=criterion,max_features=feature,n_estimators=stimatori, random_state=random, n_jobs=-1 )\n",
    "  xt.fit(train_data, np.ravel(y_train))\n",
    "  testset_score = xt.score(test_data, y_test)\n",
    "  row = pd.DataFrame(data=[[attempt, parameter, testset_score]], columns=column_bar)\n",
    "  return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5ae9c61a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  try Parameter_changed  Accuracy\n",
      "0   1             start  0.857587\n",
      "0   1      max_features  0.857587\n",
      "0   1       n_estimator  0.858556\n",
      "0   1      random_state  0.858902\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'Score sul testset durante il tuning dei parametri'}, xlabel='Accuracy', ylabel='Parameter_changed'>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.DataFrame(columns=column_bar)\n",
    "df = pd.concat([df, create_bar_row('gini', 'log2', 20, 4, 1, 'start')]) # try 1\n",
    "df = pd.concat([df, create_bar_row('gini', 'sqrt', 20, 4, 1, 'max_features')]) # try 2\n",
    "df = pd.concat([df, create_bar_row('gini', 'sqrt', 120, 4, 1, 'n_estimator')]) # try 3\n",
    "df = pd.concat([df, create_bar_row('gini', 'log2', 120, 30, 1, 'random_state')]) # try 1\n",
    "\n",
    "print(df)\n",
    "\n",
    "fig, axs = plt.subplots()\n",
    "axs.set_xlim([0.70,0.89])\n",
    "axs.set_title(\"Score sul testset durante il tuning dei parametri\")\n",
    "\n",
    "sns.barplot(data=df, x='Accuracy',y=\"Parameter_changed\",ax=axs, orient=\"h\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "4b44ba0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 36 candidates, totalling 360 fits\n",
      "[CV 1/10] END criterion=gini, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.741) f1: (train=1.000, test=0.775) total time=   2.2s\n",
      "[CV 2/10] END criterion=gini, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.744) f1: (train=1.000, test=0.777) total time=   1.2s\n",
      "[CV 3/10] END criterion=gini, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.742) f1: (train=1.000, test=0.776) total time=   1.1s\n",
      "[CV 4/10] END criterion=gini, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.856) balanced_accuracy: (train=1.000, test=0.737) f1: (train=1.000, test=0.771) total time=   1.2s\n",
      "[CV 5/10] END criterion=gini, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.743) f1: (train=1.000, test=0.776) total time=   1.1s\n",
      "[CV 6/10] END criterion=gini, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.748) f1: (train=1.000, test=0.782) total time=   1.2s\n",
      "[CV 7/10] END criterion=gini, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.742) f1: (train=1.000, test=0.775) total time=   1.1s\n",
      "[CV 8/10] END criterion=gini, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.861) balanced_accuracy: (train=1.000, test=0.748) f1: (train=1.000, test=0.782) total time=   1.2s\n",
      "[CV 9/10] END criterion=gini, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.741) f1: (train=1.000, test=0.776) total time=   1.1s\n",
      "[CV 10/10] END criterion=gini, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.753) f1: (train=1.000, test=0.786) total time=   1.2s\n",
      "[CV 1/10] END criterion=gini, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.741) f1: (train=1.000, test=0.776) total time=   1.1s\n",
      "[CV 2/10] END criterion=gini, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.743) f1: (train=1.000, test=0.776) total time=   1.2s\n",
      "[CV 3/10] END criterion=gini, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.741) f1: (train=1.000, test=0.775) total time=   1.1s\n",
      "[CV 4/10] END criterion=gini, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.856) balanced_accuracy: (train=1.000, test=0.737) f1: (train=1.000, test=0.771) total time=   1.1s\n",
      "[CV 5/10] END criterion=gini, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.744) f1: (train=1.000, test=0.777) total time=   1.1s\n",
      "[CV 6/10] END criterion=gini, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.748) f1: (train=1.000, test=0.783) total time=   1.1s\n",
      "[CV 7/10] END criterion=gini, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.856) balanced_accuracy: (train=1.000, test=0.740) f1: (train=1.000, test=0.774) total time=   1.1s\n",
      "[CV 8/10] END criterion=gini, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.860) balanced_accuracy: (train=1.000, test=0.746) f1: (train=1.000, test=0.780) total time=   1.2s\n",
      "[CV 9/10] END criterion=gini, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.741) f1: (train=1.000, test=0.775) total time=   1.2s\n",
      "[CV 10/10] END criterion=gini, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.861) balanced_accuracy: (train=1.000, test=0.750) f1: (train=1.000, test=0.783) total time=   1.1s\n",
      "[CV 1/10] END criterion=gini, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.740) f1: (train=1.000, test=0.774) total time=   1.1s\n",
      "[CV 2/10] END criterion=gini, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.744) f1: (train=1.000, test=0.777) total time=   1.2s\n",
      "[CV 3/10] END criterion=gini, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.741) f1: (train=1.000, test=0.775) total time=   1.1s\n",
      "[CV 4/10] END criterion=gini, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.856) balanced_accuracy: (train=1.000, test=0.738) f1: (train=1.000, test=0.772) total time=   1.1s\n",
      "[CV 5/10] END criterion=gini, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.746) f1: (train=1.000, test=0.779) total time=   1.1s\n",
      "[CV 6/10] END criterion=gini, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.861) balanced_accuracy: (train=1.000, test=0.747) f1: (train=1.000, test=0.781) total time=   1.1s\n",
      "[CV 7/10] END criterion=gini, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.740) f1: (train=1.000, test=0.773) total time=   1.2s\n",
      "[CV 8/10] END criterion=gini, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.860) balanced_accuracy: (train=1.000, test=0.746) f1: (train=1.000, test=0.779) total time=   1.2s\n",
      "[CV 9/10] END criterion=gini, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.742) f1: (train=1.000, test=0.776) total time=   1.2s\n",
      "[CV 10/10] END criterion=gini, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.863) balanced_accuracy: (train=1.000, test=0.753) f1: (train=1.000, test=0.786) total time=   1.1s\n",
      "[CV 1/10] END criterion=gini, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.741) f1: (train=1.000, test=0.776) total time=   2.0s\n",
      "[CV 2/10] END criterion=gini, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.743) f1: (train=1.000, test=0.777) total time=   2.0s\n",
      "[CV 3/10] END criterion=gini, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.740) f1: (train=1.000, test=0.774) total time=   2.0s\n",
      "[CV 4/10] END criterion=gini, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.856) balanced_accuracy: (train=1.000, test=0.738) f1: (train=1.000, test=0.772) total time=   2.1s\n",
      "[CV 5/10] END criterion=gini, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.745) f1: (train=1.000, test=0.777) total time=   2.1s\n",
      "[CV 6/10] END criterion=gini, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.864) balanced_accuracy: (train=1.000, test=0.750) f1: (train=1.000, test=0.785) total time=   2.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 7/10] END criterion=gini, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.742) f1: (train=1.000, test=0.775) total time=   2.0s\n",
      "[CV 8/10] END criterion=gini, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.861) balanced_accuracy: (train=1.000, test=0.747) f1: (train=1.000, test=0.782) total time=   2.1s\n",
      "[CV 9/10] END criterion=gini, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.860) balanced_accuracy: (train=1.000, test=0.744) f1: (train=1.000, test=0.778) total time=   2.1s\n",
      "[CV 10/10] END criterion=gini, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.863) balanced_accuracy: (train=1.000, test=0.753) f1: (train=1.000, test=0.786) total time=   2.1s\n",
      "[CV 1/10] END criterion=gini, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.743) f1: (train=1.000, test=0.777) total time=   2.1s\n",
      "[CV 2/10] END criterion=gini, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.742) f1: (train=1.000, test=0.776) total time=   2.2s\n",
      "[CV 3/10] END criterion=gini, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.742) f1: (train=1.000, test=0.776) total time=   2.1s\n",
      "[CV 4/10] END criterion=gini, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.856) balanced_accuracy: (train=1.000, test=0.738) f1: (train=1.000, test=0.772) total time=   2.0s\n",
      "[CV 5/10] END criterion=gini, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.745) f1: (train=1.000, test=0.778) total time=   2.1s\n",
      "[CV 6/10] END criterion=gini, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.863) balanced_accuracy: (train=1.000, test=0.749) f1: (train=1.000, test=0.783) total time=   2.1s\n",
      "[CV 7/10] END criterion=gini, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.741) f1: (train=1.000, test=0.775) total time=   2.1s\n",
      "[CV 8/10] END criterion=gini, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.861) balanced_accuracy: (train=1.000, test=0.747) f1: (train=1.000, test=0.781) total time=   2.1s\n",
      "[CV 9/10] END criterion=gini, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.741) f1: (train=1.000, test=0.775) total time=   2.0s\n",
      "[CV 10/10] END criterion=gini, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.863) balanced_accuracy: (train=1.000, test=0.754) f1: (train=1.000, test=0.787) total time=   2.1s\n",
      "[CV 1/10] END criterion=gini, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.860) balanced_accuracy: (train=1.000, test=0.741) f1: (train=1.000, test=0.776) total time=   2.1s\n",
      "[CV 2/10] END criterion=gini, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.744) f1: (train=1.000, test=0.777) total time=   2.0s\n",
      "[CV 3/10] END criterion=gini, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.856) balanced_accuracy: (train=1.000, test=0.740) f1: (train=1.000, test=0.773) total time=   2.1s\n",
      "[CV 4/10] END criterion=gini, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.855) balanced_accuracy: (train=1.000, test=0.736) f1: (train=1.000, test=0.769) total time=   2.2s\n",
      "[CV 5/10] END criterion=gini, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.745) f1: (train=1.000, test=0.777) total time=   2.0s\n",
      "[CV 6/10] END criterion=gini, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.863) balanced_accuracy: (train=1.000, test=0.747) f1: (train=1.000, test=0.782) total time=   2.1s\n",
      "[CV 7/10] END criterion=gini, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.741) f1: (train=1.000, test=0.774) total time=   2.1s\n",
      "[CV 8/10] END criterion=gini, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.861) balanced_accuracy: (train=1.000, test=0.746) f1: (train=1.000, test=0.781) total time=   2.1s\n",
      "[CV 9/10] END criterion=gini, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.741) f1: (train=1.000, test=0.776) total time=   2.1s\n",
      "[CV 10/10] END criterion=gini, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.864) balanced_accuracy: (train=1.000, test=0.753) f1: (train=1.000, test=0.787) total time=   2.2s\n",
      "[CV 1/10] END criterion=gini, max_features=log2, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.741) f1: (train=1.000, test=0.775) total time=   1.2s\n",
      "[CV 2/10] END criterion=gini, max_features=log2, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.744) f1: (train=1.000, test=0.777) total time=   1.2s\n",
      "[CV 3/10] END criterion=gini, max_features=log2, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.742) f1: (train=1.000, test=0.776) total time=   1.2s\n",
      "[CV 4/10] END criterion=gini, max_features=log2, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.856) balanced_accuracy: (train=1.000, test=0.737) f1: (train=1.000, test=0.771) total time=   1.2s\n",
      "[CV 5/10] END criterion=gini, max_features=log2, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.743) f1: (train=1.000, test=0.776) total time=   1.2s\n",
      "[CV 6/10] END criterion=gini, max_features=log2, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.748) f1: (train=1.000, test=0.782) total time=   1.2s\n",
      "[CV 7/10] END criterion=gini, max_features=log2, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.742) f1: (train=1.000, test=0.775) total time=   1.2s\n",
      "[CV 8/10] END criterion=gini, max_features=log2, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.861) balanced_accuracy: (train=1.000, test=0.748) f1: (train=1.000, test=0.782) total time=   1.1s\n",
      "[CV 9/10] END criterion=gini, max_features=log2, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.741) f1: (train=1.000, test=0.776) total time=   1.1s\n",
      "[CV 10/10] END criterion=gini, max_features=log2, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.753) f1: (train=1.000, test=0.786) total time=   1.1s\n",
      "[CV 1/10] END criterion=gini, max_features=log2, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.741) f1: (train=1.000, test=0.776) total time=   1.2s\n",
      "[CV 2/10] END criterion=gini, max_features=log2, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.743) f1: (train=1.000, test=0.776) total time=   1.1s\n",
      "[CV 3/10] END criterion=gini, max_features=log2, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.741) f1: (train=1.000, test=0.775) total time=   1.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/10] END criterion=gini, max_features=log2, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.856) balanced_accuracy: (train=1.000, test=0.737) f1: (train=1.000, test=0.771) total time=   1.1s\n",
      "[CV 5/10] END criterion=gini, max_features=log2, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.744) f1: (train=1.000, test=0.777) total time=   1.1s\n",
      "[CV 6/10] END criterion=gini, max_features=log2, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.748) f1: (train=1.000, test=0.783) total time=   1.1s\n",
      "[CV 7/10] END criterion=gini, max_features=log2, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.856) balanced_accuracy: (train=1.000, test=0.740) f1: (train=1.000, test=0.774) total time=   1.1s\n",
      "[CV 8/10] END criterion=gini, max_features=log2, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.860) balanced_accuracy: (train=1.000, test=0.746) f1: (train=1.000, test=0.780) total time=   1.2s\n",
      "[CV 9/10] END criterion=gini, max_features=log2, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.741) f1: (train=1.000, test=0.775) total time=   1.1s\n",
      "[CV 10/10] END criterion=gini, max_features=log2, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.861) balanced_accuracy: (train=1.000, test=0.750) f1: (train=1.000, test=0.783) total time=   1.1s\n",
      "[CV 1/10] END criterion=gini, max_features=log2, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.742) f1: (train=1.000, test=0.776) total time=   1.1s\n",
      "[CV 2/10] END criterion=gini, max_features=log2, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.745) f1: (train=1.000, test=0.778) total time=   1.2s\n",
      "[CV 3/10] END criterion=gini, max_features=log2, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.741) f1: (train=1.000, test=0.775) total time=   1.1s\n",
      "[CV 4/10] END criterion=gini, max_features=log2, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.855) balanced_accuracy: (train=1.000, test=0.735) f1: (train=1.000, test=0.769) total time=   1.1s\n",
      "[CV 5/10] END criterion=gini, max_features=log2, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.745) f1: (train=1.000, test=0.778) total time=   1.1s\n",
      "[CV 6/10] END criterion=gini, max_features=log2, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.749) f1: (train=1.000, test=0.783) total time=   1.1s\n",
      "[CV 7/10] END criterion=gini, max_features=log2, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.742) f1: (train=1.000, test=0.775) total time=   1.1s\n",
      "[CV 8/10] END criterion=gini, max_features=log2, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.861) balanced_accuracy: (train=1.000, test=0.746) f1: (train=1.000, test=0.780) total time=   1.1s\n",
      "[CV 9/10] END criterion=gini, max_features=log2, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.743) f1: (train=1.000, test=0.777) total time=   1.1s\n",
      "[CV 10/10] END criterion=gini, max_features=log2, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.863) balanced_accuracy: (train=1.000, test=0.752) f1: (train=1.000, test=0.785) total time=   1.1s\n",
      "[CV 1/10] END criterion=gini, max_features=log2, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.741) f1: (train=1.000, test=0.776) total time=   2.0s\n",
      "[CV 2/10] END criterion=gini, max_features=log2, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.743) f1: (train=1.000, test=0.777) total time=   2.1s\n",
      "[CV 3/10] END criterion=gini, max_features=log2, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.740) f1: (train=1.000, test=0.774) total time=   2.0s\n",
      "[CV 4/10] END criterion=gini, max_features=log2, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.856) balanced_accuracy: (train=1.000, test=0.738) f1: (train=1.000, test=0.772) total time=   2.1s\n",
      "[CV 5/10] END criterion=gini, max_features=log2, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.745) f1: (train=1.000, test=0.777) total time=   2.1s\n",
      "[CV 6/10] END criterion=gini, max_features=log2, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.864) balanced_accuracy: (train=1.000, test=0.750) f1: (train=1.000, test=0.785) total time=   2.0s\n",
      "[CV 7/10] END criterion=gini, max_features=log2, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.742) f1: (train=1.000, test=0.775) total time=   2.0s\n",
      "[CV 8/10] END criterion=gini, max_features=log2, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.861) balanced_accuracy: (train=1.000, test=0.747) f1: (train=1.000, test=0.782) total time=   2.1s\n",
      "[CV 9/10] END criterion=gini, max_features=log2, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.860) balanced_accuracy: (train=1.000, test=0.744) f1: (train=1.000, test=0.778) total time=   2.0s\n",
      "[CV 10/10] END criterion=gini, max_features=log2, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.863) balanced_accuracy: (train=1.000, test=0.753) f1: (train=1.000, test=0.786) total time=   2.0s\n",
      "[CV 1/10] END criterion=gini, max_features=log2, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.743) f1: (train=1.000, test=0.777) total time=   2.0s\n",
      "[CV 2/10] END criterion=gini, max_features=log2, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.742) f1: (train=1.000, test=0.776) total time=   2.1s\n",
      "[CV 3/10] END criterion=gini, max_features=log2, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.742) f1: (train=1.000, test=0.776) total time=   2.0s\n",
      "[CV 4/10] END criterion=gini, max_features=log2, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.856) balanced_accuracy: (train=1.000, test=0.738) f1: (train=1.000, test=0.772) total time=   2.0s\n",
      "[CV 5/10] END criterion=gini, max_features=log2, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.745) f1: (train=1.000, test=0.778) total time=   2.0s\n",
      "[CV 6/10] END criterion=gini, max_features=log2, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.863) balanced_accuracy: (train=1.000, test=0.749) f1: (train=1.000, test=0.783) total time=   2.0s\n",
      "[CV 7/10] END criterion=gini, max_features=log2, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.741) f1: (train=1.000, test=0.775) total time=   2.0s\n",
      "[CV 8/10] END criterion=gini, max_features=log2, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.861) balanced_accuracy: (train=1.000, test=0.747) f1: (train=1.000, test=0.781) total time=   2.0s\n",
      "[CV 9/10] END criterion=gini, max_features=log2, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.741) f1: (train=1.000, test=0.775) total time=   2.0s\n",
      "[CV 10/10] END criterion=gini, max_features=log2, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.863) balanced_accuracy: (train=1.000, test=0.754) f1: (train=1.000, test=0.787) total time=   2.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/10] END criterion=gini, max_features=log2, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.741) f1: (train=1.000, test=0.775) total time=   2.1s\n",
      "[CV 2/10] END criterion=gini, max_features=log2, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.741) f1: (train=1.000, test=0.775) total time=   2.0s\n",
      "[CV 3/10] END criterion=gini, max_features=log2, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.742) f1: (train=1.000, test=0.776) total time=   2.1s\n",
      "[CV 4/10] END criterion=gini, max_features=log2, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.855) balanced_accuracy: (train=1.000, test=0.736) f1: (train=1.000, test=0.770) total time=   2.0s\n",
      "[CV 5/10] END criterion=gini, max_features=log2, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.744) f1: (train=1.000, test=0.777) total time=   2.0s\n",
      "[CV 6/10] END criterion=gini, max_features=log2, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.863) balanced_accuracy: (train=1.000, test=0.749) f1: (train=1.000, test=0.784) total time=   2.1s\n",
      "[CV 7/10] END criterion=gini, max_features=log2, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.856) balanced_accuracy: (train=1.000, test=0.740) f1: (train=1.000, test=0.773) total time=   2.1s\n",
      "[CV 8/10] END criterion=gini, max_features=log2, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.748) f1: (train=1.000, test=0.783) total time=   2.0s\n",
      "[CV 9/10] END criterion=gini, max_features=log2, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.742) f1: (train=1.000, test=0.776) total time=   2.1s\n",
      "[CV 10/10] END criterion=gini, max_features=log2, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.864) balanced_accuracy: (train=1.000, test=0.754) f1: (train=1.000, test=0.788) total time=   2.0s\n",
      "[CV 1/10] END criterion=entropy, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.741) f1: (train=1.000, test=0.776) total time=   1.1s\n",
      "[CV 2/10] END criterion=entropy, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.856) balanced_accuracy: (train=1.000, test=0.741) f1: (train=1.000, test=0.774) total time=   1.1s\n",
      "[CV 3/10] END criterion=entropy, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.740) f1: (train=1.000, test=0.774) total time=   1.1s\n",
      "[CV 4/10] END criterion=entropy, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.855) balanced_accuracy: (train=1.000, test=0.736) f1: (train=1.000, test=0.770) total time=   1.1s\n",
      "[CV 5/10] END criterion=entropy, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.743) f1: (train=1.000, test=0.776) total time=   1.2s\n",
      "[CV 6/10] END criterion=entropy, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.747) f1: (train=1.000, test=0.782) total time=   1.2s\n",
      "[CV 7/10] END criterion=entropy, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.856) balanced_accuracy: (train=1.000, test=0.741) f1: (train=1.000, test=0.774) total time=   1.1s\n",
      "[CV 8/10] END criterion=entropy, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.860) balanced_accuracy: (train=1.000, test=0.745) f1: (train=1.000, test=0.778) total time=   1.1s\n",
      "[CV 9/10] END criterion=entropy, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.742) f1: (train=1.000, test=0.777) total time=   1.1s\n",
      "[CV 10/10] END criterion=entropy, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.752) f1: (train=1.000, test=0.785) total time=   1.2s\n",
      "[CV 1/10] END criterion=entropy, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.860) balanced_accuracy: (train=1.000, test=0.743) f1: (train=1.000, test=0.778) total time=   1.1s\n",
      "[CV 2/10] END criterion=entropy, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.742) f1: (train=1.000, test=0.775) total time=   1.1s\n",
      "[CV 3/10] END criterion=entropy, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.741) f1: (train=1.000, test=0.775) total time=   1.1s\n",
      "[CV 4/10] END criterion=entropy, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.855) balanced_accuracy: (train=1.000, test=0.735) f1: (train=1.000, test=0.769) total time=   1.1s\n",
      "[CV 5/10] END criterion=entropy, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.745) f1: (train=1.000, test=0.778) total time=   1.1s\n",
      "[CV 6/10] END criterion=entropy, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.861) balanced_accuracy: (train=1.000, test=0.746) f1: (train=1.000, test=0.781) total time=   1.1s\n",
      "[CV 7/10] END criterion=entropy, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.743) f1: (train=1.000, test=0.777) total time=   1.2s\n",
      "[CV 8/10] END criterion=entropy, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.861) balanced_accuracy: (train=1.000, test=0.746) f1: (train=1.000, test=0.780) total time=   1.1s\n",
      "[CV 9/10] END criterion=entropy, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.741) f1: (train=1.000, test=0.776) total time=   1.1s\n",
      "[CV 10/10] END criterion=entropy, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.863) balanced_accuracy: (train=1.000, test=0.753) f1: (train=1.000, test=0.786) total time=   1.1s\n",
      "[CV 1/10] END criterion=entropy, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.741) f1: (train=1.000, test=0.775) total time=   1.2s\n",
      "[CV 2/10] END criterion=entropy, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.742) f1: (train=1.000, test=0.775) total time=   1.1s\n",
      "[CV 3/10] END criterion=entropy, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.740) f1: (train=1.000, test=0.774) total time=   1.1s\n",
      "[CV 4/10] END criterion=entropy, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.855) balanced_accuracy: (train=1.000, test=0.735) f1: (train=1.000, test=0.769) total time=   1.2s\n",
      "[CV 5/10] END criterion=entropy, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.860) balanced_accuracy: (train=1.000, test=0.747) f1: (train=1.000, test=0.781) total time=   1.1s\n",
      "[CV 6/10] END criterion=entropy, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.863) balanced_accuracy: (train=1.000, test=0.749) f1: (train=1.000, test=0.784) total time=   1.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 7/10] END criterion=entropy, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.742) f1: (train=1.000, test=0.775) total time=   1.1s\n",
      "[CV 8/10] END criterion=entropy, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.860) balanced_accuracy: (train=1.000, test=0.745) f1: (train=1.000, test=0.779) total time=   1.2s\n",
      "[CV 9/10] END criterion=entropy, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.860) balanced_accuracy: (train=1.000, test=0.743) f1: (train=1.000, test=0.778) total time=   1.2s\n",
      "[CV 10/10] END criterion=entropy, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.863) balanced_accuracy: (train=1.000, test=0.752) f1: (train=1.000, test=0.786) total time=   1.1s\n",
      "[CV 1/10] END criterion=entropy, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.741) f1: (train=1.000, test=0.776) total time=   2.1s\n",
      "[CV 2/10] END criterion=entropy, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.742) f1: (train=1.000, test=0.775) total time=   2.1s\n",
      "[CV 3/10] END criterion=entropy, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.740) f1: (train=1.000, test=0.774) total time=   2.1s\n",
      "[CV 4/10] END criterion=entropy, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.856) balanced_accuracy: (train=1.000, test=0.738) f1: (train=1.000, test=0.772) total time=   2.1s\n",
      "[CV 5/10] END criterion=entropy, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.745) f1: (train=1.000, test=0.778) total time=   2.2s\n",
      "[CV 6/10] END criterion=entropy, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.747) f1: (train=1.000, test=0.781) total time=   2.1s\n",
      "[CV 7/10] END criterion=entropy, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.743) f1: (train=1.000, test=0.776) total time=   2.1s\n",
      "[CV 8/10] END criterion=entropy, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.861) balanced_accuracy: (train=1.000, test=0.746) f1: (train=1.000, test=0.780) total time=   2.1s\n",
      "[CV 9/10] END criterion=entropy, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.860) balanced_accuracy: (train=1.000, test=0.743) f1: (train=1.000, test=0.778) total time=   2.1s\n",
      "[CV 10/10] END criterion=entropy, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.863) balanced_accuracy: (train=1.000, test=0.753) f1: (train=1.000, test=0.786) total time=   2.1s\n",
      "[CV 1/10] END criterion=entropy, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.860) balanced_accuracy: (train=1.000, test=0.744) f1: (train=1.000, test=0.778) total time=   2.2s\n",
      "[CV 2/10] END criterion=entropy, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.743) f1: (train=1.000, test=0.776) total time=   2.1s\n",
      "[CV 3/10] END criterion=entropy, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.741) f1: (train=1.000, test=0.776) total time=   2.2s\n",
      "[CV 4/10] END criterion=entropy, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.738) f1: (train=1.000, test=0.772) total time=   2.1s\n",
      "[CV 5/10] END criterion=entropy, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.744) f1: (train=1.000, test=0.777) total time=   2.1s\n",
      "[CV 6/10] END criterion=entropy, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.747) f1: (train=1.000, test=0.782) total time=   2.1s\n",
      "[CV 7/10] END criterion=entropy, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.741) f1: (train=1.000, test=0.775) total time=   2.2s\n",
      "[CV 8/10] END criterion=entropy, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.747) f1: (train=1.000, test=0.781) total time=   2.2s\n",
      "[CV 9/10] END criterion=entropy, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.741) f1: (train=1.000, test=0.776) total time=   2.1s\n",
      "[CV 10/10] END criterion=entropy, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.864) balanced_accuracy: (train=1.000, test=0.754) f1: (train=1.000, test=0.788) total time=   2.1s\n",
      "[CV 1/10] END criterion=entropy, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.741) f1: (train=1.000, test=0.776) total time=   2.1s\n",
      "[CV 2/10] END criterion=entropy, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.744) f1: (train=1.000, test=0.778) total time=   2.1s\n",
      "[CV 3/10] END criterion=entropy, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.740) f1: (train=1.000, test=0.774) total time=   2.2s\n",
      "[CV 4/10] END criterion=entropy, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.856) balanced_accuracy: (train=1.000, test=0.738) f1: (train=1.000, test=0.772) total time=   2.1s\n",
      "[CV 5/10] END criterion=entropy, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.745) f1: (train=1.000, test=0.777) total time=   2.1s\n",
      "[CV 6/10] END criterion=entropy, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.864) balanced_accuracy: (train=1.000, test=0.751) f1: (train=1.000, test=0.786) total time=   2.1s\n",
      "[CV 7/10] END criterion=entropy, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.742) f1: (train=1.000, test=0.775) total time=   2.2s\n",
      "[CV 8/10] END criterion=entropy, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.861) balanced_accuracy: (train=1.000, test=0.746) f1: (train=1.000, test=0.780) total time=   2.1s\n",
      "[CV 9/10] END criterion=entropy, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.860) balanced_accuracy: (train=1.000, test=0.744) f1: (train=1.000, test=0.778) total time=   2.2s\n",
      "[CV 10/10] END criterion=entropy, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.751) f1: (train=1.000, test=0.784) total time=   2.1s\n",
      "[CV 1/10] END criterion=entropy, max_features=log2, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.741) f1: (train=1.000, test=0.776) total time=   1.2s\n",
      "[CV 2/10] END criterion=entropy, max_features=log2, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.856) balanced_accuracy: (train=1.000, test=0.741) f1: (train=1.000, test=0.774) total time=   1.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/10] END criterion=entropy, max_features=log2, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.740) f1: (train=1.000, test=0.774) total time=   1.2s\n",
      "[CV 4/10] END criterion=entropy, max_features=log2, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.855) balanced_accuracy: (train=1.000, test=0.736) f1: (train=1.000, test=0.770) total time=   1.2s\n",
      "[CV 5/10] END criterion=entropy, max_features=log2, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.743) f1: (train=1.000, test=0.776) total time=   1.1s\n",
      "[CV 6/10] END criterion=entropy, max_features=log2, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.747) f1: (train=1.000, test=0.782) total time=   1.2s\n",
      "[CV 7/10] END criterion=entropy, max_features=log2, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.856) balanced_accuracy: (train=1.000, test=0.741) f1: (train=1.000, test=0.774) total time=   1.2s\n",
      "[CV 8/10] END criterion=entropy, max_features=log2, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.860) balanced_accuracy: (train=1.000, test=0.745) f1: (train=1.000, test=0.778) total time=   1.1s\n",
      "[CV 9/10] END criterion=entropy, max_features=log2, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.742) f1: (train=1.000, test=0.777) total time=   1.2s\n",
      "[CV 10/10] END criterion=entropy, max_features=log2, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.752) f1: (train=1.000, test=0.785) total time=   1.1s\n",
      "[CV 1/10] END criterion=entropy, max_features=log2, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.860) balanced_accuracy: (train=1.000, test=0.743) f1: (train=1.000, test=0.778) total time=   1.1s\n",
      "[CV 2/10] END criterion=entropy, max_features=log2, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.742) f1: (train=1.000, test=0.775) total time=   1.1s\n",
      "[CV 3/10] END criterion=entropy, max_features=log2, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.741) f1: (train=1.000, test=0.775) total time=   1.1s\n",
      "[CV 4/10] END criterion=entropy, max_features=log2, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.855) balanced_accuracy: (train=1.000, test=0.735) f1: (train=1.000, test=0.769) total time=   1.1s\n",
      "[CV 5/10] END criterion=entropy, max_features=log2, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.745) f1: (train=1.000, test=0.778) total time=   1.1s\n",
      "[CV 6/10] END criterion=entropy, max_features=log2, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.861) balanced_accuracy: (train=1.000, test=0.746) f1: (train=1.000, test=0.781) total time=   1.0s\n",
      "[CV 7/10] END criterion=entropy, max_features=log2, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.743) f1: (train=1.000, test=0.777) total time=   1.2s\n",
      "[CV 8/10] END criterion=entropy, max_features=log2, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.861) balanced_accuracy: (train=1.000, test=0.746) f1: (train=1.000, test=0.780) total time=   1.2s\n",
      "[CV 9/10] END criterion=entropy, max_features=log2, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.741) f1: (train=1.000, test=0.776) total time=   1.1s\n",
      "[CV 10/10] END criterion=entropy, max_features=log2, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.863) balanced_accuracy: (train=1.000, test=0.753) f1: (train=1.000, test=0.786) total time=   1.2s\n",
      "[CV 1/10] END criterion=entropy, max_features=log2, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.860) balanced_accuracy: (train=1.000, test=0.743) f1: (train=1.000, test=0.778) total time=   1.2s\n",
      "[CV 2/10] END criterion=entropy, max_features=log2, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.743) f1: (train=1.000, test=0.776) total time=   1.2s\n",
      "[CV 3/10] END criterion=entropy, max_features=log2, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.740) f1: (train=1.000, test=0.774) total time=   1.1s\n",
      "[CV 4/10] END criterion=entropy, max_features=log2, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.855) balanced_accuracy: (train=1.000, test=0.736) f1: (train=1.000, test=0.770) total time=   1.1s\n",
      "[CV 5/10] END criterion=entropy, max_features=log2, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.744) f1: (train=1.000, test=0.777) total time=   1.1s\n",
      "[CV 6/10] END criterion=entropy, max_features=log2, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.747) f1: (train=1.000, test=0.782) total time=   1.1s\n",
      "[CV 7/10] END criterion=entropy, max_features=log2, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.743) f1: (train=1.000, test=0.777) total time=   1.2s\n",
      "[CV 8/10] END criterion=entropy, max_features=log2, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.863) balanced_accuracy: (train=1.000, test=0.750) f1: (train=1.000, test=0.785) total time=   1.1s\n",
      "[CV 9/10] END criterion=entropy, max_features=log2, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.741) f1: (train=1.000, test=0.775) total time=   1.1s\n",
      "[CV 10/10] END criterion=entropy, max_features=log2, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.752) f1: (train=1.000, test=0.784) total time=   1.1s\n",
      "[CV 1/10] END criterion=entropy, max_features=log2, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.741) f1: (train=1.000, test=0.776) total time=   2.2s\n",
      "[CV 2/10] END criterion=entropy, max_features=log2, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.742) f1: (train=1.000, test=0.775) total time=   2.2s\n",
      "[CV 3/10] END criterion=entropy, max_features=log2, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.740) f1: (train=1.000, test=0.774) total time=   2.1s\n",
      "[CV 4/10] END criterion=entropy, max_features=log2, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.856) balanced_accuracy: (train=1.000, test=0.738) f1: (train=1.000, test=0.772) total time=   2.1s\n",
      "[CV 5/10] END criterion=entropy, max_features=log2, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.745) f1: (train=1.000, test=0.778) total time=   2.1s\n",
      "[CV 6/10] END criterion=entropy, max_features=log2, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.747) f1: (train=1.000, test=0.781) total time=   2.2s\n",
      "[CV 7/10] END criterion=entropy, max_features=log2, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.743) f1: (train=1.000, test=0.776) total time=   2.2s\n",
      "[CV 8/10] END criterion=entropy, max_features=log2, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.861) balanced_accuracy: (train=1.000, test=0.746) f1: (train=1.000, test=0.780) total time=   2.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 9/10] END criterion=entropy, max_features=log2, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.860) balanced_accuracy: (train=1.000, test=0.743) f1: (train=1.000, test=0.778) total time=   2.1s\n",
      "[CV 10/10] END criterion=entropy, max_features=log2, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.863) balanced_accuracy: (train=1.000, test=0.753) f1: (train=1.000, test=0.786) total time=   2.4s\n",
      "[CV 1/10] END criterion=entropy, max_features=log2, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.860) balanced_accuracy: (train=1.000, test=0.744) f1: (train=1.000, test=0.778) total time=   2.1s\n",
      "[CV 2/10] END criterion=entropy, max_features=log2, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.743) f1: (train=1.000, test=0.776) total time=   2.1s\n",
      "[CV 3/10] END criterion=entropy, max_features=log2, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.741) f1: (train=1.000, test=0.776) total time=   2.2s\n",
      "[CV 4/10] END criterion=entropy, max_features=log2, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.738) f1: (train=1.000, test=0.772) total time=   2.1s\n",
      "[CV 5/10] END criterion=entropy, max_features=log2, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.744) f1: (train=1.000, test=0.777) total time=   2.1s\n",
      "[CV 6/10] END criterion=entropy, max_features=log2, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.747) f1: (train=1.000, test=0.782) total time=   2.2s\n",
      "[CV 7/10] END criterion=entropy, max_features=log2, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.741) f1: (train=1.000, test=0.775) total time=   2.2s\n",
      "[CV 8/10] END criterion=entropy, max_features=log2, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.747) f1: (train=1.000, test=0.781) total time=   2.1s\n",
      "[CV 9/10] END criterion=entropy, max_features=log2, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.741) f1: (train=1.000, test=0.776) total time=   2.2s\n",
      "[CV 10/10] END criterion=entropy, max_features=log2, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.864) balanced_accuracy: (train=1.000, test=0.754) f1: (train=1.000, test=0.788) total time=   2.2s\n",
      "[CV 1/10] END criterion=entropy, max_features=log2, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.742) f1: (train=1.000, test=0.776) total time=   2.1s\n",
      "[CV 2/10] END criterion=entropy, max_features=log2, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.742) f1: (train=1.000, test=0.776) total time=   2.1s\n",
      "[CV 3/10] END criterion=entropy, max_features=log2, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.740) f1: (train=1.000, test=0.774) total time=   2.0s\n",
      "[CV 4/10] END criterion=entropy, max_features=log2, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.855) balanced_accuracy: (train=1.000, test=0.736) f1: (train=1.000, test=0.770) total time=   2.0s\n",
      "[CV 5/10] END criterion=entropy, max_features=log2, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.744) f1: (train=1.000, test=0.777) total time=   2.2s\n",
      "[CV 6/10] END criterion=entropy, max_features=log2, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.864) balanced_accuracy: (train=1.000, test=0.750) f1: (train=1.000, test=0.785) total time=   2.1s\n",
      "[CV 7/10] END criterion=entropy, max_features=log2, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.743) f1: (train=1.000, test=0.776) total time=   2.1s\n",
      "[CV 8/10] END criterion=entropy, max_features=log2, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.747) f1: (train=1.000, test=0.781) total time=   2.1s\n",
      "[CV 9/10] END criterion=entropy, max_features=log2, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.860) balanced_accuracy: (train=1.000, test=0.743) f1: (train=1.000, test=0.778) total time=   2.2s\n",
      "[CV 10/10] END criterion=entropy, max_features=log2, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.863) balanced_accuracy: (train=1.000, test=0.752) f1: (train=1.000, test=0.785) total time=   2.1s\n",
      "[CV 1/10] END criterion=log_loss, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.741) f1: (train=1.000, test=0.776) total time=   1.2s\n",
      "[CV 2/10] END criterion=log_loss, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.856) balanced_accuracy: (train=1.000, test=0.741) f1: (train=1.000, test=0.774) total time=   1.2s\n",
      "[CV 3/10] END criterion=log_loss, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.740) f1: (train=1.000, test=0.774) total time=   1.2s\n",
      "[CV 4/10] END criterion=log_loss, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.855) balanced_accuracy: (train=1.000, test=0.736) f1: (train=1.000, test=0.770) total time=   1.2s\n",
      "[CV 5/10] END criterion=log_loss, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.743) f1: (train=1.000, test=0.776) total time=   1.2s\n",
      "[CV 6/10] END criterion=log_loss, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.747) f1: (train=1.000, test=0.782) total time=   1.2s\n",
      "[CV 7/10] END criterion=log_loss, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.856) balanced_accuracy: (train=1.000, test=0.741) f1: (train=1.000, test=0.774) total time=   1.2s\n",
      "[CV 8/10] END criterion=log_loss, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.860) balanced_accuracy: (train=1.000, test=0.745) f1: (train=1.000, test=0.778) total time=   1.1s\n",
      "[CV 9/10] END criterion=log_loss, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.742) f1: (train=1.000, test=0.777) total time=   1.1s\n",
      "[CV 10/10] END criterion=log_loss, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.752) f1: (train=1.000, test=0.785) total time=   1.2s\n",
      "[CV 1/10] END criterion=log_loss, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.860) balanced_accuracy: (train=1.000, test=0.743) f1: (train=1.000, test=0.778) total time=   1.1s\n",
      "[CV 2/10] END criterion=log_loss, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.742) f1: (train=1.000, test=0.775) total time=   1.2s\n",
      "[CV 3/10] END criterion=log_loss, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.741) f1: (train=1.000, test=0.775) total time=   1.2s\n",
      "[CV 4/10] END criterion=log_loss, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.855) balanced_accuracy: (train=1.000, test=0.735) f1: (train=1.000, test=0.769) total time=   1.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/10] END criterion=log_loss, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.745) f1: (train=1.000, test=0.778) total time=   1.1s\n",
      "[CV 6/10] END criterion=log_loss, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.861) balanced_accuracy: (train=1.000, test=0.746) f1: (train=1.000, test=0.781) total time=   1.2s\n",
      "[CV 7/10] END criterion=log_loss, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.743) f1: (train=1.000, test=0.777) total time=   1.2s\n",
      "[CV 8/10] END criterion=log_loss, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.861) balanced_accuracy: (train=1.000, test=0.746) f1: (train=1.000, test=0.780) total time=   1.1s\n",
      "[CV 9/10] END criterion=log_loss, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.741) f1: (train=1.000, test=0.776) total time=   1.1s\n",
      "[CV 10/10] END criterion=log_loss, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.863) balanced_accuracy: (train=1.000, test=0.753) f1: (train=1.000, test=0.786) total time=   1.1s\n",
      "[CV 1/10] END criterion=log_loss, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.742) f1: (train=1.000, test=0.776) total time=   1.1s\n",
      "[CV 2/10] END criterion=log_loss, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.743) f1: (train=1.000, test=0.777) total time=   1.1s\n",
      "[CV 3/10] END criterion=log_loss, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.742) f1: (train=1.000, test=0.777) total time=   1.1s\n",
      "[CV 4/10] END criterion=log_loss, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.738) f1: (train=1.000, test=0.772) total time=   1.2s\n",
      "[CV 5/10] END criterion=log_loss, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.744) f1: (train=1.000, test=0.778) total time=   1.1s\n",
      "[CV 6/10] END criterion=log_loss, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.863) balanced_accuracy: (train=1.000, test=0.748) f1: (train=1.000, test=0.783) total time=   1.1s\n",
      "[CV 7/10] END criterion=log_loss, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.741) f1: (train=1.000, test=0.775) total time=   1.1s\n",
      "[CV 8/10] END criterion=log_loss, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.861) balanced_accuracy: (train=1.000, test=0.746) f1: (train=1.000, test=0.780) total time=   1.1s\n",
      "[CV 9/10] END criterion=log_loss, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.741) f1: (train=1.000, test=0.775) total time=   1.1s\n",
      "[CV 10/10] END criterion=log_loss, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.863) balanced_accuracy: (train=1.000, test=0.752) f1: (train=1.000, test=0.785) total time=   1.1s\n",
      "[CV 1/10] END criterion=log_loss, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.741) f1: (train=1.000, test=0.776) total time=   2.0s\n",
      "[CV 2/10] END criterion=log_loss, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.742) f1: (train=1.000, test=0.775) total time=   2.0s\n",
      "[CV 3/10] END criterion=log_loss, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.740) f1: (train=1.000, test=0.774) total time=   2.2s\n",
      "[CV 4/10] END criterion=log_loss, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.856) balanced_accuracy: (train=1.000, test=0.738) f1: (train=1.000, test=0.772) total time=   2.1s\n",
      "[CV 5/10] END criterion=log_loss, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.745) f1: (train=1.000, test=0.778) total time=   2.1s\n",
      "[CV 6/10] END criterion=log_loss, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.747) f1: (train=1.000, test=0.781) total time=   2.1s\n",
      "[CV 7/10] END criterion=log_loss, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.743) f1: (train=1.000, test=0.776) total time=   2.1s\n",
      "[CV 8/10] END criterion=log_loss, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.861) balanced_accuracy: (train=1.000, test=0.746) f1: (train=1.000, test=0.780) total time=   2.0s\n",
      "[CV 9/10] END criterion=log_loss, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.860) balanced_accuracy: (train=1.000, test=0.743) f1: (train=1.000, test=0.778) total time=   2.1s\n",
      "[CV 10/10] END criterion=log_loss, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.863) balanced_accuracy: (train=1.000, test=0.753) f1: (train=1.000, test=0.786) total time=   2.1s\n",
      "[CV 1/10] END criterion=log_loss, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.860) balanced_accuracy: (train=1.000, test=0.744) f1: (train=1.000, test=0.778) total time=   2.0s\n",
      "[CV 2/10] END criterion=log_loss, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.743) f1: (train=1.000, test=0.776) total time=   2.1s\n",
      "[CV 3/10] END criterion=log_loss, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.741) f1: (train=1.000, test=0.776) total time=   2.1s\n",
      "[CV 4/10] END criterion=log_loss, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.738) f1: (train=1.000, test=0.772) total time=   2.0s\n",
      "[CV 5/10] END criterion=log_loss, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.744) f1: (train=1.000, test=0.777) total time=   2.2s\n",
      "[CV 6/10] END criterion=log_loss, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.747) f1: (train=1.000, test=0.782) total time=   2.0s\n",
      "[CV 7/10] END criterion=log_loss, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.741) f1: (train=1.000, test=0.775) total time=   2.1s\n",
      "[CV 8/10] END criterion=log_loss, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.747) f1: (train=1.000, test=0.781) total time=   2.1s\n",
      "[CV 9/10] END criterion=log_loss, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.741) f1: (train=1.000, test=0.776) total time=   2.0s\n",
      "[CV 10/10] END criterion=log_loss, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.864) balanced_accuracy: (train=1.000, test=0.754) f1: (train=1.000, test=0.788) total time=   2.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/10] END criterion=log_loss, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.741) f1: (train=1.000, test=0.775) total time=   2.0s\n",
      "[CV 2/10] END criterion=log_loss, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.743) f1: (train=1.000, test=0.776) total time=   2.1s\n",
      "[CV 3/10] END criterion=log_loss, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.741) f1: (train=1.000, test=0.775) total time=   2.0s\n",
      "[CV 4/10] END criterion=log_loss, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.856) balanced_accuracy: (train=1.000, test=0.737) f1: (train=1.000, test=0.771) total time=   2.0s\n",
      "[CV 5/10] END criterion=log_loss, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.745) f1: (train=1.000, test=0.778) total time=   2.1s\n",
      "[CV 6/10] END criterion=log_loss, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.863) balanced_accuracy: (train=1.000, test=0.749) f1: (train=1.000, test=0.784) total time=   2.0s\n",
      "[CV 7/10] END criterion=log_loss, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.741) f1: (train=1.000, test=0.774) total time=   2.0s\n",
      "[CV 8/10] END criterion=log_loss, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.748) f1: (train=1.000, test=0.782) total time=   2.1s\n",
      "[CV 9/10] END criterion=log_loss, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.742) f1: (train=1.000, test=0.776) total time=   2.0s\n",
      "[CV 10/10] END criterion=log_loss, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.753) f1: (train=1.000, test=0.786) total time=   2.0s\n",
      "[CV 1/10] END criterion=log_loss, max_features=log2, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.741) f1: (train=1.000, test=0.776) total time=   1.1s\n",
      "[CV 2/10] END criterion=log_loss, max_features=log2, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.856) balanced_accuracy: (train=1.000, test=0.741) f1: (train=1.000, test=0.774) total time=   1.1s\n",
      "[CV 3/10] END criterion=log_loss, max_features=log2, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.740) f1: (train=1.000, test=0.774) total time=   1.1s\n",
      "[CV 4/10] END criterion=log_loss, max_features=log2, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.855) balanced_accuracy: (train=1.000, test=0.736) f1: (train=1.000, test=0.770) total time=   1.1s\n",
      "[CV 5/10] END criterion=log_loss, max_features=log2, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.743) f1: (train=1.000, test=0.776) total time=   1.1s\n",
      "[CV 6/10] END criterion=log_loss, max_features=log2, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.747) f1: (train=1.000, test=0.782) total time=   1.1s\n",
      "[CV 7/10] END criterion=log_loss, max_features=log2, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.856) balanced_accuracy: (train=1.000, test=0.741) f1: (train=1.000, test=0.774) total time=   1.1s\n",
      "[CV 8/10] END criterion=log_loss, max_features=log2, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.860) balanced_accuracy: (train=1.000, test=0.745) f1: (train=1.000, test=0.778) total time=   1.1s\n",
      "[CV 9/10] END criterion=log_loss, max_features=log2, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.742) f1: (train=1.000, test=0.777) total time=   1.1s\n",
      "[CV 10/10] END criterion=log_loss, max_features=log2, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.752) f1: (train=1.000, test=0.785) total time=   1.0s\n",
      "[CV 1/10] END criterion=log_loss, max_features=log2, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.860) balanced_accuracy: (train=1.000, test=0.743) f1: (train=1.000, test=0.778) total time=   1.1s\n",
      "[CV 2/10] END criterion=log_loss, max_features=log2, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.742) f1: (train=1.000, test=0.775) total time=   1.1s\n",
      "[CV 3/10] END criterion=log_loss, max_features=log2, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.741) f1: (train=1.000, test=0.775) total time=   1.2s\n",
      "[CV 4/10] END criterion=log_loss, max_features=log2, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.855) balanced_accuracy: (train=1.000, test=0.735) f1: (train=1.000, test=0.769) total time=   1.1s\n",
      "[CV 5/10] END criterion=log_loss, max_features=log2, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.745) f1: (train=1.000, test=0.778) total time=   1.1s\n",
      "[CV 6/10] END criterion=log_loss, max_features=log2, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.861) balanced_accuracy: (train=1.000, test=0.746) f1: (train=1.000, test=0.781) total time=   1.1s\n",
      "[CV 7/10] END criterion=log_loss, max_features=log2, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.743) f1: (train=1.000, test=0.777) total time=   1.2s\n",
      "[CV 8/10] END criterion=log_loss, max_features=log2, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.861) balanced_accuracy: (train=1.000, test=0.746) f1: (train=1.000, test=0.780) total time=   1.2s\n",
      "[CV 9/10] END criterion=log_loss, max_features=log2, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.741) f1: (train=1.000, test=0.776) total time=   1.1s\n",
      "[CV 10/10] END criterion=log_loss, max_features=log2, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.863) balanced_accuracy: (train=1.000, test=0.753) f1: (train=1.000, test=0.786) total time=   1.1s\n",
      "[CV 1/10] END criterion=log_loss, max_features=log2, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.741) f1: (train=1.000, test=0.775) total time=   1.2s\n",
      "[CV 2/10] END criterion=log_loss, max_features=log2, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.744) f1: (train=1.000, test=0.778) total time=   1.1s\n",
      "[CV 3/10] END criterion=log_loss, max_features=log2, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.741) f1: (train=1.000, test=0.775) total time=   1.2s\n",
      "[CV 4/10] END criterion=log_loss, max_features=log2, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.738) f1: (train=1.000, test=0.772) total time=   1.1s\n",
      "[CV 5/10] END criterion=log_loss, max_features=log2, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.744) f1: (train=1.000, test=0.777) total time=   1.1s\n",
      "[CV 6/10] END criterion=log_loss, max_features=log2, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.865) balanced_accuracy: (train=1.000, test=0.750) f1: (train=1.000, test=0.786) total time=   1.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 7/10] END criterion=log_loss, max_features=log2, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.743) f1: (train=1.000, test=0.776) total time=   1.2s\n",
      "[CV 8/10] END criterion=log_loss, max_features=log2, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.860) balanced_accuracy: (train=1.000, test=0.746) f1: (train=1.000, test=0.780) total time=   1.1s\n",
      "[CV 9/10] END criterion=log_loss, max_features=log2, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.740) f1: (train=1.000, test=0.774) total time=   1.2s\n",
      "[CV 10/10] END criterion=log_loss, max_features=log2, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.863) balanced_accuracy: (train=1.000, test=0.752) f1: (train=1.000, test=0.785) total time=   1.1s\n",
      "[CV 1/10] END criterion=log_loss, max_features=log2, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.741) f1: (train=1.000, test=0.776) total time=   2.0s\n",
      "[CV 2/10] END criterion=log_loss, max_features=log2, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.742) f1: (train=1.000, test=0.775) total time=   2.1s\n",
      "[CV 3/10] END criterion=log_loss, max_features=log2, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.740) f1: (train=1.000, test=0.774) total time=   2.1s\n",
      "[CV 4/10] END criterion=log_loss, max_features=log2, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.856) balanced_accuracy: (train=1.000, test=0.738) f1: (train=1.000, test=0.772) total time=   2.1s\n",
      "[CV 5/10] END criterion=log_loss, max_features=log2, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.745) f1: (train=1.000, test=0.778) total time=   2.1s\n",
      "[CV 6/10] END criterion=log_loss, max_features=log2, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.747) f1: (train=1.000, test=0.781) total time=   2.2s\n",
      "[CV 7/10] END criterion=log_loss, max_features=log2, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.743) f1: (train=1.000, test=0.776) total time=   2.1s\n",
      "[CV 8/10] END criterion=log_loss, max_features=log2, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.861) balanced_accuracy: (train=1.000, test=0.746) f1: (train=1.000, test=0.780) total time=   2.1s\n",
      "[CV 9/10] END criterion=log_loss, max_features=log2, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.860) balanced_accuracy: (train=1.000, test=0.743) f1: (train=1.000, test=0.778) total time=   2.1s\n",
      "[CV 10/10] END criterion=log_loss, max_features=log2, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.863) balanced_accuracy: (train=1.000, test=0.753) f1: (train=1.000, test=0.786) total time=   2.1s\n",
      "[CV 1/10] END criterion=log_loss, max_features=log2, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.860) balanced_accuracy: (train=1.000, test=0.744) f1: (train=1.000, test=0.778) total time=   2.1s\n",
      "[CV 2/10] END criterion=log_loss, max_features=log2, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.743) f1: (train=1.000, test=0.776) total time=   2.4s\n",
      "[CV 3/10] END criterion=log_loss, max_features=log2, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.741) f1: (train=1.000, test=0.776) total time=   2.1s\n",
      "[CV 4/10] END criterion=log_loss, max_features=log2, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.738) f1: (train=1.000, test=0.772) total time=   2.1s\n",
      "[CV 5/10] END criterion=log_loss, max_features=log2, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.744) f1: (train=1.000, test=0.777) total time=   2.2s\n",
      "[CV 6/10] END criterion=log_loss, max_features=log2, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.747) f1: (train=1.000, test=0.782) total time=   2.1s\n",
      "[CV 7/10] END criterion=log_loss, max_features=log2, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.741) f1: (train=1.000, test=0.775) total time=   2.2s\n",
      "[CV 8/10] END criterion=log_loss, max_features=log2, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.747) f1: (train=1.000, test=0.781) total time=   2.3s\n",
      "[CV 9/10] END criterion=log_loss, max_features=log2, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.741) f1: (train=1.000, test=0.776) total time=   2.1s\n",
      "[CV 10/10] END criterion=log_loss, max_features=log2, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.864) balanced_accuracy: (train=1.000, test=0.754) f1: (train=1.000, test=0.788) total time=   2.1s\n",
      "[CV 1/10] END criterion=log_loss, max_features=log2, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.741) f1: (train=1.000, test=0.776) total time=   2.2s\n",
      "[CV 2/10] END criterion=log_loss, max_features=log2, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.742) f1: (train=1.000, test=0.776) total time=   2.1s\n",
      "[CV 3/10] END criterion=log_loss, max_features=log2, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.740) f1: (train=1.000, test=0.774) total time=   2.1s\n",
      "[CV 4/10] END criterion=log_loss, max_features=log2, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.856) balanced_accuracy: (train=1.000, test=0.738) f1: (train=1.000, test=0.772) total time=   2.2s\n",
      "[CV 5/10] END criterion=log_loss, max_features=log2, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.746) f1: (train=1.000, test=0.779) total time=   2.2s\n",
      "[CV 6/10] END criterion=log_loss, max_features=log2, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.864) balanced_accuracy: (train=1.000, test=0.750) f1: (train=1.000, test=0.785) total time=   2.2s\n",
      "[CV 7/10] END criterion=log_loss, max_features=log2, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.742) f1: (train=1.000, test=0.775) total time=   2.1s\n",
      "[CV 8/10] END criterion=log_loss, max_features=log2, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.861) balanced_accuracy: (train=1.000, test=0.747) f1: (train=1.000, test=0.781) total time=   2.1s\n",
      "[CV 9/10] END criterion=log_loss, max_features=log2, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.860) balanced_accuracy: (train=1.000, test=0.743) f1: (train=1.000, test=0.778) total time=   2.1s\n",
      "[CV 10/10] END criterion=log_loss, max_features=log2, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.753) f1: (train=1.000, test=0.786) total time=   2.2s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-96 {color: black;background-color: white;}#sk-container-id-96 pre{padding: 0;}#sk-container-id-96 div.sk-toggleable {background-color: white;}#sk-container-id-96 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-96 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-96 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-96 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-96 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-96 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-96 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-96 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-96 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-96 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-96 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-96 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-96 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-96 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-96 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-96 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-96 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-96 div.sk-item {position: relative;z-index: 1;}#sk-container-id-96 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-96 div.sk-item::before, #sk-container-id-96 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-96 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-96 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-96 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-96 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-96 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-96 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-96 div.sk-label-container {text-align: center;}#sk-container-id-96 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-96 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-96\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=StratifiedKFold(n_splits=10, random_state=None, shuffle=False),\n",
       "             estimator=ExtraTreesClassifier(n_estimators=150, n_jobs=-1,\n",
       "                                            random_state=30),\n",
       "             param_grid={&#x27;criterion&#x27;: [&#x27;gini&#x27;, &#x27;entropy&#x27;, &#x27;log_loss&#x27;],\n",
       "                         &#x27;max_features&#x27;: [&#x27;sqrt&#x27;, &#x27;log2&#x27;],\n",
       "                         &#x27;n_estimators&#x27;: [100, 200], &#x27;n_jobs&#x27;: [-1],\n",
       "                         &#x27;random_state&#x27;: [50, 100, None]},\n",
       "             refit=&#x27;balanced_accuracy&#x27;, return_train_score=True,\n",
       "             scoring={&#x27;accuracy&#x27;: &#x27;accuracy&#x27;,\n",
       "                      &#x27;balanced_accuracy&#x27;: &#x27;balanced_accuracy&#x27;,\n",
       "                      &#x27;f1&#x27;: &#x27;f1_macro&#x27;},\n",
       "             verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-112\" type=\"checkbox\" ><label for=\"sk-estimator-id-112\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=StratifiedKFold(n_splits=10, random_state=None, shuffle=False),\n",
       "             estimator=ExtraTreesClassifier(n_estimators=150, n_jobs=-1,\n",
       "                                            random_state=30),\n",
       "             param_grid={&#x27;criterion&#x27;: [&#x27;gini&#x27;, &#x27;entropy&#x27;, &#x27;log_loss&#x27;],\n",
       "                         &#x27;max_features&#x27;: [&#x27;sqrt&#x27;, &#x27;log2&#x27;],\n",
       "                         &#x27;n_estimators&#x27;: [100, 200], &#x27;n_jobs&#x27;: [-1],\n",
       "                         &#x27;random_state&#x27;: [50, 100, None]},\n",
       "             refit=&#x27;balanced_accuracy&#x27;, return_train_score=True,\n",
       "             scoring={&#x27;accuracy&#x27;: &#x27;accuracy&#x27;,\n",
       "                      &#x27;balanced_accuracy&#x27;: &#x27;balanced_accuracy&#x27;,\n",
       "                      &#x27;f1&#x27;: &#x27;f1_macro&#x27;},\n",
       "             verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-113\" type=\"checkbox\" ><label for=\"sk-estimator-id-113\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: ExtraTreesClassifier</label><div class=\"sk-toggleable__content\"><pre>ExtraTreesClassifier(n_estimators=150, n_jobs=-1, random_state=30)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-114\" type=\"checkbox\" ><label for=\"sk-estimator-id-114\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ExtraTreesClassifier</label><div class=\"sk-toggleable__content\"><pre>ExtraTreesClassifier(n_estimators=150, n_jobs=-1, random_state=30)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=10, random_state=None, shuffle=False),\n",
       "             estimator=ExtraTreesClassifier(n_estimators=150, n_jobs=-1,\n",
       "                                            random_state=30),\n",
       "             param_grid={'criterion': ['gini', 'entropy', 'log_loss'],\n",
       "                         'max_features': ['sqrt', 'log2'],\n",
       "                         'n_estimators': [100, 200], 'n_jobs': [-1],\n",
       "                         'random_state': [50, 100, None]},\n",
       "             refit='balanced_accuracy', return_train_score=True,\n",
       "             scoring={'accuracy': 'accuracy',\n",
       "                      'balanced_accuracy': 'balanced_accuracy',\n",
       "                      'f1': 'f1_macro'},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extra = ExtraTreesClassifier( n_jobs=-1, n_estimators=150, random_state=30)\n",
    "\n",
    "# Create the parameter grids\n",
    "parameter_grid = {\n",
    "    \"n_estimators\": [100, 200],\n",
    "    \"criterion\": ['gini', 'entropy', 'log_loss'],\n",
    "    \"max_features\": ['sqrt', 'log2'],\n",
    "    \"n_jobs\":[-1],\n",
    "   # \"bootstrap\":[True,False],\n",
    "    \"random_state\": [ 50, 100, None],\n",
    "   # \"warm_start\": [True, False],\n",
    "    \n",
    "}\n",
    "\n",
    "# Create Stratified folds\n",
    "# primi tentativi n_splits = 5 per limitare i tempi di esecuzione della gridSearch poi aumentato\n",
    "cross_validation = StratifiedKFold(n_splits=10)\n",
    "cross_validation.get_n_splits(train_data, np.ravel(y_train))\n",
    "\n",
    "# Create the scoring dictionary\n",
    "SCORING = {\n",
    "    \"accuracy\": \"accuracy\",\n",
    "    \"balanced_accuracy\": \"balanced_accuracy\",\n",
    "    \"f1\": \"f1_macro\",\n",
    "}\n",
    "\n",
    "# Create and fit the GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=extra,\n",
    "    param_grid=parameter_grid,\n",
    "    cv=cross_validation,\n",
    "    verbose=3,\n",
    "    scoring=SCORING,\n",
    "    return_train_score=True,\n",
    "    refit=\"balanced_accuracy\",\n",
    ")\n",
    "\n",
    "grid_search.fit(train_data, np.ravel(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "e5c00f24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.7444131043610392\n",
      "Best parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 200, 'n_jobs': -1, 'random_state': 50}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-97 {color: black;background-color: white;}#sk-container-id-97 pre{padding: 0;}#sk-container-id-97 div.sk-toggleable {background-color: white;}#sk-container-id-97 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-97 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-97 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-97 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-97 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-97 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-97 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-97 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-97 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-97 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-97 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-97 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-97 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-97 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-97 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-97 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-97 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-97 div.sk-item {position: relative;z-index: 1;}#sk-container-id-97 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-97 div.sk-item::before, #sk-container-id-97 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-97 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-97 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-97 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-97 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-97 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-97 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-97 div.sk-label-container {text-align: center;}#sk-container-id-97 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-97 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-97\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>ExtraTreesClassifier(n_estimators=200, n_jobs=-1, random_state=50)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-115\" type=\"checkbox\" checked><label for=\"sk-estimator-id-115\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ExtraTreesClassifier</label><div class=\"sk-toggleable__content\"><pre>ExtraTreesClassifier(n_estimators=200, n_jobs=-1, random_state=50)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "ExtraTreesClassifier(n_estimators=200, n_jobs=-1, random_state=50)"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Best score: {}\".format(grid_search.best_score_))\n",
    "print(\"Best parameters: {}\".format(grid_search.best_params_))\n",
    "\n",
    "best_dtc = grid_search.best_estimator_\n",
    "best_dtc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "19c3a08d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8585558168488034"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model = best_dtc\n",
    "my_model.fit(train_data, np.ravel(y_train))\n",
    "my_model.score(test_data, np.ravel(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e54eb0a",
   "metadata": {},
   "source": [
    "Risultato accuracy su testSet in base all'algoritmo utilizzato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b9e27e5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "algoritmo=[\"Decision_Tree\",\"Random_forest\",\"Extra_Tree\"]\n",
    "accuracy=[0.86917,0.87017,0.8585]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(algoritmo, accuracy, marker='o', linestyle='-', color='r')\n",
    "plt.title(' Accuracy su testSet al Variare dell algoritmo')\n",
    "plt.xlabel('Algoritmo')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.grid(True)\n",
    "plt.xticks(algoritmo)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2cac543",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
