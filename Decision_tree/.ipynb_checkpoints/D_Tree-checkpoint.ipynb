{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86789fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "#importo libreria panda per leggere ed elaborare csv\n",
    "import pandas as pd\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"decision_trees\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
    "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)\n",
    "\n",
    "from sklearn.model_selection import (\n",
    "    GridSearchCV,\n",
    "    StratifiedKFold,\n",
    "    cross_val_score,\n",
    "    train_test_split,\n",
    ")\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ff2e821",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=pd.read_csv('/Users/ragno/Documents/Progetti/Mldm/ProgettoMLDM/Dataset/train_data.csv')\n",
    "test_data=pd.read_csv('/Users/ragno/Documents/Progetti/Mldm/ProgettoMLDM/Dataset/test_data.csv')\n",
    "y_train=pd.read_csv('/Users/ragno/Documents/Progetti/Mldm/ProgettoMLDM/Dataset/train_y.csv')\n",
    "y_test=pd.read_csv('/Users/ragno/Documents/Progetti/Mldm/ProgettoMLDM/Dataset/test_y.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34e752bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "column = ['criterion', 'max_depth', 'ccp_alpha', 'min_samples_leaf', 'min_samples_split', 'accuracy']\n",
    "column_bar = ['try', 'Parameter_changed', 'Accuracy']\n",
    "\n",
    "def plot_depthsVSaccuracy(depths, ccp_alpha, title):\n",
    "  accs = pd.DataFrame(columns=column)\n",
    "  for d in depths:\n",
    "    tree_clf = DecisionTreeClassifier(criterion='log_loss',max_depth=d, min_samples_leaf=4, ccp_alpha=ccp_alpha,min_samples_split=8 )\n",
    "    tree_clf.fit(train_data, y_train)\n",
    "    testset_score = tree_clf.score(test_data, y_test)\n",
    "    row = pd.DataFrame(data=[['log_loss', d, ccp_alpha, 4, 8 ,testset_score]], columns=column)\n",
    "    accs = pd.concat([accs, row])\n",
    "\n",
    "  # plot\n",
    "  fig, ax = plt.subplots()\n",
    "  ax.plot(accs.max_depth, accs.accuracy)\n",
    "\n",
    "  ax.set(xlabel='Max depth', ylabel='Accuracy',\n",
    "        title=title)\n",
    "  ax.grid()\n",
    "  plt.show()\n",
    "\n",
    "### Create a single row equivalent to a single try for decision tree\n",
    "def create_bar_row(criterion, depth, leaf, ccp, split, attempt, parameter):\n",
    "  tree_clf = DecisionTreeClassifier(criterion=criterion,max_depth=depth, min_samples_leaf=leaf, ccp_alpha=ccp,min_samples_split=split )\n",
    "  tree_clf.fit(train_data, y_train)\n",
    "  testset_score = tree_clf.score(test_data, y_test)\n",
    "  row = pd.DataFrame(data=[[attempt, parameter, testset_score]], columns=column_bar)\n",
    "  return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "efa3b0b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "depths = np.linspace(10, 50, 41, dtype=int)\n",
    "\n",
    "plot_depthsVSaccuracy(depths, 0.0001, 'Variazione accuracy CON PRUNING') # with pruning\n",
    "plot_depthsVSaccuracy(depths, 0.0, 'Variazione accuracy SENZA PRUNING') # without pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7c0ef8e4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  try  Parameter_changed  Accuracy\n",
      "0   1              start  0.831270\n",
      "0   2          max_depth  0.840019\n",
      "0   3   min_samples_leaf  0.851120\n",
      "0   4  min_samples_split  0.858625\n",
      "0   5          ccp_alpha  0.868965\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'Score sul testset durante il tuning dei parametri'}, xlabel='Accuracy', ylabel='Parameter_changed'>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "df = pd.DataFrame(columns=column_bar)\n",
    "df = pd.concat([df, create_bar_row('entropy', 50, 1, 0.0, 20, 1, 'start')]) # try 1\n",
    "df = pd.concat([df, create_bar_row('entropy', 25, 1, 0.0, 20, 2, 'max_depth')]) # try 2\n",
    "df = pd.concat([df, create_bar_row('entropy', 25, 10, 0.0, 20, 3, 'min_samples_leaf')]) # try 3\n",
    "df = pd.concat([df, create_bar_row('entropy', 25, 10, 0.0, 40, 4, 'min_samples_split')]) # try 4\n",
    "df = pd.concat([df, create_bar_row('entropy', 25, 10, 0.0001, 40, 5, 'ccp_alpha')]) # try 5\n",
    "print(df)\n",
    "\n",
    "fig, axs = plt.subplots()\n",
    "axs.set_xlim([0.70,0.89])\n",
    "axs.set_title(\"Score sul testset durante il tuning dei parametri\")\n",
    "\n",
    "sns.barplot(data=df, x='Accuracy',y=\"Parameter_changed\",ax=axs, orient=\"h\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "01d22692",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3MAAAIoCAYAAADDd7L6AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAACqA0lEQVR4nOzde3zO9f/H8ce1ubbZ5jjHzWEWQk6JJopWZlESv+TUgVFIzoecz5ocYnRC2IhRXybkNIeOFClflKTJIYdiYjYzO3x+f3y+rqxtmtlc18Xzfru51ed9fQ6v67re2NP783m/LYZhGIiIiIiIiIhTcbF3ASIiIiIiInLzFOZERERERESckMKciIiIiIiIE1KYExERERERcUIKcyIiIiIiIk5IYU5ERERERMQJKcyJiIiIiIg4IYU5ERERERERJ6QwJyIiIiIi4oQU5kTEaezfvx+LxYLVauX06dP2Lkeus2PHDsaNG8eFCxfy9TrvvvsuERERWb524sQJXn31VapWrUrBggUpXrw4tWrV4uWXX+bEiRM3fa2ffvqJcePGcfTo0Vsr+h+OHj2KxWLJ9n0AhIeHY7FY2LhxY7b7zJ8/H4vFwqpVq/KkLn9/f7p06ZIn58pvFouFcePG3fRxWX32ERERWCyWPPuec/L95rd/fpenTp1i3Lhx7N271241iUj+UJgTEafxwQcfAJCamsrixYvtXI1cb8eOHYwfP95uYe7333+nXr16xMTEMHDgQNavX8/ChQvp2LEju3fv5siRIzd9rZ9++onx48fneZjLieeffx53d3cWLlyY7T6LFi2iZMmStGrVKk+uGR0dzejRo/PkXGJf//wuT506xfjx4xXmRO5ABexdgIhITiQnJ7N06VLq1KnDuXPnWLhwIa+//rq9y8pSUlISHh4eWCwWe5dy15g/fz7nzp1j165dVKpUydb+zDPPMGLECNLT0+1Y3c3z8fGhdevWrF69mri4OHx8fDK8/vPPP7Nz504GDRqE1Wq9pWslJSVRsGBB7r///ls6z/UMw+DKlSsULFgwz84p/y4/vksRcWwamRMRp3Dth9ru3bvz0ksv8csvv/DVV19l2i85OZkJEyZQvXp1PDw88PHxISgoiB07dtj2SU9PZ86cOdStW5eCBQtStGhRGjZsyJo1a2z7ZHcb1z9vX7p2i9bmzZsJDQ2lZMmSeHp6kpyczK+//krXrl2pUqUKnp6e+Pn50apVK/bv35/pvBcuXGDQoEEEBATg7u5OqVKlaNmyJT///DOGYVClShVCQkIyHZeQkECRIkXo3bv3DT+/jz/+mMDAQIoUKYKnpycBAQGEhoZmeh//HIX67LPPsFgsfPbZZ9mee9y4cQwZMgSASpUqYbFYMh2zYsUKHnroIby8vPD29iYkJIQffvghw3mOHDlChw4d8PX1xd3dndKlS/P444/bRhP8/f358ccf+fzzz23X8Pf3ByAuLg4XFxdKlSqVZY0uLhn/uvvuu+94+umnKV68OB4eHtx///189NFHGT6Pdu3aARAUFGS73o1unbuZ7zsnunXrxtWrV1m2bFmm1xYtWgRg+w7Hjx9PYGAgxYsXp3DhwtSrV48FCxZgGEaG4/z9/XnqqadYtWoV999/Px4eHowfP9722vV9+8qVKwwaNIi6detSpEgRihcvzkMPPcQnn3ySqR6LxcJrr73G+++/T/Xq1XF3dycyMhKAw4cP06lTJ0qVKoW7uzvVq1fnnXfeydFnEB8fz8svv4yPjw/e3t488cQT/PLLL1nueyvXyYlb/X4/+eQTateujbu7OwEBAYSHhzNu3LhM/+hz5coVhg8fTqVKlXBzc8PPz4/evXtnGvXO6Xf52Wef0aBBAwC6du1q68vX/nzr0qUL3t7e/Pzzz4SEhODl5UXZsmWZMmUKAN988w0PP/wwXl5eVK1a1fa9Xu/AgQO0bt2aYsWK4eHhQd26dbPcT0TynkbmRMQpLFiwAHd3dzp37sz58+cJCwtjwYIFPPzww7Z9UlNTadGiBV9++SX9+/fnscceIzU1lW+++Ybjx4/TqFEjwPzh5cMPP6Rbt25MmDABNzc3vv/++1u6nS40NJQnn3ySJUuWkJiYiNVq5dSpU/j4+DBlyhRKlizJ+fPniYyMJDAwkB9++IF7770XgEuXLvHwww9z9OhRXn/9dQIDA0lISOCLL77g9OnTVKtWjT59+tC/f38OHz5MlSpVbNddvHgx8fHxNwxzO3fupH379rRv355x48bh4eHBsWPH2LZtW67f7/W6d+/O+fPnmTNnDqtWraJs2bIA1KhRA4A33niDUaNG0bVrV0aNGsXVq1eZNm0ajzzyCLt27bLt17JlS9LS0pg6dSoVKlTg3Llz7Nixw/ZDbHR0NM8++yxFihTh3XffBcDd3R2Ahx56iHfeeYe2bdsycOBAHnroIQoXLpxlvdu3b+eJJ54gMDCQ999/nyJFirB8+XLat2/P5cuX6dKlC08++SRvvPEGI0aM4J133qFevXoA3HPPPdl+Djn9vnOqWbNmVKxYkYULF9KnTx9be1paGkuWLKFhw4a2z+7o0aP06NGDChUqAOYP4H369OHkyZOMGTMmw3m///57Dh48yKhRo6hUqRJeXl5ZXj85OZnz588zePBg/Pz8uHr1Klu2bKFt27YsWrSIF198McP+q1ev5ssvv2TMmDGUKVOGUqVK8dNPP9GoUSMqVKjAjBkzKFOmDJs2baJv376cO3eOsWPHZvv+DcPgmWeeYceOHYwZM4YGDRrw9ddf06JFi0z73sp1cupWvt+NGzfStm1bmjRpwooVK0hNTWX69On88ccfWb7nrVu3Mnz4cB555BH27dvH2LFj2blzJzt37rT1ecjZd1mvXj0WLVpk+/335JNPAlCuXDnbPikpKbRt25aePXsyZMgQli1bxvDhw4mPj2flypW8/vrrlCtXjjlz5tClSxdq1qzJAw88AMChQ4do1KgRpUqVYvbs2fj4+PDhhx/SpUsX/vjjD4YOHXpLn7uI/AtDRMTBHT161HBxcTE6dOhga2vatKnh5eVlxMfH29oWL15sAMb8+fOzPdcXX3xhAMbIkSNveE3AGDt2bKb2ihUrGi+99JJte9GiRQZgvPjii//6PlJTU42rV68aVapUMQYMGGBrnzBhggEYMTEx2R4bHx9vFCpUyOjXr1+G9ho1ahhBQUE3vO706dMNwLhw4UK2+1x7H7/99luG9u3btxuAsX379hteY9q0aVkef/z4caNAgQJGnz59MrRfunTJKFOmjPHcc88ZhmEY586dMwBj1qxZN7zOfffdZzRt2jRTe3p6utGjRw/DxcXFAAyLxWJUr17dGDBgQKaaqlWrZtx///1GSkpKhvannnrKKFu2rJGWlmYYhmF8/PHHOXrv2cnu+/7tt98MwFi0aNG/nmPs2LEGYHz//fe2trVr196wn6elpRkpKSnGhAkTDB8fHyM9Pd32WsWKFQ1XV1fj0KFDmY77Z9/O6v2kpKQY3bp1M+6///4MrwFGkSJFjPPnz2doDwkJMcqVK2dcvHgxQ/trr71meHh4ZNr/ehs2bDAAIzw8PEP75MmTM/3+zOl1svrss+v7/+Zmvt8GDRoY5cuXN5KTk21tly5dMnx8fIzrfxTbuHGjARhTp07NcK0VK1YYgDFv3jxb2818l7t37862z7300ksGYKxcudLWlpKSYpQsWTJT34uLizNcXV2NgQMH2to6dOhguLu7G8ePH89w3hYtWhienp43/HNHRG6dbrMUEYe3aNEi0tPTM9wWGBoaSmJiIitWrLC1bdiwAQ8Pjwz7/dOGDRsA/vW2xJv1f//3f5naUlNTeeONN6hRowZubm4UKFAANzc3Dh8+zMGDBzPUVLVqVZo1a5bt+QsVKkTXrl2JiIggMTERgG3btvHTTz/x2muv3bC2a7dYPffcc3z00UecPHkyN28xVzZt2kRqaiovvvgiqamptl8eHh40bdrUditm8eLFueeee5g2bRpvvfUWP/zww00952axWHj//fc5cuQI7777Ll27diUlJYWZM2dy33338fnnnwPmrXI///wznTt3BshQU8uWLTl9+jSHDh3K1XvN6fd9M7p27YqLi0uGiVAWLVqEl5cX7du3t7Vt27aNZs2aUaRIEVxdXbFarYwZM4a4uDj+/PPPDOesXbs2VatWzdH1P/74Yxo3boy3tzcFChTAarWyYMGCLN/PY489RrFixWzbV65cYevWrbRp0wZPT89Mn/WVK1f45ptvsr329u3bAWzf1TWdOnXKsH2r18mp3H6/iYmJfPfddzzzzDO4ubnZ2r29vTNNXnNttPyfs4q2a9cOLy8vtm7dmqH9Zr7LG7FYLLRs2dK2XaBAASpXrkzZsmUzPH9XvHhxSpUqxbFjxzLU/Pjjj1O+fPkM5+zSpQuXL19m586dt1yfiGRPYU5EHFp6ejoRERH4+vrywAMPcOHCBS5cuECzZs3w8vJiwYIFtn3Pnj2Lr69vpuejrnf27FlcXV0pU6ZMntZ57dbC6w0cOJDRo0fzzDPPsHbtWr799lt2795NnTp1SEpKylDT9bc8ZadPnz5cunSJpUuXAvD2229Trlw5WrdufcPjmjRpwurVq22hqly5ctSsWZOoqKibfJc379ptZA0aNMBqtWb4tWLFCs6dOweYP0xu3bqVkJAQpk6dSr169ShZsiR9+/bl0qVLOb5exYoV6dWrFwsWLODw4cOsWLGCK1eu2J7pu1bP4MGDM9Xz6quvAthqulk5/b5vRsWKFXn88cdZtmwZycnJnDt3jnXr1tGuXTsKFSoEwK5du2jevDlgTgTz9ddfs3v3bkaOHAmQ6dpZ9dWsrFq1iueeew4/Pz8+/PBDdu7cye7duwkNDeXKlSuZ9v/neePi4khNTWXOnDmZPutrweFGn3VcXBwFChTINPnLP3/v3up1ciq33+9ff/2FYRiULl0602v/bLv2nkuWLJmh3WKxUKZMGeLi4jK05/S7/Deenp54eHhkaHNzc6N48eKZ9nVzc8vw/cfFxWVZh6+vr+11Eck/emZORBzali1bbP8K/M8f6sB8Nuinn36iRo0alCxZkq+++or09PRsA13JkiVJS0vjzJkzN/xByN3dneTk5Ezt2f1gktXMlR9++CEvvvgib7zxRob2c+fOUbRo0Qw1/f7779nWck3lypVp0aIF77zzDi1atGDNmjWMHz8eV1fXfz22devWtG7dmuTkZL755hvCwsLo1KkT/v7+PPTQQ7Yf5P75nm/1h+ASJUoA8J///IeKFSvecN+KFSvawvkvv/zCRx99xLhx47h69Srvv/9+rq7/3HPPERYWxoEDBzLUM3z4cNq2bZvlMTf7bNs1Of2+b1a3bt2IiYnhk08+4dSpU1y9epVu3brZXl++fDlWq5V169Zl+IF89erVWZ4vp7Osfvjhh1SqVIkVK1ZkOCar3xdZnbdYsWK4urrywgsvZDsSfv3Mo//k4+NDampqptk8z5w5k6fXyancfr/FihXDYrFkej4OMr+Xa+/57NmzGQKdYRicOXPGNsp+jSPMmOvj45Plup+nTp0C/v49JyL5QyNzIuLQFixYgIuLC6tXr2b79u0Zfi1ZsgTAdgtaixYtuHLlyg1nHLw2ecJ77713w+v6+/uzb9++DG3btm0jISEhx7VbLJYMkxUAfPrpp5luc2zRogW//PJLjiYk6devH/v27eOll17C1dWVl19+Ocf1gBlSmzZtyptvvglgm1Hy2qyQ/3zP18/w+W/nhcyjQCEhIRQoUIDY2Fjq16+f5a+sVK1alVGjRlGrVi2+//77DNfJahQku0XkExISOHHihG2U4N5776VKlSr897//zbaeayNe2b2n7OT0+75ZzzzzDD4+PixcuJBFixZRtWrVDBP/WCwWChQokCHUJyUl2X5/5JbFYsHNzS1DYDhz5kyWs1lmxdPTk6CgIH744Qdq166d5Wed1T/QXBMUFARgG4m+5p+ze97qdXIqt9+vl5cX9evXZ/Xq1Vy9etXWnpCQwLp16zLs+/jjjwNmcLzeypUrSUxMtL1+s262L9+Mxx9/nG3bttnC2zWLFy/G09OThg0b5vk1ReRvGpkTEYcVFxfHJ598QkhISLa3Es6cOZPFixcTFhZGx44dWbRoET179uTQoUMEBQWRnp7Ot99+S/Xq1enQoQOPPPIIL7zwApMmTeKPP/7gqaeewt3dnR9++AFPT0/brIEvvPACo0ePZsyYMTRt2pSffvqJt99+myJFiuS4/qeeeoqIiAiqVatG7dq12bNnD9OmTct0S2X//v1ZsWIFrVu3ZtiwYTz44IMkJSXx+eef89RTT9l+qAUIDg6mRo0abN++neeffz7bqfivN2bMGH7//Xcef/xxypUrx4ULFwgPD8dqtdK0aVPAvA3y3nvvZfDgwaSmplKsWDGio6OzXP4hK7Vq1QIgPDycl156CavVyr333ou/vz8TJkxg5MiRHDlyhCeeeIJixYrxxx9/sGvXLry8vBg/fjz79u3jtddeo127dlSpUgU3Nze2bdvGvn37GDZsWIbrLF++nBUrVhAQEICHhwe1atVi8uTJfP3117Rv39625MRvv/3G22+/TVxcHNOmTbOdY+7cubRo0YKQkBC6dOmCn58f58+f5+DBg3z//fd8/PHHANSsWROAefPmUahQITw8PKhUqVK2wSCn3/fNujaL65w5czAMwzZl/DVPPvkkb731Fp06deKVV14hLi6O6dOnZwoeN+vatPevvvoqzz77LCdOnGDixImULVuWw4cP5+gc4eHhPPzwwzzyyCP06tULf39/Ll26xK+//sratWtv+A8YzZs3p0mTJgwdOpTExETq16/P119/nWVIvZXr5NStfL8TJkzgySefJCQkhH79+pGWlsa0adPw9vbm/Pnztv2Cg4MJCQnh9ddfJz4+nsaNG9tms7z//vt54YUXclX7PffcQ8GCBVm6dCnVq1fH29sbX19f2z9y3IqxY8eybt06goKCGDNmDMWLF2fp0qV8+umnTJ069ab+zBSRXLDzBCwiItmaNWuWARirV6/Odp/3338/w0xsSUlJxpgxY4wqVaoYbm5uho+Pj/HYY48ZO3bssB2TlpZmzJw506hZs6bh5uZmFClSxHjooYeMtWvX2vZJTk42hg4dapQvX94oWLCg0bRpU2Pv3r3Zzma5e/fuTLX99ddfRrdu3YxSpUoZnp6exsMPP2x8+eWXRtOmTTPNyPjXX38Z/fr1MypUqGBYrVajVKlSxpNPPmn8/PPPmc47btw4AzC++eabHH2O69atM1q0aGH4+fkZbm5uRqlSpYyWLVsaX375ZYb9fvnlF6N58+ZG4cKFjZIlSxp9+vQxPv300xzP6Dh8+HDD19fXNqPk9cesXr3aCAoKMgoXLmy4u7sbFStWNJ599lljy5YthmEYxh9//GF06dLFqFatmuHl5WV4e3sbtWvXNmbOnGmkpqbaznP06FGjefPmRqFChQzAqFixomEYhvHNN98YvXv3NurUqWMUL17ccHV1NUqWLGk88cQTxvr16zPV+t///td47rnnjFKlShlWq9UoU6aM8dhjjxnvv/9+hv1mzZplVKpUyXB1df3XGShz+n3fzGyW19cLGK6ursapU6cyvb5w4ULj3nvvNdzd3Y2AgAAjLCzMWLBgQaZZGitWrGg8+eSTWV4jq9ksp0yZYvj7+xvu7u5G9erVjfnz59tm2LweYPTu3TvL8/72229GaGio4efnZ1itVqNkyZJGo0aNjEmTJv3r+75w4YIRGhpqFC1a1PD09DSCg4ONn3/+OcvZZnNynVuZzfJWv9/o6GijVq1ahpubm1GhQgVjypQpRt++fY1ixYpl2C8pKcl4/fXXjYoVKxpWq9UoW7as0atXL+Ovv/7KsN/NfpdRUVFGtWrVDKvVmuHze+mllwwvL69M52jatKlx3333ZXnuf153//79RqtWrYwiRYoYbm5uRp06dW6qf4tI7lkM4x8rioqIiEOrX78+FouF3bt327sUEcmllJQU6tati5+fH5s3b7Z3OSLipHSbpYiIE4iPj+fAgQOsW7eOPXv2EB0dbe+SROQmdOvWjeDgYMqWLcuZM2d4//33OXjwIOHh4fYuTUScmMKciIgT+P777wkKCsLHx4exY8fyzDPP2LskEbkJly5dYvDgwZw9exar1Uq9evVYv379DdeXFBH5N7rNUkRERERExAlpaQIREREREREnpDAnIiIiIiLihBTmREREREREnJAmQLmN0tPTOXXqFIUKFcJisdi7HBERERERsRPDMLh06RK+vr64uORujE1h7jY6deoU5cuXt3cZIiIiIiLiIE6cOEG5cuVydazC3G1UqFAhwPzCChcubNdaUlJS2Lx5M82bN8dqtdq1FpGbpf4rzk59WJyZ+q84M0fqv/Hx8ZQvX96WEXJDYe42unZrZeHChR0izHl6elK4cGG7d2SRm6X+K85OfVicmfqvODNH7L+38viVQ06AkpCQQP/+/fH19cXDw4O6deuyfPnyHB27fft2goODKVWqFN7e3tSuXZvZs2eTlpZm2+fo0aNYLJZsfz3xxBMZzpmSksL48ePx9/fH3d2datWqMWfOnDx9zyIiIiIiIjfDIUfm2rZty+7du5kyZQpVq1Zl2bJldOzYkfT0dDp16pTtcVu2bCEkJIQmTZowf/58vLy8WLNmDf369SM2Npbw8HAAypYty86dOzMdv3r1at58803atGmTof3VV19lyZIlTJw4kQYNGrBp0yb69evHpUuXGDFiRN6+eRERERERkRxwuDC3fv16YmJibAEOICgoiGPHjjFkyBDat2+Pq6trlsdGRERgtVpZt24dXl5eADRr1oxDhw4RERFhC3Pu7u40bNgw0/HDhw/H09PTdl2AH3/8kQULFjB58mSGDBkCwKOPPkpcXByTJk2iZ8+eFC9ePE8/AxERERERkX/jcLdZRkdH4+3tTbt27TK0d+3alVOnTvHtt99me6zVasXNzY2CBQtmaC9atCgeHh43vG5sbCyff/45zz33XIbn2VavXo1hGHTt2jVTPUlJSWzcuDGnb01ERERERCTPONzI3IEDB6hevToFCmQsrXbt2rbXGzVqlOWxPXv2JCoqir59+zJixAg8PT1Zu3Yt0dHRhIWF3fC6CxcuxDAMunfvnqmekiVLUqZMmWzryU5ycjLJycm27fj4eMB8Bi8lJeWG9eS3a9e3dx0iuaH+K85OfVicmfqvODNH6r95UYPDhbm4uDgCAgIytV+7lTEuLi7bYwMDA9m2bRvt2rXjnXfeAcDV1ZWwsDAGDRqU7XFpaWlERkZSrVo1GjdunKmerG6j9PLyws3N7Yb1hIWFMX78+EztmzdvxtPTM9vjbqeYmBh7lyCSa+q/4uzUh8WZqf+KM3OE/nv58uVbPofDhTm48fScN3ptz549tGnThsDAQObOnYuXlxfbtm1j1KhRXLlyhdGjR2d53MaNGzl58iTTpk3L03qGDx/OwIEDbdvX1pJo3ry5QyxNEBMTQ3BwsMNMyyqSU+q/4uzUh8WZqf+KM3Ok/nvtrr1b4XBhzsfHJ8vRrvPnzwPccLKR3r17U7p0aaKjo22TpAQFBeHi4sK4cePo3LlzlqN+CxYswGq18uKLL2ZZz969ezO1JyYmcvXq1RvW4+7ujru7e6Z2q9Vq985zjSPVInKz1H/F2akPizNT/xVn5gj9Ny+u73AToNSqVYuDBw+SmpqaoX3//v0A1KxZM9tj9+7dywMPPJBptssGDRqQnp7OwYMHMx3z559/sm7dOp5++mlKlSqVZT1nz57lzJkzN12PiIiIiIhIfnG4MNemTRsSEhJYuXJlhvbIyEh8fX0JDAzM9lhfX1++++67DAuEA7Y15cqVK5fpmMWLF5OSkkK3bt2yPGfr1q2xWCxERkZmaI+IiKBgwYKZFhgXERERERG5HRzuNssWLVoQHBxMr169iI+Pp3LlykRFRbFx40Y+/PBD26hbt27diIyMJDY2looVKwIwYMAA+vbtS6tWrejRoweenp5s3bqVGTNm0KxZM+rUqZPpegsWLKB8+fKEhIRkWc99991Ht27dGDt2LK6urjRo0IDNmzczb948Jk2apDXmRERERETELhwuzAGsWrWKkSNHMmbMGM6fP0+1atWIioqiQ4cOtn3S0tJIS0vDMAxbW58+ffDz82PmzJl0796dpKQk/P39GTt2LAMGDMh0nR07dvDzzz8zZswYXFyyH6R899138fPzY86cOZw5cwZ/f3/Cw8Pp06dP3r5xERERERGRHLIY16chyVfx8fEUKVKEixcvOsRsluvXr6dly5Z2f/hT5Gap/4qzUx8WZ6b+K87MkfpvXmQDh3tmTkREREREJM+lpWH5/HP8vvgCy+efwz/m2XBGCnMiIiIiInJnW7UK/P0pEBxM/bfeokBwMPj7m+1OTGFORERERETuXKtWwbPPwu+/Z2w/edJsd+JApzAnIiIiIiJ3prQ06NcPspom5Fpb//5Oe8ulwpyIiIiIiNyZvvwy84jc9QwDTpww93NCCnMiIiIiInJnOnIkZ/udPp2/deQThTkREREREbnzbNoEw4fnbN+yZfO3lnyiMCciIiIiIneO8+ehSxd44gn4809wdc1+X4sFypeHRx65beXlJYU5ERERERG5M6xaBTVqQGSkGdT69fv7/y2WjPte254168aBz4EVsHcBIiIiIiIit+SPP+C11+A//zG3q1WDBQugUSNzu2BBM9hdPxlKuXJmkGvb9raXm1c0MiciIiIiIs7JMGDJEnM07j//MUfYRoyAH374O8iBGdiOHiU1JobvBg4kNSYGfvvNqYMcaGRORERERESc0fHj0LMnbNhgbtetCwsXwv33Z72/qytG06acTEykTtOmTntr5fU0MiciIiIiIs4jPR3eew/uu88Mcu7u8MYbsGtX9kHuDqWRORERERERcQ6HD0P37vDFF+Z2o0bms3HVqtm3LjvRyJyIiIiIiDi21FSYNg1q1zaDnJcXzJ5t/v9dGuRAI3MiIiIiIuLI9u+H0FD47jtzu1kzmD8f/P3tWpYj0MiciIiIiIg4nqtXYexYqFfPDHJFipi3VG7erCD3PxqZExERERERx7Jrlzka9+OP5vYzz8A774Cvr13LcjQamRMREREREcdw+TIMHgwPPWQGuZIlYcUKWLVKQS4LGpkTERERERH7++wzc6bK2Fhz+/nnYeZMKFHCrmU5Mo3MiYiIiIiI/cTHm4t/BwWZQa5cOVi3DpYsUZD7FxqZExERERER+1i/Hnr0gN9/N7d79ICpU6FwYfvW5SQU5kRERERE5PY6dw7694elS83te+6BDz6ARx+1Z1VOR7dZioiIiIjI7WEY8NFHUKOGGeRcXGDQINi3T0EuFzQyJyIiIiIi+e/UKejdG1avNrfvuw8WLoQHH7RrWc5MI3MiIiIiIpJ/DMMMbTVqmEGuQAFzMfDvv1eQu0UamRMRERERkfxx9Ci88grExJjb9eubwa5WLbuWdafQyJyIiIiIiOSt9HSYPRtq1jSDnIcHTJsGO3cqyOUhjcyJiIiIiEje+fln6NYNduwwtx95BBYsgCpV7FvXHUgjcyIiIiIicutSUiAsDOrWNYOctze8+y589pmCXD7RyJyIiIiIiNyaH34wR+N++MHcfuIJmDsXKlSwb113OI3MiYiIiIhI7ly5AiNHQoMGZpArVgwiI2H9egW520AjcyIiIiIicvN27DBH437+2dx+9ll4+20oXdq+dd1FNDInIiIiIiI5l5gI/frBww+bQa50aVi5Ej7+WEHuNtPInIiIiIiI5MyWLfDyy+b6cQBdusCMGVC8uD2rumtpZE5ERERERG7swgXo3h2Cg80gV6ECbNwIixYpyNmRwpyIiIiIiGRvzRq47z5zrTiA3r3hwAEICbFvXaLbLEVEREREJAtnz0KfPrBihbldpYoZ6B55xL51iY1G5kRERERE5G+GAcuWQfXqZpBzdYXXX4f//ldBzsFoZE5EREREREy//w69esG6deZ27dqwcCE88IB965IsaWRORERERORuZxgwb575bNy6deDmBhMnwu7dCnIOTCNzIiIiIiJ3s9hYc7mB7dvN7cBAczSuRg371iX/SiNzIiIiIiJ3o7Q0eOstqFXLDHIFC5rbX3+tIOckHDLMJSQk0L9/f3x9ffHw8KBu3bosX748R8du376d4OBgSpUqhbe3N7Vr12b27NmkpaVl2jcxMZExY8ZQtWpV3N3d8fHxISgoiMOHD9v2OXr0KBaLJctfOa1JRERERMSh/PgjNG4MgwZBUhI89pi53MCAAeaEJ+IUHPI2y7Zt27J7926mTJlC1apVWbZsGR07diQ9PZ1OnTple9yWLVsICQmhSZMmzJ8/Hy8vL9asWUO/fv2IjY0lPDzctm9CQgJBQUGcOnWKYcOGUbt2bS5evMiOHTu4fPlypnP36dMn07WrVKmSd29aRERERCS/Xb0Kb75pPg+XkgKFC8P06eaC4BaLvauTm+RwYW79+vXExMTYAhxAUFAQx44dY8iQIbRv3x7XbP61ICIiAqvVyrp16/Dy8gKgWbNmHDp0iIiIiAxhbtSoURw8eJB9+/YREBBga3/66aezPHeFChVo2LBhXr1NEREREZHb67vvoFs32LfP3H7qKXjvPShXzr51Sa453G2W0dHReHt7065duwztXbt25dSpU3z77bfZHmu1WnFzc6NgwYIZ2osWLYqHh4dt+/Lly3zwwQe0a9cuQ5ATEREREbnjJCWZ68QFBppBrkQJcx25NWsU5Jycw43MHThwgOrVq1OgQMbSateubXu9UaNGWR7bs2dPoqKi6Nu3LyNGjMDT05O1a9cSHR1NWFiYbb89e/aQmJhIlSpV6NWrF8uXLycxMZHatWszfvx4nnzyyUznnjJlCiNGjKBAgQLUq1ePoUOHZjuKd01ycjLJycm27fj4eABSUlJISUnJ2QeST65d3951iOSG+q84O/VhcWbqv87F8tVXuL7yCpZffwUg/bnnSJs5E0qWhNRUO1d3+zlS/82LGhwuzMXFxWU5Wla8eHHb69kJDAxk27ZttGvXjnfeeQcAV1dXwsLCGDRokG2/kydPAvDmm29Sq1YtFi9ejIuLCzNmzKBVq1Zs2LCBkJAQANzd3Xn55ZcJDg6mbNmyHD9+nDlz5tC6dWvmz59P9+7ds60nLCyM8ePHZ2rfvHkznp6eOfg08l9MTIy9SxDJNfVfcXbqw+LM1H8dW4GkJGosXkylDRsASCpenH09e3LmwQfNtePuco7Qf7Oap+NmWQzDMPKgljxTtWpV7rnnHjb8r+Ndc/r0aXx9fQkLC2PYsGFZHrtnzx5atmxJYGAgr7zyCl5eXmzbto2pU6cyatQoRo8eDcCyZcvo3LkzJUqU4MiRIxQqVAgwP9AqVapQqVIlvvrqq2xrTElJITAwkOPHj3PmzJlMo4jXZDUyV758ec6dO0fhwoVv6nPJaykpKcTExBAcHIzVarVrLSI3S/1XnJ36sDgz9V/HZ9m8GddXX8Vy/DgA6aGhpE2ZAkWL2rcwB+BI/Tc+Pp4SJUpw8eLFXGcDhxuZ8/HxyXL07fz588DfI3RZ6d27N6VLlyY6Oto2SUpQUBAuLi6MGzeOzp07ExAQgI+PDwCNGjWyBTkAT09PmjZtyurVq29Yo9VqpX379gwbNozDhw9TvXr1LPdzd3fH3d09y+Pt3XmucaRaRG6W+q84O/VhcWbqvw7o/HkYOBAiI83tSpVg/nxcHn/c8SbKsDNH6L95cX2H+15r1arFwYMHSf3HPbz79+8HoGbNmtkeu3fvXh544IFMs102aNCA9PR0Dh48CPz9/F1WDMPAxeXfP5ZrA5o52VdEREREJF+tXGku9B0ZaS4x0K8f7N8Pjz9u78okHzlcEmnTpg0JCQmsXLkyQ3tkZCS+vr4EBgZme6yvry/fffddpgXCd+7cCUC5/83WU7ZsWR566CG+/vpr26QkYN5m+fnnn//rEgQpKSmsWLGCEiVKULly5Zt6fyIiIiIieebMGXj2WfPXH39AtWrw1Vcwaxb8b6kuuXM53G2WLVq0IDg4mF69ehEfH0/lypWJiopi48aNfPjhh7ZRt27duhEZGUlsbCwVK1YEYMCAAfTt25dWrVrRo0cPPD092bp1KzNmzKBZs2bUqVPHdp3p06cTFBRESEgIr7/+OhaLhRkzZnDu3DkmTpxo22/gwIGkpKTQuHFjypQpw4kTJ5gzZw579+5l0aJF2a55JyIiIiKSbwwDFi+GAQPgr7/A1RWGDYNRo+C6JbnkzuZwYQ5g1apVjBw5kjFjxnD+/HmqVatGVFQUHTp0sO2TlpZGWloa18/f0qdPH/z8/Jg5cybdu3cnKSkJf39/xo4dy4ABAzJco1GjRmzdupVRo0bRuXNnABo2bMhnn33GQw89ZNuvZs2azJ07l2XLlhEfH0+hQoV48MEH2bRpE82bN8/nT0JERERE5B+OH4cePWDjRnP7/vth4UKoW9euZcnt53CzWd7J4uPjKVKkyC3NWJNXUlJSWL9+PS1btrT7w58iN0v9V5yd+rA4M/VfO0pPh/ffNxcAT0gAd3cYNw4GDQJ9FzniSP03L7KBQ47MiYiIiIjIdX75Bbp3hy+/NLcbN4YPPjCfkZO7lsNNgCIiIiIiIv+TmgrTpkGdOmaQ8/KC2bPhiy8U5EQjcyIiIiIiDmnfPujWDb77ztwODoZ588Df365liePQyJyIiIiIiCNJToaxY+GBB8wgV7SoOcHJpk0KcpKBRuZERERERBzFt9+ao3E//mhuP/MMvPsulC1r17LEMWlkTkRERETE3i5fNmelbNTIDHKlSsFHH8GqVQpyki2NzImIiIiI2NNnn5kzVcbGmtvPPw+zZoGPjz2rEiegkTkREREREXu4eNFc/DsoyAxy5crBp5/CkiUKcpIjCnMiIiIiIrfbp5/CffeZs1MC9Oxp3l7ZsqV96xKnotssRURERERul3PnoH9/WLrU3L7nHnPx70cftWdV4qQ0MiciIiIikt8MA1asgBo1zCDn4gKDB5trySnISS5pZE5EREREJD+dOgWvvgqffGJu16wJCxbAgw/aty5xehqZExERERHJD4ZhhrYaNcwgZ7Wai4Hv2aMgJ3lCI3MiIiIiInntt9/glVdgyxZzu0EDM9jVqmXfuuSOopE5EREREZG8kpYGs2ebt1Ju2QIeHjBtGuzYoSAneU4jcyIiIiIieeHgQXPx7x07zO0mTcyZKqtUsW9dcsfSyJyIiIiIyK1ISYE33oC6dc0g5+0N774L27cryEm+0siciIiIiEhu/fADhIbC3r3m9hNPwNy5UKGCXcuSu4NG5kREREREbtaVKzBihDmxyd69ULw4LF4M69cryMlto5E5EREREZGbsWMHdOsGP/9sbj/7LLz9NpQubd+65K6jkTkRERERkZxISIB+/eDhh80gV6YMrFwJH3+sICd2oZE5EREREZF/ExNjrht39Ki53aULvPUWFCtmz6rkLqcwJyIiIiKSnQsXYNAgWLjQ3K5QAebNg5AQu5YlArrNUkREREQka598AjVq/B3kXnsNDhxQkBOHoZE5EREREZHr/fkn9O0LK1aY21WrwoIF5rNyIg5EI3MiIiIiIgCGAUuXmqNxK1aAqysMG2YuPaAgJw5II3MiIiIiIr//Dj17wqefmtt16pijcQ88YN+6RG5AI3MiIiIicvdKTzcnNLnvPjPIubnBxImwe7eCnDg8jcyJiIiIyN0pNha6d4fPPjO3GzY0R+Nq1LBrWSI5pZE5EREREbm7pKWZa8TVqmUGOU9PmDkTvvpKQU6cikbmREREROTu8eOPEBoKu3aZ2489BvPnQ0CAfesSyQWNzImIiIjIne/qVZgwAe6/3wxyhQubIW7LFgU5cVoamRMRERGRO9t335mjcfv3m9utWsF774Gfn33rErlFGpkTERERkTtTUhIMHQqBgWaQK1ECoqLgk08U5OSOoJE5EREREbnzfPGFOVPl4cPmdseOEB4OJUvaty6RPKSRORERERG5c1y6BL17Q9OmZpDz9YU1a2DZMgU5ueNoZE5ERERE7gwbN8Irr8CJE+Z29+4wbRoULWrXskTyi8KciIiIiDi38+dhwABYvNjcrlTJnKny8cftW5dIPtNtliIiIiLivP7zH6he3QxyFgv0729OdqIgJ3cBjcyJiIiIiPM5c8Z8Nm7VKnO7enVYsAAeesi+dYncRhqZExERERHnYRgQGQk1aphBrkABGDUKfvhBQU7uOhqZExERERHncOwY9OgBmzaZ2/XqmaNxdevatSwRe3HIkbmEhAT69++Pr68vHh4e1K1bl+XLl+fo2O3btxMcHEypUqXw9vamdu3azJ49m7S0tEz7JiYmMmbMGKpWrYq7uzs+Pj4EBQVx+Np6JP+TkpLC+PHj8ff3x93dnWrVqjFnzpw8ea8iIiIi8i/S0+Gdd6BmTTPIubtDWBh8+62CnNzVHHJkrm3btuzevZspU6ZQtWpVli1bRseOHUlPT6dTp07ZHrdlyxZCQkJo0qQJ8+fPx8vLizVr1tCvXz9iY2MJDw+37ZuQkEBQUBCnTp1i2LBh1K5dm4sXL7Jjxw4uX76c4byvvvoqS5YsYeLEiTRo0IBNmzbRr18/Ll26xIgRI/LtcxARERG56/3yC3TrBl99ZW43bmyOxt17r33rEnEADhfm1q9fT0xMjC3AAQQFBXHs2DGGDBlC+/btcXV1zfLYiIgIrFYr69atw8vLC4BmzZpx6NAhIiIiMoS5UaNGcfDgQfbt20dAQICt/emnn85wzh9//JEFCxYwefJkhgwZAsCjjz5KXFwckyZNomfPnhQvXjxPPwMRERGRu15qKsyYAWPHQnIyeHnBlCnw6qvg4pA3l4ncdg73OyE6Ohpvb2/atWuXob1r166cOnWKb7/9NttjrVYrbm5uFCxYMEN70aJF8fDwsG1fvnyZDz74gHbt2mUIcllZvXo1hmHQtWvXTPUkJSWxcePGnL41EREREcmJ//4XGjaEYcPMIBccDAcOwGuvKciJXMfhfjccOHCA6tWrU6BAxkHD2rVr217PTs+ePbl69Sp9+/bl1KlTXLhwgSVLlhAdHc3QoUNt++3Zs4fExESqVKlCr169KFasGG5ubtSvX59PP/00Uz0lS5akTJkyN12PiIiIiNyE5GQYMwbq14c9e6BoUVi0yHxOzt/f3tWJOByHu80yLi4uy9Gya7cyxsXFZXtsYGAg27Zto127drzzzjsAuLq6EhYWxqBBg2z7nTx5EoA333yTWrVqsXjxYlxcXJgxYwatWrViw4YNhISE2K6X1W2UXl5euLm53bCe5ORkkpOTbdvx8fGAOaFKSkpKtsfdDteub+86RHJD/VecnfqwOLP86r+WXbtwffllLAcPApDeujVps2dD2bLmLZciecCR/vzNixocLswBWCyWXL22Z88e2rRpQ2BgIHPnzsXLy4tt27YxatQorly5wujRowFIT08HwM3NjQ0bNlCoUCHAfDavSpUqTJw40RbmbqWesLAwxo8fn6l98+bNeHp6Znvc7RQTE2PvEkRyTf1XnJ36sDizvOq/rsnJVFu6lHvWrsViGFwpUoT9r7zCqUaNzLXjfvghT64jcj1H+PP3n5Mu5obDhTkfH58sR7vOnz8PcMPJRnr37k3p0qWJjo62TZISFBSEi4sL48aNo3PnzgQEBODj4wNAo0aNbEEOwNPTk6ZNm7J69eoM9ezduzfTtRITE7l69eoN6xk+fDgDBw60bcfHx1O+fHmaN29O4cKFsz3udkhJSSEmJobg4GCsVqtdaxG5Weq/4uzUh8WZ5WX/tXz2Ga4DB2I5cgSA9M6dcZ0+nbo+PtTNg1pF/smR/vy9dtferXC4MFerVi2ioqJITU3N8Nzc/v37AahZs2a2x+7du5eOHTtmmu2yQYMGpKenc/DgQQICAmzPu2XFMAxcrnuwtlatWixfvpwzZ85keG4uJ/W4u7vj7u6eqd1qtdq981zjSLWI3Cz1X3F26sPizG6p/168CEOHwrx55na5cjB3Li4tWzrehA5yR3KEP3/z4voO9/ulTZs2JCQksHLlygztkZGR+Pr6EhgYmO2xvr6+fPfdd5kWCN+5cycA5cqVA6Bs2bI89NBDfP311xkS8eXLl/n8889p2LChra1169ZYLBYiIyMznDMiIoKCBQvyxBNP5O6NioiIiNyN1q2D++77O8j16gU//ggtW9q3LhEn5HAjcy1atCA4OJhevXoRHx9P5cqViYqKYuPGjXz44Ye2Ubdu3boRGRlJbGwsFStWBGDAgAH07duXVq1a0aNHDzw9Pdm6dSszZsygWbNm1KlTx3ad6dOnExQUREhICK+//joWi4UZM2Zw7tw5Jk6caNvvvvvuo1u3bowdOxZXV1caNGjA5s2bmTdvHpMmTdIacyIiIiI5ce4c9OsHy5aZ25UrwwcfQNOm9q1LxIk5XJgDWLVqFSNHjmTMmDGcP3+eatWqERUVRYcOHWz7pKWlkZaWhmEYtrY+ffrg5+fHzJkz6d69O0lJSfj7+zN27FgGDBiQ4RqNGjVi69atjBo1is6dOwPQsGFDPvvsMx566KEM+7777rv4+fkxZ84czpw5g7+/P+Hh4fTp0ycfPwURERGRO4BhwIoV0KePGehcXGDgQBg/HhxkQjgRZ2Uxrk9Dkq/i4+MpUqQIFy9edIgJUNavX0/Lli3tfr+wyM1S/xVnpz4szuym+u+pU+ZtlGvWmNs1a8LChdCgQf4XKpIFR/rzNy+ygcM9MyciIiIiTs4wYMECqFHDDHJWK4wbZy4EriAnkmcc8jZLEREREXFSv/0GL78MW7ea2w0amKNxN5gBXERyRyNzIiIiInLr0tIgPNwMbVu3gocHTJ8OO3cqyInkE43MiYiIiEjOpKVh+fxz/L74AouXFwQFgasrHDwI3bqZwQ3MGSo/+MCcsVJE8o3CnIiIiIj8u1WroF8/Cvz+O/UB3noL/PygSRNYuRKuXoVChWDqVHjlFXPWShHJVwpzIiIiInJjq1bBs8+aE5tc7+RJiIoy/79FC5g7F8qXv/31idylFOZEREREJHtpaeZi3zdazap4cXPWygL60VLkdtL4t4iIiIhk78sv4fffb7zP+fPw1Ve3px4RsVGYExEREZHsnTiRs/1On87fOkQkE42Fi4iIiEhmiYkwbx688UbO9i9bNn/rEZFMFOZERERE5G/nz8Pbb8Ps2RAXZ7a5uEB6etb7WyxQrhw88sjtq1FEAIU5EREREQHzNsm33oL334eEBLOtcmV4/XVzyYGOHc226ydCsVjM/86aZa43JyK3lcKciIiIyN3syBFzbbhFi8y14gBq14YRI8zlCK6FNKvVnNXy+slQypUzg1zbtre9bBFRmBMRERG5O+3fD1OmwPLlf99C2bixGeJatPh71O2atm2hdWtSt29n74YN1G3RggJBQRqRE7EjhTkRERGRu8nOnRAWBmvX/t3WogUMH/7vz725umI0bcrJxETqNG2qICdiZwpzIiIiInc6w4CYGDPEffaZ2WaxQLt2MGwY3H+/XcsTkdxRmBMRERG5U6WnQ3S0GeL27DHbrFZ48UUYOhSqVrVvfSJySxTmRERERO40KSmwdCm8+Sb8/LPZ5ukJr7wCgwaZE5eIiNNTmBMRERG5U1y+DAsWwLRpcOKE2Va0KPTpA337QokSdi1PRPKWwpyIiIiIs7twAd5911wm4OxZs61MGRg4EHr0gMKF7VmdiOQThTkRERERZ/XHH2aAe/ddiI832ypVMp+H69IFPDzsWZ2I5DOFORERERFnc/SoeSvlwoVw5YrZVrOmOTNl+/ZQQD/iidwN9DtdRERExFn89JO50PeyZZCWZrY1bGiuEffUU+DiYt/6ROS2UpgTERERcXS7dpnLC6xe/XdbcDCMGAFNm5prxonIXUdhTkRERMQRGQZs22aGuK1bzTaLBdq0MUfi6te3b30iYncKcyIiIiKOJD0d1qwxQ9yuXWZbgQLQuTO8/jpUr27f+kTEYSjMiYiIiDiClBRYvtx8Ju6nn8w2Dw94+WVzoe+KFe1bn4g4HIU5EREREXtKSoJFi8zZKY8eNdsKF4bevaF/fyhVyp7ViYgDU5gTERERsYf4eHjvPZg501wvDqBkSXOh7169oEgR+9YnIg5PYU5ERETkdjp7FsLD4e234eJFs61CBXOh79BQKFjQvvWJiNNQmBMRERG5HY4fhxkzYP5889ZKMCczGTYMOnYEq9W+9YmI01GYExEREclPhw7Bm2/CkiWQmmq21a9vrhHXurUW+haRXFOYExEREckP339vLi+wcqW5ZhzAY4+Za8Q9/rgW+haRW6YwJyIiIpJXDAO++ALeeAM2b/67vXVrM8QFBtqvNhG54yjMiYiIiNwqw4BPPzVD3M6dZpurq/ks3OuvQ82a9q1PRO5ICnMiIiIiuZWaCh9/bN5OuX+/2ebubs5KOWQIVKpk3/pE5I6mMCciIiJys65cgchImDoVjhwx2woVMteHGzAAypSxb30icldQmBMRERHJqUuXYO5ceOstOH3abCtRAvr1g969oVgx+9YnIncVhTkRERGRfxMXB7Nnw5w58NdfZlu5cjB4MHTvDl5e9q1PRO5KCnMiIiIi2Tl50lzoe948SEw026pWNSc1ef55cHOzb30icldTmBMRERH5p8OHzefhIiMhJcVsu/9+c3mBtm3NmSpFROxMYU5ERETkmr17YcoUc4bK9HSzrUkTGDECmjfXQt8i4lAU5kRERES++spcXmD9+r/bnnzSHIlr3Nh+dYmI3ICLvQvISkJCAv3798fX1xcPDw/q1q3L8uXLc3Ts9u3bCQ4OplSpUnh7e1O7dm1mz55NWlpahv0effRRLBZLpl9PPPFEhv2OHj2a5X4WiyXHNYmIiIgDMgzYsMEceXvkETPIubhAhw7mCN26dQpyIuLQHHJkrm3btuzevZspU6ZQtWpVli1bRseOHUlPT6dTp07ZHrdlyxZCQkJo0qQJ8+fPx8vLizVr1tCvXz9iY2MJDw/PsH9AQABLly7N0Fa0aNEsz92nT59M165SpUru3qCIiIjYT1oarFxpjsTt3Wu2ublBly7mQt+VK9uzOhGRHHO4MLd+/XpiYmJsAQ4gKCiIY8eOMWTIENq3b49rNg8dR0REYLVaWbduHV7/myK4WbNmHDp0iIiIiExhrmDBgjRs2DBHdVWoUCHH+4qIiIgDunoVliyBN980JzgBc0mBnj1h4EDw9bVvfSIiN8nhbrOMjo7G29ubdu3aZWjv2rUrp06d4ttvv832WKvVipubGwULFszQXrRoUTw8PPKlXhEREXFwiYkwaxYEBJhrwh0+bC7uPW4cHDsG06cryImIU3K4kbkDBw5QvXp1ChTIWFrt2rVtrzdq1CjLY3v27ElUVBR9+/ZlxIgReHp6snbtWqKjowkLC8u0f2xsLMWLFyc+Pp6KFSvSoUMHRo0alSkMAkyZMoURI0ZQoEAB6tWrx9ChQ3n66adv+F6Sk5NJTk62bcfHxwOQkpJCyrVpju3k2vXtXYdIbqj/irNTH75N/voLl3ffxeXtt7HExQFg+PqS3r8/6d27g7e3uZ++h5ui/ivOzJH6b17UYDEMw8iDWvJM1apVCQgIYOPGjRnaT58+ja+vL2+88QbDhw/P9vgdO3bQrl07Tp06BYCrqythYWEMGTIkw36jRo3Cz8+PatWqkZSUxIYNG3j//fdp1KgR27dvx8XFxXbdsWPHEhwcTNmyZTl+/Dhz5szhm2++Yf78+XTv3j3bWsaNG8f48eMztS9btgxPT88cfyYiIiKSc+7nz3PPmjVU2riRAleuAJBQpgy/tm3LiaAg0q1WO1coIgKXL1+mU6dOXLx4kcKFC+fqHA4Z5u655x42bNiQof1amAsLC2PYsGFZHrtnzx5atmxJYGAgr7zyCl5eXmzbto2pU6cyatQoRo8efcNrz5gxg8GDB7Nq1SratGmT7X4pKSkEBgZy/Phxzpw5k2kU8ZqsRubKly/PuXPncv2F5ZWUlBRiYmIIDg7Gqr/UxMmo/4qzUx/OJ0eO4DJjBi6RkViuXgXAqFWLtKFDMf7v/yCbv6/l5qj/ijNzpP4bHx9PiRIlbinMOdyfaj4+PsT971aI650/fx6A4sWLZ3ts7969KV26NNHR0bZJUoKCgnBxcWHcuHF07tyZgICAbI9//vnnGTx4MN98880Nw5zVaqV9+/YMGzaMw4cPU7169Sz3c3d3x93dPcvj7d15rnGkWkRulvqvODv14Tyyf7+50Pfy5X8v9N2oEYwYgaVlSwpooe98of4rzswR+m9eXN/hJkCpVasWBw8eJDU1NUP7/v37AahZs2a2x+7du5cHHngg02yXDRo0ID09nYMHD+aohmu3WN7ItQHNnOwrIiIi+WDnTnj6aahdG5YtM4PcE0/A55+bi4A/+SQoyInIHczhkkibNm1ISEhg5cqVGdojIyPx9fUlMDAw22N9fX357rvvMi0QvnPnTgDKlSt3w2tHRkYC/OsSBCkpKaxYsYISJUpQWWvRiIiI3D6GAZs3Q1CQOfq2dq0Z2Nq1gz17/l4EXCFORO4CDnebZYsWLQgODqZXr17Ex8dTuXJloqKi2LhxIx9++KFt1K1bt25ERkYSGxtLxYoVARgwYAB9+/alVatW9OjRA09PT7Zu3cqMGTNo1qwZderUAeDLL79k8uTJtGnThoCAAK5cucKGDRuYN28ejz32GK1atbLVM3DgQFJSUmjcuDFlypThxIkTzJkzh71797Jo0aJs17wTERGRPJSeDtHR5kLfe/aYbQUKwIsvwtChcO+99q1PRMQOHC7MAaxatYqRI0cyZswYzp8/T7Vq1YiKiqJDhw62fdLS0khLS+P6+Vv69OmDn58fM2fOpHv37iQlJeHv78/YsWMZMGCAbb+yZcvi6urKxIkTOXfuHBaLhSpVqjBhwgQGDRqU4dbJmjVrMnfuXJYtW0Z8fDyFChXiwQcfZNOmTTRv3vz2fCAiIiJ3q5QUWLrUXOj755/NtoIF4ZVXYNAgKF/evvWJiNiRQ4Y5b29vwsPDCQ8Pz3afiIgIIiIiMrW3bduWtm3b3vD8lStX5tNPP81RLaGhoYSGhuZoXxEREckjly/DggUwbRqcOGG2FS0Kr70GfftCyZJ2LU9ExBE4ZJgTERGRu9SFC/DuuzBrFpw9a7aVLm2OwvXoAXZe2kdExJEozImIiIj9/fGHGeDefRfi4802f3/zebiuXcHDw57ViYg4JIU5ERERsZ+jR2H6dPOWyitXzLb77oPhw6F9ey30LSJyA/oTUkRERG6/n34yF/petgyuLSkUGGiGuFatQOu4ioj8K4U5ERERuX127TKXF1i9+u+2Zs1gxAh49FGtDycichMU5kRERCR/GQZs3w5vvAFbt/7d3qaNORLXoIH9ahMRcWK5CnPnzp2jRIkSeV2LiIiI3EnS02HNGnMkbtcus83VFTp3htdfhxo17FufiIiTy9UN6eXKlaN9+/bExMTkdT0iIiLi7FJSYMkSqFXLHH3btcucjfK11yA2FiIjFeRERPJArsJc7dq1+fjjj3niiSeoVKkSkyZN4uTJk3ldm4iIiDiTpCRzaYGqVeHFF81JTgoXNm+lPHoU5syBihXtXaWIyB0jV2Fu165d7Nu3j9dee41Lly4xZswY/P39efrpp1mzZg3p6el5XaeIiIg4qvh4ePNNqFQJevc2g1vJkuYzcsePm/8tXdreVYqI3HFyPe9vzZo1CQ8P59SpUyxbtoymTZvy6aef0qZNG8qXL8/IkSM5cuRIXtYqIiIijuTsWRg1CipUgGHDzIW/K1QwR+COHjVH5IoUsXeVIiJ3rFtexMXNzY0OHTqwZcsWYmNjGTlyJGlpaUyZMoWqVasSHBzMypUrMQwjL+oVEREReztxAvr1M2+ZnDwZLl6EatUgIgJ+/dV8Ns7T095Viojc8fJsRU7DMDhw4AD79u0jLi4OwzAoW7Ysn3/+Oc899xx169bl8OHDeXU5ERERud0OHYLQUAgIgNmzzWfk6teHlSvhxx/hpZfAarV3lSIid41bDnO//fYbo0aNonz58rRu3ZoNGzbwzDPPsHnzZk6cOMGxY8cYNGgQP/30E7169cqLmkVEROR2+v57aNcOqleHRYsgNRWCgmDzZnOmyrZtwSXP/n1YRERyKFfrzKWkpLBy5Uo++OADPvvsM9LT06lUqRKTJ08mNDSUUqVK2fYtW7YsU6dO5dKlSyxZsiTPChcREZF8ZBjwxRfm5CWbN//d/vTT5rNwDRvarzYREQFyGeZ8fX05f/48rq6uPPPMM/To0YPg4OAbHlOxYkUuX76cqyJFRETkNjEM+PRTM8Tt3Gm2ubpChw7mJCc1a9q3PhERsclVmPP29mbgwIGEhoZSOodTDb/66qt07NgxN5cTERGR/JaaCh9/DGFhsH+/2ebuDl27wpAh5nNyIiLiUHIV5o4cOYLFYrmpYwoXLkzhwoVzczkRERHJL8nJEBlprhN3bUkhb2/o1QsGDICyZe1bn4iIZCtXYS4+Pp5jx45RuXJlPLOYejgxMZHY2Fj8/f0V4ERERBzRpUswdy689RacPm22+fiYSw689hoUK2bf+kRE5F/lauqpCRMm0KhRI9LS0rJ8PS0tjcaNGzN58uRbKk5ERETyWFwcjB1rrhE3ZIgZ5Pz8YNYsOHYMRo9WkBMRcRK5CnMbN26kefPmFCpUKMvXCxcuTEhICOvXr7+l4kRERCSPnDwJAweaIW7CBPjrL6hSBRYsMG+v7NcPvLzsXaWIiNyEXIW548ePU6VKlRvuc88993D8+PFcFSUiIiJ55PBhePllqFQJZs6ExESoWxc++ggOHjQXAXdzs3eVIiKSC7l6Zs5isZCcnHzDfZKTk7O9DVNERETy2d69MGWKOUNlerrZ1qSJuUZcSAjc5ERmIiLieHIV5qpXr87GjRsxDCPLWS3T09PZsGED99577y0XKCIiIjfhq6/M5QWuf9ThySfNENe4sf3qEhGRPJer2yw7derEL7/8QmhoKBcvXszw2sWLFwkNDeXXX3/l+eefz5MiRURE5AYMAzZsMEfeHnnEDHIuLuZC33v3wrp1CnIiInegXI3Mvfrqq6xatYrIyEg++eQTGjRogJ+fHydPnmT37t1cuHCBJk2a8Nprr+V1vSIiInJNWhqsXGmOxO3da7ZZrdClCwwdCpUr27M6ERHJZ7kKc1arlc2bNzN69GjmzZtHTEyM7bXChQszZMgQJkyYgNVqzbNCRURE5H+uXoUlS8yFvg8fNtu8vKBHD3PGSj8/+9YnIiK3Ra7CHIC7uztTp05lypQp/Pzzz1y4cIGiRYty77334urqmpc1ioiICJgzUc6fD9Onm0sNgLkmXN++0KePuei3iIjcNXId5q5xcXGhRo0aeVGLiIiIZOWvv+DttyE83Fz0G6BsWRg0CF55BbJZ91VERO5stxzmREREJJ+cPg1vvQXvvw8JCWbbPfeYz8O99BK4u9u3PhERsatch7lLly7x9ttvs2XLFk6dOpXlunMWi4XY2NhbKlBEROSuc+QITJ0KixaZz8cB1KplLi/Qrh0U0L/FiohILsPc2bNnadSoEbGxsRQuXJj4+HiKFCnC1atXSUpKAsDX11cToIiIiPxTWhqWzz/H74svsHh5QVAQXHvWfP9+c6Hv5cv/Xui7USMzxD35pBb6FhGRDHK1zty4ceOIjY1l8eLF/PXXXwAMGDCAxMREvv32Wx588EH8/f358ccf87RYERERp7ZqFfj7UyA4mPpvvUWB4GDw9zeXFnj6aahdG5YtM4NcSAh8/rm5CPhTTynIiYhIJrkKc+vXr+fxxx/n+eefx/KPv1waNGjAhg0bOHr0KOPGjcuLGkVERJzfqlXw7LPw++8Z23//HUaMgLVrzcD27LOwZw9s3GguAq4QJyIi2chVmDt9+jT333+/bdvV1dV2eyVAsWLFaNGiBR9//PGtVygiIuLs0tKgXz8wjOz38fKCAwfg44+hXr3bV5uIiDitXIW5IkWKkJKSYtsuVqwYv//jXxoLFy7MH3/8cWvViYiI3Am+/DLziNw/JSbCn3/ennpEROSOkKswFxAQwNGjR23b999/PzExMZw/fx6ApKQk1q5dS4UKFfKkSBEREad2+nTe7iciIkIuw1zz5s3ZunUrly9fBqBHjx78+eef1KlTh3bt2lGzZk1iY2Pp0qVLXtYqIiLifOLjISIiZ/uWLZuvpYiIyJ0lV2GuZ8+ezJ8/3xbm2rZty7Rp00hISGDlypWcOXOGgQMHMmTIkDwtVkRExKl89RXUqQObN994P4sFypeHRx65PXWJiMgdIVdhrmzZsrRv354SJUrY2gYNGsS5c+c4ffo0CQkJTJs2Dddr6+aIiIjcTa5ehZEjoWlTOHrUXH5g0iQztP1zdspr27Nm/b3enIiISA7kKsyFhoYya9asTO2urq6ULl0603IFIiIid42ff4aHHoI33jDXi3vpJfjvf81w95//gJ9fxv3LlTPb27a1T70iIuK0CuTmoGXLllG6dOm8rkVERMR5GQa89x4MHgxJSVCsGMybZ64bd03bttC6Nanbt7N3wwbqtmhBgaAgjciJiEiu5CrMVa5cmdOacUtERMR05gyEhsKGDeZ2cDAsWpR5FA7A1RWjaVNOJiZSp2lTBTkREcm1XN1m2a1bNz799FNOnjyZ1/UAkJCQQP/+/fH19cXDw4O6deuyfPnyHB27fft2goODKVWqFN7e3tSuXZvZs2eTlpaWYb9HH30Ui8WS6dcTTzyR6ZwpKSmMHz8ef39/3N3dqVatGnPmzMmT9yoiIk5u9WqoVcsMcu7u5rNvGzdmHeRERETyUK5G5tq0acPWrVtp1KgRQ4cOpUGDBtk+K5ebtebatm3L7t27mTJlClWrVmXZsmV07NiR9PR0OnXqlO1xW7ZsISQkhCZNmjB//ny8vLxYs2YN/fr1IzY2lvDw8Az7BwQEsHTp0gxtRYsWzXTeV199lSVLljBx4kQaNGjApk2b6NevH5cuXWLEiBE3/f5EROQOkJAAAwbABx+Y23XqwNKlcN999q1LRETuGrkKcwEBAVgsFgzDoG/fvtnuZ7FYSE1Nvalzr1+/npiYGFuAAwgKCuLYsWMMGTKE9u3bZztLZkREBFarlXXr1uHl5QVAs2bNOHToEBEREZnCXMGCBWnYsOEN6/nxxx9ZsGABkydPti218OijjxIXF8ekSZPo2bMnxYsXv6n3KCIiTu6bb+D55yE21pyNcvBgmDjRHJkTERG5TXIV5l588cV8m7EyOjoab29v2rVrl6G9a9eudOrUiW+//ZZGjRpleazVasXNzY2CBQtmaC9atCgeHh65qmf16tUYhkHXrl0z1TN//nw2btx4w9FCERG5g6SkwOTJ5jIDaWnm2nCLF8Ojj9q7MhERuQvlKsxFRETkcRl/O3DgANWrV6dAgYyl1a5d2/Z6dmGuZ8+eREVF0bdvX0aMGIGnpydr164lOjqasLCwTPvHxsZSvHhx4uPjqVixIh06dGDUqFEZwuCBAwcoWbIkZcqUybae7CQnJ5OcnGzbjo+PB8xn8FJSUm70MeS7a9e3dx0iuaH+K3Zx+DCuXbvismsXAOkdOpA2ezYULWqGvJugPizOTP1XnJkj9d+8qCFXYS4/xcXFERAQkKn92q2McXFx2R4bGBjItm3baNeuHe+88w5grn0XFhbGoEGDMuz78MMP0759e6pVq0ZSUhIbNmxg6tSpfPXVV2zfvh0XFxfb9bK6jdLLyws3N7cb1hMWFsb48eMztW/evBlPT89sj7udYmJi7F2CSK6p/8ptYRhUjImh5oIFuCQnk+LpyX979uRkkyawY8ctnVp9WJyZ+q84M0fov5cvX77lczhcmANueAvnjV7bs2cPbdq0ITAwkLlz5+Ll5cW2bdsYNWoUV65cYfTo0bZ9J02alOHYli1b4u/vz+DBg/nkk09o06bNLdczfPhwBg4caNuOj4+nfPnyNG/enMKFC2d73O2QkpJCTEwMwcHBWK1Wu9YicrPUf+W2OXsW1x49cFm3DoD0pk1hwQLqVKhAnVs4rfqwODP1X3FmjtR/r921dytyPQFKTlgsFmJjY2/q3D4+PlmOdp0/fx7ghpON9O7dm9KlSxMdHW2bJCUoKAgXFxfGjRtH586db1j7888/z+DBg/nmm29sYc7Hx4e9e/dm2jcxMZGrV6/esB53d3fcs3gY3mq12r3zXONItYjcLPVfyVfr15trx/3xB1it8MYbuAwcaLtzIy+oD4szU/8VZ+YI/Tcvrp+rv5HS09MxDCPTrwsXLnD06FGOHj1KcnIy6enpN33uWrVqcfDgwUyzYO7fvx+AmjVrZnvs3r17eeCBBzLNdtmgQQPS09M5ePBgjmq4/i/qWrVqcfbsWc6cOXPT9YiIiBO6fBlefRWefNIMcvfdB7t3mzNW5mGQExERuVW5+lvp6NGj/Pbbb5l+nT9/niNHjvDMM8/g7+/Pjz/+eNPnbtOmDQkJCaxcuTJDe2RkJL6+vgQGBmZ7rK+vL999912mBcJ37twJQLly5W547cjISIAMyxW0bt0ai8Vie+2aiIgIChYsmOUi4yIi4qS++w7q1YP33jO3+/c32+rcyk2VIiIi+SPPn5nz9/dnxYoV1KlTh5EjRzJz5sybOr5FixYEBwfTq1cv4uPjqVy5MlFRUWzcuJEPP/zQNurWrVs3IiMjiY2NpWLFigAMGDCAvn370qpVK3r06IGnpydbt25lxowZNGvWjDr/+8v4yy+/ZPLkybRp04aAgACuXLnChg0bmDdvHo899hitWrWy1XPffffRrVs3xo4di6urKw0aNGDz5s3MmzePSZMmaY05EZE7QVoaTJkC48ZBair4+kJEBAQH27syERGRbOXLBChWq5Xg4GA++uijmw5zAKtWrWLkyJGMGTOG8+fPU61aNaKioujQoYNtn7S0NNLS0jAMw9bWp08f/Pz8mDlzJt27dycpKQl/f3/Gjh3LgAEDbPuVLVsWV1dXJk6cyLlz57BYLFSpUoUJEyYwaNCgTM9DvPvuu/j5+TFnzhzOnDmDv78/4eHh9OnTJxefjoiIOJTffoMXXoCvvza3n30W5s4F/WOdiIg4uHybzfLy5cu2SUtulre3N+Hh4YSHh2e7T0RERJbr3bVt25a2bdve8PyVK1fm008/zXE9VquVcePGMW7cuBwfIyIiDs4wzAW/+/SBS5egUCF4+20z2N1gpmIRERFHkS9h7osvviAqKop77703P04vIiJya+LioEcPuPZ8duPGsGQJVKpk37pERERuQq7C3GOPPZZle2pqKidPnuTo0aMYhsGoUaNuqTgREZE8t3kzdOkCp09DgQIwYQIMHQr/mAlZRETE0eUqzH322WdZtlssFooVK0ZwcDADBgwgJCTkVmoTERHJO0lJMGwYzJ5tbt97LyxdCg88YN+6REREcilXYS4368eJiIjYzd690Lkz/PSTud27N0ydCp6edi1LRETkVmj1UxERuXOlpZmh7cEHzSBXujR8+qk50YmCnIiIOLlchbmLFy+yb98+Ll++nOXriYmJ7Nu3j/j4+FsqTkREJNeOH4fHH4fXX4eUFGjdGvbvh5Yt7V2ZiIhInshVmJswYQKNGjUiLS0ty9fT0tJo3LgxkydPvqXiREREcmXZMqhdGz7/HLy84IMPIDoaSpa0d2UiIiJ5JldhbuPGjTRv3pxChQpl+XrhwoUJCQlh/fr1t1SciIjITfnrL+jUyXw+7uJFaNjQfF6uWzetHSciInecXIW548ePU6VKlRvuc88993D8+PFcFSUiInLTtm83R+OiosxlBsaPhy+/hMqV7V2ZiIhIvsjVbJYWi4Xk5OQb7pOcnJztbZgiIiJ5JjkZRo6Et94CwzDD24cfQmCgvSsTERHJV7kKc9WrV2fjxo0YhoEli9tW0tPT2bBhA/fee+8tFygiIpKtAwfMWyr37TO3X37ZDHXe3vatS0RE5DbI1W2WnTp14pdffiE0NJSLFy9meO3ixYuEhoby66+/8vzzz+dJkSIiIhmkp8OsWVC/vhnkSpSATz6BefMU5ERE5K6Rq5G5V199lVWrVhEZGcknn3xCgwYN8PPz4+TJk+zevZsLFy7QpEkTXnvttbyuV0RE7na//w5dusDWreZ2y5awYAGUKWPXskRERG63XI3MWa1WNm/ezODBg0lPTycmJoaIiAhiYmJIT09nyJAhbNq0CavVmtf1iojI3ezjj81JTrZuhYIF4b33YN06BTkREbkr5WpkDsDd3Z2pU6cyZcoUfv75Zy5cuEDRokW59957cXV1zcsaRUTkbnfxIvTtC4sXm9sPPABLl4KezRYRkbtYrsPcNS4uLtSoUSMvahEREcnsyy/hhRfg2DFwcYHhw2HsWNDdHyIicpfL1W2WP/30E7Nnz+bs2bNZvv7nn38ye/ZsDh48eEvFiYjIXezqVRgxApo2NYNcpUrwxRcwaZKCnIiICLkMc1OmTOHNN9/Ex8cny9d9fHyYNm0aU6dOvaXiRETkLnXwIDz0EISFmWvHdekCe/dC48b2rkxERMRh5CrMffnllzz++OO4uGR9uKurK48//jhffPHFLRUnIiJ3GcOAd96BevXg+++heHH4z39g0SIoXNje1YmIiDiUXD0zd+bMGcqXL3/Dffz8/Dh9+nSuihIRkbvQmTMQGgobNpjbwcEQEQG+vnYtS0RExFHlamTOy8uLP//884b7/Pnnn3h4eOSqKBERuctER0PNmmaQc3eH8HDYuFFBTkRE5AZyFeYeeOABVq9ezYULF7J8/a+//iI6Opp69erdSm0iInKnS0iA7t2hbVuIi4M6dWDPHnMZgmxu5RcRERFTrv6m7N27N3FxcQQFBWV6Lu7zzz8nKCiIv/76i9deey1PihQRkTvQzp1Qty4sWAAWCwwdCt9+C/fdZ+/KREREnEKunpl7+umnGTx4MNOnTycoKAh3d3fKlCnDmTNnSE5OxjAMBg8ezDPPPJPH5YqIiNNLSTGXF5g0CdLToUIFczHwpk3tXZmIiIhTyfU9LFOnTmXdunU88cQTeHt78/vvv+Pt7U2LFi349NNPmTp1KqmpqXlZq4iIOLvDh+Hhh2HCBDPIde4M//2vgpyIiEgu5Gpk7pqWLVvSsmXLTO0//fQTgwYNYunSpZw5c+ZWLiEiIncCw4D582HAALh8GYoUgffeg44d7V2ZiIiI07qlMHe9hIQEli9fzoIFC9i1axeGYeDm5pZXpxcREWf155/mJCdr15rbQUEQGQn/ssSNiIiI3Ngth7mvvvqKhQsX8vHHH3P58mUMw+D++++na9eudOrUKS9qFBERZ/Xpp+bacX/+CW5u8MYb5uicZqoUERG5ZbkKc3/88QeRkZEsXLiQw4cPYxgGZcqUITExkRdffJGIiIg8LlNERJxKYiIMHgzvv29u33cfLF1qLj0gIiIieSLHYS49PZ1PP/2UBQsWsH79elJTU/Hw8OC5557jxRdfpHnz5litVt1aKSJyt9u9G55/Hn75xdweMMAckfPwsG9dIiIid5gch7ly5crxxx9/ANC4cWNefPFFnnvuOQoXLpxvxYmIiBNJTYUpU2D8ePP/fX3NZ+OaNbN3ZSIiInekHIe5M2fO4OLiwqBBgxg+fDhFixbNx7JERMSpHDkCL7wAO3aY2+3ambdYFi9u37pERETuYDl+Av3555/Hw8OD6dOnU7ZsWdq1a8eaNWu0lpyIyN3MMCAiwnwWbscOKFTIXAB8xQoFORERkXyW4zC3ePFiTp8+zbvvvkutWrVYuXIlbdq0oUyZMrz22mt88803+VmniIg4mrg4ePZZ6NoVEhLgkUdg3z5zhM5isXd1IiIid7ybmhu6UKFC9OjRg127drFv3z769OmDxWLh3XffpXHjxlgsFg4dOsTx48fzq14REXEEmzZBrVqwahUUKABhYbB9O/j727syERGRu0auF/qpWbMms2bN4tSpUyxfvpzg4GAsFgtffvklAQEBBAcHExUVlZe1ioiIvSUlQb9+8MQTcPo0VKsG334Lw4aBq6u9qxMREbmr3PKqrVarleeee46NGzdy9OhRxo0bR4UKFdi6dSvPP/98XtQoIiKO4IcfoH59mD3b3O7dG/bsgXr17FuXiIjIXeqWw9z1ypUrx5gxYzhy5AibN2+mffv2eXl6ERGxh7Q0ePNNCAyEn36CMmVg/Xp4+23w9LR3dSIiInetHC9NcLOaNWtGM60tJCLi3I4dgxdfhC++MLefeQbmzYOSJe1aloiIiOTxyJyIiNwhDAOWLoXatc0g5+UFH3xgTniiICciIuIQ8m1kTkREnNRff0GvXuZacQANG8KHH8I999i3LhEREclAI3MiIvK3bdvM0bgVK8zZKSdMgC+/VJATERFxQBqZExERSE6GkSNhxgxzu3JlczQuMNC+dYmIiEi2HHJkLiEhgf79++Pr64uHhwd169Zl+fLlOTp2+/btBAcHU6pUKby9valduzazZ88mLS0t22OSkpKoWrUqFouF6dOnZ3jt6NGjWCyWLH/ltCYREYe2fz80aPB3kHvlFXMZAgU5ERERh+aQI3Nt27Zl9+7dTJkyhapVq7Js2TI6duxIeno6nTp1yva4LVu2EBISQpMmTZg/fz5eXl6sWbOGfv36ERsbS3h4eJbHjR49msTExBvW1KdPn0zXrlKlys2/ORERR5GeDuHhMHy4OTJXsiQsWACtWtm7MhEREckBhwtz69evJyYmxhbgAIKCgjh27BhDhgyhffv2uLq6ZnlsREQEVquVdevW4eXlBZhLJBw6dIiIiIgsw9yuXbuYM2cOS5cupV27dtnWVaFCBRo2bJgH71BExAH8/jt06QJbt5rbTz5pBrnSpe1aloiIiOScw91mGR0djbe3d6Zg1bVrV06dOsW3336b7bFWqxU3NzcKFiyYob1o0aJ4eHhk2v/q1auEhobSu3dv6tevnzdvQETE0X30EdSqZQa5ggXhvfdg7VoFORERESfjcCNzBw4coHr16hQokLG02rVr215v1KhRlsf27NmTqKgo+vbty4gRI/D09GTt2rVER0cTFhaWaf8JEyaQmJjIxIkTOXv27A3rmjJlCiNGjKBAgQLUq1ePoUOH8vTTT9/wmOTkZJKTk23b8fHxAKSkpJCSknLDY/Pbtevbuw6R3FD/zaWLF3Ht3x+XpUsBSH/gAdIiIuDeeyE11b613WXUh8WZqf+KM3Ok/psXNThcmIuLiyMgICBTe/HixW2vZycwMJBt27bRrl073nnnHQBcXV0JCwtj0KBBGfbdu3cvU6dOZe3atXh5eWUb5tzd3Xn55ZcJDg6mbNmyHD9+nDlz5tC6dWvmz59P9+7ds60nLCyM8ePHZ2rfvHkznp6e2R53O8XExNi7BJFcU//NueI//sgDs2ZhPXsWw8WFX/7v/zjUvj1GbCzExtq7vLuW+rA4M/VfcWaO0H8vX758y+dwuDAHYLFYcvXanj17aNOmDYGBgcydOxcvLy+2bdvGqFGjuHLlCqNHjwYgNTWV0NBQ2rdvT0hIyA1rKVu2LPPmzcvQ1q5dOwIDAxk2bBhdunTJNIp4zfDhwxk4cKBtOz4+nvLly9O8eXMKFy58w+vmt5SUFGJiYggODsZqtdq1FpGbpf57E65exWX8eFymT8diGBiVKpEWEUHAQw+R+Z/N5HZRHxZnpv4rzsyR+u+1u/ZuhcOFOR8fnyxH386fPw/8PUKXld69e1O6dGmio6Ntk6QEBQXh4uLCuHHj6Ny5MwEBAcyaNYsjR47w0UcfceHCBeDvD/PKlStcuHCBQoUKZTvRitVqpX379gwbNozDhw9TvXr1LPdzd3fH3d09y+Pt3XmucaRaRG6W+u+/OHgQOnc2lxkA6NoVy6xZFLDzPybJ39SHxZmp/4ozc4T+mxfXd7gJUGrVqsXBgwdJ/cfzG/v37wegZs2a2R67d+9eHnjggUwhrEGDBqSnp3Pw4EHAfO7u4sWLVKlShWLFilGsWDHq1KkDmMsUFCtWzHa97BiGAYCLi8N9hCJytzMMePttqFfPDHLFi8PKlbBwISjIiYiI3DEcLom0adOGhIQEVq5cmaE9MjISX19fAm+wiK2vry/fffddpgXCd+7cCUC5cuUAGDZsGNu3b8/wKyoqCjAnUdm+fTuVK1fO9jopKSmsWLGCEiVK3HA/EZHb7vRpaNkS+vSBK1egeXNzUfC2be1dmYiIiOQxh7vNskWLFgQHB9OrVy/i4+OpXLkyUVFRbNy4kQ8//NA26tatWzciIyOJjY2lYsWKAAwYMIC+ffvSqlUrevTogaenJ1u3bmXGjBk0a9bMNvpWrVo1qlWrluG6R48eBeCee+7h0UcftbUPHDiQlJQUGjduTJkyZThx4gRz5sxh7969LFq0KNtbMUVEbrvoaHj5ZYiLAw8PmDoVevcG3UEgIiJyR3K4MAewatUqRo4cyZgxYzh//jzVqlUjKiqKDh062PZJS0sjLS3NdrsjQJ8+ffDz82PmzJl0796dpKQk/P39GTt2LAMGDMhVLTVr1mTu3LksW7aM+Ph4ChUqxIMPPsimTZto3rz5Lb9XEZFbdukS9O9v3kYJULcuLF0KNWrYsyoRERHJZw4Z5ry9vQkPDyc8PDzbfSIiIoiIiMjU3rZtW9rm4nYif3//DMHwmtDQUEJDQ2/6fCIit8XOnfD883DkCFgsMHQoTJgAbm72rkxERETymUOGORER+RcpKTBxIkyeDOnpUKECLF4MTZvauzIRERG5TRTmRESczS+/mKNxu3eb288/b85eWaSIfesSERGR20pPxYuIOAvDgHnz4P77zSBXtChERcGSJQpyIiIidyGNzImIOIM//4Ru3WDdOnP7sccgIgLKl7drWSIiImI/GpkTEXF069ZBrVrmf93cYMYMiIlRkBMREbnLaWRORMRRJSbCoEEwd665XbOmueRA7dr2rUtEREQcgkbmREQc0e7d5rNx14LcwIFmm4KciIiI/I/CnIiII0lNhUmT4KGH4PBh8PODLVvMWys9POxdnYiIiDgQ3WYpIuIoYmPhhRfMhcABnnsO3nsPihe3b10iIiLikDQyJyJib4YBCxdC3bpmkCtc2FxuYPlyBTkRERHJlkbmRETs6dw56NEDVq0ytx95BBYvBn9/u5YlIiIijk8jcyIi9rJpk7nkwKpVYLVCWBhs364gJyIiIjmikTkRkdstKQlefx3mzDG3q1eHDz+EevXsW5eIiIg4FYU5EZHb6YcfoHNnOHjQ3H7tNZg6FQoWtG9dIiIi4nR0m6WIyO2QlgZvvgmBgWaQK1MGNmwwR+cU5ERERCQXNDInIpLfjh2DF1+EL74wt9u0gXnzoEQJ+9YlIiIiTk0jcyIi+cUwzGfhatc2g5y3t7kEwcqVCnIiIiJyyzQyJyKSH/76C3r1ghUrzO2HHjLXjrvnHvvWJSIiIncMjcyJiOS1rVvNJQdWrABXV5gwwRyZU5ATERGRPKSRORGRvHLlCowcCW+9ZW5XqWLeZvngg/atS0RERO5ICnMiInlh/35zyYH9+83tHj1gxgzw8rJvXSIiInLH0m2WIiK3Ij3dHImrX98MciVLwpo18P77CnIiIiKSrzQyJyKSW7//Di+9BNu2mdtPPQUffAClS9u3LhEREbkraGRORCQ3PvrInORk2zbw9DRH4tasUZATERGR20YjcyIiN+PiRXjtNXNiE4AGDcz/r1rVvnWJiIjIXUcjcyIiOfXFF+YC4B9+CC4uMHo0fP21gpyIiIjYhUbmRET+zdWrMGYMTJ0KhgEBAeYC4I0a2bsyERERuYspzImI3MhPP8Hzz8MPP5jboaEwaxYUKmTXskRERER0m6WISFYMA+bMgQceMIOcjw+sXAkLFijIiYiIiEPQyJyIyD+dPg1du8KmTeZ2SAgsWgRly9q3LhEREZHraGROROR6q1aZSw5s2gQeHubo3IYNCnIiIiLicDQyJyICcOkS9OtnjsAB1K0LS5dCjRp2LUtEREQkOxqZExHZscMMb4sWgcUCw4bBt98qyImIiIhD08iciNy9UlJg4kSYPBnS06FCBXPJgSZN7F2ZiIiIyL9SmBORu9Mvv5hLDuzebW6/8IL5fFyRIvatS0RERCSHdJuliNxdDAPmzoX77zeDXNGisHw5LF6sICciIiJORSNzInL3+OMP6N4d1q0ztx97DCIjoVw5+9YlIiIikgsamRORu8PateaSA+vWgZsbvPUWxMQoyImIiIjT0siciNzZEhNh0CDz1kowA93SpeZ/RURERJyYRuZE5M61a5f5bNy1IDdwoNmmICciIiJ3AIU5EbnzpKaaSw40agSHD4OfH2zZAjNmgIeHvasTERERyRO6zVJE7iyxseYyAzt3mtvPPQfvvw/Fitm3LhEREZE85pAjcwkJCfTv3x9fX188PDyoW7cuy5cvz9Gx27dvJzg4mFKlSuHt7U3t2rWZPXs2aWlp2R6TlJRE1apVsVgsTJ8+PdPrKSkpjB8/Hn9/f9zd3alWrRpz5szJ9fsTkVuQlobl88/x++ILLJ9/Dtd+bxsGLFwIdeuaQa5wYXMB8OXLFeRERETkjuSQI3Nt27Zl9+7dTJkyhapVq7Js2TI6duxIeno6nTp1yva4LVu2EBISQpMmTZg/fz5eXl6sWbOGfv36ERsbS3h4eJbHjR49msTExGzP++qrr7JkyRImTpxIgwYN2LRpE/369ePSpUuMGDHilt+viOTQqlXQrx8Ffv+d+mDOSFmunHlL5Zo1EB1t7tekibluXMWK9qxWREREJF85XJhbv349MTExtgAHEBQUxLFjxxgyZAjt27fH1dU1y2MjIiKwWq2sW7cOLy8vAJo1a8ahQ4eIiIjIMszt2rWLOXPmsHTpUtq1a5fp9R9//JEFCxYwefJkhgwZAsCjjz5KXFwckyZNomfPnhQvXjyv3r6IZGfVKnj2WXME7nq//w5du5r/b7WawW7wYMjmzwkRERGRO4XD3WYZHR2Nt7d3pmDVtWtXTp06xbfffpvtsVarFTc3NwoWLJihvWjRonhkMenB1atXCQ0NpXfv3tSvXz/Lc65evRrDMOh67YfF6+pJSkpi48aNOX1rIpJbaWnQr1/mIHe9AgVgxw54/XUFOREREbkrONzI3IEDB6hevToFCmQsrXbt2rbXGzVqlOWxPXv2JCoqir59+zJixAg8PT1Zu3Yt0dHRhIWFZdp/woQJJCYmMnHiRM6ePZttPSVLlqRMmTLZ1pOd5ORkkpOTbdvx8fGA+QxeSkpKtsfdDteub+86RHLC8vnnFPj99xvvlJpK6oULGOrT4gT0Z7A4M/VfcWaO1H/zogaHC3NxcXEEBARkar92K2NcXFy2xwYGBrJt2zbatWvHO++8A4CrqythYWEMGjQow7579+5l6tSprF27Fi8vr2zDXFxcXJa3UXp5eeHm5nbDesLCwhg/fnym9s2bN+Pp6ZntcbdTTEyMvUsQ+Vd+X3xB1mPnGe3dsIGTN3j+VcTR6M9gcWbqv+LMHKH/Xr58+ZbP4XBhDsBiseTqtT179tCmTRsCAwOZO3cuXl5ebNu2jVGjRnHlyhVGjx4NQGpqKqGhobRv356QkJB8q2f48OEMHDjQth0fH0/58uVp3rw5hQsX/tfr5qeUlBRiYmIIDg7GarXatRaRf2NJTzcnO/kXdVu0oE7TprehIpFboz+DxZmp/4ozc6T+e+2uvVvhcGHOx8cny9Gu8+fPA9xwspHevXtTunRpoqOjbZOkBAUF4eLiwrhx4+jcuTMBAQHMmjWLI0eO8NFHH3HhwgXg7w/zypUrXLhwgUKFCuHq6oqPjw979+7NdK3ExESuXr16w3rc3d1xd3fP1G61Wu3eea5xpFpEMrl6Fd57D7IY4c7AYoFy5SgQFKTn5cSp6M9gcWbqv+LMHKH/5sX1HW4ClFq1anHw4EFSU1MztO/fvx+AmjVrZnvs3r17eeCBBzLNdtmgQQPS09M5ePAgYD7ndvHiRapUqUKxYsUoVqwYderUAcxlCooVK2a7Xq1atTh79ixnzpy56XpEJJcMA1auhBo1oH9/+OsvKF/efO2fo+HXtmfNUpATERGRu4rDhbk2bdqQkJDAypUrM7RHRkbi6+tLYGBgtsf6+vry3XffZVogfOfOnQCUK1cOgGHDhrF9+/YMv6KiogBzEpXt27dTuXJlAFq3bo3FYiEyMjLDOSMiIihYsCBPPPHErb1hEcno22/hkUfMZQhiY6FMGZg/H44cMQOen1/G/cuVg//8B9q2tU+9IiIiInbicLdZtmjRguDgYHr16kV8fDyVK1cmKiqKjRs38uGHH9pG3bp160ZkZCSxsbFU/N/CwAMGDKBv3760atWKHj164OnpydatW5kxYwbNmjWzjb5Vq1aNatWqZbju0aNHAbjnnnt49NFHbe333Xcf3bp1Y+zYsbi6utKgQQM2b97MvHnzmDRpktaYE8krv/0GI0bA8uXmdsGC5npxQ4eCt7fZ1rYttG5N6vbt7N2wgbotWujWShEREblrOVyYA1i1ahUjR45kzJgxnD9/nmrVqhEVFUWHDh1s+6SlpZGWloZx3bpTffr0wc/Pj5kzZ9K9e3eSkpLw9/dn7NixDBgwINf1vPvuu/j5+TFnzhzOnDmDv78/4eHh9OnT55bep4gAFy7AG29AeLj5jJzFAi+9BJMmZR6FA3B1xWjalJOJieZkJwpyIiIicpdyyDDn7e1NeHg44eHh2e4TERFBREREpva2bdvSNhe3W/n7+2cIhtezWq2MGzeOcePG3fR5RSQbKSnw/vvm5CbXJj16/HGYPh3q1rVraSIiIiLOwCHDnIjcwQwDPvnEvH3y8GGzrXp1M8S1aJF5ghMRERERyZLDTYAiInew3bvh0UehTRszyJUqZY7O7dsHLVsqyImIiIjcBI3MiUj+O3bMnNxk2TJz28MDBg0yR+cKF7ZvbSIiIiJOSmFORPLPxYsQFmauAZecbLa9+KI5ucm1deNEREREJFcU5kQk76WkwLx5MG4cnDtntj36KMyYAfXq2bMyERERkTuGwpyI5B3DgLVrzdsnDx0y2+69F6ZNg6ee0jNxIiIiInlIYU5E8saePeYi3599Zm6XLGkuO9C9O1itdi1NRERE5E6kMCcit+bECRg5EpYsMbfd3WHgQHj9dShSxL61iYiIiNzBFOZEJHfi4+HNN+Gtt+DKFbPt+edh8mSoUMG+tYmIiIjcBRTmROTmpKbCBx/A2LHw559mW5Mm5uQm9evbtzYRERGRu4jCnIjkjGHA+vUwZAgcPGi2Va0KU6fC009rchMRERGR20xhTkT+3d695iLf27aZ2z4+5rIDPXpochMRERERO1GYE5Hs/f47jBoFixebI3NubtC/PwwfDkWL2rs6ERERkbuawpyIZHbpknn75IwZkJRktnXsCG+8Af7+di1NREREREwKcyLyt9RUWLgQxoyBP/4w2x5+GKZPh8BA+9YmIiIiIhkozImIeQvlxo3m5CY//mi2Va5sLj3Qpo0mNxERERFxQApzIne7//4XBg+GLVvM7eLFzWUHevY0n5ETEREREYekMCdytzp1ypzcJCLi78lN+vaFESOgWDF7VyciIiIi/0JhTuRuk5BgPgM3bRpcvmy2tW9vTm4SEGDf2kREREQkxxTmRO4WaWnmKNzo0XD6tNnWqJE5Y2XDhnYtTURERERunsKcyN1g82bzubj9+83tgABzcpP/+z9NbiIiIiLipBTmRO5kBw6YIW7TJnO7WDFzZO7VV8Hd3b61iYiIiMgtUZgTuROdPm2uFbdwIaSng9UKr71mTnhSvLi9qxMRERGRPKAwJ3InSUw0n4GbOtX8f4Bnn4UpU+Cee+xbm4iIiIjkKYU5kTtBWhosXmyOvJ06ZbYFBprBrnFj+9YmIiIiIvlCYU7E2W3ZYj4X99//mtv+/uZI3HPPaXITERERkTuYwpyIs/rxRxgyBDZsMLeLFDEnN3ntNU1uIiIiInIXUJgTcTZ//GFObvLBB+bkJgUKQO/eZpDz8bF3dSIiIiJymyjMiTiLy5fhrbfM9eESEsy2tm3NWyqrVLFvbSIiIiJy2ynMiTi69HRYsgRGjoSTJ822Bg3MyU0eecS+tYmIiIiI3SjMiTiy7dth0CD44Qdzu2JFCAuD9u3BxcW+tYmIiIiIXSnMiTiigwdh6FBYt87cLlzYHJnr2xc8POxbm4iIiIg4BIU5EUfy558wbhzMm2euHVegAPTsCWPHQokS9q5ORERERByIwpyII0hKglmzzFsoL10y21q3Nic7ufdeu5YmIiIiIo5JYU7EntLTYdkyGDECTpww2x54wJzcpGlT+9YmIiIiIg5NYU7EXj7/3JzcZM8ec7t8eXNkrmNHTW4iIiIiIv9KYU7kdjt0yJzcZM0ac7tQIXNkrl8/KFjQvrWJiIiIiNNQmBO5Xc6ehfHj4f33zclNXF2hRw9zcpNSpexdnYiIiIg4GYU5kfx25QqEh8Mbb0B8vNnWqpU5uUn16vatTURERESclsKcSH5JT4fly2H4cDh+3Gy7/36YPh0ee8y+tYmIiIiI01OYE8kPX35pTm6ye7e57ednjsw9/7wmNxERERGRPKEwJ5KXDh+G11+H6Ghz29sbhg2DAQPA09O+tYmIiIjIHUVhTiQvxMXBhAnw7ruQmmqOvr38sjnhSenS9q5ORERERO5ADnm/V0JCAv3798fX1xcPDw/q1q3L8uXLc3Ts9u3bCQ4OplSpUnh7e1O7dm1mz55NWlpahv1GjhzJ/fffT/HixfHw8CAgIIBXXnmFY8eOZdjv6NGjWCyWLH/ltCa5gyUnm8/A3XMPzJ5tBrmWLWH/fnPWSgU5EREREcknDjky17ZtW3bv3s2UKVOoWrUqy5Yto2PHjqSnp9OpU6dsj9uyZQshISE0adKE+fPn4+XlxZo1a+jXrx+xsbGEh4fb9r1w4QIdO3akevXqFCpUiJ9++olJkyaxZs0afvzxR3x8fDKcu0+fPpmuXaVKlbx94+I8DAM++si8hfLoUbOtTh0z2DVrZtfSREREROTu4HBhbv369cTExNgCHEBQUBDHjh1jyJAhtG/fHldX1yyPjYiIwGq1sm7dOry8vABo1qwZhw4dIiIiIkOYe+eddzIc++ijj1KpUiVatmzJJ598QmhoaIbXK1SoQMOGDfPyrYqz+vprc3KTb781t319YfJkeOEFc+04EREREZHbwOFus4yOjsbb25t27dplaO/atSunTp3i22s/QGfBarXi5uZGwYIFM7QXLVoUDw+Pf712yZIlAShQwOEyrjiC2Fh49ll4+GEzyHl5mc/J/fILdOmiICciIiIit5XDpZYDBw5QvXr1TIGqdu3attcbNWqU5bE9e/YkKiqKvn37MmLECDw9PVm7di3R0dGEhYVleUxqaiopKSn8/PPP9O/fn6pVq9K2bdtM+02ZMoURI0ZQoEAB6tWrx9ChQ3n66adv+F6Sk5NJTk62bcf/b8HolJQUUlJSbnhsfrt2fXvX4RTOn8fljTdwee89LCkpGC4uGF27kjZ2LJQpY+6jz/G2Uv8VZ6c+LM5M/VecmSP137yoweHCXFxcHAEBAZnaixcvbns9O4GBgWzbto127drZbqN0dXUlLCyMQYMGZdr/zJkzlC1bNsPx27dvx9vb29bm7u7Oyy+/THBwMGXLluX48ePMmTOH1q1bM3/+fLp3755tPWFhYYwfPz5T++bNm/F0kGnqY2Ji7F2Cw3JJSaHS+vVU/egjXBMTAfijXj1+fOklLlWsCN9/b+cKRf1XnJ36sDgz9V9xZo7Qfy9fvnzL57AYhmHkQS15pmrVqtxzzz1s2LAhQ/vp06fx9fUlLCyMYcOGZXnsnj17aNmyJYGBgbzyyit4eXmxbds2pk6dyqhRoxg9enSG/VNTU9m7dy/JyckcPHiQqVOnYrFY+OyzzzKEvH9KSUkhMDCQ48ePc+bMmWxvy8xqZK58+fKcO3eOwoUL5/QjyRcpKSnExMQQHByM1Wq1ay0OxzCwrFyJ66hRWI4cMZtq1iTtzTcxgoPtXJyA+q84P/VhcWbqv+LMHKn/xsfHU6JECS5evJjrbOBwI3M+Pj5Zjr6dP38e+HuELiu9e/emdOnSREdH2yZJCQoKwsXFhXHjxtG5c+cMo34FChSgfv36ADRu3JgnnniCSpUqMWXKlAyTpfyT1Wqlffv2DBs2jMOHD1O9evUs93N3d8fd3T3L4+3dea5xpFocws6d5uQmO3ea22XKwKRJWLp0oYCeiXM46r/i7NSHxZmp/4ozc4T+mxfXd7gJUGrVqsXBgwdJTU3N0L5//34Aatasme2xe/fu5YEHHsg022WDBg1IT0/n4MGDN7x2uXLl8PX15ZdffvnXOq8NaLq4ONxHKLlx5Ai0bw+NGplBztMTxo6Fw4ehWzdNbiIiIiIiDsfhkkibNm1ISEhg5cqVGdojIyPx9fUlMDAw22N9fX357rvvMi0QvvN/oyzlypW74bV//fVXfv/9dypXrnzD/VJSUlixYgUlSpT4133Fwf31FwweDNWrm+vGWSwQGmqGuHHj4LrnJ0VEREREHInD3WbZokULgoOD6dWrF/Hx8VSuXJmoqCg2btzIhx9+aBt169atG5GRkcTGxlKxYkUABgwYQN++fWnVqhU9evTA09OTrVu3MmPGDJo1a0adOnUA2LdvHwMGDODZZ58lICAAFxcX9u/fz8yZM/Hx8WHw4MG2egYOHEhKSgqNGzemTJkynDhxgjlz5rB3714WLVqU7Zp34uCuXoX33jOXFvjfLbwEB5uLfv9v5lQREREREUfmcGEOYNWqVYwcOZIxY8Zw/vx5qlWrRlRUFB06dLDtk5aWRlpaGtfP39KnTx/8/PyYOXMm3bt3JykpCX9/f8aOHcuAAQNs+5UuXRpfX19mzJjB6dOnSU1NpVy5cjz11FOMGDGC8uXL2/atWbMmc+fOZdmyZcTHx1OoUCEefPBBNm3aRPPmzW/PByJ5xzAgOhpefx1+/dVsu+8+M8SFhJgjcyIiIiIiTsAhw5y3tzfh4eE3nIQkIiKCiIiITO1t27bNcp2465UuXZolS5bkqJbQ0FBCQ0NztK84uF27zMlNvvrK3C5dGiZOhK5dQQvFi4iIiIiT0U+wcuc7ehSGD4fly83tggXN5+SGDIFChexamoiIiIhIbinMyZ3rwgV44w0IDzefkbNY4KWXYNIk8POzd3UiIiIiIrdEYU7uPCkp8P77MH48XFuz8PHHzefi6ta1a2kiIiIiInlFYU7uHIYBn3wCQ4eaSwuAueTA9OnQooUmNxERERGRO4rCnNwZvvvOnNzkiy/M7VKlzGUHunXT5CYiIiIickfST7ni3I4dg5EjYelSc9vDwwx1Q4dC4cL2rU1EREREJB8pzIlzungRpkyBmTMhOdlse+EFmDwZrlsnUERERETkTqUwJ84lJQXmz4exY+HcObPt0UdhxgyoV8+upYmIiIiI3E4Kc+IcDAPWrjVvnzx0yGy7916YNg2eekqTm4iIiIjIXUdhThzfnj3mIt+ffWZulyhhLjvw8stgtdq1NBERERERe1GYE8d14oQ5ucmSJea2uzsMGADDhkGRIvatTURERETEzhTmxPFcumRObvLWW3DlitnWubM5uUnFivatTURERETEQSjMieNITYUPPjAnN/nzT7OtSRNzcpP69e1bm4iIiIiIg1GYE/szDFi/HoYMgYMHzbaqVWHqVHj6aU1uIiIiIiKSBRd7FyB3ub17ITjYnJHy4EHw8YE5c+DAAWjdWkFORERERCQbGpkT+zh5EkaNgshIc2TOzQ3694fhw6FoUXtXJyIiIiLi8BTm5Pa6dMlcG276dEhKMts6duT/27vzsCiudA3gbwFNg80miCwutIgKMSIakagoMIlLcBsJLhCjoI5GE3eNawSXGbdxG2+MuRHBiOIS0ahJ3IGY6ES8cUVNIhFHZYniKLiynftHP92x7QYaXJqW9/c8PkmfPlX1VfVHdX1dVafwj38ASqVRQyMiIiIiMiUs5ujlKCkB4uOBTz4B8vJUbYGBqqIuIMC4sRERERERmSAWc/RiCQHs26ca3CQjQ9Xm5QUsXgz068d74oiIiIiIqonFHL04Z86oiriDB1WvHR2BOXOA0aNV98gREREREVG1sZij5y87W3U5ZXz8n4ObjB0LzJoF1K1r7OiIiIiIiF4JLObo+bl3T3UP3NKlwIMHqrYBA4CFCwFPT+PGRkRERET0imExR8+utBRISFCdjcvJUbV16AAsW6b6LxERERERPXcs5ujZHDgATJkCnDuneu3pqRrc5N13ObgJEREREdELxGKOquf8edXgJvv2qV7Xras6MzdmDCCXGzc2IiIiIqJagMUcVU1urmpEyrg4oKwMkMmAjz4CZs9WjVZJREREREQvBYs5Msz9+8Dy5apLKO/fV7WFh6sGN/HyMm5sRERERES1EIs5qlhpKbBxo+qxAtnZqraAANXgJp06GTc2IiIiIqJajMUcle/QIdXgJmfOqF4rlcCiRarHDXBwEyIiIiIio2IxR7oyMoCPPwa+/Vb12t5eNbjJRx9xcBMiIiIiohrCzNgBkBGUlkJKS0OD77+HlJamupQSAPLygA8+AHx9VYWchQUwfjyQmQlMnsxCjoiIiIioBuGZudomORkYPx4W16+jHaAa1KRBA6BLF2DPHuDePVW/sDDVJZXNmhkzWiIiIiIiKgeLudokOVk1AqUQ2u03bgBJSar/9/dXDW7SufPLj4+IiIiIiAzGYq62KC1VXTL5dCH3JCcn4McfVc+OIyIiIiKiGo33zNUWR48C169X3Cc/X1XMERERERFRjcdirrbIyXm+/YiIiIiIyKhYzNUWbm7Ptx8RERERERkVi7naonNnoGHD8h/2LUlAo0Yc+ISIiIiIyESwmKstzM2BVatU//90Qad+vXKlqh8REREREdV4LOZqk7Aw4KuvVM+Ve1LDhqr2sDDjxEVERERERFXGRxPUNmFhQN++KElJwenvvoPfO+/AIiSEZ+SIiIiIiEwMi7nayNwcIigIN+7fR+ugIBZyREREREQmiJdZEhERERERmaAaWczdu3cPEyZMgLu7O6ysrODn54ctW7YYNG1KSgq6du2K+vXrw8bGBr6+vvjXv/6F0tJSrX6zZs1CmzZt4OjoCCsrK3h6emLkyJG4evWqzjyLi4sxd+5cKJVKyOVyeHt7Y/Xq1c9lXYmIiIiIiKqjRl5mGRYWhvT0dCxatAjNmzfH5s2bERERgbKyMkRGRpY73aFDh9C9e3d06dIFX3zxBRQKBXbv3o3x48cjMzMTq9SjOQK4c+cOIiIi4OPjA1tbW1y4cAELFizA7t27kZGRAScnJ03fMWPGYOPGjZg/fz78/f2xf/9+jB8/HoWFhZg5c+YL3RZERERERET61Lhi7ttvv8XBgwc1BRwAhISE4OrVq5g6dSoGDhwI83Lu8UpISIBMJsPevXuhUCgAAG+//TZ++eUXJCQkaBVzn376qda0wcHBaNKkCUJDQ/H1119j2LBhAICMjAzExcXh73//O6ZOnarpm5+fjwULFuCDDz6Ao6Pjc98OREREREREFalxl1nu3LkTNjY26N+/v1Z7dHQ0srOz8dNPP5U7rUwmg6WlJaytrbXaHRwcYGVlVemynZ2dAQAWFn/WuLt27YIQAtHR0TrxPHz4EPv27at0vkRERERERM9bjTszd/78efj4+GgVVADg6+ureb9jx456p/3ggw+QlJSEcePGYebMmahTpw727NmDnTt3YuHChXqnKSkpQXFxMS5duoQJEyagefPmCHvieWvnz5+Hs7MzXF1dy42nPI8fP8bjx481rwsKCgCo7sErLi4ud7qXQb18Y8dBVB3MXzJ1zGEyZcxfMmU1KX+fRww1rpjLz8+Hp6enTrv6Usb8/Pxypw0ICMCRI0fQv39/zWWU5ubmWLhwISZPnqzTPzc3F25ublrTp6SkwMbGRisefZdRKhQKWFpaVhjPwoULMXfuXJ32AwcOoE6dOuVO9zIdPHjQ2CEQVRvzl0wdc5hMGfOXTFlNyN8HDx488zxqXDEHAJIkVeu9//u//0O/fv0QEBCAzz//HAqFAkeOHMHs2bPx6NEjfPLJJ1r969Wrh/T0dDx+/BgXL17EkiVLEBISgtTUVK0ir7rxzJgxA5MmTdK8LigoQKNGjdCtWzfY2dmVO93LUFxcjIMHD6Jr166QyWRGjYWoqpi/ZOqYw2TKmL9kympS/qqv2nsWNa6Yc3Jy0nu26/bt2wBQ4WAjH374IVxcXLBz507NICkhISEwMzNDbGws3nvvPa2zfhYWFmjXrh0AoFOnTujRoweaNGmCRYsWaQZLcXJywunTp3WWdf/+fRQVFVUYj1wuh1wu12mXyWRGTx61mhQLUVUxf8nUMYfJlDF/yZTVhPx9HsuvcQOgtGrVChcvXkRJSYlW+7lz5wAAr7/+ernTnj59Gm+88YbOaJf+/v4oKyvDxYsXK1x2w4YN4e7ujl9//VUrnps3byI3N7fK8RAREREREb0oNa6Y69evH+7du4cdO3ZotW/YsAHu7u4ICAgod1p3d3ecPHlS5wHhx48fB6Aq1ipy+fJlXL9+HV5eXpq2vn37QpIkbNiwQatvQkICrK2t0aNHD4PWi4iIiIiI6HmqcZdZvvPOO+jatStGjx6NgoICeHl5ISkpCfv27UNiYqLmrNvw4cOxYcMGZGZmwsPDAwAwceJEjBs3Dr1798aoUaNQp04dHD58GMuWLcPbb7+N1q1bAwDOnj2LiRMnIjw8HJ6enjAzM8O5c+ewYsUKODk5YcqUKZp4WrZsieHDhyMmJgbm5ubw9/fHgQMH8L//+79YsGABnzFHRERERERGUeOKOQBITk7GrFmzMGfOHNy+fRve3t5ISkrCoEGDNH1KS0tRWloKIYSmbezYsWjQoAFWrFiBESNG4OHDh1AqlYiJicHEiRM1/VxcXODu7o5ly5YhJycHJSUlaNiwIXr16oWZM2eiUaNGWvGsWbMGDRo0wOrVq5GbmwulUolVq1Zh7NixL35jEBERERER6SGJJ6sheqHu3r0LBwcHXLt2rUaMZnngwAF069bN6Dd/ElUV85dMHXOYTBnzl0xZTcpf9Uj3d+7cgb29fbXmUSPPzL2qCgsLAUDnzB8REREREdVOhYWF1S7meGbuJSorK0N2djZsbW0rfD7dy6D+JaAmnCUkqirmL5k65jCZMuYvmbKalL9CCBQWFsLd3R1mZtUbl5Jn5l4iMzOzSkfUfNns7OyMnshE1cX8JVPHHCZTxvwlU1ZT8re6Z+TUatyjCYiIiIiIiKhyLOaIiIiIiIhMEIu5WkoulyMmJgZyudzYoRBVGfOXTB1zmEwZ85dM2auWvxwAhYiIiIiIyATxzBwREREREZEJYjFHRERERERkgljMERERERERmSAWcybop59+Qr9+/dC4cWPI5XK4uLigQ4cOmDx5sqbPmjVrkJCQ8EKW/+DBA8TGxiI1NfWFzJ+MIyEhAZIkQZIkvZ+tEAJeXl6QJAnBwcEvPb7KREVFQalUvtBlZGdnIzY2FqdPn9a7fBsbmxe6/NoiKysLkiS9sH2YqXoZOV6R2NhYSJL0wpdz+PBhtGvXDgqFApIkYdeuXS98mc+KOaufsXP2edL3Gau/N7OysjRtmzdvxsqVK196fPT8KJVKREVFVWtaYxwLsJgzMd988w06duyIgoICLFmyBAcOHMCqVavQqVMnbN26VdPvRRdzc+fOZTH3irK1tUVcXJxOe1paGjIzM2Fra2uEqGqG7OxszJ07V28xR8+Pm5sbjh8/jp49exo7FHrJhBAYMGAAZDIZdu/ejePHjyMoKMjYYVWKOVs79ezZE8ePH4ebm5umjcUcvWwWxg6AqmbJkiVo0qQJ9u/fDwuLPz++QYMGYcmSJS902UIIPHr06IUug4xv4MCB2LRpEz799FPY2dlp2uPi4tChQwcUFBQYMTqqDeRyOd58801jh0FGkJ2djdu3b6Nfv3546623jB2OwZiztZOzszOcnZ2NHQbVcjwzZ2Ly8/NRr149rUJOzcxM9XEqlUpkZGQgLS1Nc9mc+jKHR48eYfLkyfDz84O9vT0cHR3RoUMHfP311zrzkyQJH330EdauXQsfHx/I5XJs2LBBs+OaO3euZv7VPR1NNU9ERAQAICkpSdN29+5d7NixA8OGDdPpP3fuXAQEBMDR0RF2dnZo27Yt4uLi8ORTT3744QfIZDJMmTJFa1r1JSr6zgRWJCEhAS1atIBcLoePjw++/PJLvf2KioqwYMECeHt7Qy6Xw9nZGdHR0bh586ZWP6VSiV69emHnzp3w9fWFlZUVPD098a9//UvTJzU1Ff7+/gCA6OhoTe7HxsZqzevy5csIDQ2FjY0NGjVqhMmTJ+Px48dVWr9XgfqSvLNnz6J///6a/c2kSZNQUlKCX375BT169ICtrS2USqXWj1H6LmdSzy8jIwMRERGwt7eHi4sLhg0bhrt371Yptt9//x2DBg2Cu7u75lL1t956S+uM69atW9GtWze4ubnB2toaPj4+mD59Ou7fv681L/UlNZcuXUL37t2hUCjg5uaGRYsWAQD+/e9/IzAwEAqFAs2bN8eGDRu0plf/DRw8eBDR0dFwdHSEQqFA79698fvvv1e6LkIIrFmzBn5+frC2tkbdunURHh6uM+2pU6fQq1cv1K9fH3K5HO7u7ujZsyeuX79epW2nz9atW9GhQwcoFArY2Nige/fuOHXqlFafkydPYtCgQVAqlbC2toZSqURERASuXr2q6RMbG4uGDRsCAKZNm6b13fUyMGdfvZw1ZLsZsv8vz9OXWQYHB+Obb77B1atXNd8RL+PS5Jrq0qVLiIiIgIuLC+RyORo3bowhQ4ZovhNv3LiBkSNHolGjRrC0tIS7uzvCw8ORl5cHQPW9K0kSEhMTMWnSJLi6usLa2hpBQUE6+5jKVOX492nVicOQYwFDjp8MwTNzJqZDhw5Yt24dxo0bh/feew9t27aFTCbT6rNz506Eh4fD3t4ea9asAQDNgxEfP36M27dvY8qUKWjQoAGKiopw6NAhhIWFIT4+HkOGDNGa165du3D06FHMmTMHrq6ucHR0xL59+9CjRw8MHz4cI0aMAAD+MvUKsbOzQ3h4ONavX49Ro0YBUBV2ZmZmGDhwoM7lI1lZWRg1ahQaN24MQHUgMHbsWNy4cQNz5swBAAQGBmLBggWYPn06unTpgj59+iAjIwMffvghBg8ejOHDhxscX0JCAqKjo9G3b18sW7YMd+/eRWxsLB4/fqz5QQMAysrK0LdvXxw9ehQff/wxOnbsiKtXryImJgbBwcE4efIkrK2tNf1Pnz6NCRMmIDY2Fq6urti0aRPGjx+PoqIiTJkyBW3btkV8fDyio6Mxe/ZszeVU6oNPACguLkafPn0wfPhwTJ48Gd9//z3mz58Pe3t7zbaobQYMGIDBgwdj1KhROHjwIJYsWYLi4mIcOnQIY8aMwZQpU7B582ZMmzYNXl5eCAsLq3B+7777LgYOHIjhw4fj3LlzmDFjBgBg/fr1BscUGhqK0tJSLFmyBI0bN8atW7dw7Ngx3LlzR9Pnt99+Q2hoKCZMmACFQoFLly5h8eLFOHHiBI4cOaI1v+LiYoSFheGDDz7A1KlTsXnzZsyYMQMFBQXYsWMHpk2bhoYNG2L16tWIiorC66+/jjfeeENrHsOHD0fXrl2xefNmXLt2DbNnz0ZwcDDOnj0LBweHctdl1KhRSEhIwLhx47B48WLcvn0b8+bNQ8eOHXHmzBm4uLjg/v376Nq1K5o0aYJPP/0ULi4uyM3NRUpKCgoLCw3ebvr84x//wOzZszV/F0VFRVi6dCk6d+6MEydO4LXXXgOg2k+0aNECgwYNgqOjI3JycvDZZ5/B398fFy5cQL169TBixAi0bt0aYWFhGDt2LCIjI43yUF/m7KuTs4ZsN6Dy/b+h1qxZg5EjRyIzMxM7d+40eLpX0ZkzZxAYGIh69eph3rx5aNasGXJycrB7924UFRXh1q1b8Pf3R3FxMWbOnAlfX1/k5+dj//79+O9//wsXFxfNvGbOnIm2bdti3bp1mu/84OBgnDp1Cp6engbFU9XjX30MjcPQYwFDjp8MIsik3Lp1SwQGBgoAAoCQyWSiY8eOYuHChaKwsFDTr2XLliIoKKjS+ZWUlIji4mIxfPhw0aZNG633AAh7e3tx+/ZtrfabN28KACImJuZ5rBLVEPHx8QKASE9PFykpKQKAOH/+vBBCCH9/fxEVFSWEqDi3SktLRXFxsZg3b55wcnISZWVlmvfKyspEaGiocHBwEOfPnxevvfaa8Pb2Fvfu3TM4xtLSUuHu7i7atm2rNe+srCwhk8mEh4eHpi0pKUkAEDt27NCaR3p6ugAg1qxZo2nz8PAQkiSJ06dPa/Xt2rWrsLOzE/fv39eaNj4+Xie2oUOHCgBi27ZtWu2hoaGiRYsWBq/jqyImJkYAEMuWLdNq9/PzEwBEcnKypq24uFg4OzuLsLAwIYQQV65c0dnO6vktWbJEa35jxowRVlZWWvlQkVu3bgkAYuXKlQavS1lZmSguLhZpaWkCgDhz5ozmPfXn/mSeqdcHgPj555817fn5+cLc3FxMmjRJ06b+u+vXr5/WMn/88UcBQCxYsEBrWU/m+PHjx/Vu42vXrglra2vx8ccfCyGEOHnypAAgdu3aZfA666P+DNT+85//CAsLCzF27FitfoWFhcLV1VUMGDCg3HmVlJSIe/fuCYVCIVatWqVpV3/2S5cufaZYq4M5+2rlrKHbzdD9v77PWL0trly5omnr2bOn1jrXVn/5y1+Eg4OD+OOPP/S+P2zYMCGTycSFCxfKnYf6WKS87/wRI0ZUO76Kjn89PDzE0KFDqxVHdY8FKjp+qgwvszQxTk5OOHr0KNLT07Fo0SL07dsXv/76K2bMmIFWrVrh1q1blc5j+/bt6NSpE2xsbGBhYQGZTIa4uDhcvHhRp+9f/vIX1K1b90WsCtVgQUFBaNq0KdavX49z584hPT1d7yWWAHDkyBG8/fbbsLe3h7m5OWQyGebMmYP8/Hz88ccfmn6SJOHLL7+Era0t2rVrhytXrmDbtm1QKBQGx/XLL78gOzsbkZGRWpeueHh4oGPHjlp99+7dCwcHB/Tu3RslJSWaf35+fnB1ddUZwKdly5Zo3bq1VltkZCQKCgrw888/GxSfJEno3bu3Vpuvr6/WpWS1Ta9evbRe+/j4QJIkvPPOO5o2CwsLeHl5GbSd+vTpo/Xa19cXjx490sq1ijg6OqJp06ZYunQpli9fjlOnTqGsrEyn3++//47IyEi4urpq8lo9EMfT+0pJkhAaGqqzPm5ubmjTpo3WsuvXr693Pd977z2t1x07doSHhwdSUlLKXZe9e/dCkiQMHjxYK8ddXV3RunVrTY57eXmhbt26mDZtGtauXYsLFy5UvqEMsH//fpSUlGDIkCFay7eyskJQUJDW39i9e/c0Z7IsLCxgYWEBGxsb3L9/X+93jzExZ1+NnDV0uwHPZ/9Pf3rw4AHS0tIwYMCAcq/c+u677xASEgIfH59K51fed35FuaZPVY5/nyUOQ48FDD1+qgyLORPVrl07TJs2Ddu3b0d2djYmTpyIrKysSgdBSU5OxoABA9CgQQMkJibi+PHjmgN1fYObPDlCE9UekiQhOjoaiYmJWLt2LZo3b47OnTvr9Dtx4gS6desGAPjiiy/w448/Ij09HbNmzQIAPHz4UKu/k5MT+vTpg0ePHqFHjx5o1apVleLKz88HALi6uuq893RbXl4e7ty5A0tLS8hkMq1/ubm5Oj98VDRP9XIrU6dOHVhZWWm1yeXyWj1wkKOjo9ZrS0tLvdvJ0tLSoO3k5OSk9Vp9Gd7TuVYeSZJw+PBhdO/eHUuWLEHbtm3h7OyMcePGaS7funfvHjp37oyffvoJCxYsQGpqKtLT05GcnKx3WeWtz9PrXtF6lpd/FeVeXl4ehBBwcXHRyfF///vfmhy3t7dHWloa/Pz8MHPmTLRs2RLu7u6IiYlBcXFxJVusfOr7Wvz9/XWWv3XrVq2/scjISPzP//wPRowYgf379+PEiRNIT0+Hs7OzwZ/dy8KchU67KeasIdutsnUBDN//05/++9//orS0VOs2hKfdvHmzwvefVJ1ce1pVj3+fJQ5DjgWqevxUEd4z9wqQyWSIiYnBihUrcP78+Qr7JiYmokmTJti6davWrwvlDdBQm2/cre2ioqIwZ84crF27Fn//+9/19tmyZQtkMhn27t2rteMq77lQBw8exGeffYb27dtj586d2LFjB959912DY1IfFOXm5uq893RbvXr14OTkhH379umd19OPWKhonk8fjJFp8/Dw0Ay68+uvv2Lbtm2IjY1FUVER1q5diyNHjiA7Oxupqalaw+I/fZ/N81Re/nl5eZU7Tb169SBJEo4ePar33rIn21q1aoUtW7ZACIGzZ88iISEB8+bNg7W1NaZPn16tmOvVqwcA+Oqrr+Dh4VFuv7t372Lv3r2IiYnRWpb6HhaqHHO2ejlb2XarbF0A7v+rw9HREebm5hUOVuPs7GzwYDblfT5V+Wyqevz7ouJQq+rxU0V4Zs7E5OTk6G1XnyJ2d3cHoNoh6qvqJUmCpaWlViLn5uYaNJqPWlV/VSTT1KBBA0ydOhW9e/fG0KFD9faRJAkWFhYwNzfXtD18+BAbN27U6ZuTk4PBgwcjKCgIx44d09wcfOXKFYNjatGiBdzc3JCUlKQ12tPVq1dx7Ngxrb69evVCfn4+SktL0a5dO51/LVq00OqfkZGBM2fOaLVt3rwZtra2aNu2LQDm/quoefPmmD17Nlq1aqW5nEq9f3z6YPPzzz9/YXFs2rRJ6/WxY8dw9epVBAcHlztNr169IITAjRs39Oa4vjPfkiShdevWWLFiBRwcHJ7pErLu3bvDwsICmZmZepffrl07zTKFEDrbc926dSgtLa328msr5mz1clbfdlMzZP9vqPKOv2oT9UiP27dvL/f2n3feeQcpKSn45ZdfKp1fed/5FeXa057H8e/ziOPJeAw9fqoMz8yZmO7du6Nhw4bo3bs3vL29UVZWhtOnT2PZsmWwsbHB+PHjAfz5i9bWrVvh6ekJKysrtGrVCr169UJycjLGjBmD8PBwXLt2DfPnz4ebmxt+++03g2KwtbWFh4cHvv76a7z11ltwdHREvXr1XuoQ0vRyqIeqLk/Pnj2xfPlyREZGYuTIkcjPz8c///lPnQOK0tJSREREQJIkbN68Gebm5khISICfnx8GDhyIH374AZaWlpXGY2Zmhvnz52PEiBHo168f/va3v+HOnTuaEcieNGjQIGzatAmhoaEYP3482rdvD5lMhuvXryMlJQV9+/ZFv379NP3d3d3Rp08fxMbGws3NDYmJiTh48CAWL16MOnXqAACaNm0Ka2trbNq0CT4+PrCxsYG7u7vmRxSq+c6ePYuPPvoI/fv3R7NmzWBpaYkjR47g7Nmzml/7O3bsiLp16+KDDz5ATEwMZDIZNm3apHOw9zydPHkSI0aMQP/+/XHt2jXMmjULDRo0wJgxY8qdplOnThg5ciSio6Nx8uRJdOnSBQqFAjk5Ofjhhx/QqlUrjB49Gnv37sWaNWvw17/+FZ6enhBCIDk5GXfu3EHXrl2rHbNSqcS8efMwa9Ys/P777+jRowfq1q2LvLw8nDhxAgqFAnPnzoWdnR26dOmCpUuXar4r0tLSEBcXV+Goh6TCnK1ezhqy3dQM2f8bqlWrVkhOTsZnn32GN954A2ZmZpofNmqT5cuXIzAwEAEBAZg+fTq8vLyQl5eH3bt34/PPP8e8efPw3XffoUuXLpg5cyZatWqFO3fuYN++fZg0aRK8vb018/rjjz803/l3795FTEwMrKysNCPDGuJ5HP8+jzjUDD1+MojBQ6VQjbB161YRGRkpmjVrJmxsbIRMJhONGzcW77//vtaIQFlZWaJbt27C1tZWANAaWWnRokVCqVQKuVwufHx8xBdffKEzSpkQqtEsP/zwQ71xHDp0SLRp00bI5XIBQGvUHzJNT45mWZGnR7Ncv369aNGihZDL5cLT01MsXLhQxMXFaY3wNWvWLGFmZiYOHz6sNa9jx44JCwsLMX78+CrFum7dOtGsWTNhaWkpmjdvLtavX68zapoQqhHa/vnPf4rWrVsLKysrYWNjI7y9vcWoUaPEb7/9punn4eEhevbsKb766ivRsmVLYWlpKZRKpVi+fLnOspOSkoS3t7eQyWRao7oOHTpUKBQKnf76/rZqA/V637x5U6u9vO0UFBQkWrZsKYSoeGTAp+enbzS5iuTl5YmoqCjh7e0tFAqFsLGxEb6+vmLFihWipKRE0+/YsWOiQ4cOok6dOsLZ2VmMGDFC/PzzzzpxGbI+T1Ln2tPxHzhwQLz//vvCwcFBWFtbi9DQUK0cVS9L3yh569evFwEBAUKhUAhra2vRtGlTMWTIEHHy5EkhhBCXLl0SERERomnTpsLa2lrY29uL9u3bi4SEBIO2mVp5ubxr1y4REhIi7OzshFwuFx4eHiI8PFwcOnRI0+f69evi3XffFXXr1hW2traiR48e4vz58zqjxtWE0SyZs9pMNWcN3W6G7v8NHc3y9u3bIjw8XDg4OAhJkmrl/l/twoULon///sLJyUlYWlqKxo0bi6ioKPHo0SMhhGoU02HDhglXV1chk8mEu7u7GDBggMjLyxNC/DmK5MaNG8W4ceOEs7OzkMvlonPnzppcqQpDj3/LG83SkDiqcixgyPGTISQhqvhkOiKiV4xSqcTrr7+OvXv3GjsUqmXUz01MT0+vlb/ek+l51XKW+/+aKzU1FSEhIdi+fTvCw8NrfRzl4T1zREREREREJoj3zBFRjVBWVlbuM4DULCy4y6LyMYeqh9vNeLjtq4fbjdSEEJUOpGRubv5Kj87OyyyJqEaIiorChg0bKuzD3RVVhDlUPdxuxsNtXz3cbqSmvgSyIvHx8YiKino5ARkBizkiqhGysrLKHcJY7VW4P4NeHOZQ9XC7GQ+3ffVwu5FaYWFhpY83aNKkySv9vEAWc0RERERERCaIA6AQERERERGZIBZzREREREREJojFHBERERERkQliMUdERERERGSCWMwREVGtolQqoVQqjR2GjpoaFxER1Vws5oiI6JUxZMgQSJIEV1dXlJSUGDucZxYbGwtJkpCammrsUIiIqAZiMUdERK+EgoIC7NixA5IkIS8vD998842xQ6qSw4cP4/Dhw8YOg4iITAiLOSIieiUkJSXhwYMHmDx5MiRJQlxcnLFDqpKmTZuiadOmxg6DiIhMCIs5IiJ6JcTFxcHS0hIzZsxAp06d8O233yInJ8fg6W/duoWRI0eifv36qFOnDvz9/bFz504kJCRAkiQkJCToTLN3716EhITA3t4e1tbW8PPzw8qVK1FaWqrVLysrC5IkISoqCpcuXUJYWBjq1asHSZKQlZUFQPeeueDgYMydOxcAEBISAkmSIEmSVh/1NHfv3sXo0aPh5uYGhUKBLl264OeffwYA5ObmYujQoZr16t69Oy5fvqx3Gxw7dgw9e/aEo6MjrKys4O3tjdjYWDx48MDg7UhERC+PhbEDICIielbnzp1Deno6+vXrB0dHRwwZMgQ//PADNmzYgOnTp1c6/b179xAUFIQLFy4gMDAQgYGBuHHjBiIiItCtWze906xatQoTJkyAo6MjIiMjoVAosGfPHkycOBFHjx7FV199BUmStKa5fPky3nzzTbRs2RJDhw7F7du3YWlpqXf+UVFRAIC0tDQMHTpUU8Q5ODho9SsqKkLXrl3x6NEjDBw4EHl5edi2bRvefvttHDt2DD169ICrqysGDx6My5cvY8+ePejVqxcyMjJgbm6umc+OHTswaNAgWFpaYuDAgahfvz4OHTqEuXPn4sCBA0hJSYFcLq90WxIR0UskiIiITNz48eMFAJGcnCyEEOLOnTvCyspKNGvWTKevh4eH8PDw0GqbPXu2ACA+/PBDrfaUlBQBQAAQ8fHxmvbMzExhYWEh6tevL/7zn/9o2h8/fiyCgoIEALFx40ZN+5UrVzTz+eSTT/Sug764YmJiBACRkpJS7jQARP/+/UVxcbGmfdGiRQKAcHBwEBMnThRlZWWa90aPHq21rYQQoqCgQDg4OAi5XC7OnDmjaS8rKxORkZECgJg/f77eGIiIyHh4mSUREZm0oqIiJCYmom7duujZsycAwN7eHn379sVvv/2G77//vtJ5JCYmQi6XIyYmRqs9ODgY3bt31+m/adMmlJSUYPLkyWjUqJGm3dLSEosWLQIAvZdlurq6Yvbs2VVZPYMsXboUFhZ/XmwTGRkJACgpKcH8+fO1zhBGREQAAM6cOaNp27VrF+7cuYNhw4bB19dX0y5JEhYtWgQLCwu960NERMbFYo6IiEzarl27kJ+fj4EDB2pdsjhkyBAAwPr16yucvqCgAFlZWfDy8oKzs7PO+x07dtRpO3XqFABVsfe0N998E9bW1jh9+rTOe61bty73ssrqcnBwgIeHh1abm5sbAKBZs2ZQKBR637tx44amraL1adSoEZo2bYrMzEwUFhY+z9CJiOgZsZgjIiKTpi7W3n//fa327t27w9XVFdu3b0dBQUG506vf01fIAYCLi0u50+h7DwDq16+Pu3fvGjSvZ2Vvb6/Tpj5LZ2dnV+57xcXFmrbK1sfV1VWrHxER1Qws5oiIyGRdu3YNBw8eBAB06tRJM+KjJEmwsLBAbm4uHjx4gC1btpQ7D3XBc/PmTb3v5+XllTuNvvcA4I8//tBbSD09IEpNUdn6qNv1rRMRERkPR7MkIiKTFR8fj7KyMgQGBqJFixY67xcVFWHjxo2Ii4vDyJEj9c7Dzs4OSqUSly9fxs2bN3XO0B07dkxnmjZt2mDnzp1ITU1F+/bttd47ceIEHj58iA4dOjzDmqmoR5t8+lEHz1ubNm0AAKmpqRgwYIDWezdu3EBmZiY8PT1ha2v7QuMgIqKq4Zk5IiIySUIIxMfHQ5IkfPnll1i3bp3Ovy+//BJt2rTBiRMncP78+XLn9d577+Hx48ea57qppaamYv/+/Tr9IyMjYWFhgeXLlyM7O1vTXlxcrHkUgvrRAs/C0dERAHD9+vVnnldF+vbtC3t7e8THxyMjI0PTLoTAjBkzUFxc/FzWh4iIni+emSMiIpN0+PBhZGVlISQkBE2aNCm3X3R0NE6dOoW4uDisWLFCb59p06Zhx44d+PTTT3H27FkEBgbi+vXr2LZtG3r37o09e/bAzOzP3z+bNm2KxYsXY/LkyfD19cWAAQOgUCiwd+9eXLp0CX379sXgwYOfeR3VDwufNWsWLl26BHt7e9jb22P06NHPPO8n2dnZ4YsvvkBERAQCAgIwcOBAODs74/Dhwzh58iTat2+PqVOnPtdlEhHRs+OZOSIiMklxcXEAgGHDhlXYLzIyEpaWlkhMTERRUZHePra2tvj+++8xfPhwXLx4EStWrMCFCxeQlJSEoKAgALr3i02aNAlff/01Xn/9dSQmJmL16tWQyWRYtmyZ3geGV8drr72G+Ph4ODo6YsWKFZgxYwYWL178zPPVp3///khJSUGXLl2QnJyMFStWoKCgAJ988gmOHDkCKyurF7JcIiKqPkkIIYwdBBERUU01ePBgbNq0CRcuXICPj4+xwyEiItLgmTkiIiIAOTk5Om1paWnYsmULWrRowUKOiIhqHN4zR0REBCA0NBTW1tbw8/ODQqHAhQsXsG/fPpibm2P16tXGDo+IiEgHL7MkIiICsHLlSmzatAmZmZkoLCyEg4MDOnXqhBkzZiAgIMDY4REREelgMUdERERERGSCeM8cERERERGRCWIxR0REREREZIJYzBEREREREZkgFnNEREREREQmiMUcERERERGRCWIxR0REREREZIJYzBEREREREZkgFnNEREREREQm6P8BbQhSU49Z76AAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "algoritmo=[\"Start\",\"Max_depth\",\"min_samples_leaf\",\"min_samples_split\",\"ccp_alpha\"]\n",
    "accuracy=[0.8312,0.8400,0.8511,0.8586,0.8689]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(algoritmo, accuracy, marker='o', linestyle='-', color='r')\n",
    "plt.title(' Accuracy su testSet al Variare dell algoritmo')\n",
    "plt.xlabel('Algoritmo')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.grid(True)\n",
    "plt.xticks(algoritmo)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "328fa9b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 288 candidates, totalling 1440 fits\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.782) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.870, test=0.866) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.785, test=0.777) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.740, test=0.738) f1: (train=0.783, test=0.780) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.784, test=0.781) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.872) balanced_accuracy: (train=0.741, test=0.748) f1: (train=0.783, test=0.790) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.782) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.870, test=0.866) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.785, test=0.777) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.740, test=0.738) f1: (train=0.783, test=0.780) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.784, test=0.781) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.872) balanced_accuracy: (train=0.741, test=0.748) f1: (train=0.783, test=0.790) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.782) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.870, test=0.866) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.785, test=0.777) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.740, test=0.738) f1: (train=0.783, test=0.780) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.784, test=0.781) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.872) balanced_accuracy: (train=0.741, test=0.748) f1: (train=0.783, test=0.790) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.782) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.870, test=0.866) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.785, test=0.777) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.740, test=0.738) f1: (train=0.783, test=0.780) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.784, test=0.781) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.872) balanced_accuracy: (train=0.741, test=0.748) f1: (train=0.783, test=0.790) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.782) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.870, test=0.866) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.785, test=0.777) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.740, test=0.738) f1: (train=0.783, test=0.780) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.784, test=0.781) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.872) balanced_accuracy: (train=0.741, test=0.748) f1: (train=0.783, test=0.790) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.782) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.870, test=0.866) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.785, test=0.777) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.740, test=0.738) f1: (train=0.783, test=0.780) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.784, test=0.781) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.872) balanced_accuracy: (train=0.741, test=0.748) f1: (train=0.783, test=0.790) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.785, test=0.782) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.742, test=0.735) f1: (train=0.784, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.737) f1: (train=0.782, test=0.779) total time=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.737) f1: (train=0.782, test=0.779) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.739, test=0.747) f1: (train=0.780, test=0.788) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.785, test=0.782) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.742, test=0.735) f1: (train=0.784, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.737) f1: (train=0.782, test=0.779) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.737) f1: (train=0.782, test=0.779) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.739, test=0.747) f1: (train=0.780, test=0.788) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.785, test=0.782) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.742, test=0.735) f1: (train=0.784, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.737) f1: (train=0.782, test=0.779) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.737) f1: (train=0.782, test=0.779) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.739, test=0.747) f1: (train=0.780, test=0.788) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.785, test=0.782) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.742, test=0.735) f1: (train=0.784, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.737) f1: (train=0.782, test=0.779) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.737) f1: (train=0.782, test=0.779) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.739, test=0.747) f1: (train=0.780, test=0.788) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.785, test=0.782) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.742, test=0.735) f1: (train=0.784, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.737) f1: (train=0.782, test=0.779) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.737) f1: (train=0.782, test=0.779) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.739, test=0.747) f1: (train=0.780, test=0.788) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.785, test=0.782) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.742, test=0.735) f1: (train=0.784, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.737) f1: (train=0.782, test=0.779) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.737) f1: (train=0.782, test=0.779) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.739, test=0.747) f1: (train=0.780, test=0.788) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.866) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.784, test=0.781) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.742, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.736) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.739, test=0.736) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.738, test=0.746) f1: (train=0.779, test=0.788) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.866) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.784, test=0.781) total time=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.742, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.736) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.739, test=0.736) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.738, test=0.746) f1: (train=0.779, test=0.788) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.866) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.784, test=0.781) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.742, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.736) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.739, test=0.736) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.738, test=0.746) f1: (train=0.779, test=0.788) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.866) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.784, test=0.781) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.742, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.736) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.739, test=0.736) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.738, test=0.746) f1: (train=0.779, test=0.788) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.866) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.784, test=0.781) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.742, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.736) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.739, test=0.736) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.738, test=0.746) f1: (train=0.779, test=0.788) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.866) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.784, test=0.781) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.742, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.736) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.739, test=0.736) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.738, test=0.746) f1: (train=0.779, test=0.788) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.866, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.866, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.866, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.866, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.866, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.866, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.871, test=0.868) balanced_accuracy: (train=0.745, test=0.741) f1: (train=0.787, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.870, test=0.866) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.741, test=0.739) f1: (train=0.784, test=0.781) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.782) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.872) balanced_accuracy: (train=0.743, test=0.750) f1: (train=0.784, test=0.791) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.871, test=0.868) balanced_accuracy: (train=0.745, test=0.741) f1: (train=0.787, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.870, test=0.866) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.741, test=0.739) f1: (train=0.784, test=0.781) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.782) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.872) balanced_accuracy: (train=0.743, test=0.750) f1: (train=0.784, test=0.791) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.871, test=0.868) balanced_accuracy: (train=0.745, test=0.741) f1: (train=0.787, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.870, test=0.866) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.741, test=0.739) f1: (train=0.784, test=0.781) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.782) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.872) balanced_accuracy: (train=0.743, test=0.750) f1: (train=0.784, test=0.791) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.871, test=0.868) balanced_accuracy: (train=0.745, test=0.741) f1: (train=0.787, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.870, test=0.866) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.741, test=0.739) f1: (train=0.784, test=0.781) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.782) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.872) balanced_accuracy: (train=0.743, test=0.750) f1: (train=0.784, test=0.791) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.871, test=0.868) balanced_accuracy: (train=0.745, test=0.741) f1: (train=0.787, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.870, test=0.866) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.741, test=0.739) f1: (train=0.784, test=0.781) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.782) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.872) balanced_accuracy: (train=0.743, test=0.750) f1: (train=0.784, test=0.791) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.871, test=0.868) balanced_accuracy: (train=0.745, test=0.741) f1: (train=0.787, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.870, test=0.866) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.741, test=0.739) f1: (train=0.784, test=0.781) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.782) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.872) balanced_accuracy: (train=0.743, test=0.750) f1: (train=0.784, test=0.791) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.784, test=0.777) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.740, test=0.738) f1: (train=0.782, test=0.780) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.742, test=0.738) f1: (train=0.784, test=0.780) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.872) balanced_accuracy: (train=0.741, test=0.749) f1: (train=0.782, test=0.790) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.784, test=0.777) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.740, test=0.738) f1: (train=0.782, test=0.780) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.742, test=0.738) f1: (train=0.784, test=0.780) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.872) balanced_accuracy: (train=0.741, test=0.749) f1: (train=0.782, test=0.790) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.784, test=0.777) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.740, test=0.738) f1: (train=0.782, test=0.780) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.742, test=0.738) f1: (train=0.784, test=0.780) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.872) balanced_accuracy: (train=0.741, test=0.749) f1: (train=0.782, test=0.790) total time=   0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.784, test=0.777) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.740, test=0.738) f1: (train=0.782, test=0.780) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.742, test=0.738) f1: (train=0.784, test=0.780) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.872) balanced_accuracy: (train=0.741, test=0.749) f1: (train=0.782, test=0.790) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.784, test=0.777) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.740, test=0.738) f1: (train=0.782, test=0.780) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.742, test=0.738) f1: (train=0.784, test=0.780) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.872) balanced_accuracy: (train=0.741, test=0.749) f1: (train=0.782, test=0.790) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.784, test=0.777) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.740, test=0.738) f1: (train=0.782, test=0.780) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.742, test=0.738) f1: (train=0.784, test=0.780) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.872) balanced_accuracy: (train=0.741, test=0.749) f1: (train=0.782, test=0.790) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.785, test=0.782) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.742, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.736) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.739, test=0.736) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.739, test=0.748) f1: (train=0.780, test=0.789) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.785, test=0.782) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.742, test=0.735) f1: (train=0.783, test=0.776) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.736) f1: (train=0.781, test=0.778) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.739, test=0.736) f1: (train=0.781, test=0.778) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.739, test=0.748) f1: (train=0.780, test=0.789) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.785, test=0.782) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.742, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.736) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.739, test=0.736) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.739, test=0.748) f1: (train=0.780, test=0.789) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.785, test=0.782) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.742, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.736) f1: (train=0.781, test=0.778) total time=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.739, test=0.736) f1: (train=0.781, test=0.778) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.739, test=0.748) f1: (train=0.780, test=0.789) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.785, test=0.782) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.742, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.736) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.739, test=0.736) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.739, test=0.748) f1: (train=0.780, test=0.789) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.785, test=0.782) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.742, test=0.735) f1: (train=0.783, test=0.776) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.736) f1: (train=0.781, test=0.778) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.739, test=0.736) f1: (train=0.781, test=0.778) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.739, test=0.748) f1: (train=0.780, test=0.789) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.866, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.866, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.866, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.866, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.866, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.866, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.871, test=0.868) balanced_accuracy: (train=0.745, test=0.741) f1: (train=0.787, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.870, test=0.866) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.741, test=0.739) f1: (train=0.784, test=0.781) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.782) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.872) balanced_accuracy: (train=0.743, test=0.750) f1: (train=0.784, test=0.791) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.871, test=0.868) balanced_accuracy: (train=0.745, test=0.741) f1: (train=0.787, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.870, test=0.866) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.741, test=0.739) f1: (train=0.784, test=0.781) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.782) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.872) balanced_accuracy: (train=0.743, test=0.750) f1: (train=0.784, test=0.791) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.871, test=0.868) balanced_accuracy: (train=0.745, test=0.741) f1: (train=0.787, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.870, test=0.866) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.741, test=0.739) f1: (train=0.784, test=0.781) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.782) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.872) balanced_accuracy: (train=0.743, test=0.750) f1: (train=0.784, test=0.791) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.871, test=0.868) balanced_accuracy: (train=0.745, test=0.741) f1: (train=0.787, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.870, test=0.866) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.741, test=0.739) f1: (train=0.784, test=0.781) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.782) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.872) balanced_accuracy: (train=0.743, test=0.750) f1: (train=0.784, test=0.791) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.871, test=0.868) balanced_accuracy: (train=0.745, test=0.741) f1: (train=0.787, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.870, test=0.866) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.741, test=0.739) f1: (train=0.784, test=0.781) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.782) total time=   0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.872) balanced_accuracy: (train=0.743, test=0.750) f1: (train=0.784, test=0.791) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.871, test=0.868) balanced_accuracy: (train=0.745, test=0.741) f1: (train=0.787, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.870, test=0.866) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.741, test=0.739) f1: (train=0.784, test=0.781) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.782) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.872) balanced_accuracy: (train=0.743, test=0.750) f1: (train=0.784, test=0.791) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.784, test=0.777) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.740, test=0.738) f1: (train=0.782, test=0.780) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.742, test=0.738) f1: (train=0.784, test=0.780) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.872) balanced_accuracy: (train=0.741, test=0.749) f1: (train=0.782, test=0.790) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.784, test=0.777) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.740, test=0.738) f1: (train=0.782, test=0.780) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.742, test=0.738) f1: (train=0.784, test=0.780) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.872) balanced_accuracy: (train=0.741, test=0.749) f1: (train=0.782, test=0.790) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.784, test=0.777) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.740, test=0.738) f1: (train=0.782, test=0.780) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.742, test=0.738) f1: (train=0.784, test=0.780) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.872) balanced_accuracy: (train=0.741, test=0.749) f1: (train=0.782, test=0.790) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.784, test=0.777) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.740, test=0.738) f1: (train=0.782, test=0.780) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.742, test=0.738) f1: (train=0.784, test=0.780) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.872) balanced_accuracy: (train=0.741, test=0.749) f1: (train=0.782, test=0.790) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.784, test=0.777) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.740, test=0.738) f1: (train=0.782, test=0.780) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.742, test=0.738) f1: (train=0.784, test=0.780) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.872) balanced_accuracy: (train=0.741, test=0.749) f1: (train=0.782, test=0.790) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.784, test=0.777) total time=   0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.740, test=0.738) f1: (train=0.782, test=0.780) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.742, test=0.738) f1: (train=0.784, test=0.780) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.872) balanced_accuracy: (train=0.741, test=0.749) f1: (train=0.782, test=0.790) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.785, test=0.782) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.742, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.736) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.739, test=0.736) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.739, test=0.748) f1: (train=0.780, test=0.789) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.785, test=0.782) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.742, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.736) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.739, test=0.736) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.739, test=0.748) f1: (train=0.780, test=0.789) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.785, test=0.782) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.742, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.736) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.739, test=0.736) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.739, test=0.748) f1: (train=0.780, test=0.789) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.785, test=0.782) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.742, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.736) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.739, test=0.736) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.739, test=0.748) f1: (train=0.780, test=0.789) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.785, test=0.782) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.742, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.736) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.739, test=0.736) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.739, test=0.748) f1: (train=0.780, test=0.789) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.785, test=0.782) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.742, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.736) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.739, test=0.736) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.739, test=0.748) f1: (train=0.780, test=0.789) total time=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.866, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.866, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.866, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.866, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.866, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.866, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.871, test=0.868) balanced_accuracy: (train=0.745, test=0.741) f1: (train=0.787, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.870, test=0.866) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.741, test=0.739) f1: (train=0.784, test=0.781) total time=   0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.782) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.872) balanced_accuracy: (train=0.743, test=0.750) f1: (train=0.784, test=0.791) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.871, test=0.868) balanced_accuracy: (train=0.745, test=0.741) f1: (train=0.787, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.870, test=0.866) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.741, test=0.739) f1: (train=0.784, test=0.781) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.782) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.872) balanced_accuracy: (train=0.743, test=0.750) f1: (train=0.784, test=0.791) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.871, test=0.868) balanced_accuracy: (train=0.745, test=0.741) f1: (train=0.787, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.870, test=0.866) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.741, test=0.739) f1: (train=0.784, test=0.781) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.782) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.872) balanced_accuracy: (train=0.743, test=0.750) f1: (train=0.784, test=0.791) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.871, test=0.868) balanced_accuracy: (train=0.745, test=0.741) f1: (train=0.787, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.870, test=0.866) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.741, test=0.739) f1: (train=0.784, test=0.781) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.782) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.872) balanced_accuracy: (train=0.743, test=0.750) f1: (train=0.784, test=0.791) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.871, test=0.868) balanced_accuracy: (train=0.745, test=0.741) f1: (train=0.787, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.870, test=0.866) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.741, test=0.739) f1: (train=0.784, test=0.781) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.782) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.872) balanced_accuracy: (train=0.743, test=0.750) f1: (train=0.784, test=0.791) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.871, test=0.868) balanced_accuracy: (train=0.745, test=0.741) f1: (train=0.787, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.870, test=0.866) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.741, test=0.739) f1: (train=0.784, test=0.781) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.782) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.872) balanced_accuracy: (train=0.743, test=0.750) f1: (train=0.784, test=0.791) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.784, test=0.777) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.740, test=0.738) f1: (train=0.782, test=0.780) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.742, test=0.738) f1: (train=0.784, test=0.780) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.872) balanced_accuracy: (train=0.741, test=0.749) f1: (train=0.782, test=0.790) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.784, test=0.777) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.740, test=0.738) f1: (train=0.782, test=0.780) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.742, test=0.738) f1: (train=0.784, test=0.780) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.872) balanced_accuracy: (train=0.741, test=0.749) f1: (train=0.782, test=0.790) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.784, test=0.777) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.740, test=0.738) f1: (train=0.782, test=0.780) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.742, test=0.738) f1: (train=0.784, test=0.780) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.872) balanced_accuracy: (train=0.741, test=0.749) f1: (train=0.782, test=0.790) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.784, test=0.777) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.740, test=0.738) f1: (train=0.782, test=0.780) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.742, test=0.738) f1: (train=0.784, test=0.780) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.872) balanced_accuracy: (train=0.741, test=0.749) f1: (train=0.782, test=0.790) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.784, test=0.777) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.740, test=0.738) f1: (train=0.782, test=0.780) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.742, test=0.738) f1: (train=0.784, test=0.780) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.872) balanced_accuracy: (train=0.741, test=0.749) f1: (train=0.782, test=0.790) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.784, test=0.777) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.740, test=0.738) f1: (train=0.782, test=0.780) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.742, test=0.738) f1: (train=0.784, test=0.780) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.872) balanced_accuracy: (train=0.741, test=0.749) f1: (train=0.782, test=0.790) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.785, test=0.782) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.742, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.736) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.739, test=0.736) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.739, test=0.748) f1: (train=0.780, test=0.789) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.785, test=0.782) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.742, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.736) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.739, test=0.736) f1: (train=0.781, test=0.778) total time=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.739, test=0.748) f1: (train=0.780, test=0.789) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.785, test=0.782) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.742, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.736) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.739, test=0.736) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.739, test=0.748) f1: (train=0.780, test=0.789) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.785, test=0.782) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.742, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.736) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.739, test=0.736) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.739, test=0.748) f1: (train=0.780, test=0.789) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.785, test=0.782) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.742, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.736) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.739, test=0.736) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.739, test=0.748) f1: (train=0.780, test=0.789) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.785, test=0.782) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.742, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.736) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.739, test=0.736) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.739, test=0.748) f1: (train=0.780, test=0.789) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.866, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.866, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.866, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.866, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.866, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.866, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.746, test=0.743) f1: (train=0.787, test=0.784) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.870, test=0.866) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.786, test=0.778) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.782) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.871, test=0.868) balanced_accuracy: (train=0.744, test=0.741) f1: (train=0.787, test=0.783) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.873) balanced_accuracy: (train=0.744, test=0.752) f1: (train=0.785, test=0.793) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.746, test=0.743) f1: (train=0.787, test=0.784) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.870, test=0.866) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.786, test=0.778) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.782) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.871, test=0.868) balanced_accuracy: (train=0.744, test=0.741) f1: (train=0.787, test=0.783) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.873) balanced_accuracy: (train=0.744, test=0.752) f1: (train=0.785, test=0.793) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.746, test=0.743) f1: (train=0.787, test=0.784) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.870, test=0.866) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.786, test=0.778) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.782) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.871, test=0.868) balanced_accuracy: (train=0.744, test=0.741) f1: (train=0.787, test=0.783) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.873) balanced_accuracy: (train=0.744, test=0.752) f1: (train=0.785, test=0.793) total time=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.746, test=0.743) f1: (train=0.787, test=0.784) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.870, test=0.866) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.786, test=0.778) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.782) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.871, test=0.868) balanced_accuracy: (train=0.744, test=0.741) f1: (train=0.787, test=0.783) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.873) balanced_accuracy: (train=0.744, test=0.752) f1: (train=0.785, test=0.793) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.746, test=0.743) f1: (train=0.787, test=0.784) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.870, test=0.866) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.786, test=0.778) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.782) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.871, test=0.868) balanced_accuracy: (train=0.744, test=0.741) f1: (train=0.787, test=0.783) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.873) balanced_accuracy: (train=0.744, test=0.752) f1: (train=0.785, test=0.793) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.746, test=0.743) f1: (train=0.787, test=0.784) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.870, test=0.866) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.786, test=0.778) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.782) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.871, test=0.868) balanced_accuracy: (train=0.744, test=0.741) f1: (train=0.787, test=0.783) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.873) balanced_accuracy: (train=0.744, test=0.752) f1: (train=0.785, test=0.793) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.743, test=0.741) f1: (train=0.785, test=0.782) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.742, test=0.735) f1: (train=0.784, test=0.777) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.785, test=0.782) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.784, test=0.781) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.872) balanced_accuracy: (train=0.742, test=0.750) f1: (train=0.783, test=0.791) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.743, test=0.741) f1: (train=0.785, test=0.782) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.742, test=0.735) f1: (train=0.784, test=0.777) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.785, test=0.782) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.784, test=0.781) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.872) balanced_accuracy: (train=0.742, test=0.750) f1: (train=0.783, test=0.791) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.743, test=0.741) f1: (train=0.785, test=0.782) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.742, test=0.735) f1: (train=0.784, test=0.777) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.785, test=0.782) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.784, test=0.781) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.872) balanced_accuracy: (train=0.742, test=0.750) f1: (train=0.783, test=0.791) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.743, test=0.741) f1: (train=0.785, test=0.782) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.742, test=0.735) f1: (train=0.784, test=0.777) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.785, test=0.782) total time=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.784, test=0.781) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.872) balanced_accuracy: (train=0.742, test=0.750) f1: (train=0.783, test=0.791) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.743, test=0.741) f1: (train=0.785, test=0.782) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.742, test=0.735) f1: (train=0.784, test=0.777) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.785, test=0.782) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.784, test=0.781) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.872) balanced_accuracy: (train=0.742, test=0.750) f1: (train=0.783, test=0.791) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.743, test=0.741) f1: (train=0.785, test=0.782) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.742, test=0.735) f1: (train=0.784, test=0.777) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.785, test=0.782) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.784, test=0.781) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.872) balanced_accuracy: (train=0.742, test=0.750) f1: (train=0.783, test=0.791) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.737) f1: (train=0.781, test=0.779) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.738) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.740, test=0.749) f1: (train=0.781, test=0.789) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.737) f1: (train=0.781, test=0.779) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.738) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.740, test=0.749) f1: (train=0.781, test=0.789) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.737) f1: (train=0.781, test=0.779) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.738) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.740, test=0.749) f1: (train=0.781, test=0.789) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.737) f1: (train=0.781, test=0.779) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.738) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.740, test=0.749) f1: (train=0.781, test=0.789) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.737) f1: (train=0.781, test=0.779) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.738) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.740, test=0.749) f1: (train=0.781, test=0.789) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.737) f1: (train=0.781, test=0.779) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.738) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.740, test=0.749) f1: (train=0.781, test=0.789) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.780, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.865, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.780, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.865, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.780, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.865, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.780, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.865, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.780, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.865, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.780, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.865, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.749, test=0.745) f1: (train=0.790, test=0.786) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.746, test=0.738) f1: (train=0.788, test=0.780) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.789, test=0.785) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.788, test=0.784) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.870, test=0.873) balanced_accuracy: (train=0.746, test=0.754) f1: (train=0.788, test=0.795) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.749, test=0.745) f1: (train=0.790, test=0.786) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.746, test=0.738) f1: (train=0.788, test=0.780) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.789, test=0.785) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.788, test=0.784) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.870, test=0.873) balanced_accuracy: (train=0.746, test=0.754) f1: (train=0.788, test=0.795) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.749, test=0.745) f1: (train=0.790, test=0.786) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.746, test=0.738) f1: (train=0.788, test=0.780) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.789, test=0.785) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.788, test=0.784) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.870, test=0.873) balanced_accuracy: (train=0.746, test=0.754) f1: (train=0.788, test=0.795) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.749, test=0.745) f1: (train=0.790, test=0.786) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.746, test=0.738) f1: (train=0.788, test=0.780) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.789, test=0.785) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.788, test=0.784) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.870, test=0.873) balanced_accuracy: (train=0.746, test=0.754) f1: (train=0.788, test=0.795) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.749, test=0.745) f1: (train=0.790, test=0.786) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.746, test=0.738) f1: (train=0.788, test=0.780) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.789, test=0.785) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.788, test=0.784) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.870, test=0.873) balanced_accuracy: (train=0.746, test=0.754) f1: (train=0.788, test=0.795) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.749, test=0.745) f1: (train=0.790, test=0.786) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.746, test=0.738) f1: (train=0.788, test=0.780) total time=   0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.789, test=0.785) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.788, test=0.784) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.870, test=0.873) balanced_accuracy: (train=0.746, test=0.754) f1: (train=0.788, test=0.795) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.870, test=0.865) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.784, test=0.781) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.872) balanced_accuracy: (train=0.744, test=0.752) f1: (train=0.785, test=0.793) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.870, test=0.865) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.784, test=0.781) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.872) balanced_accuracy: (train=0.744, test=0.752) f1: (train=0.785, test=0.793) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.870, test=0.865) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.784, test=0.781) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.872) balanced_accuracy: (train=0.744, test=0.752) f1: (train=0.785, test=0.793) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.870, test=0.865) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.784, test=0.781) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.872) balanced_accuracy: (train=0.744, test=0.752) f1: (train=0.785, test=0.793) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.870, test=0.865) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.784, test=0.781) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.872) balanced_accuracy: (train=0.744, test=0.752) f1: (train=0.785, test=0.793) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.870, test=0.865) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.784, test=0.781) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.872) balanced_accuracy: (train=0.744, test=0.752) f1: (train=0.785, test=0.793) total time=   0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.737) f1: (train=0.781, test=0.779) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.738) f1: (train=0.783, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.740, test=0.749) f1: (train=0.781, test=0.789) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.737) f1: (train=0.781, test=0.779) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.738) f1: (train=0.783, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.740, test=0.749) f1: (train=0.781, test=0.789) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.737) f1: (train=0.781, test=0.779) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.738) f1: (train=0.783, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.740, test=0.749) f1: (train=0.781, test=0.789) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.737) f1: (train=0.781, test=0.779) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.738) f1: (train=0.783, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.740, test=0.749) f1: (train=0.781, test=0.789) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.737) f1: (train=0.781, test=0.779) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.738) f1: (train=0.783, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.740, test=0.749) f1: (train=0.781, test=0.789) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.737) f1: (train=0.781, test=0.779) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.738) f1: (train=0.783, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.740, test=0.749) f1: (train=0.781, test=0.789) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.780, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.865, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.780, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.737, test=0.734) f1: (train=0.780, test=0.777) total time=   1.4s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.779, test=0.776) total time=   1.6s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   2.9s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.780, test=0.776) total time=   3.9s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.779, test=0.776) total time=   2.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.737, test=0.731) f1: (train=0.780, test=0.773) total time=   4.1s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.872, test=0.870) balanced_accuracy: (train=0.747, test=0.742) f1: (train=0.789, test=0.785) total time=   5.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.872, test=0.870) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.790, test=0.786) total time=   8.5s\n",
      "[CV 2/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.872, test=0.867) balanced_accuracy: (train=0.746, test=0.738) f1: (train=0.789, test=0.780) total time=  16.4s\n",
      "[CV 1/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   1.2s\n",
      "[CV 2/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.779, test=0.772) total time=   1.4s\n",
      "[CV 5/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.866, test=0.870) balanced_accuracy: (train=0.733, test=0.741) f1: (train=0.776, test=0.784) total time=   1.8s\n",
      "[CV 3/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   2.6s\n",
      "[CV 3/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.735, test=0.732) f1: (train=0.779, test=0.775) total time=   4.6s\n",
      "[CV 2/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.737, test=0.730) f1: (train=0.780, test=0.773) total time=   1.3s\n",
      "[CV 2/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.737, test=0.731) f1: (train=0.780, test=0.774) total time=   2.2s\n",
      "[CV 5/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.866, test=0.871) balanced_accuracy: (train=0.733, test=0.742) f1: (train=0.776, test=0.785) total time=   2.1s\n",
      "[CV 2/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.737, test=0.731) f1: (train=0.780, test=0.773) total time=   4.2s\n",
      "[CV 4/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.872, test=0.870) balanced_accuracy: (train=0.747, test=0.742) f1: (train=0.790, test=0.785) total time=   5.4s\n",
      "[CV 1/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.872, test=0.870) balanced_accuracy: (train=0.748, test=0.744) f1: (train=0.790, test=0.786) total time=   7.2s\n",
      "[CV 3/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.873, test=0.870) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.790, test=0.786) total time=  17.3s\n",
      "[CV 3/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.737, test=0.733) f1: (train=0.780, test=0.775) total time=   1.2s\n",
      "[CV 4/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   1.3s\n",
      "[CV 1/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   2.4s\n",
      "[CV 1/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   2.6s\n",
      "[CV 4/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   3.3s\n",
      "[CV 1/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   1.4s\n",
      "[CV 4/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.737, test=0.735) f1: (train=0.779, test=0.778) total time=   1.4s\n",
      "[CV 1/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   2.2s\n",
      "[CV 5/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.787) total time=   4.2s\n",
      "[CV 2/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.873, test=0.868) balanced_accuracy: (train=0.747, test=0.739) f1: (train=0.790, test=0.781) total time=   5.2s\n",
      "[CV 1/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.872, test=0.870) balanced_accuracy: (train=0.748, test=0.744) f1: (train=0.790, test=0.786) total time=   8.7s\n",
      "[CV 4/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.872, test=0.870) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.789, test=0.784) total time=  16.6s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.732) f1: (train=0.779, test=0.775) total time=   1.6s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   1.6s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.866, test=0.870) balanced_accuracy: (train=0.733, test=0.742) f1: (train=0.776, test=0.785) total time=   1.9s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   2.4s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.733, test=0.743) f1: (train=0.776, test=0.786) total time=   4.4s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   1.7s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   1.3s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   2.4s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   4.5s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.783) total time=   5.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.744, test=0.741) f1: (train=0.787, test=0.784) total time=   8.5s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.785, test=0.782) total time=  17.1s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.870, test=0.874) balanced_accuracy: (train=0.741, test=0.751) f1: (train=0.784, test=0.794) total time=  13.8s\n",
      "[CV 1/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.778, test=0.776) total time=   1.4s\n",
      "[CV 4/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   1.4s\n",
      "[CV 5/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.866, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.776, test=0.787) total time=   2.2s\n",
      "[CV 2/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.780, test=0.773) total time=   4.3s\n",
      "[CV 5/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.733, test=0.743) f1: (train=0.777, test=0.786) total time=   4.4s\n",
      "[CV 1/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.744, test=0.740) f1: (train=0.787, test=0.783) total time=   4.9s\n",
      "[CV 2/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.872, test=0.867) balanced_accuracy: (train=0.745, test=0.737) f1: (train=0.788, test=0.779) total time=   8.9s\n",
      "[CV 5/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.870, test=0.874) balanced_accuracy: (train=0.742, test=0.750) f1: (train=0.785, test=0.793) total time=  17.8s\n",
      "[CV 3/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.732) f1: (train=0.779, test=0.775) total time=   1.4s\n",
      "[CV 2/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.736, test=0.729) f1: (train=0.779, test=0.772) total time=   1.6s\n",
      "[CV 4/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.778, test=0.775) total time=   1.5s\n",
      "[CV 1/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.735) f1: (train=0.779, test=0.778) total time=   2.5s\n",
      "[CV 1/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   4.5s\n",
      "[CV 2/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.780, test=0.773) total time=   4.2s\n",
      "[CV 1/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.735) f1: (train=0.779, test=0.778) total time=   2.1s\n",
      "[CV 3/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   4.1s\n",
      "[CV 4/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.779, test=0.777) total time=   4.8s\n",
      "[CV 2/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.872, test=0.867) balanced_accuracy: (train=0.744, test=0.736) f1: (train=0.787, test=0.779) total time=   3.7s\n",
      "[CV 3/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.786, test=0.783) total time=   9.1s\n",
      "[CV 1/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.744, test=0.741) f1: (train=0.787, test=0.784) total time=  15.3s\n",
      "[CV 5/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.870, test=0.874) balanced_accuracy: (train=0.742, test=0.751) f1: (train=0.785, test=0.794) total time=  17.0s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   1.2s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.735, test=0.735) f1: (train=0.778, test=0.778) total time=   1.3s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   2.0s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.780, test=0.772) total time=   3.9s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   4.3s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.872, test=0.867) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.787, test=0.779) total time=   5.1s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.870, test=0.874) balanced_accuracy: (train=0.741, test=0.750) f1: (train=0.784, test=0.793) total time=   8.2s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.787, test=0.778) total time=  18.6s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.866, test=0.869) balanced_accuracy: (train=0.732, test=0.741) f1: (train=0.775, test=0.784) total time=   1.4s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.737, test=0.731) f1: (train=0.780, test=0.773) total time=   2.0s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.779, test=0.776) total time=   2.2s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.776, test=0.786) total time=   4.3s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.866, test=0.871) balanced_accuracy: (train=0.733, test=0.742) f1: (train=0.776, test=0.785) total time=   1.4s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.776) total time=   1.3s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.866, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.776, test=0.787) total time=   2.3s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.780, test=0.773) total time=   4.3s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.779, test=0.777) total time=   4.5s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.744, test=0.740) f1: (train=0.787, test=0.783) total time=   5.4s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.786, test=0.783) total time=   8.7s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.744, test=0.741) f1: (train=0.787, test=0.784) total time=  19.0s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.779, test=0.776) total time=   1.3s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.776) total time=   1.2s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.779, test=0.776) total time=   2.0s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.780, test=0.772) total time=   2.4s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   4.3s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.736, test=0.729) f1: (train=0.779, test=0.772) total time=   1.2s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.776) total time=   2.2s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.779, test=0.776) total time=   2.0s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.866, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.786) total time=   4.3s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.872, test=0.867) balanced_accuracy: (train=0.745, test=0.737) f1: (train=0.788, test=0.779) total time=   6.3s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.741) f1: (train=0.786, test=0.784) total time=   9.7s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.744, test=0.741) f1: (train=0.787, test=0.783) total time=  20.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   1.2s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   1.3s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.786) total time=   2.2s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   2.2s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.733, test=0.743) f1: (train=0.776, test=0.786) total time=   3.8s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.776) total time=   1.4s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.737, test=0.730) f1: (train=0.780, test=0.772) total time=   1.3s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   1.4s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   1.9s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.778) total time=   4.0s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.782) total time=   5.3s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.744, test=0.740) f1: (train=0.787, test=0.783) total time=   8.5s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.785, test=0.782) total time=   8.7s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.744, test=0.740) f1: (train=0.786, test=0.783) total time=  18.0s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   3.9s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   4.2s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.776) total time=   1.0s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.737, test=0.731) f1: (train=0.780, test=0.773) total time=   2.1s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.779, test=0.776) total time=   4.4s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.741) f1: (train=0.786, test=0.783) total time=   5.5s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.870, test=0.875) balanced_accuracy: (train=0.742, test=0.752) f1: (train=0.785, test=0.795) total time=   5.8s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.787, test=0.779) total time=   8.9s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.783) total time=  17.2s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.866, test=0.870) balanced_accuracy: (train=0.733, test=0.742) f1: (train=0.776, test=0.785) total time=   1.1s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.778, test=0.775) total time=   1.2s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.866, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.776, test=0.787) total time=   2.0s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.778, test=0.776) total time=   2.0s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.779, test=0.776) total time=   4.4s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.864) balanced_accuracy: (train=0.735, test=0.729) f1: (train=0.778, test=0.771) total time=   1.3s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.866, test=0.870) balanced_accuracy: (train=0.733, test=0.742) f1: (train=0.776, test=0.785) total time=   1.4s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   2.2s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   4.2s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.777) total time=   4.7s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.744, test=0.740) f1: (train=0.787, test=0.783) total time=   5.6s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.870, test=0.874) balanced_accuracy: (train=0.742, test=0.751) f1: (train=0.785, test=0.794) total time=  10.3s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.785, test=0.782) total time=  15.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.865, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   1.3s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.786) total time=   1.6s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   2.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.735) f1: (train=0.780, test=0.778) total time=   4.2s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.786) total time=   1.2s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.786) total time=   1.9s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.735) f1: (train=0.779, test=0.778) total time=   3.9s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   3.7s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.871, test=0.875) balanced_accuracy: (train=0.746, test=0.753) f1: (train=0.788, test=0.795) total time=   4.6s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.872, test=0.870) balanced_accuracy: (train=0.746, test=0.743) f1: (train=0.789, test=0.785) total time=   5.7s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.871, test=0.875) balanced_accuracy: (train=0.744, test=0.753) f1: (train=0.787, test=0.796) total time=   8.1s\n",
      "[CV 2/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.872, test=0.867) balanced_accuracy: (train=0.746, test=0.738) f1: (train=0.789, test=0.780) total time=  15.9s\n",
      "[CV 3/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.779, test=0.776) total time=   2.3s\n",
      "[CV 2/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.780, test=0.773) total time=   4.2s\n",
      "[CV 3/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.737, test=0.733) f1: (train=0.780, test=0.775) total time=   1.4s\n",
      "[CV 4/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.737, test=0.735) f1: (train=0.779, test=0.778) total time=   1.2s\n",
      "[CV 3/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   1.9s\n",
      "[CV 4/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   4.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.872, test=0.870) balanced_accuracy: (train=0.748, test=0.743) f1: (train=0.791, test=0.785) total time=   5.3s\n",
      "[CV 1/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.872, test=0.870) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.790, test=0.785) total time=   7.1s\n",
      "[CV 3/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.872, test=0.870) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.789, test=0.785) total time=   8.4s\n",
      "[CV 5/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.871, test=0.875) balanced_accuracy: (train=0.745, test=0.753) f1: (train=0.787, test=0.796) total time=  12.7s\n",
      "[CV 2/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.779, test=0.772) total time=   1.4s\n",
      "[CV 3/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.737, test=0.734) f1: (train=0.780, test=0.777) total time=   1.1s\n",
      "[CV 4/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.780, test=0.777) total time=   2.2s\n",
      "[CV 2/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.737, test=0.730) f1: (train=0.780, test=0.773) total time=   2.3s\n",
      "[CV 1/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.737, test=0.735) f1: (train=0.780, test=0.777) total time=   4.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.737, test=0.733) f1: (train=0.780, test=0.775) total time=   1.3s\n",
      "[CV 4/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   1.3s\n",
      "[CV 4/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.780, test=0.777) total time=   1.7s\n",
      "[CV 4/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   2.1s\n",
      "[CV 1/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.735) f1: (train=0.779, test=0.778) total time=   4.1s\n",
      "[CV 3/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.872, test=0.870) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.790, test=0.786) total time=   5.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.872, test=0.870) balanced_accuracy: (train=0.747, test=0.742) f1: (train=0.790, test=0.785) total time=   8.3s\n",
      "[CV 1/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.872, test=0.870) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.790, test=0.785) total time=  16.6s\n",
      "[CV 4/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.872, test=0.870) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.789, test=0.785) total time=  15.8s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.777) total time=   1.4s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   1.3s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   2.1s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.778) total time=   4.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.782) total time=   5.2s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.744, test=0.740) f1: (train=0.787, test=0.783) total time=   8.5s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.783) total time=   8.6s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.744, test=0.740) f1: (train=0.786, test=0.783) total time=  17.5s\n",
      "[CV 3/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   2.4s\n",
      "[CV 3/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   4.2s\n",
      "[CV 2/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.864) balanced_accuracy: (train=0.735, test=0.729) f1: (train=0.778, test=0.771) total time=   1.2s\n",
      "[CV 2/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.736, test=0.729) f1: (train=0.779, test=0.772) total time=   1.3s\n",
      "[CV 5/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.866, test=0.869) balanced_accuracy: (train=0.732, test=0.741) f1: (train=0.775, test=0.784) total time=   1.3s\n",
      "[CV 2/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.780, test=0.772) total time=   2.1s\n",
      "[CV 4/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   4.3s\n",
      "[CV 4/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.741) f1: (train=0.786, test=0.783) total time=   5.5s\n",
      "[CV 4/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.783) total time=   5.9s\n",
      "[CV 2/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.787, test=0.779) total time=  10.2s\n",
      "[CV 4/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.783) total time=  15.8s\n",
      "[CV 3/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.779, test=0.776) total time=   1.5s\n",
      "[CV 5/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.866, test=0.869) balanced_accuracy: (train=0.732, test=0.741) f1: (train=0.775, test=0.784) total time=   1.5s\n",
      "[CV 2/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.737, test=0.731) f1: (train=0.780, test=0.773) total time=   2.1s\n",
      "[CV 5/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.866, test=0.871) balanced_accuracy: (train=0.733, test=0.742) f1: (train=0.776, test=0.786) total time=   2.3s\n",
      "[CV 4/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   4.6s\n",
      "[CV 2/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.736, test=0.729) f1: (train=0.779, test=0.772) total time=   1.4s\n",
      "[CV 5/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.866, test=0.869) balanced_accuracy: (train=0.732, test=0.741) f1: (train=0.775, test=0.784) total time=   1.4s\n",
      "[CV 2/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.780, test=0.772) total time=   2.2s\n",
      "[CV 4/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   4.1s\n",
      "[CV 1/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.744, test=0.741) f1: (train=0.787, test=0.783) total time=   5.4s\n",
      "[CV 2/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.744, test=0.736) f1: (train=0.787, test=0.779) total time=   9.2s\n",
      "[CV 5/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.870, test=0.874) balanced_accuracy: (train=0.742, test=0.751) f1: (train=0.785, test=0.794) total time=   9.4s\n",
      "[CV 2/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.787, test=0.778) total time=  18.5s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.733, test=0.743) f1: (train=0.777, test=0.786) total time=   2.1s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   4.2s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.777) total time=   1.3s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.864) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.779, test=0.772) total time=   1.3s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.779, test=0.776) total time=   1.9s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   4.1s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.745, test=0.741) f1: (train=0.788, test=0.783) total time=   5.4s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.785, test=0.782) total time=   3.5s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.783) total time=   8.1s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.870, test=0.874) balanced_accuracy: (train=0.741, test=0.751) f1: (train=0.784, test=0.794) total time=  14.8s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.783) total time=  12.6s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.866, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.786) total time=   4.2s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.737, test=0.731) f1: (train=0.780, test=0.773) total time=   1.4s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.735) f1: (train=0.779, test=0.778) total time=   2.2s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.776, test=0.786) total time=   4.1s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.745, test=0.741) f1: (train=0.787, test=0.783) total time=   5.6s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.785, test=0.782) total time=   5.8s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.744, test=0.741) f1: (train=0.787, test=0.783) total time=   8.6s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.785, test=0.782) total time=  18.8s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.737, test=0.731) f1: (train=0.780, test=0.773) total time=   1.4s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   2.2s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   2.4s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.776, test=0.786) total time=   4.2s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.778, test=0.776) total time=   1.3s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   1.5s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.779, test=0.776) total time=   2.0s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.866, test=0.871) balanced_accuracy: (train=0.733, test=0.742) f1: (train=0.776, test=0.786) total time=   2.2s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.780, test=0.773) total time=   4.0s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.785, test=0.782) total time=   5.9s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.870, test=0.874) balanced_accuracy: (train=0.742, test=0.751) f1: (train=0.785, test=0.794) total time=   9.8s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.744, test=0.736) f1: (train=0.787, test=0.779) total time=  19.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.780, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.786) total time=   1.3s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.786) total time=   1.4s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   2.1s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.737, test=0.731) f1: (train=0.780, test=0.773) total time=   2.0s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.780, test=0.772) total time=   4.2s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.737, test=0.730) f1: (train=0.780, test=0.773) total time=   4.1s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.735) f1: (train=0.779, test=0.778) total time=   2.1s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.733, test=0.743) f1: (train=0.776, test=0.786) total time=   4.2s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.744, test=0.736) f1: (train=0.787, test=0.778) total time=   5.4s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.871, test=0.870) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.783) total time=   5.4s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.744, test=0.740) f1: (train=0.786, test=0.783) total time=   8.4s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.783) total time=  13.3s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.778, test=0.776) total time=   1.5s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.778, test=0.776) total time=   1.2s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.866, test=0.870) balanced_accuracy: (train=0.733, test=0.742) f1: (train=0.776, test=0.785) total time=   1.6s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.779, test=0.773) total time=   2.3s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.866, test=0.870) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.785) total time=   2.2s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   4.2s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.778, test=0.776) total time=   1.5s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.777) total time=   1.6s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.776) total time=   2.2s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.779, test=0.776) total time=   2.1s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.866, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.786) total time=   4.3s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.872, test=0.867) balanced_accuracy: (train=0.745, test=0.737) f1: (train=0.788, test=0.779) total time=   5.7s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.745, test=0.741) f1: (train=0.787, test=0.784) total time=   8.9s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.785, test=0.783) total time=  15.2s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.741) f1: (train=0.786, test=0.783) total time=  13.6s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.778) total time=   4.4s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.732) f1: (train=0.779, test=0.775) total time=   1.3s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.776) total time=   1.3s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.866, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.776, test=0.787) total time=   2.1s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.780, test=0.773) total time=   4.3s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.779, test=0.777) total time=   4.9s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.870, test=0.875) balanced_accuracy: (train=0.742, test=0.752) f1: (train=0.785, test=0.795) total time=   5.6s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.787, test=0.779) total time=   8.6s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.870, test=0.874) balanced_accuracy: (train=0.742, test=0.750) f1: (train=0.785, test=0.793) total time=  19.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.865, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.780, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.778) total time=   3.9s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.863) balanced_accuracy: (train=0.736, test=0.729) f1: (train=0.778, test=0.771) total time=   1.4s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.732) f1: (train=0.779, test=0.775) total time=   1.2s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   1.4s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   2.0s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.737, test=0.730) f1: (train=0.780, test=0.773) total time=   4.1s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.870, test=0.875) balanced_accuracy: (train=0.741, test=0.751) f1: (train=0.784, test=0.794) total time=   5.3s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.785, test=0.782) total time=   8.6s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.783) total time=   7.3s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.870, test=0.874) balanced_accuracy: (train=0.741, test=0.750) f1: (train=0.784, test=0.793) total time=  12.6s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.736, test=0.729) f1: (train=0.779, test=0.772) total time=   1.0s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.737, test=0.731) f1: (train=0.780, test=0.773) total time=   1.5s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.779, test=0.776) total time=   2.3s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.866, test=0.871) balanced_accuracy: (train=0.733, test=0.742) f1: (train=0.776, test=0.786) total time=   2.2s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.778) total time=   4.1s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.864) balanced_accuracy: (train=0.735, test=0.729) f1: (train=0.778, test=0.771) total time=   1.3s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.779, test=0.776) total time=   1.4s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.779, test=0.773) total time=   2.2s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.779, test=0.777) total time=   2.2s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   4.3s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.783) total time=   5.1s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.870, test=0.874) balanced_accuracy: (train=0.742, test=0.751) f1: (train=0.785, test=0.794) total time=   8.9s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.744, test=0.736) f1: (train=0.787, test=0.779) total time=  18.8s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.864) balanced_accuracy: (train=0.735, test=0.729) f1: (train=0.778, test=0.771) total time=   1.3s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.778, test=0.776) total time=   1.3s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.736, test=0.729) f1: (train=0.779, test=0.772) total time=   1.5s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.866, test=0.869) balanced_accuracy: (train=0.732, test=0.741) f1: (train=0.775, test=0.784) total time=   1.3s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.735) f1: (train=0.779, test=0.778) total time=   2.2s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.779, test=0.777) total time=   2.3s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.866, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.786) total time=   4.0s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.866, test=0.871) balanced_accuracy: (train=0.733, test=0.742) f1: (train=0.776, test=0.785) total time=   1.2s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.776) total time=   1.3s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   2.2s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   4.3s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.741) f1: (train=0.786, test=0.783) total time=   4.6s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.785, test=0.782) total time=   5.4s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.783) total time=   9.8s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.744, test=0.741) f1: (train=0.787, test=0.784) total time=  19.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.869, test=0.864) balanced_accuracy: (train=0.739, test=0.731) f1: (train=0.782, test=0.773) total time=   1.2s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   2.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.737, test=0.730) f1: (train=0.780, test=0.773) total time=   3.5s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.786) total time=   4.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.737, test=0.735) f1: (train=0.780, test=0.778) total time=   2.1s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.735) f1: (train=0.780, test=0.778) total time=   4.2s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.872, test=0.870) balanced_accuracy: (train=0.746, test=0.743) f1: (train=0.789, test=0.785) total time=   5.2s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.872, test=0.870) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.790, test=0.786) total time=   8.4s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.746, test=0.741) f1: (train=0.789, test=0.783) total time=  13.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.746, test=0.741) f1: (train=0.789, test=0.784) total time=  12.6s\n",
      "[CV 1/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.735) f1: (train=0.779, test=0.778) total time=   3.9s\n",
      "[CV 5/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.786) total time=   1.3s\n",
      "[CV 3/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.737, test=0.734) f1: (train=0.780, test=0.777) total time=   1.2s\n",
      "[CV 2/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.737, test=0.730) f1: (train=0.780, test=0.773) total time=   1.9s\n",
      "[CV 2/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.780, test=0.773) total time=   4.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.871, test=0.875) balanced_accuracy: (train=0.745, test=0.754) f1: (train=0.788, test=0.796) total time=   5.2s\n",
      "[CV 3/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.873, test=0.870) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.790, test=0.786) total time=   8.5s\n",
      "[CV 4/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.872, test=0.870) balanced_accuracy: (train=0.746, test=0.743) f1: (train=0.789, test=0.785) total time=   8.2s\n",
      "[CV 1/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.873, test=0.870) balanced_accuracy: (train=0.748, test=0.743) f1: (train=0.790, test=0.786) total time=  16.3s\n",
      "[CV 4/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.737, test=0.734) f1: (train=0.780, test=0.777) total time=   2.1s\n",
      "[CV 3/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.735, test=0.732) f1: (train=0.779, test=0.775) total time=   4.2s\n",
      "[CV 4/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.780, test=0.776) total time=   3.8s\n",
      "[CV 2/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.737, test=0.730) f1: (train=0.780, test=0.773) total time=   1.9s\n",
      "[CV 2/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.737, test=0.730) f1: (train=0.780, test=0.773) total time=   4.1s\n",
      "[CV 4/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.780, test=0.776) total time=   4.4s\n",
      "[CV 2/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.873, test=0.868) balanced_accuracy: (train=0.747, test=0.739) f1: (train=0.791, test=0.781) total time=   5.3s\n",
      "[CV 5/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.871, test=0.875) balanced_accuracy: (train=0.745, test=0.753) f1: (train=0.788, test=0.796) total time=   8.4s\n",
      "[CV 3/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.873, test=0.870) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.790, test=0.785) total time=  16.5s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.732) f1: (train=0.779, test=0.775) total time=   1.4s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   1.3s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.737, test=0.731) f1: (train=0.780, test=0.773) total time=   2.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.778) total time=   4.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   4.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.864) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.779, test=0.772) total time=   1.3s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.779, test=0.776) total time=   1.9s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.733, test=0.743) f1: (train=0.776, test=0.786) total time=   4.1s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.745, test=0.741) f1: (train=0.788, test=0.783) total time=   5.3s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.871, test=0.870) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.783) total time=   4.9s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.870, test=0.874) balanced_accuracy: (train=0.741, test=0.750) f1: (train=0.784, test=0.793) total time=   7.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.744, test=0.740) f1: (train=0.787, test=0.783) total time=  16.8s\n",
      "[CV 3/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.732) f1: (train=0.779, test=0.775) total time=   1.4s\n",
      "[CV 4/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   1.6s\n",
      "[CV 1/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.776) total time=   2.2s\n",
      "[CV 4/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   2.5s\n",
      "[CV 4/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.779, test=0.776) total time=   3.1s\n",
      "[CV 3/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.777) total time=   3.6s\n",
      "[CV 4/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.779, test=0.776) total time=   2.4s\n",
      "[CV 1/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   4.3s\n",
      "[CV 4/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.779, test=0.777) total time=   4.5s\n",
      "[CV 2/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.872, test=0.867) balanced_accuracy: (train=0.744, test=0.736) f1: (train=0.787, test=0.779) total time=   5.3s\n",
      "[CV 4/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.783) total time=  10.2s\n",
      "[CV 1/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.744, test=0.741) f1: (train=0.787, test=0.784) total time=  18.1s\n",
      "[CV 1/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.777) total time=   1.6s\n",
      "[CV 3/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.776) total time=   1.4s\n",
      "[CV 5/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.866, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.776, test=0.787) total time=   2.1s\n",
      "[CV 4/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.779, test=0.777) total time=   2.1s\n",
      "[CV 2/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.780, test=0.773) total time=   4.7s\n",
      "[CV 5/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.866, test=0.871) balanced_accuracy: (train=0.733, test=0.742) f1: (train=0.776, test=0.785) total time=   1.6s\n",
      "[CV 3/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.776) total time=   1.5s\n",
      "[CV 4/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   2.2s\n",
      "[CV 3/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   4.3s\n",
      "[CV 5/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.870, test=0.874) balanced_accuracy: (train=0.741, test=0.750) f1: (train=0.784, test=0.793) total time=   5.4s\n",
      "[CV 1/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.744, test=0.740) f1: (train=0.786, test=0.783) total time=   9.2s\n",
      "[CV 3/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.785, test=0.783) total time=   9.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.870, test=0.874) balanced_accuracy: (train=0.742, test=0.751) f1: (train=0.785, test=0.794) total time=  18.8s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.777) total time=   2.1s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.737, test=0.730) f1: (train=0.780, test=0.773) total time=   3.9s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.732) f1: (train=0.779, test=0.775) total time=   1.2s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   1.3s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.737, test=0.730) f1: (train=0.780, test=0.772) total time=   2.1s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.733, test=0.743) f1: (train=0.777, test=0.786) total time=   2.1s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.737, test=0.730) f1: (train=0.780, test=0.773) total time=   4.4s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.783) total time=   5.5s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.744, test=0.741) f1: (train=0.787, test=0.784) total time=   8.2s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.785, test=0.782) total time=  12.7s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.785, test=0.782) total time=  16.8s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.780, test=0.773) total time=   4.3s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.866, test=0.869) balanced_accuracy: (train=0.732, test=0.741) f1: (train=0.775, test=0.784) total time=   1.4s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.780, test=0.772) total time=   2.1s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   3.9s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.744, test=0.741) f1: (train=0.787, test=0.783) total time=   5.6s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.785, test=0.782) total time=   9.0s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.744, test=0.741) f1: (train=0.787, test=0.783) total time=  12.3s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.785, test=0.782) total time=  15.9s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   4.3s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.777) total time=   4.2s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.735) f1: (train=0.779, test=0.778) total time=   2.1s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   4.2s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.733, test=0.743) f1: (train=0.777, test=0.786) total time=   4.6s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.872, test=0.867) balanced_accuracy: (train=0.744, test=0.736) f1: (train=0.787, test=0.779) total time=   5.4s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.786, test=0.783) total time=  10.1s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.872, test=0.867) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.787, test=0.779) total time=  18.7s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.865, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.780, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.735, test=0.732) f1: (train=0.779, test=0.775) total time=   1.3s\n",
      "[CV 2/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.737, test=0.731) f1: (train=0.780, test=0.773) total time=   1.8s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.779, test=0.776) total time=   1.9s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.744) f1: (train=0.777, test=0.787) total time=   4.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.735, test=0.732) f1: (train=0.779, test=0.775) total time=   1.2s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.732) f1: (train=0.779, test=0.775) total time=   2.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.866, test=0.871) balanced_accuracy: (train=0.733, test=0.742) f1: (train=0.776, test=0.786) total time=   1.8s\n",
      "[CV 2/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.738, test=0.730) f1: (train=0.781, test=0.773) total time=   3.9s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.789, test=0.784) total time=   4.7s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.746, test=0.741) f1: (train=0.789, test=0.784) total time=   8.3s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.872, test=0.870) balanced_accuracy: (train=0.747, test=0.742) f1: (train=0.790, test=0.785) total time=  16.3s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.871, test=0.875) balanced_accuracy: (train=0.745, test=0.753) f1: (train=0.787, test=0.796) total time=  12.6s\n",
      "[CV 2/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.737, test=0.731) f1: (train=0.780, test=0.773) total time=   3.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.787) total time=   1.3s\n",
      "[CV 4/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.780, test=0.777) total time=   1.9s\n",
      "[CV 1/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.735) f1: (train=0.779, test=0.778) total time=   3.9s\n",
      "[CV 3/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   4.1s\n",
      "[CV 5/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.871, test=0.875) balanced_accuracy: (train=0.746, test=0.753) f1: (train=0.788, test=0.796) total time=   4.9s\n",
      "[CV 2/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.873, test=0.868) balanced_accuracy: (train=0.747, test=0.739) f1: (train=0.790, test=0.781) total time=   8.4s\n",
      "[CV 1/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.873, test=0.870) balanced_accuracy: (train=0.748, test=0.744) f1: (train=0.791, test=0.786) total time=  13.8s\n",
      "[CV 4/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.872, test=0.870) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.789, test=0.785) total time=  12.6s\n",
      "[CV 5/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.787) total time=   4.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.737, test=0.734) f1: (train=0.780, test=0.777) total time=   1.2s\n",
      "[CV 5/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.787) total time=   2.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.737, test=0.735) f1: (train=0.780, test=0.777) total time=   4.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.873, test=0.870) balanced_accuracy: (train=0.747, test=0.744) f1: (train=0.790, test=0.786) total time=   5.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.872, test=0.870) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.790, test=0.785) total time=   9.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.872, test=0.870) balanced_accuracy: (train=0.746, test=0.743) f1: (train=0.789, test=0.785) total time=   8.4s\n",
      "[CV 2/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.872, test=0.867) balanced_accuracy: (train=0.746, test=0.738) f1: (train=0.790, test=0.781) total time=  14.4s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.735) f1: (train=0.779, test=0.778) total time=   2.1s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.733, test=0.743) f1: (train=0.777, test=0.786) total time=   2.1s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.786) total time=   4.1s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.786) total time=   1.2s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.735, test=0.735) f1: (train=0.778, test=0.778) total time=   1.4s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.786) total time=   1.9s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.780, test=0.772) total time=   4.1s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   4.2s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.744, test=0.741) f1: (train=0.787, test=0.783) total time=   4.8s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.787, test=0.779) total time=   8.2s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.783) total time=  16.7s\n",
      "[CV 1/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.778, test=0.776) total time=   1.4s\n",
      "[CV 1/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.777) total time=   1.5s\n",
      "[CV 2/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.737, test=0.731) f1: (train=0.780, test=0.773) total time=   1.5s\n",
      "[CV 4/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.779, test=0.776) total time=   2.5s\n",
      "[CV 3/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.779, test=0.776) total time=   2.4s\n",
      "[CV 2/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.780, test=0.773) total time=   4.6s\n",
      "[CV 5/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.866, test=0.871) balanced_accuracy: (train=0.733, test=0.742) f1: (train=0.776, test=0.785) total time=   1.4s\n",
      "[CV 4/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.778, test=0.775) total time=   1.4s\n",
      "[CV 5/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.866, test=0.870) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.785) total time=   2.1s\n",
      "[CV 2/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.780, test=0.773) total time=   4.4s\n",
      "[CV 1/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.744, test=0.741) f1: (train=0.787, test=0.783) total time=   5.5s\n",
      "[CV 2/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.744, test=0.736) f1: (train=0.787, test=0.779) total time=   8.3s\n",
      "[CV 3/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.785, test=0.783) total time=   9.5s\n",
      "[CV 1/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.744, test=0.741) f1: (train=0.787, test=0.784) total time=  18.6s\n",
      "[CV 5/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.866, test=0.870) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.785) total time=   2.4s\n",
      "[CV 3/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   3.7s\n",
      "[CV 5/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.733, test=0.743) f1: (train=0.777, test=0.786) total time=   3.3s\n",
      "[CV 3/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   2.1s\n",
      "[CV 5/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.866, test=0.871) balanced_accuracy: (train=0.733, test=0.742) f1: (train=0.776, test=0.786) total time=   2.2s\n",
      "[CV 2/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.780, test=0.773) total time=   4.2s\n",
      "[CV 3/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.785, test=0.782) total time=   5.6s\n",
      "[CV 1/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.745, test=0.741) f1: (train=0.787, test=0.784) total time=   9.1s\n",
      "[CV 3/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.785, test=0.783) total time=  15.1s\n",
      "[CV 4/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.741) f1: (train=0.786, test=0.783) total time=  16.7s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   4.0s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.737, test=0.731) f1: (train=0.780, test=0.773) total time=   2.0s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   4.0s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   4.3s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.744, test=0.741) f1: (train=0.787, test=0.783) total time=   5.2s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.871, test=0.870) balanced_accuracy: (train=0.743, test=0.741) f1: (train=0.786, test=0.784) total time=   7.9s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.744, test=0.740) f1: (train=0.787, test=0.783) total time=  18.2s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   1.5s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.776) total time=   2.3s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   2.3s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.780, test=0.773) total time=   4.0s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.777) total time=   4.2s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.866, test=0.870) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.785) total time=   2.2s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.780, test=0.773) total time=   4.2s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.787, test=0.779) total time=   5.8s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.744, test=0.740) f1: (train=0.786, test=0.783) total time=   9.1s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.741) f1: (train=0.786, test=0.783) total time=   9.5s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.744, test=0.741) f1: (train=0.787, test=0.784) total time=  18.4s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.779, test=0.776) total time=   2.4s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   4.2s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.778, test=0.776) total time=   1.3s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.737, test=0.731) f1: (train=0.780, test=0.773) total time=   1.4s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.737, test=0.731) f1: (train=0.780, test=0.773) total time=   2.1s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.779, test=0.776) total time=   4.1s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.745, test=0.741) f1: (train=0.787, test=0.783) total time=   6.2s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.744, test=0.740) f1: (train=0.786, test=0.783) total time=  10.0s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.741) f1: (train=0.786, test=0.783) total time=   6.7s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.870, test=0.874) balanced_accuracy: (train=0.742, test=0.751) f1: (train=0.785, test=0.794) total time=  17.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.865, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.732) f1: (train=0.779, test=0.775) total time=   1.3s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.735) f1: (train=0.779, test=0.778) total time=   2.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.735, test=0.732) f1: (train=0.779, test=0.775) total time=   2.8s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   3.6s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.735) f1: (train=0.779, test=0.778) total time=   1.9s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.779, test=0.776) total time=   2.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.744) f1: (train=0.777, test=0.787) total time=   4.1s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.872, test=0.870) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.790, test=0.785) total time=   4.7s\n",
      "[CV 2/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.872, test=0.868) balanced_accuracy: (train=0.747, test=0.739) f1: (train=0.790, test=0.781) total time=   7.1s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.872, test=0.870) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.789, test=0.784) total time=   8.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.747, test=0.742) f1: (train=0.790, test=0.785) total time=  16.1s\n",
      "[CV 2/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.737, test=0.730) f1: (train=0.780, test=0.773) total time=   2.3s\n",
      "[CV 1/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.735) f1: (train=0.779, test=0.778) total time=   4.3s\n",
      "[CV 5/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.786) total time=   3.7s\n",
      "[CV 4/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.737, test=0.734) f1: (train=0.780, test=0.777) total time=   2.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.733, test=0.743) f1: (train=0.777, test=0.786) total time=   4.1s\n",
      "[CV 2/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.873, test=0.868) balanced_accuracy: (train=0.747, test=0.739) f1: (train=0.791, test=0.781) total time=   5.2s\n",
      "[CV 5/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.871, test=0.875) balanced_accuracy: (train=0.745, test=0.753) f1: (train=0.788, test=0.796) total time=   5.4s\n",
      "[CV 2/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.873, test=0.867) balanced_accuracy: (train=0.747, test=0.738) f1: (train=0.790, test=0.780) total time=   8.7s\n",
      "[CV 4/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.873, test=0.869) balanced_accuracy: (train=0.747, test=0.742) f1: (train=0.790, test=0.784) total time=  17.6s\n",
      "[CV 2/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.737, test=0.730) f1: (train=0.780, test=0.773) total time=   2.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   2.3s\n",
      "[CV 3/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   4.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   1.2s\n",
      "[CV 3/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.732) f1: (train=0.779, test=0.775) total time=   1.2s\n",
      "[CV 2/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.737, test=0.731) f1: (train=0.780, test=0.774) total time=   2.1s\n",
      "[CV 5/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.866, test=0.871) balanced_accuracy: (train=0.733, test=0.742) f1: (train=0.776, test=0.785) total time=   2.2s\n",
      "[CV 2/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.737, test=0.731) f1: (train=0.780, test=0.773) total time=   4.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.872, test=0.870) balanced_accuracy: (train=0.747, test=0.742) f1: (train=0.790, test=0.785) total time=   5.1s\n",
      "[CV 5/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.871, test=0.875) balanced_accuracy: (train=0.744, test=0.753) f1: (train=0.787, test=0.795) total time=   8.6s\n",
      "[CV 2/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.873, test=0.868) balanced_accuracy: (train=0.747, test=0.739) f1: (train=0.790, test=0.781) total time=  16.4s\n",
      "[CV 5/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.872, test=0.875) balanced_accuracy: (train=0.746, test=0.754) f1: (train=0.788, test=0.796) total time=  16.1s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.732) f1: (train=0.779, test=0.775) total time=   1.3s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.737, test=0.730) f1: (train=0.780, test=0.772) total time=   2.1s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.777) total time=   2.2s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   4.1s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.745, test=0.737) f1: (train=0.788, test=0.779) total time=   5.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.783) total time=   8.5s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.744, test=0.740) f1: (train=0.787, test=0.783) total time=  16.9s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.783) total time=  11.7s\n",
      "[CV 4/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   4.2s\n",
      "[CV 4/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.778, test=0.776) total time=   1.4s\n",
      "[CV 2/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.737, test=0.731) f1: (train=0.780, test=0.773) total time=   1.2s\n",
      "[CV 2/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.737, test=0.731) f1: (train=0.780, test=0.773) total time=   2.2s\n",
      "[CV 3/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   4.1s\n",
      "[CV 3/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.777) total time=   4.4s\n",
      "[CV 5/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.870, test=0.874) balanced_accuracy: (train=0.742, test=0.752) f1: (train=0.785, test=0.794) total time=   5.2s\n",
      "[CV 3/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.786, test=0.783) total time=   6.8s\n",
      "[CV 4/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.787, test=0.783) total time=  17.6s\n",
      "[CV 1/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.778, test=0.776) total time=   1.4s\n",
      "[CV 2/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.864) balanced_accuracy: (train=0.735, test=0.729) f1: (train=0.778, test=0.771) total time=   1.4s\n",
      "[CV 5/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.866, test=0.871) balanced_accuracy: (train=0.733, test=0.742) f1: (train=0.776, test=0.785) total time=   1.4s\n",
      "[CV 1/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.776) total time=   1.4s\n",
      "[CV 3/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   2.2s\n",
      "[CV 1/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.778, test=0.776) total time=   2.5s\n",
      "[CV 1/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.778) total time=   4.6s\n",
      "[CV 4/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.778, test=0.776) total time=   1.5s\n",
      "[CV 2/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.737, test=0.731) f1: (train=0.780, test=0.773) total time=   1.3s\n",
      "[CV 3/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   2.2s\n",
      "[CV 5/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.776, test=0.786) total time=   4.2s\n",
      "[CV 2/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.787, test=0.779) total time=   5.5s\n",
      "[CV 3/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.785, test=0.782) total time=   5.8s\n",
      "[CV 1/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.744, test=0.741) f1: (train=0.787, test=0.783) total time=   9.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.785, test=0.782) total time=  18.4s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.737, test=0.730) f1: (train=0.780, test=0.772) total time=   2.2s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.779, test=0.776) total time=   2.0s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.778) total time=   4.0s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   4.0s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   2.0s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   2.1s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.786) total time=   4.2s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.745, test=0.737) f1: (train=0.788, test=0.779) total time=   5.3s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.783) total time=   8.2s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.744, test=0.740) f1: (train=0.787, test=0.783) total time=  18.2s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.864) balanced_accuracy: (train=0.735, test=0.729) f1: (train=0.778, test=0.771) total time=   1.2s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.777) total time=   1.7s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.776) total time=   1.5s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.735) f1: (train=0.779, test=0.778) total time=   2.2s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.779, test=0.777) total time=   2.5s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   4.1s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.778, test=0.776) total time=   1.4s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.866, test=0.870) balanced_accuracy: (train=0.733, test=0.742) f1: (train=0.776, test=0.785) total time=   1.3s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.779, test=0.776) total time=   2.1s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.866, test=0.871) balanced_accuracy: (train=0.733, test=0.742) f1: (train=0.776, test=0.786) total time=   2.4s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.780, test=0.773) total time=   3.9s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.785, test=0.782) total time=   5.2s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.741) f1: (train=0.786, test=0.784) total time=   7.1s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.785, test=0.783) total time=   9.3s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.870, test=0.874) balanced_accuracy: (train=0.742, test=0.751) f1: (train=0.785, test=0.794) total time=  18.6s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   2.5s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   4.2s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.733, test=0.743) f1: (train=0.777, test=0.786) total time=   4.0s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.780, test=0.772) total time=   2.0s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   4.2s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.744, test=0.741) f1: (train=0.787, test=0.783) total time=   6.0s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.785, test=0.782) total time=   9.8s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.870, test=0.874) balanced_accuracy: (train=0.742, test=0.751) f1: (train=0.785, test=0.794) total time=   8.5s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.787, test=0.778) total time=  15.7s\n",
      "[CV 4/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.741) f1: (train=0.786, test=0.783) total time=   5.8s\n",
      "[CV 3/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.785, test=0.782) total time=   9.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.741) f1: (train=0.786, test=0.783) total time=   9.1s\n",
      "[CV 1/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.744, test=0.741) f1: (train=0.787, test=0.784) total time=  18.6s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   2.4s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   3.9s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.786) total time=   1.2s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.786) total time=   1.2s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.779, test=0.776) total time=   2.0s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.777) total time=   2.1s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   4.2s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.739) f1: (train=0.786, test=0.782) total time=   5.5s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.870, test=0.874) balanced_accuracy: (train=0.741, test=0.751) f1: (train=0.784, test=0.794) total time=   8.0s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.787, test=0.778) total time=  18.1s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.732) f1: (train=0.779, test=0.775) total time=   1.3s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.779, test=0.776) total time=   1.4s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.778, test=0.775) total time=   1.4s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.866, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.776, test=0.787) total time=   2.1s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.778, test=0.776) total time=   2.3s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   4.3s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.732) f1: (train=0.779, test=0.775) total time=   1.4s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   1.4s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   2.4s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   4.1s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.777) total time=   4.3s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.870, test=0.874) balanced_accuracy: (train=0.742, test=0.752) f1: (train=0.785, test=0.794) total time=   5.6s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.872, test=0.867) balanced_accuracy: (train=0.745, test=0.737) f1: (train=0.788, test=0.779) total time=   8.6s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.787, test=0.783) total time=  18.5s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.777) total time=   1.5s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.776) total time=   1.5s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.779, test=0.773) total time=   2.2s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.866, test=0.870) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.785) total time=   2.3s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.780, test=0.773) total time=   4.3s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.777) total time=   1.3s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.778, test=0.775) total time=   1.3s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   2.1s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.776, test=0.786) total time=   4.2s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.786, test=0.783) total time=   6.2s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.744, test=0.736) f1: (train=0.787, test=0.779) total time=   8.5s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.785, test=0.783) total time=  10.2s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.744, test=0.741) f1: (train=0.787, test=0.784) total time=  16.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.780, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.737, test=0.736) f1: (train=0.780, test=0.778) total time=   1.3s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.732) f1: (train=0.779, test=0.775) total time=   1.9s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.735) f1: (train=0.779, test=0.778) total time=   4.2s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.737, test=0.734) f1: (train=0.780, test=0.777) total time=   1.1s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.779, test=0.778) total time=   1.1s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.866, test=0.870) balanced_accuracy: (train=0.732, test=0.741) f1: (train=0.775, test=0.785) total time=   1.2s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.737, test=0.734) f1: (train=0.780, test=0.777) total time=   1.8s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.786) total time=   3.8s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.872, test=0.870) balanced_accuracy: (train=0.748, test=0.743) f1: (train=0.790, test=0.785) total time=   5.1s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.871, test=0.875) balanced_accuracy: (train=0.744, test=0.753) f1: (train=0.787, test=0.796) total time=   4.8s\n",
      "[CV 2/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.872, test=0.867) balanced_accuracy: (train=0.746, test=0.738) f1: (train=0.789, test=0.780) total time=   8.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.746, test=0.741) f1: (train=0.789, test=0.784) total time=  15.5s\n",
      "[CV 3/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.732) f1: (train=0.779, test=0.775) total time=   1.1s\n",
      "[CV 4/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.737, test=0.735) f1: (train=0.779, test=0.778) total time=   1.3s\n",
      "[CV 1/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.737, test=0.734) f1: (train=0.779, test=0.777) total time=   1.9s\n",
      "[CV 5/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.866, test=0.871) balanced_accuracy: (train=0.733, test=0.742) f1: (train=0.776, test=0.785) total time=   2.2s\n",
      "[CV 3/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   4.1s\n",
      "[CV 4/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   1.2s\n",
      "[CV 1/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   1.3s\n",
      "[CV 5/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.787) total time=   2.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.737, test=0.730) f1: (train=0.780, test=0.773) total time=   4.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.780, test=0.776) total time=   4.4s\n",
      "[CV 1/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.873, test=0.869) balanced_accuracy: (train=0.748, test=0.742) f1: (train=0.791, test=0.784) total time=   4.9s\n",
      "[CV 3/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.873, test=0.870) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.790, test=0.785) total time=   6.7s\n",
      "[CV 4/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.872, test=0.870) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.789, test=0.784) total time=  13.8s\n",
      "[CV 3/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.872, test=0.870) balanced_accuracy: (train=0.746, test=0.743) f1: (train=0.789, test=0.785) total time=  16.4s\n",
      "[CV 1/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   1.2s\n",
      "[CV 5/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.787) total time=   1.2s\n",
      "[CV 5/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.787) total time=   2.1s\n",
      "[CV 3/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.735, test=0.732) f1: (train=0.779, test=0.775) total time=   3.9s\n",
      "[CV 5/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.786) total time=   4.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.873, test=0.869) balanced_accuracy: (train=0.748, test=0.742) f1: (train=0.791, test=0.784) total time=   3.8s\n",
      "[CV 3/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.873, test=0.870) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.790, test=0.785) total time=   8.2s\n",
      "[CV 1/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.873, test=0.870) balanced_accuracy: (train=0.748, test=0.744) f1: (train=0.791, test=0.786) total time=  16.5s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   1.2s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.737, test=0.730) f1: (train=0.780, test=0.772) total time=   1.3s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   1.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   2.3s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.777) total time=   2.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   4.2s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.732) f1: (train=0.779, test=0.775) total time=   1.3s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.786) total time=   1.1s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   2.1s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.733, test=0.743) f1: (train=0.777, test=0.786) total time=   2.1s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.737, test=0.730) f1: (train=0.780, test=0.773) total time=   4.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.739) f1: (train=0.786, test=0.782) total time=   5.2s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.870, test=0.874) balanced_accuracy: (train=0.741, test=0.751) f1: (train=0.784, test=0.794) total time=   8.4s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.787, test=0.778) total time=  12.8s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.785, test=0.782) total time=  13.5s\n",
      "[CV 2/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.780, test=0.773) total time=   4.5s\n",
      "[CV 4/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.779, test=0.777) total time=   4.2s\n",
      "[CV 3/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   2.1s\n",
      "[CV 5/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.776, test=0.786) total time=   4.3s\n",
      "[CV 2/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.787, test=0.779) total time=   5.5s\n",
      "[CV 1/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.744, test=0.740) f1: (train=0.786, test=0.783) total time=   8.9s\n",
      "[CV 5/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.870, test=0.874) balanced_accuracy: (train=0.742, test=0.751) f1: (train=0.785, test=0.794) total time=   9.5s\n",
      "[CV 2/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.787, test=0.778) total time=  18.4s\n",
      "[CV 2/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.780, test=0.772) total time=   2.4s\n",
      "[CV 5/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.776, test=0.786) total time=   4.6s\n",
      "[CV 3/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.732) f1: (train=0.779, test=0.775) total time=   1.2s\n",
      "[CV 1/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.776) total time=   1.3s\n",
      "[CV 5/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.866, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.776, test=0.787) total time=   2.1s\n",
      "[CV 2/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.780, test=0.773) total time=   4.3s\n",
      "[CV 1/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.745, test=0.741) f1: (train=0.787, test=0.783) total time=   5.9s\n",
      "[CV 4/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.783) total time=   5.8s\n",
      "[CV 5/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.870, test=0.874) balanced_accuracy: (train=0.742, test=0.751) f1: (train=0.785, test=0.794) total time=   8.7s\n",
      "[CV 2/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.872, test=0.867) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.787, test=0.779) total time=  14.5s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   1.3s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.732) f1: (train=0.779, test=0.775) total time=   1.2s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.864) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.779, test=0.772) total time=   1.3s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.779, test=0.776) total time=   2.0s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   2.2s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   4.0s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   4.0s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.786) total time=   2.0s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.778) total time=   4.2s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.786) total time=   4.2s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.870, test=0.874) balanced_accuracy: (train=0.742, test=0.751) f1: (train=0.784, test=0.793) total time=   3.6s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.787, test=0.779) total time=   8.5s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.783) total time=  18.2s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.866, test=0.871) balanced_accuracy: (train=0.733, test=0.742) f1: (train=0.776, test=0.785) total time=   1.3s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.776) total time=   1.4s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   2.1s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   2.3s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.779, test=0.776) total time=   3.9s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.779, test=0.777) total time=   4.1s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   1.9s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   4.2s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.733, test=0.743) f1: (train=0.777, test=0.786) total time=   4.2s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.872, test=0.867) balanced_accuracy: (train=0.744, test=0.736) f1: (train=0.787, test=0.779) total time=   5.5s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.783) total time=   8.5s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.870, test=0.874) balanced_accuracy: (train=0.742, test=0.750) f1: (train=0.785, test=0.793) total time=  13.5s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.870, test=0.874) balanced_accuracy: (train=0.742, test=0.751) f1: (train=0.785, test=0.794) total time=  15.5s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.780, test=0.773) total time=   4.1s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.779, test=0.773) total time=   2.3s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.779, test=0.777) total time=   2.2s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   4.2s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.783) total time=   6.1s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.745, test=0.741) f1: (train=0.787, test=0.784) total time=  10.3s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.785, test=0.783) total time=  14.0s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.785, test=0.782) total time=   9.6s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.865, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 2/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.780, test=0.773) total time=   1.3s\n",
      "[CV 2/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.737, test=0.731) f1: (train=0.780, test=0.773) total time=   1.8s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.786) total time=   4.5s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.732) f1: (train=0.779, test=0.775) total time=   1.2s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   1.6s\n",
      "[CV 2/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.738, test=0.731) f1: (train=0.781, test=0.773) total time=   1.9s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.779, test=0.776) total time=   4.2s\n",
      "[CV 2/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.872, test=0.867) balanced_accuracy: (train=0.747, test=0.739) f1: (train=0.790, test=0.781) total time=   4.9s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.871, test=0.875) balanced_accuracy: (train=0.745, test=0.753) f1: (train=0.787, test=0.796) total time=   8.6s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.873, test=0.870) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.790, test=0.785) total time=  13.3s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.746, test=0.741) f1: (train=0.789, test=0.784) total time=  12.3s\n",
      "[CV 5/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.787) total time=   4.3s\n",
      "[CV 3/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.732) f1: (train=0.779, test=0.775) total time=   1.3s\n",
      "[CV 1/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   1.9s\n",
      "[CV 3/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.779, test=0.776) total time=   2.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.787) total time=   3.9s\n",
      "[CV 2/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.873, test=0.868) balanced_accuracy: (train=0.747, test=0.739) f1: (train=0.790, test=0.781) total time=   4.9s\n",
      "[CV 4/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.872, test=0.870) balanced_accuracy: (train=0.747, test=0.742) f1: (train=0.790, test=0.785) total time=   8.4s\n",
      "[CV 1/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.872, test=0.870) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.790, test=0.785) total time=  17.1s\n",
      "[CV 5/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.872, test=0.875) balanced_accuracy: (train=0.746, test=0.754) f1: (train=0.788, test=0.796) total time=  13.3s\n",
      "[CV 3/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   3.1s\n",
      "[CV 1/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   1.1s\n",
      "[CV 1/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.737, test=0.734) f1: (train=0.779, test=0.777) total time=   2.1s\n",
      "[CV 4/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   4.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.872, test=0.870) balanced_accuracy: (train=0.748, test=0.743) f1: (train=0.791, test=0.785) total time=   5.2s\n",
      "[CV 4/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.872, test=0.870) balanced_accuracy: (train=0.746, test=0.743) f1: (train=0.789, test=0.786) total time=   3.8s\n",
      "[CV 4/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.872, test=0.870) balanced_accuracy: (train=0.747, test=0.742) f1: (train=0.790, test=0.785) total time=   6.6s\n",
      "[CV 5/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.871, test=0.875) balanced_accuracy: (train=0.744, test=0.752) f1: (train=0.787, test=0.795) total time=  16.5s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.776) total time=   1.4s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.786) total time=   1.2s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.786) total time=   1.3s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   2.3s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.867, test=0.870) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.786) total time=   2.1s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   4.1s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   4.2s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.737, test=0.731) f1: (train=0.780, test=0.773) total time=   2.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   4.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.870, test=0.875) balanced_accuracy: (train=0.741, test=0.751) f1: (train=0.784, test=0.794) total time=   5.1s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.786, test=0.778) total time=   8.3s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.785, test=0.782) total time=   8.7s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.870, test=0.874) balanced_accuracy: (train=0.741, test=0.750) f1: (train=0.784, test=0.793) total time=  15.3s\n",
      "[CV 3/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   2.5s\n",
      "[CV 5/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.866, test=0.870) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.785) total time=   2.3s\n",
      "[CV 5/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.776, test=0.786) total time=   3.4s\n",
      "[CV 5/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.733, test=0.743) f1: (train=0.777, test=0.786) total time=   4.3s\n",
      "[CV 1/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.778, test=0.776) total time=   2.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   4.2s\n",
      "[CV 5/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.870, test=0.874) balanced_accuracy: (train=0.741, test=0.750) f1: (train=0.784, test=0.793) total time=   5.5s\n",
      "[CV 5/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.870, test=0.875) balanced_accuracy: (train=0.742, test=0.752) f1: (train=0.785, test=0.795) total time=   5.8s\n",
      "[CV 1/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.744, test=0.741) f1: (train=0.787, test=0.783) total time=   8.7s\n",
      "[CV 2/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.872, test=0.867) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.787, test=0.779) total time=  16.2s\n",
      "[CV 4/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.778, test=0.776) total time=   1.4s\n",
      "[CV 4/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   1.4s\n",
      "[CV 1/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.776) total time=   2.2s\n",
      "[CV 3/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   2.4s\n",
      "[CV 2/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.780, test=0.773) total time=   4.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.779, test=0.777) total time=   4.3s\n",
      "[CV 5/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.866, test=0.870) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.785) total time=   2.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.778) total time=   4.3s\n",
      "[CV 3/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.786, test=0.783) total time=   5.5s\n",
      "[CV 5/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.870, test=0.875) balanced_accuracy: (train=0.742, test=0.752) f1: (train=0.785, test=0.795) total time=   5.8s\n",
      "[CV 2/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.787, test=0.779) total time=   8.8s\n",
      "[CV 4/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.783) total time=  18.1s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   1.3s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   2.2s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.867, test=0.870) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.786) total time=   2.2s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   3.8s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.786) total time=   4.0s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.867, test=0.870) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.786) total time=   2.2s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   4.1s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.783) total time=   5.2s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.870, test=0.874) balanced_accuracy: (train=0.741, test=0.751) f1: (train=0.784, test=0.794) total time=   5.5s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.744, test=0.736) f1: (train=0.787, test=0.779) total time=   8.1s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.785, test=0.782) total time=  13.1s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.870, test=0.874) balanced_accuracy: (train=0.741, test=0.751) f1: (train=0.784, test=0.794) total time=  16.1s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.736, test=0.729) f1: (train=0.779, test=0.772) total time=   1.4s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.778, test=0.775) total time=   1.4s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.778, test=0.776) total time=   2.1s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   4.1s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.870, test=0.874) balanced_accuracy: (train=0.741, test=0.750) f1: (train=0.784, test=0.793) total time=   5.5s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.744, test=0.736) f1: (train=0.787, test=0.779) total time=   9.0s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.870, test=0.874) balanced_accuracy: (train=0.742, test=0.751) f1: (train=0.785, test=0.794) total time=   9.7s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.787, test=0.778) total time=  18.5s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.866, test=0.871) balanced_accuracy: (train=0.733, test=0.742) f1: (train=0.776, test=0.786) total time=   2.5s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   4.2s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.779, test=0.776) total time=   1.3s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.866, test=0.869) balanced_accuracy: (train=0.732, test=0.741) f1: (train=0.775, test=0.784) total time=   1.3s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.778, test=0.776) total time=   2.1s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.780, test=0.773) total time=   4.5s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.870, test=0.874) balanced_accuracy: (train=0.741, test=0.750) f1: (train=0.784, test=0.793) total time=   4.5s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.783) total time=   5.8s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.744, test=0.741) f1: (train=0.787, test=0.783) total time=  10.2s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.783) total time=  11.8s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.741) f1: (train=0.786, test=0.783) total time=   9.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.870) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.786) total time=   1.2s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.737, test=0.735) f1: (train=0.780, test=0.778) total time=   1.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.867, test=0.872) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.787) total time=   1.9s\n",
      "[CV 2/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.737, test=0.731) f1: (train=0.780, test=0.773) total time=   4.3s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.870) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.786) total time=   1.3s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.737, test=0.735) f1: (train=0.780, test=0.778) total time=   1.3s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.867, test=0.872) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.787) total time=   2.1s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.737, test=0.735) f1: (train=0.780, test=0.778) total time=   3.7s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.873, test=0.870) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.790, test=0.786) total time=   4.9s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.746, test=0.741) f1: (train=0.788, test=0.783) total time=   4.6s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.872, test=0.870) balanced_accuracy: (train=0.747, test=0.742) f1: (train=0.790, test=0.785) total time=   7.1s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.872, test=0.870) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.789, test=0.785) total time=  16.2s\n",
      "[CV 5/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.786) total time=   1.1s\n",
      "[CV 1/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   1.3s\n",
      "[CV 3/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.780, test=0.776) total time=   2.1s\n",
      "[CV 2/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.737, test=0.730) f1: (train=0.780, test=0.773) total time=   2.4s\n",
      "[CV 1/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.737, test=0.735) f1: (train=0.780, test=0.777) total time=   4.2s\n",
      "[CV 1/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   1.3s\n",
      "[CV 2/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.738, test=0.731) f1: (train=0.781, test=0.774) total time=   1.2s\n",
      "[CV 2/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.737, test=0.730) f1: (train=0.780, test=0.773) total time=   1.9s\n",
      "[CV 3/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.735, test=0.732) f1: (train=0.779, test=0.775) total time=   4.1s\n",
      "[CV 5/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.786) total time=   4.2s\n",
      "[CV 2/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.873, test=0.868) balanced_accuracy: (train=0.747, test=0.739) f1: (train=0.791, test=0.781) total time=   4.9s\n",
      "[CV 4/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.872, test=0.870) balanced_accuracy: (train=0.747, test=0.742) f1: (train=0.790, test=0.785) total time=   6.7s\n",
      "[CV 5/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.871, test=0.875) balanced_accuracy: (train=0.744, test=0.752) f1: (train=0.787, test=0.795) total time=  17.5s\n",
      "[CV 1/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   1.5s\n",
      "[CV 2/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.738, test=0.731) f1: (train=0.781, test=0.774) total time=   1.2s\n",
      "[CV 3/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.780, test=0.776) total time=   2.4s\n",
      "[CV 5/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.866, test=0.871) balanced_accuracy: (train=0.733, test=0.742) f1: (train=0.776, test=0.785) total time=   2.2s\n",
      "[CV 2/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.780, test=0.773) total time=   3.9s\n",
      "[CV 2/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.737, test=0.730) f1: (train=0.780, test=0.773) total time=   1.3s\n",
      "[CV 2/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.779, test=0.772) total time=   1.2s\n",
      "[CV 3/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.780, test=0.776) total time=   2.1s\n",
      "[CV 1/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.735) f1: (train=0.779, test=0.778) total time=   4.1s\n",
      "[CV 3/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   4.1s\n",
      "[CV 5/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.871, test=0.875) balanced_accuracy: (train=0.746, test=0.753) f1: (train=0.788, test=0.796) total time=   3.7s\n",
      "[CV 2/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.873, test=0.868) balanced_accuracy: (train=0.747, test=0.739) f1: (train=0.790, test=0.781) total time=   8.2s\n",
      "[CV 3/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.873, test=0.870) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.790, test=0.786) total time=  16.8s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.863) balanced_accuracy: (train=0.736, test=0.729) f1: (train=0.778, test=0.771) total time=   1.4s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.777) total time=   1.3s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.864) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.779, test=0.772) total time=   1.1s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.737, test=0.730) f1: (train=0.780, test=0.772) total time=   2.3s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.737, test=0.731) f1: (train=0.780, test=0.773) total time=   2.1s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.778) total time=   4.1s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.786) total time=   3.2s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.737, test=0.731) f1: (train=0.780, test=0.773) total time=   1.9s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   4.3s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.744, test=0.736) f1: (train=0.787, test=0.778) total time=   5.3s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.785, test=0.782) total time=   5.1s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.744, test=0.740) f1: (train=0.786, test=0.783) total time=   8.4s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.783) total time=  17.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.736, test=0.729) f1: (train=0.779, test=0.772) total time=   1.5s\n",
      "[CV 3/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.776) total time=   1.6s\n",
      "[CV 1/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.735) f1: (train=0.779, test=0.778) total time=   2.3s\n",
      "[CV 4/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.779, test=0.777) total time=   2.3s\n",
      "[CV 5/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.866, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.786) total time=   4.5s\n",
      "[CV 5/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.866, test=0.870) balanced_accuracy: (train=0.733, test=0.742) f1: (train=0.776, test=0.785) total time=   1.3s\n",
      "[CV 3/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   2.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.779, test=0.777) total time=   2.1s\n",
      "[CV 1/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   4.3s\n",
      "[CV 3/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.785, test=0.782) total time=   5.4s\n",
      "[CV 5/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.870, test=0.874) balanced_accuracy: (train=0.742, test=0.751) f1: (train=0.785, test=0.794) total time=   8.6s\n",
      "[CV 2/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.744, test=0.736) f1: (train=0.787, test=0.779) total time=  17.7s\n",
      "[CV 3/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.785, test=0.782) total time=  13.3s\n",
      "[CV 5/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.866, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.786) total time=   4.5s\n",
      "[CV 3/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.779, test=0.776) total time=   1.4s\n",
      "[CV 2/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.779, test=0.773) total time=   2.2s\n",
      "[CV 1/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   4.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.777) total time=   4.4s\n",
      "[CV 5/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.870, test=0.874) balanced_accuracy: (train=0.742, test=0.752) f1: (train=0.785, test=0.794) total time=   5.4s\n",
      "[CV 4/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.783) total time=   7.3s\n",
      "[CV 5/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.870, test=0.874) balanced_accuracy: (train=0.742, test=0.750) f1: (train=0.785, test=0.793) total time=  13.1s\n",
      "[CV 3/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.785, test=0.782) total time=  17.6s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.786) total time=   4.0s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.866, test=0.870) balanced_accuracy: (train=0.733, test=0.742) f1: (train=0.776, test=0.785) total time=   1.3s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.737, test=0.731) f1: (train=0.780, test=0.773) total time=   1.9s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   4.1s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.744, test=0.740) f1: (train=0.786, test=0.783) total time=   5.1s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.786, test=0.778) total time=   8.8s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.870, test=0.874) balanced_accuracy: (train=0.741, test=0.751) f1: (train=0.784, test=0.794) total time=   9.0s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.744, test=0.736) f1: (train=0.787, test=0.778) total time=  16.4s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.780, test=0.772) total time=   2.3s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.780, test=0.773) total time=   3.7s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.733, test=0.743) f1: (train=0.777, test=0.786) total time=   4.0s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   2.1s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.778) total time=   4.3s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.786, test=0.783) total time=   5.5s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.783) total time=   5.5s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.870, test=0.874) balanced_accuracy: (train=0.742, test=0.751) f1: (train=0.785, test=0.794) total time=   8.6s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.872, test=0.867) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.787, test=0.779) total time=  13.3s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.778, test=0.776) total time=   1.4s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.732) f1: (train=0.779, test=0.775) total time=   1.5s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.866, test=0.871) balanced_accuracy: (train=0.733, test=0.742) f1: (train=0.776, test=0.785) total time=   1.3s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   1.4s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.776) total time=   1.8s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.737, test=0.731) f1: (train=0.780, test=0.773) total time=   2.3s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.780, test=0.773) total time=   4.3s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.779, test=0.777) total time=   4.1s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.866, test=0.870) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.785) total time=   2.0s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.778) total time=   4.2s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.787, test=0.779) total time=   4.5s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.870, test=0.874) balanced_accuracy: (train=0.742, test=0.752) f1: (train=0.785, test=0.794) total time=   5.7s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.872, test=0.867) balanced_accuracy: (train=0.745, test=0.737) f1: (train=0.788, test=0.779) total time=   8.7s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.787, test=0.783) total time=  14.1s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.870, test=0.874) balanced_accuracy: (train=0.742, test=0.751) f1: (train=0.785, test=0.794) total time=   8.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.749, test=0.745) f1: (train=0.790, test=0.786) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.746, test=0.738) f1: (train=0.788, test=0.780) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.789, test=0.785) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.788, test=0.784) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.870, test=0.873) balanced_accuracy: (train=0.746, test=0.754) f1: (train=0.788, test=0.795) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.749, test=0.745) f1: (train=0.790, test=0.786) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.746, test=0.738) f1: (train=0.788, test=0.780) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.789, test=0.785) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.788, test=0.784) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.870, test=0.873) balanced_accuracy: (train=0.746, test=0.754) f1: (train=0.788, test=0.795) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.749, test=0.745) f1: (train=0.790, test=0.786) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.746, test=0.738) f1: (train=0.788, test=0.780) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.789, test=0.785) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.788, test=0.784) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.870, test=0.873) balanced_accuracy: (train=0.746, test=0.754) f1: (train=0.788, test=0.795) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.749, test=0.745) f1: (train=0.790, test=0.786) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.746, test=0.738) f1: (train=0.788, test=0.780) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.789, test=0.785) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.788, test=0.784) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.870, test=0.873) balanced_accuracy: (train=0.746, test=0.754) f1: (train=0.788, test=0.795) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.749, test=0.745) f1: (train=0.790, test=0.786) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.746, test=0.738) f1: (train=0.788, test=0.780) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.789, test=0.785) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.788, test=0.784) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.870, test=0.873) balanced_accuracy: (train=0.746, test=0.754) f1: (train=0.788, test=0.795) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.749, test=0.745) f1: (train=0.790, test=0.786) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.746, test=0.738) f1: (train=0.788, test=0.780) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.789, test=0.785) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.788, test=0.784) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.870, test=0.873) balanced_accuracy: (train=0.746, test=0.754) f1: (train=0.788, test=0.795) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.870, test=0.865) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.784, test=0.781) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.872) balanced_accuracy: (train=0.744, test=0.752) f1: (train=0.785, test=0.793) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.870, test=0.865) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.784, test=0.781) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.872) balanced_accuracy: (train=0.744, test=0.752) f1: (train=0.785, test=0.793) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.870, test=0.865) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.784, test=0.781) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.872) balanced_accuracy: (train=0.744, test=0.752) f1: (train=0.785, test=0.793) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.870, test=0.865) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.784, test=0.781) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.872) balanced_accuracy: (train=0.744, test=0.752) f1: (train=0.785, test=0.793) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.870, test=0.865) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.784, test=0.781) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.872) balanced_accuracy: (train=0.744, test=0.752) f1: (train=0.785, test=0.793) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.870, test=0.865) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.784, test=0.781) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.872) balanced_accuracy: (train=0.744, test=0.752) f1: (train=0.785, test=0.793) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.737) f1: (train=0.781, test=0.779) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.738) f1: (train=0.783, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.740, test=0.749) f1: (train=0.781, test=0.789) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.737) f1: (train=0.781, test=0.779) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.738) f1: (train=0.783, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.740, test=0.749) f1: (train=0.781, test=0.789) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.737) f1: (train=0.781, test=0.779) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.738) f1: (train=0.783, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.740, test=0.749) f1: (train=0.781, test=0.789) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.737) f1: (train=0.781, test=0.779) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.738) f1: (train=0.783, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.740, test=0.749) f1: (train=0.781, test=0.789) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.737) f1: (train=0.781, test=0.779) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.738) f1: (train=0.783, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.740, test=0.749) f1: (train=0.781, test=0.789) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.737) f1: (train=0.781, test=0.779) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.738) f1: (train=0.783, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.740, test=0.749) f1: (train=0.781, test=0.789) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.780, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.865, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.780, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.865, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.780, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.865, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.780, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.865, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.780, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.865, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.780, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.865, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.749, test=0.745) f1: (train=0.790, test=0.786) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.746, test=0.738) f1: (train=0.788, test=0.780) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.789, test=0.785) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.788, test=0.784) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.870, test=0.873) balanced_accuracy: (train=0.746, test=0.754) f1: (train=0.788, test=0.795) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.749, test=0.745) f1: (train=0.790, test=0.786) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.746, test=0.738) f1: (train=0.788, test=0.780) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.789, test=0.785) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.788, test=0.784) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.870, test=0.873) balanced_accuracy: (train=0.746, test=0.754) f1: (train=0.788, test=0.795) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.749, test=0.745) f1: (train=0.790, test=0.786) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.746, test=0.738) f1: (train=0.788, test=0.780) total time=   0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.789, test=0.785) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.788, test=0.784) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.870, test=0.873) balanced_accuracy: (train=0.746, test=0.754) f1: (train=0.788, test=0.795) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.749, test=0.745) f1: (train=0.790, test=0.786) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.746, test=0.738) f1: (train=0.788, test=0.780) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.789, test=0.785) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.788, test=0.784) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.870, test=0.873) balanced_accuracy: (train=0.746, test=0.754) f1: (train=0.788, test=0.795) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.749, test=0.745) f1: (train=0.790, test=0.786) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.746, test=0.738) f1: (train=0.788, test=0.780) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.789, test=0.785) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.788, test=0.784) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.870, test=0.873) balanced_accuracy: (train=0.746, test=0.754) f1: (train=0.788, test=0.795) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.749, test=0.745) f1: (train=0.790, test=0.786) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.746, test=0.738) f1: (train=0.788, test=0.780) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.789, test=0.785) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.788, test=0.784) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.870, test=0.873) balanced_accuracy: (train=0.746, test=0.754) f1: (train=0.788, test=0.795) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.870, test=0.865) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.784, test=0.781) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.872) balanced_accuracy: (train=0.744, test=0.752) f1: (train=0.785, test=0.793) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.870, test=0.865) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.784, test=0.781) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.872) balanced_accuracy: (train=0.744, test=0.752) f1: (train=0.785, test=0.793) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.870, test=0.865) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.784, test=0.781) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.872) balanced_accuracy: (train=0.744, test=0.752) f1: (train=0.785, test=0.793) total time=   0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.870, test=0.865) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.784, test=0.781) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.872) balanced_accuracy: (train=0.744, test=0.752) f1: (train=0.785, test=0.793) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.870, test=0.865) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.784, test=0.781) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.872) balanced_accuracy: (train=0.744, test=0.752) f1: (train=0.785, test=0.793) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.870, test=0.865) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.784, test=0.781) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.872) balanced_accuracy: (train=0.744, test=0.752) f1: (train=0.785, test=0.793) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.737) f1: (train=0.781, test=0.779) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.738) f1: (train=0.783, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.740, test=0.749) f1: (train=0.781, test=0.789) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.783, test=0.776) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.737) f1: (train=0.781, test=0.779) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.738) f1: (train=0.783, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.740, test=0.749) f1: (train=0.781, test=0.789) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.737) f1: (train=0.781, test=0.779) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.738) f1: (train=0.783, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.740, test=0.749) f1: (train=0.781, test=0.789) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.737) f1: (train=0.781, test=0.779) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.738) f1: (train=0.783, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.740, test=0.749) f1: (train=0.781, test=0.789) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.737) f1: (train=0.781, test=0.779) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.738) f1: (train=0.783, test=0.780) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.740, test=0.749) f1: (train=0.781, test=0.789) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.737) f1: (train=0.781, test=0.779) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.738) f1: (train=0.783, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.740, test=0.749) f1: (train=0.781, test=0.789) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.780, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.865, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.780, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.865, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.780, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.865, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.780, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.865, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.780, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.865, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.780, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.865, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.746, test=0.743) f1: (train=0.787, test=0.784) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.870, test=0.866) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.786, test=0.778) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.782) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.871, test=0.868) balanced_accuracy: (train=0.744, test=0.741) f1: (train=0.787, test=0.783) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.873) balanced_accuracy: (train=0.744, test=0.752) f1: (train=0.785, test=0.793) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.746, test=0.743) f1: (train=0.787, test=0.784) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.870, test=0.866) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.786, test=0.778) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.782) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.871, test=0.868) balanced_accuracy: (train=0.744, test=0.741) f1: (train=0.787, test=0.783) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.873) balanced_accuracy: (train=0.744, test=0.752) f1: (train=0.785, test=0.793) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.746, test=0.743) f1: (train=0.787, test=0.784) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.870, test=0.866) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.786, test=0.778) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.782) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.871, test=0.868) balanced_accuracy: (train=0.744, test=0.741) f1: (train=0.787, test=0.783) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.873) balanced_accuracy: (train=0.744, test=0.752) f1: (train=0.785, test=0.793) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.746, test=0.743) f1: (train=0.787, test=0.784) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.870, test=0.866) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.786, test=0.778) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.782) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.871, test=0.868) balanced_accuracy: (train=0.744, test=0.741) f1: (train=0.787, test=0.783) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.873) balanced_accuracy: (train=0.744, test=0.752) f1: (train=0.785, test=0.793) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.746, test=0.743) f1: (train=0.787, test=0.784) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.870, test=0.866) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.786, test=0.778) total time=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.782) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.871, test=0.868) balanced_accuracy: (train=0.744, test=0.741) f1: (train=0.787, test=0.783) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.873) balanced_accuracy: (train=0.744, test=0.752) f1: (train=0.785, test=0.793) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.746, test=0.743) f1: (train=0.787, test=0.784) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.870, test=0.866) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.786, test=0.778) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.782) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.871, test=0.868) balanced_accuracy: (train=0.744, test=0.741) f1: (train=0.787, test=0.783) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.873) balanced_accuracy: (train=0.744, test=0.752) f1: (train=0.785, test=0.793) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.743, test=0.741) f1: (train=0.785, test=0.782) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.742, test=0.735) f1: (train=0.784, test=0.777) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.785, test=0.782) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.784, test=0.781) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.872) balanced_accuracy: (train=0.742, test=0.750) f1: (train=0.783, test=0.791) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.743, test=0.741) f1: (train=0.785, test=0.782) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.742, test=0.735) f1: (train=0.784, test=0.777) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.785, test=0.782) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.784, test=0.781) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.872) balanced_accuracy: (train=0.742, test=0.750) f1: (train=0.783, test=0.791) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.743, test=0.741) f1: (train=0.785, test=0.782) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.742, test=0.735) f1: (train=0.784, test=0.777) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.785, test=0.782) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.784, test=0.781) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.872) balanced_accuracy: (train=0.742, test=0.750) f1: (train=0.783, test=0.791) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.743, test=0.741) f1: (train=0.785, test=0.782) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.742, test=0.735) f1: (train=0.784, test=0.777) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.785, test=0.782) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.784, test=0.781) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.872) balanced_accuracy: (train=0.742, test=0.750) f1: (train=0.783, test=0.791) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.743, test=0.741) f1: (train=0.785, test=0.782) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.742, test=0.735) f1: (train=0.784, test=0.777) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.785, test=0.782) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.784, test=0.781) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.872) balanced_accuracy: (train=0.742, test=0.750) f1: (train=0.783, test=0.791) total time=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.743, test=0.741) f1: (train=0.785, test=0.782) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.742, test=0.735) f1: (train=0.784, test=0.777) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.785, test=0.782) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.784, test=0.781) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.872) balanced_accuracy: (train=0.742, test=0.750) f1: (train=0.783, test=0.791) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.737) f1: (train=0.781, test=0.779) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.738) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.740, test=0.749) f1: (train=0.781, test=0.789) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.737) f1: (train=0.781, test=0.779) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.738) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.740, test=0.749) f1: (train=0.781, test=0.789) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.737) f1: (train=0.781, test=0.779) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.738) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.740, test=0.749) f1: (train=0.781, test=0.789) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.737) f1: (train=0.781, test=0.779) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.738) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.740, test=0.749) f1: (train=0.781, test=0.789) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.737) f1: (train=0.781, test=0.779) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.738) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.740, test=0.749) f1: (train=0.781, test=0.789) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.737) f1: (train=0.781, test=0.779) total time=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.738) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.740, test=0.749) f1: (train=0.781, test=0.789) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.780, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.865, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.780, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.865, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.780, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.865, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.780, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.865, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.780, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.865, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.780, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.865, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.749, test=0.745) f1: (train=0.790, test=0.786) total time=   0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.746, test=0.738) f1: (train=0.788, test=0.780) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.789, test=0.785) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.788, test=0.784) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.870, test=0.873) balanced_accuracy: (train=0.746, test=0.754) f1: (train=0.788, test=0.795) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.749, test=0.745) f1: (train=0.790, test=0.786) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.746, test=0.738) f1: (train=0.788, test=0.780) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.789, test=0.785) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.788, test=0.784) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.870, test=0.873) balanced_accuracy: (train=0.746, test=0.754) f1: (train=0.788, test=0.795) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.749, test=0.745) f1: (train=0.790, test=0.786) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.746, test=0.738) f1: (train=0.788, test=0.780) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.789, test=0.785) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.788, test=0.784) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.870, test=0.873) balanced_accuracy: (train=0.746, test=0.754) f1: (train=0.788, test=0.795) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.749, test=0.745) f1: (train=0.790, test=0.786) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.746, test=0.738) f1: (train=0.788, test=0.780) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.789, test=0.785) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.788, test=0.784) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.870, test=0.873) balanced_accuracy: (train=0.746, test=0.754) f1: (train=0.788, test=0.795) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.749, test=0.745) f1: (train=0.790, test=0.786) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.746, test=0.738) f1: (train=0.788, test=0.780) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.789, test=0.785) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.788, test=0.784) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.870, test=0.873) balanced_accuracy: (train=0.746, test=0.754) f1: (train=0.788, test=0.795) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.749, test=0.745) f1: (train=0.790, test=0.786) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.746, test=0.738) f1: (train=0.788, test=0.780) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.789, test=0.785) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.788, test=0.784) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.870, test=0.873) balanced_accuracy: (train=0.746, test=0.754) f1: (train=0.788, test=0.795) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.870, test=0.865) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.784, test=0.781) total time=   0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.872) balanced_accuracy: (train=0.744, test=0.752) f1: (train=0.785, test=0.793) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.870, test=0.865) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.784, test=0.781) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.872) balanced_accuracy: (train=0.744, test=0.752) f1: (train=0.785, test=0.793) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.870, test=0.865) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.784, test=0.781) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.872) balanced_accuracy: (train=0.744, test=0.752) f1: (train=0.785, test=0.793) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.870, test=0.865) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.784, test=0.781) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.872) balanced_accuracy: (train=0.744, test=0.752) f1: (train=0.785, test=0.793) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.870, test=0.865) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.784, test=0.781) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.872) balanced_accuracy: (train=0.744, test=0.752) f1: (train=0.785, test=0.793) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.870, test=0.865) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.784, test=0.781) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.872) balanced_accuracy: (train=0.744, test=0.752) f1: (train=0.785, test=0.793) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.737) f1: (train=0.781, test=0.779) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.738) f1: (train=0.783, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.740, test=0.749) f1: (train=0.781, test=0.789) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.737) f1: (train=0.781, test=0.779) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.738) f1: (train=0.783, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.740, test=0.749) f1: (train=0.781, test=0.789) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.737) f1: (train=0.781, test=0.779) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.738) f1: (train=0.783, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.740, test=0.749) f1: (train=0.781, test=0.789) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.737) f1: (train=0.781, test=0.779) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.738) f1: (train=0.783, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.740, test=0.749) f1: (train=0.781, test=0.789) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.737) f1: (train=0.781, test=0.779) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.738) f1: (train=0.783, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.740, test=0.749) f1: (train=0.781, test=0.789) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.737) f1: (train=0.781, test=0.779) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.738) f1: (train=0.783, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.740, test=0.749) f1: (train=0.781, test=0.789) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.780, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.865, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.780, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.865, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.780, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.865, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.780, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.865, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.780, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.865, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.780, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.865, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.749, test=0.745) f1: (train=0.790, test=0.786) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.746, test=0.738) f1: (train=0.788, test=0.780) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.789, test=0.785) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.788, test=0.784) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.870, test=0.873) balanced_accuracy: (train=0.746, test=0.754) f1: (train=0.788, test=0.795) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.749, test=0.745) f1: (train=0.790, test=0.786) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.746, test=0.738) f1: (train=0.788, test=0.780) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.789, test=0.785) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.788, test=0.784) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.870, test=0.873) balanced_accuracy: (train=0.746, test=0.754) f1: (train=0.788, test=0.795) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.749, test=0.745) f1: (train=0.790, test=0.786) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.746, test=0.738) f1: (train=0.788, test=0.780) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.789, test=0.785) total time=   0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.788, test=0.784) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.870, test=0.873) balanced_accuracy: (train=0.746, test=0.754) f1: (train=0.788, test=0.795) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.749, test=0.745) f1: (train=0.790, test=0.786) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.746, test=0.738) f1: (train=0.788, test=0.780) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.789, test=0.785) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.788, test=0.784) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.870, test=0.873) balanced_accuracy: (train=0.746, test=0.754) f1: (train=0.788, test=0.795) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.749, test=0.745) f1: (train=0.790, test=0.786) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.746, test=0.738) f1: (train=0.788, test=0.780) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.789, test=0.785) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.788, test=0.784) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.870, test=0.873) balanced_accuracy: (train=0.746, test=0.754) f1: (train=0.788, test=0.795) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.749, test=0.745) f1: (train=0.790, test=0.786) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.746, test=0.738) f1: (train=0.788, test=0.780) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.789, test=0.785) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.788, test=0.784) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.870, test=0.873) balanced_accuracy: (train=0.746, test=0.754) f1: (train=0.788, test=0.795) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.870, test=0.865) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.784, test=0.781) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.872) balanced_accuracy: (train=0.744, test=0.752) f1: (train=0.785, test=0.793) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.870, test=0.865) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.784, test=0.781) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.872) balanced_accuracy: (train=0.744, test=0.752) f1: (train=0.785, test=0.793) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.870, test=0.865) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.784, test=0.781) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.872) balanced_accuracy: (train=0.744, test=0.752) f1: (train=0.785, test=0.793) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.870, test=0.865) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.784, test=0.781) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.872) balanced_accuracy: (train=0.744, test=0.752) f1: (train=0.785, test=0.793) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.870, test=0.865) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.784, test=0.781) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.872) balanced_accuracy: (train=0.744, test=0.752) f1: (train=0.785, test=0.793) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.870, test=0.865) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.784, test=0.781) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.872) balanced_accuracy: (train=0.744, test=0.752) f1: (train=0.785, test=0.793) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.737) f1: (train=0.781, test=0.779) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.738) f1: (train=0.783, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.740, test=0.749) f1: (train=0.781, test=0.789) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.737) f1: (train=0.781, test=0.779) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.738) f1: (train=0.783, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.740, test=0.749) f1: (train=0.781, test=0.789) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.737) f1: (train=0.781, test=0.779) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.738) f1: (train=0.783, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.740, test=0.749) f1: (train=0.781, test=0.789) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.737) f1: (train=0.781, test=0.779) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.738) f1: (train=0.783, test=0.780) total time=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.740, test=0.749) f1: (train=0.781, test=0.789) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.737) f1: (train=0.781, test=0.779) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.738) f1: (train=0.783, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.740, test=0.749) f1: (train=0.781, test=0.789) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.737) f1: (train=0.781, test=0.779) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.738) f1: (train=0.783, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.740, test=0.749) f1: (train=0.781, test=0.789) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.780, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.865, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.780, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.865, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.780, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.865, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.780, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.865, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.780, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.865, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.780, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.865, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.749, test=0.745) f1: (train=0.790, test=0.786) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.746, test=0.738) f1: (train=0.788, test=0.780) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.789, test=0.785) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.788, test=0.784) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.870, test=0.873) balanced_accuracy: (train=0.746, test=0.754) f1: (train=0.788, test=0.795) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.749, test=0.745) f1: (train=0.790, test=0.786) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.746, test=0.738) f1: (train=0.788, test=0.780) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.789, test=0.785) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.788, test=0.784) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.870, test=0.873) balanced_accuracy: (train=0.746, test=0.754) f1: (train=0.788, test=0.795) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.749, test=0.745) f1: (train=0.790, test=0.786) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.746, test=0.738) f1: (train=0.788, test=0.780) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.789, test=0.785) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.788, test=0.784) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.870, test=0.873) balanced_accuracy: (train=0.746, test=0.754) f1: (train=0.788, test=0.795) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.749, test=0.745) f1: (train=0.790, test=0.786) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.746, test=0.738) f1: (train=0.788, test=0.780) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.789, test=0.785) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.788, test=0.784) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.870, test=0.873) balanced_accuracy: (train=0.746, test=0.754) f1: (train=0.788, test=0.795) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.749, test=0.745) f1: (train=0.790, test=0.786) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.746, test=0.738) f1: (train=0.788, test=0.780) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.789, test=0.785) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.788, test=0.784) total time=   0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.870, test=0.873) balanced_accuracy: (train=0.746, test=0.754) f1: (train=0.788, test=0.795) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.749, test=0.745) f1: (train=0.790, test=0.786) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.746, test=0.738) f1: (train=0.788, test=0.780) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.789, test=0.785) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.788, test=0.784) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.870, test=0.873) balanced_accuracy: (train=0.746, test=0.754) f1: (train=0.788, test=0.795) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.870, test=0.865) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.784, test=0.781) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.872) balanced_accuracy: (train=0.744, test=0.752) f1: (train=0.785, test=0.793) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.870, test=0.865) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.784, test=0.781) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.872) balanced_accuracy: (train=0.744, test=0.752) f1: (train=0.785, test=0.793) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.870, test=0.865) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.784, test=0.781) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.872) balanced_accuracy: (train=0.744, test=0.752) f1: (train=0.785, test=0.793) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.870, test=0.865) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.784, test=0.781) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.872) balanced_accuracy: (train=0.744, test=0.752) f1: (train=0.785, test=0.793) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.870, test=0.865) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.784, test=0.781) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.872) balanced_accuracy: (train=0.744, test=0.752) f1: (train=0.785, test=0.793) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.870, test=0.865) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.784, test=0.781) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.872) balanced_accuracy: (train=0.744, test=0.752) f1: (train=0.785, test=0.793) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.737) f1: (train=0.781, test=0.779) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.738) f1: (train=0.783, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.740, test=0.749) f1: (train=0.781, test=0.789) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.737) f1: (train=0.781, test=0.779) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.738) f1: (train=0.783, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.740, test=0.749) f1: (train=0.781, test=0.789) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.737) f1: (train=0.781, test=0.779) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.738) f1: (train=0.783, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.740, test=0.749) f1: (train=0.781, test=0.789) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.737) f1: (train=0.781, test=0.779) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.738) f1: (train=0.783, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.740, test=0.749) f1: (train=0.781, test=0.789) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.737) f1: (train=0.781, test=0.779) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.738) f1: (train=0.783, test=0.780) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.740, test=0.749) f1: (train=0.781, test=0.789) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.737) f1: (train=0.781, test=0.779) total time=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.738) f1: (train=0.783, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.740, test=0.749) f1: (train=0.781, test=0.789) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.780, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.865, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.780, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.865, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.780, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.865, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.780, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.865, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.780, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.865, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.780, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.865, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False),\n",
       "             estimator=DecisionTreeClassifier(min_samples_leaf=50,\n",
       "                                              min_samples_split=50,\n",
       "                                              random_state=10),\n",
       "             param_grid={&#x27;ccp_alpha&#x27;: [0.0001],\n",
       "                         &#x27;criterion&#x27;: [&#x27;gini&#x27;, &#x27;entropy&#x27;, &#x27;log_loss&#x27;],\n",
       "                         &#x27;max_depth&#x27;: [10, 20, 30, None],\n",
       "                         &#x27;min_samples_leaf&#x27;: [20, 50, 100, 200],\n",
       "                         &#x27;min_samples_split&#x27;: [6, 8],\n",
       "                         &#x27;random_state&#x27;: [30, 50, None]},\n",
       "             refit=&#x27;balanced_accuracy&#x27;, return_train_score=True,\n",
       "             scoring={&#x27;accuracy&#x27;: &#x27;accuracy&#x27;,\n",
       "                      &#x27;balanced_accuracy&#x27;: &#x27;balanced_accuracy&#x27;,\n",
       "                      &#x27;f1&#x27;: &#x27;f1_macro&#x27;},\n",
       "             verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False),\n",
       "             estimator=DecisionTreeClassifier(min_samples_leaf=50,\n",
       "                                              min_samples_split=50,\n",
       "                                              random_state=10),\n",
       "             param_grid={&#x27;ccp_alpha&#x27;: [0.0001],\n",
       "                         &#x27;criterion&#x27;: [&#x27;gini&#x27;, &#x27;entropy&#x27;, &#x27;log_loss&#x27;],\n",
       "                         &#x27;max_depth&#x27;: [10, 20, 30, None],\n",
       "                         &#x27;min_samples_leaf&#x27;: [20, 50, 100, 200],\n",
       "                         &#x27;min_samples_split&#x27;: [6, 8],\n",
       "                         &#x27;random_state&#x27;: [30, 50, None]},\n",
       "             refit=&#x27;balanced_accuracy&#x27;, return_train_score=True,\n",
       "             scoring={&#x27;accuracy&#x27;: &#x27;accuracy&#x27;,\n",
       "                      &#x27;balanced_accuracy&#x27;: &#x27;balanced_accuracy&#x27;,\n",
       "                      &#x27;f1&#x27;: &#x27;f1_macro&#x27;},\n",
       "             verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(min_samples_leaf=50, min_samples_split=50,\n",
       "                       random_state=10)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(min_samples_leaf=50, min_samples_split=50,\n",
       "                       random_state=10)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False),\n",
       "             estimator=DecisionTreeClassifier(min_samples_leaf=50,\n",
       "                                              min_samples_split=50,\n",
       "                                              random_state=10),\n",
       "             param_grid={'ccp_alpha': [0.0001],\n",
       "                         'criterion': ['gini', 'entropy', 'log_loss'],\n",
       "                         'max_depth': [10, 20, 30, None],\n",
       "                         'min_samples_leaf': [20, 50, 100, 200],\n",
       "                         'min_samples_split': [6, 8],\n",
       "                         'random_state': [30, 50, None]},\n",
       "             refit='balanced_accuracy', return_train_score=True,\n",
       "             scoring={'accuracy': 'accuracy',\n",
       "                      'balanced_accuracy': 'balanced_accuracy',\n",
       "                      'f1': 'f1_macro'},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "#GRID SEARCH\n",
    "tree_clf = DecisionTreeClassifier(max_features=None,max_depth=None, random_state=10, min_samples_leaf=50,min_samples_split=50)\n",
    "\n",
    "parameter_grid = {\n",
    "    \"max_depth\": [10, 20, 30, None],\n",
    "    \"criterion\": ['gini', 'entropy', 'log_loss'],\n",
    "    'random_state': [30, 50, None],\n",
    "    'min_samples_leaf':[20, 50, 100, 200],\n",
    "    'ccp_alpha': [.0001],\n",
    "    'min_samples_split': [6, 8 ]\n",
    "}\n",
    "\n",
    "# Create Stratified folds\n",
    "cross_validation = StratifiedKFold(n_splits=5)\n",
    "cross_validation.get_n_splits(train_data, y_train)\n",
    "\n",
    "# Create the scoring dictionary\n",
    "SCORING = {\n",
    "    \"accuracy\": \"accuracy\",\n",
    "    \"balanced_accuracy\": \"balanced_accuracy\",\n",
    "    \"f1\": \"f1_macro\",\n",
    "}\n",
    "\n",
    "# Create and fit the GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=tree_clf,\n",
    "    param_grid=parameter_grid,\n",
    "    cv=cross_validation,\n",
    "    verbose=3,\n",
    "    scoring=SCORING,\n",
    "    return_train_score=True,\n",
    "    refit=\"balanced_accuracy\",\n",
    ")\n",
    "\n",
    "grid_search.fit(train_data,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "62d3ccd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.7443202990579671\n",
      "Best parameters: {'ccp_alpha': 0.0001, 'criterion': 'entropy', 'max_depth': 20, 'min_samples_leaf': 20, 'min_samples_split': 6, 'random_state': 30}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(ccp_alpha=0.0001, criterion=&#x27;entropy&#x27;, max_depth=20,\n",
       "                       min_samples_leaf=20, min_samples_split=6,\n",
       "                       random_state=30)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" checked><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(ccp_alpha=0.0001, criterion=&#x27;entropy&#x27;, max_depth=20,\n",
       "                       min_samples_leaf=20, min_samples_split=6,\n",
       "                       random_state=30)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.0001, criterion='entropy', max_depth=20,\n",
       "                       min_samples_leaf=20, min_samples_split=6,\n",
       "                       random_state=30)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Best score: {}\".format(grid_search.best_score_))\n",
    "print(\"Best parameters: {}\".format(grid_search.best_params_))\n",
    "\n",
    "best_dtc = grid_search.best_estimator_\n",
    "best_dtc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e0da7fcb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8686194494397566"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model =best_dtc\n",
    "my_model.fit(train_data, y_train)\n",
    "my_model.score(test_data,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5722cc90",
   "metadata": {},
   "source": [
    "RANDOM FOREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07321942",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b318752",
   "metadata": {},
   "outputs": [],
   "source": [
    "column = ['criterion', 'max_depth', 'max_features', 'n_estimators', 'random_state', 'accuracy']\n",
    "column_bar = ['try', 'Parameter_changed', 'Accuracy']\n",
    "\n",
    "### Create a single row equivalent to a single try for decision tree\n",
    "def create_bar_row(criterion, depth, feature, stimatori,random, attempt, parameter):\n",
    "  rf = RandomForestClassifier(criterion=criterion,max_depth=depth, max_features=feature,n_estimators=stimatori, random_state=random )\n",
    "  rf.fit(train_data, np.ravel(y_train))\n",
    "  testset_score = rf.score(test_data, y_test)\n",
    "  row = pd.DataFrame(data=[[attempt, parameter, testset_score]], columns=column_bar)\n",
    "  return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "080a26fd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  try Parameter_changed  Accuracy\n",
      "0   1             start  0.867029\n",
      "0   2         max_depth  0.867720\n",
      "0   3      max_features  0.867236\n",
      "0   4      n_estimators  0.868204\n",
      "0   5      random_state  0.867513\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'Score sul testset durante il tuning dei parametri'}, xlabel='Accuracy', ylabel='Parameter_changed'>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.DataFrame(columns=column_bar)\n",
    "df = pd.concat([df, create_bar_row('gini', None, 20, 40, 2,1, 'start')]) # try 1\n",
    "df = pd.concat([df, create_bar_row('gini', 40, 20, 40, 5,2, 'max_depth')]) # try 2\n",
    "df = pd.concat([df, create_bar_row('gini', 40, None, 40, 5,3, 'max_features')]) # try 3\n",
    "df = pd.concat([df, create_bar_row('gini', 40, None, 100, 5,4, 'n_estimators')]) # try 4\n",
    "df = pd.concat([df, create_bar_row('gini', 40, None, 100, 10,5, 'random_state')]) # try 5\n",
    "print(df)\n",
    "\n",
    "fig, axs = plt.subplots()\n",
    "axs.set_xlim([0.70,0.89])\n",
    "axs.set_title(\"Score sul testset durante il tuning dei parametri\")\n",
    "\n",
    "sns.barplot(data=df, x='Accuracy',y=\"Parameter_changed\",ax=axs, orient=\"h\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d044b92",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "algoritmo=[\"Start\",\"Max_depth\",\"Max_features\",\"n_estimators\",\"random_state\"]\n",
    "accuracy=[0.8670,0.8677,0.8672,0.8682,0.8675]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(algoritmo, accuracy, marker='o', linestyle='-', color='r')\n",
    "plt.title(' Accuracy su testSet al Variare dell algoritmo')\n",
    "plt.xlabel('Algoritmo')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.grid(True)\n",
    "plt.xticks(algoritmo)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c6bd8475",
   "metadata": {},
   "outputs": [],
   "source": [
    "column = ['criterion', 'max_depth', 'max_features', 'n_estimators', 'random_state', 'accuracy']\n",
    "\n",
    "def plot_nEstimatorVSaccuracy(nEstimators,title):\n",
    "  accs = pd.DataFrame(columns=column)\n",
    "  for e in nEstimators:\n",
    "    rt = RandomForestClassifier(n_jobs=-1,criterion='gini',max_depth=40, max_features=None, n_estimators=e, random_state=10 )\n",
    "    rt.fit(train_data, np.ravel(y_train))\n",
    "    testset_score = rt.score(test_data, np.ravel(y_test) )\n",
    "    row = pd.DataFrame(data=[['gini',40, None,e, 10, testset_score]], columns=column)\n",
    "    accs = pd.concat([accs, row])\n",
    "\n",
    "  # plot\n",
    "  fig, ax = plt.subplots()\n",
    "  ax.plot(accs.n_estimators, accs.accuracy)\n",
    "\n",
    "  ax.set(xlabel='n_estimators', ylabel='Accuracy',\n",
    "        title=title)\n",
    "  ax.grid()\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9616697a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_estimators = np.linspace(10, 50, 51, dtype=int)\n",
    "\n",
    "plot_nEstimatorVSaccuracy(n_estimators,  'Variazione accuracy CON PRUNING') # with pruning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aada8db8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 243 candidates, totalling 1215 fits\n",
      "[CV 5/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.786) total time=   1.2s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.866, test=0.870) balanced_accuracy: (train=0.732, test=0.741) f1: (train=0.775, test=0.785) total time=   1.1s\n",
      "[CV 2/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.738, test=0.731) f1: (train=0.781, test=0.773) total time=   1.9s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.780, test=0.776) total time=   3.6s\n",
      "[CV 2/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.737, test=0.731) f1: (train=0.780, test=0.774) total time=   1.3s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.737, test=0.734) f1: (train=0.780, test=0.777) total time=   1.2s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   2.2s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.735, test=0.732) f1: (train=0.779, test=0.775) total time=   3.9s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.786) total time=   4.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.872, test=0.868) balanced_accuracy: (train=0.747, test=0.739) f1: (train=0.790, test=0.781) total time=   4.3s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.872, test=0.870) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.789, test=0.785) total time=   8.2s\n",
      "[CV 2/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.873, test=0.868) balanced_accuracy: (train=0.747, test=0.739) f1: (train=0.790, test=0.781) total time=  16.3s\n",
      "[CV 1/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   1.3s\n",
      "[CV 3/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.737, test=0.734) f1: (train=0.780, test=0.777) total time=   1.2s\n",
      "[CV 5/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.787) total time=   2.2s\n",
      "[CV 4/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   2.4s\n",
      "[CV 4/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   4.2s\n",
      "[CV 2/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.779, test=0.772) total time=   1.3s\n",
      "[CV 5/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.866, test=0.870) balanced_accuracy: (train=0.733, test=0.741) f1: (train=0.776, test=0.784) total time=   1.2s\n",
      "[CV 1/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   2.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   4.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.873, test=0.870) balanced_accuracy: (train=0.747, test=0.744) f1: (train=0.790, test=0.786) total time=   5.1s\n",
      "[CV 3/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.872, test=0.870) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.790, test=0.786) total time=   5.2s\n",
      "[CV 1/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.872, test=0.870) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.790, test=0.785) total time=   8.8s\n",
      "[CV 3/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.873, test=0.870) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.790, test=0.785) total time=  12.3s\n",
      "[CV 2/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.737, test=0.730) f1: (train=0.780, test=0.773) total time=   1.4s\n",
      "[CV 5/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.786) total time=   1.4s\n",
      "[CV 1/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   1.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.866, test=0.870) balanced_accuracy: (train=0.733, test=0.741) f1: (train=0.776, test=0.784) total time=   1.3s\n",
      "[CV 3/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   2.1s\n",
      "[CV 2/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.737, test=0.730) f1: (train=0.780, test=0.773) total time=   4.1s\n",
      "[CV 2/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.737, test=0.731) f1: (train=0.780, test=0.773) total time=   3.9s\n",
      "[CV 1/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   1.8s\n",
      "[CV 3/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.779, test=0.776) total time=   2.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   3.9s\n",
      "[CV 1/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.873, test=0.870) balanced_accuracy: (train=0.748, test=0.744) f1: (train=0.791, test=0.786) total time=   5.2s\n",
      "[CV 3/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.873, test=0.870) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.790, test=0.786) total time=   8.6s\n",
      "[CV 5/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.871, test=0.875) balanced_accuracy: (train=0.744, test=0.753) f1: (train=0.787, test=0.796) total time=   7.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.873, test=0.870) balanced_accuracy: (train=0.748, test=0.743) f1: (train=0.790, test=0.786) total time=  16.7s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.779, test=0.776) total time=   2.2s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.780, test=0.772) total time=   4.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.737, test=0.730) f1: (train=0.780, test=0.773) total time=   3.4s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.866, test=0.870) balanced_accuracy: (train=0.733, test=0.742) f1: (train=0.776, test=0.785) total time=   1.3s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.867, test=0.870) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.786) total time=   2.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.737, test=0.730) f1: (train=0.780, test=0.773) total time=   4.1s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.783) total time=   5.1s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.870, test=0.874) balanced_accuracy: (train=0.741, test=0.751) f1: (train=0.784, test=0.794) total time=   5.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.744, test=0.736) f1: (train=0.787, test=0.779) total time=   7.2s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.785, test=0.782) total time=  16.9s\n",
      "[CV 4/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.778, test=0.776) total time=   1.4s\n",
      "[CV 5/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.866, test=0.870) balanced_accuracy: (train=0.733, test=0.742) f1: (train=0.776, test=0.785) total time=   1.5s\n",
      "[CV 2/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.779, test=0.773) total time=   2.5s\n",
      "[CV 2/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.780, test=0.772) total time=   2.4s\n",
      "[CV 1/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.778) total time=   4.5s\n",
      "[CV 3/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.732) f1: (train=0.779, test=0.775) total time=   1.3s\n",
      "[CV 1/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.776) total time=   1.2s\n",
      "[CV 1/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.735) f1: (train=0.779, test=0.778) total time=   2.4s\n",
      "[CV 4/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.779, test=0.776) total time=   4.2s\n",
      "[CV 1/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.745, test=0.741) f1: (train=0.787, test=0.783) total time=   5.7s\n",
      "[CV 3/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.785, test=0.782) total time=   5.8s\n",
      "[CV 5/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.870, test=0.874) balanced_accuracy: (train=0.742, test=0.751) f1: (train=0.785, test=0.794) total time=  10.3s\n",
      "[CV 3/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.785, test=0.782) total time=  16.5s\n",
      "[CV 5/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.866, test=0.870) balanced_accuracy: (train=0.733, test=0.742) f1: (train=0.776, test=0.785) total time=   1.5s\n",
      "[CV 2/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.779, test=0.773) total time=   2.2s\n",
      "[CV 4/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   2.5s\n",
      "[CV 4/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.779, test=0.776) total time=   3.9s\n",
      "[CV 1/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.778, test=0.776) total time=   1.1s\n",
      "[CV 1/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.777) total time=   1.4s\n",
      "[CV 4/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.778, test=0.775) total time=   1.4s\n",
      "[CV 1/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.778, test=0.776) total time=   2.1s\n",
      "[CV 2/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.780, test=0.773) total time=   4.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.737, test=0.731) f1: (train=0.780, test=0.774) total time=   1.4s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.737, test=0.734) f1: (train=0.780, test=0.777) total time=   2.1s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.737, test=0.735) f1: (train=0.780, test=0.778) total time=   4.3s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   1.1s\n",
      "[CV 2/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.869, test=0.864) balanced_accuracy: (train=0.739, test=0.731) f1: (train=0.782, test=0.773) total time=   1.3s\n",
      "[CV 2/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.737, test=0.731) f1: (train=0.780, test=0.773) total time=   2.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   4.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.872, test=0.868) balanced_accuracy: (train=0.747, test=0.739) f1: (train=0.790, test=0.781) total time=   4.9s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.872, test=0.870) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.789, test=0.785) total time=   4.3s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.871, test=0.875) balanced_accuracy: (train=0.745, test=0.752) f1: (train=0.788, test=0.795) total time=   7.3s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.871, test=0.875) balanced_accuracy: (train=0.744, test=0.753) f1: (train=0.787, test=0.795) total time=  16.4s\n",
      "[CV 3/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.737, test=0.733) f1: (train=0.780, test=0.775) total time=   1.2s\n",
      "[CV 4/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   1.3s\n",
      "[CV 1/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   2.1s\n",
      "[CV 4/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.737, test=0.734) f1: (train=0.780, test=0.777) total time=   2.5s\n",
      "[CV 4/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   3.3s\n",
      "[CV 4/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.780, test=0.776) total time=   3.9s\n",
      "[CV 5/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.787) total time=   2.2s\n",
      "[CV 3/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   3.9s\n",
      "[CV 4/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.873, test=0.870) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.790, test=0.785) total time=   5.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.872, test=0.870) balanced_accuracy: (train=0.746, test=0.743) f1: (train=0.789, test=0.786) total time=   5.1s\n",
      "[CV 5/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.871, test=0.875) balanced_accuracy: (train=0.745, test=0.753) f1: (train=0.788, test=0.796) total time=   8.6s\n",
      "[CV 2/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.873, test=0.868) balanced_accuracy: (train=0.747, test=0.739) f1: (train=0.791, test=0.782) total time=  15.9s\n",
      "[CV 5/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.787) total time=   1.3s\n",
      "[CV 2/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.737, test=0.731) f1: (train=0.780, test=0.774) total time=   2.4s\n",
      "[CV 5/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.787) total time=   2.4s\n",
      "[CV 4/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   3.9s\n",
      "[CV 5/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.786) total time=   3.9s\n",
      "[CV 2/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.737, test=0.730) f1: (train=0.780, test=0.773) total time=   1.9s\n",
      "[CV 3/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   4.1s\n",
      "[CV 5/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.871, test=0.875) balanced_accuracy: (train=0.745, test=0.754) f1: (train=0.788, test=0.796) total time=   5.1s\n",
      "[CV 2/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.873, test=0.868) balanced_accuracy: (train=0.747, test=0.739) f1: (train=0.790, test=0.781) total time=   7.8s\n",
      "[CV 3/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.872, test=0.870) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.789, test=0.785) total time=   7.1s\n",
      "[CV 5/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.871, test=0.875) balanced_accuracy: (train=0.745, test=0.753) f1: (train=0.787, test=0.796) total time=  16.4s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.786) total time=   2.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   1.9s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.737, test=0.730) f1: (train=0.780, test=0.773) total time=   4.3s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.863) balanced_accuracy: (train=0.736, test=0.729) f1: (train=0.778, test=0.771) total time=   1.3s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   1.2s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.779, test=0.776) total time=   2.2s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.778) total time=   4.3s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   4.2s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.870, test=0.874) balanced_accuracy: (train=0.742, test=0.751) f1: (train=0.784, test=0.793) total time=   4.8s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.783) total time=   8.4s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.870, test=0.874) balanced_accuracy: (train=0.741, test=0.751) f1: (train=0.784, test=0.794) total time=  16.9s\n",
      "[CV 2/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.864) balanced_accuracy: (train=0.735, test=0.729) f1: (train=0.778, test=0.771) total time=   1.6s\n",
      "[CV 3/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.779, test=0.776) total time=   1.5s\n",
      "[CV 4/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.778, test=0.775) total time=   1.4s\n",
      "[CV 5/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.866, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.776, test=0.787) total time=   2.2s\n",
      "[CV 1/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   3.6s\n",
      "[CV 2/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.780, test=0.773) total time=   4.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.779, test=0.773) total time=   2.2s\n",
      "[CV 5/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.866, test=0.871) balanced_accuracy: (train=0.733, test=0.742) f1: (train=0.776, test=0.786) total time=   2.3s\n",
      "[CV 2/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.780, test=0.773) total time=   4.4s\n",
      "[CV 4/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.783) total time=   5.5s\n",
      "[CV 1/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.745, test=0.741) f1: (train=0.787, test=0.784) total time=   8.7s\n",
      "[CV 3/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.785, test=0.783) total time=  17.8s\n",
      "[CV 5/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.870, test=0.874) balanced_accuracy: (train=0.742, test=0.751) f1: (train=0.785, test=0.794) total time=  15.3s\n",
      "[CV 3/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.777) total time=   3.6s\n",
      "[CV 2/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.737, test=0.731) f1: (train=0.780, test=0.773) total time=   2.2s\n",
      "[CV 4/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.779, test=0.776) total time=   4.2s\n",
      "[CV 5/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.733, test=0.743) f1: (train=0.777, test=0.786) total time=   4.2s\n",
      "[CV 1/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.744, test=0.740) f1: (train=0.787, test=0.783) total time=   3.9s\n",
      "[CV 2/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.872, test=0.867) balanced_accuracy: (train=0.745, test=0.737) f1: (train=0.788, test=0.779) total time=   8.4s\n",
      "[CV 4/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.787, test=0.783) total time=  18.2s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.732) f1: (train=0.779, test=0.775) total time=   1.2s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.737, test=0.730) f1: (train=0.780, test=0.772) total time=   1.3s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.735, test=0.735) f1: (train=0.778, test=0.778) total time=   1.2s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.866, test=0.870) balanced_accuracy: (train=0.733, test=0.742) f1: (train=0.776, test=0.785) total time=   1.4s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.735) f1: (train=0.779, test=0.778) total time=   1.9s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.737, test=0.731) f1: (train=0.780, test=0.773) total time=   2.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.779, test=0.778) total time=   1.3s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.735) f1: (train=0.779, test=0.778) total time=   1.9s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.866, test=0.871) balanced_accuracy: (train=0.733, test=0.742) f1: (train=0.776, test=0.786) total time=   2.1s\n",
      "[CV 2/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.738, test=0.730) f1: (train=0.781, test=0.773) total time=   4.2s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.737, test=0.736) f1: (train=0.780, test=0.778) total time=   1.2s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.735) f1: (train=0.779, test=0.778) total time=   1.9s\n",
      "[CV 2/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.737, test=0.730) f1: (train=0.780, test=0.773) total time=   3.9s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.780, test=0.776) total time=   3.8s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.872, test=0.870) balanced_accuracy: (train=0.747, test=0.742) f1: (train=0.790, test=0.784) total time=   4.5s\n",
      "[CV 2/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.872, test=0.868) balanced_accuracy: (train=0.747, test=0.739) f1: (train=0.790, test=0.781) total time=   8.4s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.872, test=0.870) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.790, test=0.785) total time=  16.4s\n",
      "[CV 4/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   1.3s\n",
      "[CV 2/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.738, test=0.731) f1: (train=0.781, test=0.774) total time=   1.3s\n",
      "[CV 4/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.780, test=0.777) total time=   2.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   2.3s\n",
      "[CV 5/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.733, test=0.743) f1: (train=0.777, test=0.786) total time=   4.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   1.2s\n",
      "[CV 4/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   1.1s\n",
      "[CV 3/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.780, test=0.776) total time=   2.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   1.9s\n",
      "[CV 1/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.735) f1: (train=0.779, test=0.778) total time=   4.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.872, test=0.870) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.790, test=0.786) total time=   4.9s\n",
      "[CV 5/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.871, test=0.875) balanced_accuracy: (train=0.744, test=0.753) f1: (train=0.787, test=0.795) total time=   8.5s\n",
      "[CV 2/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.873, test=0.868) balanced_accuracy: (train=0.747, test=0.739) f1: (train=0.790, test=0.781) total time=  16.7s\n",
      "[CV 1/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   1.5s\n",
      "[CV 4/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   1.1s\n",
      "[CV 3/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.732) f1: (train=0.779, test=0.775) total time=   1.2s\n",
      "[CV 4/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.737, test=0.735) f1: (train=0.779, test=0.778) total time=   1.2s\n",
      "[CV 5/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.787) total time=   2.2s\n",
      "[CV 1/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.735) f1: (train=0.779, test=0.778) total time=   4.2s\n",
      "[CV 1/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.735) f1: (train=0.779, test=0.778) total time=   3.9s\n",
      "[CV 5/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.866, test=0.870) balanced_accuracy: (train=0.733, test=0.741) f1: (train=0.776, test=0.784) total time=   1.1s\n",
      "[CV 4/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.737, test=0.734) f1: (train=0.780, test=0.777) total time=   1.9s\n",
      "[CV 2/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.780, test=0.773) total time=   4.1s\n",
      "[CV 4/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.873, test=0.870) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.790, test=0.785) total time=   4.8s\n",
      "[CV 5/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.871, test=0.875) balanced_accuracy: (train=0.745, test=0.753) f1: (train=0.788, test=0.796) total time=   5.6s\n",
      "[CV 2/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.873, test=0.867) balanced_accuracy: (train=0.747, test=0.738) f1: (train=0.790, test=0.780) total time=   6.8s\n",
      "[CV 2/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.873, test=0.868) balanced_accuracy: (train=0.747, test=0.739) f1: (train=0.791, test=0.782) total time=  12.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.872, test=0.870) balanced_accuracy: (train=0.746, test=0.743) f1: (train=0.789, test=0.785) total time=  11.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   4.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   3.8s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.735) f1: (train=0.779, test=0.778) total time=   2.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   4.3s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.786) total time=   4.4s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.872, test=0.867) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.787, test=0.779) total time=   4.7s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.871, test=0.870) balanced_accuracy: (train=0.743, test=0.741) f1: (train=0.786, test=0.784) total time=   8.2s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.787, test=0.778) total time=  17.2s\n",
      "[CV 5/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.866, test=0.871) balanced_accuracy: (train=0.733, test=0.742) f1: (train=0.776, test=0.785) total time=   1.4s\n",
      "[CV 1/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.776) total time=   1.2s\n",
      "[CV 5/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.866, test=0.869) balanced_accuracy: (train=0.732, test=0.741) f1: (train=0.775, test=0.784) total time=   1.5s\n",
      "[CV 2/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.737, test=0.731) f1: (train=0.780, test=0.773) total time=   2.1s\n",
      "[CV 5/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.866, test=0.871) balanced_accuracy: (train=0.733, test=0.742) f1: (train=0.776, test=0.786) total time=   2.4s\n",
      "[CV 1/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   4.2s\n",
      "[CV 3/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.779, test=0.776) total time=   1.3s\n",
      "[CV 1/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.776) total time=   2.1s\n",
      "[CV 3/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.779, test=0.776) total time=   2.1s\n",
      "[CV 5/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.866, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.786) total time=   4.3s\n",
      "[CV 2/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.872, test=0.867) balanced_accuracy: (train=0.745, test=0.737) f1: (train=0.788, test=0.779) total time=   5.5s\n",
      "[CV 4/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.741) f1: (train=0.786, test=0.784) total time=   8.8s\n",
      "[CV 1/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.744, test=0.741) f1: (train=0.787, test=0.783) total time=  17.9s\n",
      "[CV 4/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.741) f1: (train=0.786, test=0.783) total time=  12.9s\n",
      "[CV 1/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   4.5s\n",
      "[CV 4/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   1.3s\n",
      "[CV 1/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.776) total time=   2.2s\n",
      "[CV 4/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.779, test=0.777) total time=   2.2s\n",
      "[CV 1/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   4.5s\n",
      "[CV 4/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.783) total time=   4.9s\n",
      "[CV 4/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.741) f1: (train=0.786, test=0.784) total time=   8.8s\n",
      "[CV 1/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.744, test=0.741) f1: (train=0.787, test=0.783) total time=  18.7s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.863) balanced_accuracy: (train=0.736, test=0.729) f1: (train=0.778, test=0.771) total time=   1.4s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.777) total time=   1.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.737, test=0.734) f1: (train=0.780, test=0.777) total time=   1.2s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   1.1s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.737, test=0.735) f1: (train=0.780, test=0.778) total time=   1.9s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.779, test=0.776) total time=   4.5s\n",
      "[CV 2/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.780, test=0.773) total time=   1.2s\n",
      "[CV 2/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.737, test=0.731) f1: (train=0.780, test=0.773) total time=   1.8s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   1.9s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.780, test=0.776) total time=   3.9s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.871, test=0.875) balanced_accuracy: (train=0.745, test=0.753) f1: (train=0.787, test=0.796) total time=   4.7s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.872, test=0.870) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.790, test=0.785) total time=   7.2s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.745, test=0.741) f1: (train=0.788, test=0.784) total time=   7.8s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.871, test=0.875) balanced_accuracy: (train=0.744, test=0.752) f1: (train=0.787, test=0.795) total time=  11.4s\n",
      "[CV 2/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.737, test=0.730) f1: (train=0.780, test=0.773) total time=   1.4s\n",
      "[CV 5/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.787) total time=   1.3s\n",
      "[CV 2/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.737, test=0.731) f1: (train=0.780, test=0.774) total time=   2.1s\n",
      "[CV 5/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.787) total time=   2.4s\n",
      "[CV 2/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.737, test=0.730) f1: (train=0.780, test=0.773) total time=   3.4s\n",
      "[CV 3/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   3.9s\n",
      "[CV 1/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.737, test=0.734) f1: (train=0.779, test=0.777) total time=   2.2s\n",
      "[CV 1/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.737, test=0.735) f1: (train=0.780, test=0.777) total time=   4.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.873, test=0.870) balanced_accuracy: (train=0.748, test=0.744) f1: (train=0.791, test=0.786) total time=   4.9s\n",
      "[CV 2/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.873, test=0.868) balanced_accuracy: (train=0.747, test=0.739) f1: (train=0.790, test=0.781) total time=   8.6s\n",
      "[CV 5/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.871, test=0.875) balanced_accuracy: (train=0.744, test=0.753) f1: (train=0.787, test=0.796) total time=   8.6s\n",
      "[CV 2/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.872, test=0.867) balanced_accuracy: (train=0.746, test=0.738) f1: (train=0.790, test=0.781) total time=  14.1s\n",
      "[CV 1/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.737, test=0.734) f1: (train=0.779, test=0.777) total time=   2.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.779, test=0.776) total time=   2.3s\n",
      "[CV 5/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.733, test=0.743) f1: (train=0.777, test=0.786) total time=   4.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.786) total time=   1.6s\n",
      "[CV 2/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.738, test=0.731) f1: (train=0.781, test=0.774) total time=   1.1s\n",
      "[CV 3/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   2.1s\n",
      "[CV 5/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.733, test=0.743) f1: (train=0.777, test=0.786) total time=   4.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.873, test=0.868) balanced_accuracy: (train=0.747, test=0.739) f1: (train=0.791, test=0.781) total time=   5.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.872, test=0.870) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.790, test=0.786) total time=   5.4s\n",
      "[CV 1/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.872, test=0.870) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.790, test=0.785) total time=   8.4s\n",
      "[CV 4/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.873, test=0.869) balanced_accuracy: (train=0.747, test=0.742) f1: (train=0.790, test=0.784) total time=  16.5s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.735, test=0.735) f1: (train=0.778, test=0.778) total time=   1.2s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.779, test=0.776) total time=   2.1s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   2.4s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   4.1s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.776) total time=   1.3s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.737, test=0.730) f1: (train=0.780, test=0.772) total time=   1.3s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   2.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   2.3s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.786) total time=   4.3s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.744, test=0.740) f1: (train=0.786, test=0.783) total time=   4.9s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.785, test=0.782) total time=   8.5s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.870, test=0.874) balanced_accuracy: (train=0.741, test=0.751) f1: (train=0.784, test=0.794) total time=   8.5s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.744, test=0.736) f1: (train=0.787, test=0.778) total time=  17.2s\n",
      "[CV 1/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.778, test=0.776) total time=   2.5s\n",
      "[CV 3/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   4.6s\n",
      "[CV 1/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.777) total time=   1.2s\n",
      "[CV 3/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.776) total time=   1.3s\n",
      "[CV 4/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   2.1s\n",
      "[CV 1/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.778) total time=   4.3s\n",
      "[CV 3/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.786, test=0.783) total time=   5.5s\n",
      "[CV 3/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.785, test=0.782) total time=   8.6s\n",
      "[CV 4/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.741) f1: (train=0.786, test=0.783) total time=   9.2s\n",
      "[CV 5/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.870, test=0.874) balanced_accuracy: (train=0.742, test=0.751) f1: (train=0.785, test=0.794) total time=  15.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.737, test=0.731) f1: (train=0.780, test=0.773) total time=   1.5s\n",
      "[CV 4/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.779, test=0.776) total time=   2.1s\n",
      "[CV 3/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.779, test=0.776) total time=   2.5s\n",
      "[CV 3/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   3.8s\n",
      "[CV 2/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.864) balanced_accuracy: (train=0.735, test=0.729) f1: (train=0.778, test=0.771) total time=   1.6s\n",
      "[CV 5/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.866, test=0.870) balanced_accuracy: (train=0.733, test=0.742) f1: (train=0.776, test=0.785) total time=   1.4s\n",
      "[CV 4/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.779, test=0.776) total time=   1.8s\n",
      "[CV 3/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.779, test=0.776) total time=   2.1s\n",
      "[CV 5/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.866, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.786) total time=   4.2s\n",
      "[CV 2/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.872, test=0.867) balanced_accuracy: (train=0.745, test=0.737) f1: (train=0.788, test=0.779) total time=   5.6s\n",
      "[CV 5/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.870, test=0.874) balanced_accuracy: (train=0.742, test=0.751) f1: (train=0.785, test=0.794) total time=   9.1s\n",
      "[CV 2/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.744, test=0.736) f1: (train=0.787, test=0.779) total time=  18.4s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.776) total time=   1.5s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False),\n",
       "             estimator=RandomForestClassifier(max_depth=100, max_features=None,\n",
       "                                              max_leaf_nodes=100,\n",
       "                                              n_estimators=50, n_jobs=-1,\n",
       "                                              random_state=100),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;criterion&#x27;: [&#x27;gini&#x27;, &#x27;entropy&#x27;, &#x27;log_loss&#x27;],\n",
       "                         &#x27;max_depth&#x27;: [10, 40, None],\n",
       "                         &#x27;max_features&#x27;: [&#x27;sqrt&#x27;, &#x27;log2&#x27;, None],\n",
       "                         &#x27;n_estimators&#x27;: [30, 50, 100],\n",
       "                         &#x27;random_state&#x27;: [10, 30, 100]},\n",
       "             refit=&#x27;balanced_accuracy&#x27;, return_train_score=True,\n",
       "             scoring={&#x27;accuracy&#x27;: &#x27;accuracy&#x27;,\n",
       "                      &#x27;balanced_accuracy&#x27;: &#x27;balanced_accuracy&#x27;,\n",
       "                      &#x27;f1&#x27;: &#x27;f1_macro&#x27;},\n",
       "             verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False),\n",
       "             estimator=RandomForestClassifier(max_depth=100, max_features=None,\n",
       "                                              max_leaf_nodes=100,\n",
       "                                              n_estimators=50, n_jobs=-1,\n",
       "                                              random_state=100),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;criterion&#x27;: [&#x27;gini&#x27;, &#x27;entropy&#x27;, &#x27;log_loss&#x27;],\n",
       "                         &#x27;max_depth&#x27;: [10, 40, None],\n",
       "                         &#x27;max_features&#x27;: [&#x27;sqrt&#x27;, &#x27;log2&#x27;, None],\n",
       "                         &#x27;n_estimators&#x27;: [30, 50, 100],\n",
       "                         &#x27;random_state&#x27;: [10, 30, 100]},\n",
       "             refit=&#x27;balanced_accuracy&#x27;, return_train_score=True,\n",
       "             scoring={&#x27;accuracy&#x27;: &#x27;accuracy&#x27;,\n",
       "                      &#x27;balanced_accuracy&#x27;: &#x27;balanced_accuracy&#x27;,\n",
       "                      &#x27;f1&#x27;: &#x27;f1_macro&#x27;},\n",
       "             verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=100, max_features=None, max_leaf_nodes=100,\n",
       "                       n_estimators=50, n_jobs=-1, random_state=100)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=100, max_features=None, max_leaf_nodes=100,\n",
       "                       n_estimators=50, n_jobs=-1, random_state=100)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False),\n",
       "             estimator=RandomForestClassifier(max_depth=100, max_features=None,\n",
       "                                              max_leaf_nodes=100,\n",
       "                                              n_estimators=50, n_jobs=-1,\n",
       "                                              random_state=100),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'criterion': ['gini', 'entropy', 'log_loss'],\n",
       "                         'max_depth': [10, 40, None],\n",
       "                         'max_features': ['sqrt', 'log2', None],\n",
       "                         'n_estimators': [30, 50, 100],\n",
       "                         'random_state': [10, 30, 100]},\n",
       "             refit='balanced_accuracy', return_train_score=True,\n",
       "             scoring={'accuracy': 'accuracy',\n",
       "                      'balanced_accuracy': 'balanced_accuracy',\n",
       "                      'f1': 'f1_macro'},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "rf = RandomForestClassifier( n_jobs=-1, n_estimators=50, max_depth=100,max_leaf_nodes=100, random_state=100, max_features=None)\n",
    "\n",
    "parameter_grid = {\n",
    "    \"n_estimators\": [30, 50, 100],\n",
    "    \"max_depth\": [10, 40, None],\n",
    "    \"max_features\": [\"sqrt\",\"log2\", None],\n",
    "    \"random_state\":[10,30,100],\n",
    "    \"criterion\": ['gini', 'entropy', 'log_loss']\n",
    "}\n",
    "\n",
    "cross_validation = StratifiedKFold(n_splits=5)\n",
    "cross_validation.get_n_splits(train_data, np.ravel(y_train))\n",
    "\n",
    "# Create the scoring dictionary\n",
    "SCORING = {\n",
    "    \"accuracy\": \"accuracy\",\n",
    "    \"balanced_accuracy\": \"balanced_accuracy\",\n",
    "    \"f1\": \"f1_macro\",\n",
    "}\n",
    "\n",
    "# Create and fit the GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=rf,\n",
    "    param_grid=parameter_grid,\n",
    "    n_jobs=-1,\n",
    "    cv=cross_validation,\n",
    "    verbose=3,\n",
    "    scoring=SCORING,\n",
    "    return_train_score=True,\n",
    "    refit=\"balanced_accuracy\",\n",
    ")\n",
    "\n",
    "grid_search.fit(train_data, np.ravel(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "35a074af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.7444008926792822\n",
      "Best parameters: {'criterion': 'gini', 'max_depth': 40, 'max_features': None, 'n_estimators': 30, 'random_state': 10}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_depth=40, max_features=None, max_leaf_nodes=100,\n",
       "                       n_estimators=30, n_jobs=-1, random_state=10)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=40, max_features=None, max_leaf_nodes=100,\n",
       "                       n_estimators=30, n_jobs=-1, random_state=10)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(max_depth=40, max_features=None, max_leaf_nodes=100,\n",
       "                       n_estimators=30, n_jobs=-1, random_state=10)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Best score: {}\".format(grid_search.best_score_))\n",
    "print(\"Best parameters: {}\".format(grid_search.best_params_))\n",
    "\n",
    "best_dtc = grid_search.best_estimator_\n",
    "best_dtc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "69089f07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8695186056162678"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model = best_dtc\n",
    "my_model.fit(train_data, np.ravel(y_train))\n",
    "my_model.score(test_data, np.ravel(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b587ca52",
   "metadata": {},
   "source": [
    "EXTRA TREE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "594e3215",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "47a73cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "column = ['criterion','max_features', 'n_estimators', 'random_state', 'accuracy']\n",
    "column_bar = ['try', 'Parameter_changed', 'Accuracy']\n",
    "\n",
    "### Create a single row equivalent to a single try for decision tree\n",
    "def create_bar_row(criterion,feature, stimatori,random, attempt, parameter):\n",
    "  xt = ExtraTreesClassifier(criterion=criterion,max_features=feature,n_estimators=stimatori, random_state=random, n_jobs=-1 )\n",
    "  xt.fit(train_data, np.ravel(y_train))\n",
    "  testset_score = xt.score(test_data, y_test)\n",
    "  row = pd.DataFrame(data=[[attempt, parameter, testset_score]], columns=column_bar)\n",
    "  return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5ae9c61a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  try Parameter_changed  Accuracy\n",
      "0   1             start  0.857587\n",
      "0   2      max_features  0.857587\n",
      "0   3       n_estimator  0.858556\n",
      "0   4      random_state  0.858902\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'Score sul testset durante il tuning dei parametri'}, xlabel='Accuracy', ylabel='Parameter_changed'>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.DataFrame(columns=column_bar)\n",
    "df = pd.concat([df, create_bar_row('gini', 'log2', 20, 4, 1, 'start')]) # try 1\n",
    "df = pd.concat([df, create_bar_row('gini', 'sqrt', 20, 4, 2, 'max_features')]) # try 2\n",
    "df = pd.concat([df, create_bar_row('gini', 'sqrt', 120, 4, 3, 'n_estimator')]) # try 3\n",
    "df = pd.concat([df, create_bar_row('gini', 'log2', 120, 30, 4, 'random_state')]) # try 4\n",
    "\n",
    "print(df)\n",
    "\n",
    "fig, axs = plt.subplots()\n",
    "axs.set_xlim([0.70,0.89])\n",
    "axs.set_title(\"Score sul testset durante il tuning dei parametri\")\n",
    "\n",
    "sns.barplot(data=df, x='Accuracy',y=\"Parameter_changed\",ax=axs, orient=\"h\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f57e65fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "algoritmo=[\"Start\",\"Max_features\",\"n_estimators\",\"random_state\"]\n",
    "accuracy=[0.8575,0.8575,0.8585,0.8589]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(algoritmo, accuracy, marker='o', linestyle='-', color='r')\n",
    "plt.title(' Accuracy su testSet al Variare dell algoritmo')\n",
    "plt.xlabel('Algoritmo')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.grid(True)\n",
    "plt.xticks(algoritmo)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4b44ba0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 36 candidates, totalling 360 fits\n",
      "[CV 1/10] END criterion=gini, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.740) f1: (train=1.000, test=0.774) total time=   1.8s\n",
      "[CV 2/10] END criterion=gini, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.863) balanced_accuracy: (train=1.000, test=0.747) f1: (train=1.000, test=0.783) total time=   1.2s\n",
      "[CV 3/10] END criterion=gini, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.740) f1: (train=1.000, test=0.774) total time=   1.1s\n",
      "[CV 4/10] END criterion=gini, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.739) f1: (train=1.000, test=0.775) total time=   1.2s\n",
      "[CV 5/10] END criterion=gini, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.745) f1: (train=1.000, test=0.781) total time=   1.2s\n",
      "[CV 6/10] END criterion=gini, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.743) f1: (train=1.000, test=0.777) total time=   1.3s\n",
      "[CV 7/10] END criterion=gini, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.860) balanced_accuracy: (train=1.000, test=0.744) f1: (train=1.000, test=0.778) total time=   1.2s\n",
      "[CV 8/10] END criterion=gini, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.743) f1: (train=1.000, test=0.777) total time=   1.2s\n",
      "[CV 9/10] END criterion=gini, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.861) balanced_accuracy: (train=1.000, test=0.747) f1: (train=1.000, test=0.781) total time=   1.2s\n",
      "[CV 10/10] END criterion=gini, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.863) balanced_accuracy: (train=1.000, test=0.754) f1: (train=1.000, test=0.787) total time=   1.3s\n",
      "[CV 1/10] END criterion=gini, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.855) balanced_accuracy: (train=1.000, test=0.739) f1: (train=1.000, test=0.772) total time=   1.3s\n",
      "[CV 2/10] END criterion=gini, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.864) balanced_accuracy: (train=1.000, test=0.749) f1: (train=1.000, test=0.785) total time=   1.3s\n",
      "[CV 3/10] END criterion=gini, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.856) balanced_accuracy: (train=1.000, test=0.738) f1: (train=1.000, test=0.772) total time=   1.2s\n",
      "[CV 4/10] END criterion=gini, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.738) f1: (train=1.000, test=0.773) total time=   1.2s\n",
      "[CV 5/10] END criterion=gini, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.745) f1: (train=1.000, test=0.781) total time=   1.3s\n",
      "[CV 6/10] END criterion=gini, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.860) balanced_accuracy: (train=1.000, test=0.743) f1: (train=1.000, test=0.777) total time=   1.2s\n",
      "[CV 7/10] END criterion=gini, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.741) f1: (train=1.000, test=0.775) total time=   1.1s\n",
      "[CV 8/10] END criterion=gini, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.742) f1: (train=1.000, test=0.777) total time=   1.2s\n",
      "[CV 9/10] END criterion=gini, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.861) balanced_accuracy: (train=1.000, test=0.748) f1: (train=1.000, test=0.781) total time=   1.2s\n",
      "[CV 10/10] END criterion=gini, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.752) f1: (train=1.000, test=0.785) total time=   1.2s\n",
      "[CV 1/10] END criterion=gini, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.741) f1: (train=1.000, test=0.775) total time=   1.1s\n",
      "[CV 2/10] END criterion=gini, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.861) balanced_accuracy: (train=1.000, test=0.744) f1: (train=1.000, test=0.780) total time=   1.2s\n",
      "[CV 3/10] END criterion=gini, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.856) balanced_accuracy: (train=1.000, test=0.738) f1: (train=1.000, test=0.772) total time=   1.3s\n",
      "[CV 4/10] END criterion=gini, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.737) f1: (train=1.000, test=0.772) total time=   1.2s\n",
      "[CV 5/10] END criterion=gini, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.863) balanced_accuracy: (train=1.000, test=0.747) f1: (train=1.000, test=0.782) total time=   1.4s\n",
      "[CV 6/10] END criterion=gini, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.744) f1: (train=1.000, test=0.777) total time=   1.3s\n",
      "[CV 7/10] END criterion=gini, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.741) f1: (train=1.000, test=0.775) total time=   1.4s\n",
      "[CV 8/10] END criterion=gini, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.740) f1: (train=1.000, test=0.775) total time=   1.2s\n",
      "[CV 9/10] END criterion=gini, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.863) balanced_accuracy: (train=1.000, test=0.749) f1: (train=1.000, test=0.783) total time=   1.3s\n",
      "[CV 10/10] END criterion=gini, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.863) balanced_accuracy: (train=1.000, test=0.753) f1: (train=1.000, test=0.786) total time=   1.2s\n",
      "[CV 1/10] END criterion=gini, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.740) f1: (train=1.000, test=0.774) total time=   2.1s\n",
      "[CV 2/10] END criterion=gini, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.863) balanced_accuracy: (train=1.000, test=0.747) f1: (train=1.000, test=0.783) total time=   2.1s\n",
      "[CV 3/10] END criterion=gini, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.740) f1: (train=1.000, test=0.773) total time=   2.1s\n",
      "[CV 4/10] END criterion=gini, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.738) f1: (train=1.000, test=0.773) total time=   2.1s\n",
      "[CV 5/10] END criterion=gini, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.863) balanced_accuracy: (train=1.000, test=0.747) f1: (train=1.000, test=0.782) total time=   2.2s\n",
      "[CV 6/10] END criterion=gini, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.744) f1: (train=1.000, test=0.778) total time=   2.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 7/10] END criterion=gini, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.743) f1: (train=1.000, test=0.777) total time=   2.1s\n",
      "[CV 8/10] END criterion=gini, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.860) balanced_accuracy: (train=1.000, test=0.743) f1: (train=1.000, test=0.778) total time=   2.1s\n",
      "[CV 9/10] END criterion=gini, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.747) f1: (train=1.000, test=0.782) total time=   2.1s\n",
      "[CV 10/10] END criterion=gini, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.752) f1: (train=1.000, test=0.785) total time=   2.1s\n",
      "[CV 1/10] END criterion=gini, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.741) f1: (train=1.000, test=0.774) total time=   2.1s\n",
      "[CV 2/10] END criterion=gini, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.863) balanced_accuracy: (train=1.000, test=0.747) f1: (train=1.000, test=0.783) total time=   2.1s\n",
      "[CV 3/10] END criterion=gini, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.856) balanced_accuracy: (train=1.000, test=0.739) f1: (train=1.000, test=0.773) total time=   2.0s\n",
      "[CV 4/10] END criterion=gini, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.737) f1: (train=1.000, test=0.772) total time=   2.2s\n",
      "[CV 5/10] END criterion=gini, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.745) f1: (train=1.000, test=0.780) total time=   2.0s\n",
      "[CV 6/10] END criterion=gini, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.860) balanced_accuracy: (train=1.000, test=0.743) f1: (train=1.000, test=0.777) total time=   2.2s\n",
      "[CV 7/10] END criterion=gini, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.742) f1: (train=1.000, test=0.776) total time=   2.1s\n",
      "[CV 8/10] END criterion=gini, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.743) f1: (train=1.000, test=0.777) total time=   2.0s\n",
      "[CV 9/10] END criterion=gini, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.861) balanced_accuracy: (train=1.000, test=0.748) f1: (train=1.000, test=0.782) total time=   2.1s\n",
      "[CV 10/10] END criterion=gini, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.863) balanced_accuracy: (train=1.000, test=0.754) f1: (train=1.000, test=0.787) total time=   2.0s\n",
      "[CV 1/10] END criterion=gini, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.856) balanced_accuracy: (train=1.000, test=0.740) f1: (train=1.000, test=0.773) total time=   2.1s\n",
      "[CV 2/10] END criterion=gini, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.865) balanced_accuracy: (train=1.000, test=0.749) f1: (train=1.000, test=0.785) total time=   2.1s\n",
      "[CV 3/10] END criterion=gini, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.856) balanced_accuracy: (train=1.000, test=0.738) f1: (train=1.000, test=0.771) total time=   2.0s\n",
      "[CV 4/10] END criterion=gini, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.739) f1: (train=1.000, test=0.774) total time=   2.0s\n",
      "[CV 5/10] END criterion=gini, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.747) f1: (train=1.000, test=0.782) total time=   2.0s\n",
      "[CV 6/10] END criterion=gini, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.742) f1: (train=1.000, test=0.776) total time=   2.0s\n",
      "[CV 7/10] END criterion=gini, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.742) f1: (train=1.000, test=0.775) total time=   2.0s\n",
      "[CV 8/10] END criterion=gini, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.860) balanced_accuracy: (train=1.000, test=0.743) f1: (train=1.000, test=0.778) total time=   2.1s\n",
      "[CV 9/10] END criterion=gini, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.748) f1: (train=1.000, test=0.783) total time=   2.0s\n",
      "[CV 10/10] END criterion=gini, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.754) f1: (train=1.000, test=0.786) total time=   2.0s\n",
      "[CV 1/10] END criterion=gini, max_features=log2, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.740) f1: (train=1.000, test=0.774) total time=   1.2s\n",
      "[CV 2/10] END criterion=gini, max_features=log2, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.863) balanced_accuracy: (train=1.000, test=0.747) f1: (train=1.000, test=0.783) total time=   1.1s\n",
      "[CV 3/10] END criterion=gini, max_features=log2, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.740) f1: (train=1.000, test=0.774) total time=   1.1s\n",
      "[CV 4/10] END criterion=gini, max_features=log2, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.739) f1: (train=1.000, test=0.775) total time=   1.1s\n",
      "[CV 5/10] END criterion=gini, max_features=log2, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.745) f1: (train=1.000, test=0.781) total time=   1.1s\n",
      "[CV 6/10] END criterion=gini, max_features=log2, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.743) f1: (train=1.000, test=0.777) total time=   1.1s\n",
      "[CV 7/10] END criterion=gini, max_features=log2, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.860) balanced_accuracy: (train=1.000, test=0.744) f1: (train=1.000, test=0.778) total time=   1.1s\n",
      "[CV 8/10] END criterion=gini, max_features=log2, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.743) f1: (train=1.000, test=0.777) total time=   1.2s\n",
      "[CV 9/10] END criterion=gini, max_features=log2, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.861) balanced_accuracy: (train=1.000, test=0.747) f1: (train=1.000, test=0.781) total time=   1.1s\n",
      "[CV 10/10] END criterion=gini, max_features=log2, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.863) balanced_accuracy: (train=1.000, test=0.754) f1: (train=1.000, test=0.787) total time=   1.1s\n",
      "[CV 1/10] END criterion=gini, max_features=log2, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.855) balanced_accuracy: (train=1.000, test=0.739) f1: (train=1.000, test=0.772) total time=   1.1s\n",
      "[CV 2/10] END criterion=gini, max_features=log2, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.864) balanced_accuracy: (train=1.000, test=0.749) f1: (train=1.000, test=0.785) total time=   1.1s\n",
      "[CV 3/10] END criterion=gini, max_features=log2, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.856) balanced_accuracy: (train=1.000, test=0.738) f1: (train=1.000, test=0.772) total time=   1.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/10] END criterion=gini, max_features=log2, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.738) f1: (train=1.000, test=0.773) total time=   1.1s\n",
      "[CV 5/10] END criterion=gini, max_features=log2, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.745) f1: (train=1.000, test=0.781) total time=   1.1s\n",
      "[CV 6/10] END criterion=gini, max_features=log2, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.860) balanced_accuracy: (train=1.000, test=0.743) f1: (train=1.000, test=0.777) total time=   1.1s\n",
      "[CV 7/10] END criterion=gini, max_features=log2, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.741) f1: (train=1.000, test=0.775) total time=   1.1s\n",
      "[CV 8/10] END criterion=gini, max_features=log2, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.742) f1: (train=1.000, test=0.777) total time=   1.1s\n",
      "[CV 9/10] END criterion=gini, max_features=log2, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.861) balanced_accuracy: (train=1.000, test=0.748) f1: (train=1.000, test=0.781) total time=   1.2s\n",
      "[CV 10/10] END criterion=gini, max_features=log2, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.752) f1: (train=1.000, test=0.785) total time=   1.1s\n",
      "[CV 1/10] END criterion=gini, max_features=log2, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.740) f1: (train=1.000, test=0.774) total time=   1.1s\n",
      "[CV 2/10] END criterion=gini, max_features=log2, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.864) balanced_accuracy: (train=1.000, test=0.748) f1: (train=1.000, test=0.784) total time=   1.1s\n",
      "[CV 3/10] END criterion=gini, max_features=log2, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.739) f1: (train=1.000, test=0.773) total time=   1.1s\n",
      "[CV 4/10] END criterion=gini, max_features=log2, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.739) f1: (train=1.000, test=0.774) total time=   1.1s\n",
      "[CV 5/10] END criterion=gini, max_features=log2, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.861) balanced_accuracy: (train=1.000, test=0.745) f1: (train=1.000, test=0.780) total time=   1.1s\n",
      "[CV 6/10] END criterion=gini, max_features=log2, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.743) f1: (train=1.000, test=0.776) total time=   1.2s\n",
      "[CV 7/10] END criterion=gini, max_features=log2, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.743) f1: (train=1.000, test=0.777) total time=   1.2s\n",
      "[CV 8/10] END criterion=gini, max_features=log2, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.741) f1: (train=1.000, test=0.775) total time=   1.2s\n",
      "[CV 9/10] END criterion=gini, max_features=log2, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.863) balanced_accuracy: (train=1.000, test=0.750) f1: (train=1.000, test=0.784) total time=   1.2s\n",
      "[CV 10/10] END criterion=gini, max_features=log2, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.754) f1: (train=1.000, test=0.786) total time=   1.2s\n",
      "[CV 1/10] END criterion=gini, max_features=log2, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.740) f1: (train=1.000, test=0.774) total time=   2.1s\n",
      "[CV 2/10] END criterion=gini, max_features=log2, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.863) balanced_accuracy: (train=1.000, test=0.747) f1: (train=1.000, test=0.783) total time=   2.0s\n",
      "[CV 3/10] END criterion=gini, max_features=log2, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.740) f1: (train=1.000, test=0.773) total time=   2.1s\n",
      "[CV 4/10] END criterion=gini, max_features=log2, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.738) f1: (train=1.000, test=0.773) total time=   2.0s\n",
      "[CV 5/10] END criterion=gini, max_features=log2, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.863) balanced_accuracy: (train=1.000, test=0.747) f1: (train=1.000, test=0.782) total time=   2.1s\n",
      "[CV 6/10] END criterion=gini, max_features=log2, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.744) f1: (train=1.000, test=0.778) total time=   2.1s\n",
      "[CV 7/10] END criterion=gini, max_features=log2, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.743) f1: (train=1.000, test=0.777) total time=   2.1s\n",
      "[CV 8/10] END criterion=gini, max_features=log2, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.860) balanced_accuracy: (train=1.000, test=0.743) f1: (train=1.000, test=0.778) total time=   2.1s\n",
      "[CV 9/10] END criterion=gini, max_features=log2, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.747) f1: (train=1.000, test=0.782) total time=   2.1s\n",
      "[CV 10/10] END criterion=gini, max_features=log2, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.752) f1: (train=1.000, test=0.785) total time=   2.1s\n",
      "[CV 1/10] END criterion=gini, max_features=log2, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.741) f1: (train=1.000, test=0.774) total time=   2.1s\n",
      "[CV 2/10] END criterion=gini, max_features=log2, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.863) balanced_accuracy: (train=1.000, test=0.747) f1: (train=1.000, test=0.783) total time=   2.0s\n",
      "[CV 3/10] END criterion=gini, max_features=log2, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.856) balanced_accuracy: (train=1.000, test=0.739) f1: (train=1.000, test=0.773) total time=   2.0s\n",
      "[CV 4/10] END criterion=gini, max_features=log2, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.737) f1: (train=1.000, test=0.772) total time=   2.1s\n",
      "[CV 5/10] END criterion=gini, max_features=log2, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.745) f1: (train=1.000, test=0.780) total time=   2.0s\n",
      "[CV 6/10] END criterion=gini, max_features=log2, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.860) balanced_accuracy: (train=1.000, test=0.743) f1: (train=1.000, test=0.777) total time=   2.0s\n",
      "[CV 7/10] END criterion=gini, max_features=log2, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.742) f1: (train=1.000, test=0.776) total time=   2.0s\n",
      "[CV 8/10] END criterion=gini, max_features=log2, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.743) f1: (train=1.000, test=0.777) total time=   2.1s\n",
      "[CV 9/10] END criterion=gini, max_features=log2, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.861) balanced_accuracy: (train=1.000, test=0.748) f1: (train=1.000, test=0.782) total time=   2.1s\n",
      "[CV 10/10] END criterion=gini, max_features=log2, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.863) balanced_accuracy: (train=1.000, test=0.754) f1: (train=1.000, test=0.787) total time=   2.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/10] END criterion=gini, max_features=log2, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.741) f1: (train=1.000, test=0.774) total time=   2.2s\n",
      "[CV 2/10] END criterion=gini, max_features=log2, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.865) balanced_accuracy: (train=1.000, test=0.749) f1: (train=1.000, test=0.785) total time=   2.3s\n",
      "[CV 3/10] END criterion=gini, max_features=log2, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.740) f1: (train=1.000, test=0.773) total time=   2.4s\n",
      "[CV 4/10] END criterion=gini, max_features=log2, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.740) f1: (train=1.000, test=0.775) total time=   2.2s\n",
      "[CV 5/10] END criterion=gini, max_features=log2, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.746) f1: (train=1.000, test=0.781) total time=   2.3s\n",
      "[CV 6/10] END criterion=gini, max_features=log2, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.742) f1: (train=1.000, test=0.776) total time=   2.3s\n",
      "[CV 7/10] END criterion=gini, max_features=log2, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.856) balanced_accuracy: (train=1.000, test=0.740) f1: (train=1.000, test=0.773) total time=   2.2s\n",
      "[CV 8/10] END criterion=gini, max_features=log2, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.742) f1: (train=1.000, test=0.776) total time=   2.2s\n",
      "[CV 9/10] END criterion=gini, max_features=log2, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.861) balanced_accuracy: (train=1.000, test=0.747) f1: (train=1.000, test=0.782) total time=   2.1s\n",
      "[CV 10/10] END criterion=gini, max_features=log2, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.863) balanced_accuracy: (train=1.000, test=0.754) f1: (train=1.000, test=0.787) total time=   2.2s\n",
      "[CV 1/10] END criterion=entropy, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.855) balanced_accuracy: (train=1.000, test=0.738) f1: (train=1.000, test=0.771) total time=   1.2s\n",
      "[CV 2/10] END criterion=entropy, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.863) balanced_accuracy: (train=1.000, test=0.747) f1: (train=1.000, test=0.783) total time=   1.2s\n",
      "[CV 3/10] END criterion=entropy, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.856) balanced_accuracy: (train=1.000, test=0.739) f1: (train=1.000, test=0.772) total time=   1.2s\n",
      "[CV 4/10] END criterion=entropy, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.740) f1: (train=1.000, test=0.774) total time=   1.2s\n",
      "[CV 5/10] END criterion=entropy, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.861) balanced_accuracy: (train=1.000, test=0.745) f1: (train=1.000, test=0.779) total time=   1.2s\n",
      "[CV 6/10] END criterion=entropy, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.742) f1: (train=1.000, test=0.776) total time=   1.2s\n",
      "[CV 7/10] END criterion=entropy, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.741) f1: (train=1.000, test=0.775) total time=   1.2s\n",
      "[CV 8/10] END criterion=entropy, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.742) f1: (train=1.000, test=0.776) total time=   1.2s\n",
      "[CV 9/10] END criterion=entropy, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.861) balanced_accuracy: (train=1.000, test=0.747) f1: (train=1.000, test=0.781) total time=   1.2s\n",
      "[CV 10/10] END criterion=entropy, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.753) f1: (train=1.000, test=0.785) total time=   1.2s\n",
      "[CV 1/10] END criterion=entropy, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.856) balanced_accuracy: (train=1.000, test=0.739) f1: (train=1.000, test=0.772) total time=   1.3s\n",
      "[CV 2/10] END criterion=entropy, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.865) balanced_accuracy: (train=1.000, test=0.749) f1: (train=1.000, test=0.785) total time=   1.2s\n",
      "[CV 3/10] END criterion=entropy, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.740) f1: (train=1.000, test=0.774) total time=   1.2s\n",
      "[CV 4/10] END criterion=entropy, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.738) f1: (train=1.000, test=0.772) total time=   1.2s\n",
      "[CV 5/10] END criterion=entropy, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.861) balanced_accuracy: (train=1.000, test=0.745) f1: (train=1.000, test=0.780) total time=   1.2s\n",
      "[CV 6/10] END criterion=entropy, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.742) f1: (train=1.000, test=0.776) total time=   1.2s\n",
      "[CV 7/10] END criterion=entropy, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.855) balanced_accuracy: (train=1.000, test=0.739) f1: (train=1.000, test=0.771) total time=   1.2s\n",
      "[CV 8/10] END criterion=entropy, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.741) f1: (train=1.000, test=0.776) total time=   1.2s\n",
      "[CV 9/10] END criterion=entropy, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.860) balanced_accuracy: (train=1.000, test=0.746) f1: (train=1.000, test=0.779) total time=   1.1s\n",
      "[CV 10/10] END criterion=entropy, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.753) f1: (train=1.000, test=0.785) total time=   1.2s\n",
      "[CV 1/10] END criterion=entropy, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.740) f1: (train=1.000, test=0.774) total time=   1.1s\n",
      "[CV 2/10] END criterion=entropy, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.863) balanced_accuracy: (train=1.000, test=0.748) f1: (train=1.000, test=0.783) total time=   1.3s\n",
      "[CV 3/10] END criterion=entropy, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.856) balanced_accuracy: (train=1.000, test=0.739) f1: (train=1.000, test=0.772) total time=   1.2s\n",
      "[CV 4/10] END criterion=entropy, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.739) f1: (train=1.000, test=0.773) total time=   1.2s\n",
      "[CV 5/10] END criterion=entropy, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.746) f1: (train=1.000, test=0.782) total time=   1.2s\n",
      "[CV 6/10] END criterion=entropy, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.860) balanced_accuracy: (train=1.000, test=0.744) f1: (train=1.000, test=0.778) total time=   1.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 7/10] END criterion=entropy, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.740) f1: (train=1.000, test=0.774) total time=   1.2s\n",
      "[CV 8/10] END criterion=entropy, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.743) f1: (train=1.000, test=0.777) total time=   1.2s\n",
      "[CV 9/10] END criterion=entropy, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.860) balanced_accuracy: (train=1.000, test=0.746) f1: (train=1.000, test=0.780) total time=   1.2s\n",
      "[CV 10/10] END criterion=entropy, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.752) f1: (train=1.000, test=0.785) total time=   1.2s\n",
      "[CV 1/10] END criterion=entropy, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.855) balanced_accuracy: (train=1.000, test=0.738) f1: (train=1.000, test=0.771) total time=   2.2s\n",
      "[CV 2/10] END criterion=entropy, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.864) balanced_accuracy: (train=1.000, test=0.747) f1: (train=1.000, test=0.783) total time=   2.2s\n",
      "[CV 3/10] END criterion=entropy, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.856) balanced_accuracy: (train=1.000, test=0.739) f1: (train=1.000, test=0.772) total time=   2.2s\n",
      "[CV 4/10] END criterion=entropy, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.739) f1: (train=1.000, test=0.774) total time=   2.1s\n",
      "[CV 5/10] END criterion=entropy, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.861) balanced_accuracy: (train=1.000, test=0.745) f1: (train=1.000, test=0.780) total time=   2.2s\n",
      "[CV 6/10] END criterion=entropy, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.740) f1: (train=1.000, test=0.774) total time=   2.1s\n",
      "[CV 7/10] END criterion=entropy, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.742) f1: (train=1.000, test=0.776) total time=   2.2s\n",
      "[CV 8/10] END criterion=entropy, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.743) f1: (train=1.000, test=0.777) total time=   2.2s\n",
      "[CV 9/10] END criterion=entropy, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.748) f1: (train=1.000, test=0.782) total time=   2.2s\n",
      "[CV 10/10] END criterion=entropy, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.863) balanced_accuracy: (train=1.000, test=0.752) f1: (train=1.000, test=0.785) total time=   2.1s\n",
      "[CV 1/10] END criterion=entropy, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.856) balanced_accuracy: (train=1.000, test=0.739) f1: (train=1.000, test=0.772) total time=   2.2s\n",
      "[CV 2/10] END criterion=entropy, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.865) balanced_accuracy: (train=1.000, test=0.748) f1: (train=1.000, test=0.784) total time=   2.1s\n",
      "[CV 3/10] END criterion=entropy, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.856) balanced_accuracy: (train=1.000, test=0.739) f1: (train=1.000, test=0.772) total time=   2.1s\n",
      "[CV 4/10] END criterion=entropy, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.736) f1: (train=1.000, test=0.771) total time=   2.1s\n",
      "[CV 5/10] END criterion=entropy, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.861) balanced_accuracy: (train=1.000, test=0.744) f1: (train=1.000, test=0.779) total time=   2.1s\n",
      "[CV 6/10] END criterion=entropy, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.742) f1: (train=1.000, test=0.776) total time=   2.1s\n",
      "[CV 7/10] END criterion=entropy, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.856) balanced_accuracy: (train=1.000, test=0.740) f1: (train=1.000, test=0.773) total time=   2.1s\n",
      "[CV 8/10] END criterion=entropy, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.860) balanced_accuracy: (train=1.000, test=0.742) f1: (train=1.000, test=0.777) total time=   2.1s\n",
      "[CV 9/10] END criterion=entropy, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.861) balanced_accuracy: (train=1.000, test=0.747) f1: (train=1.000, test=0.781) total time=   2.1s\n",
      "[CV 10/10] END criterion=entropy, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.863) balanced_accuracy: (train=1.000, test=0.753) f1: (train=1.000, test=0.786) total time=   2.1s\n",
      "[CV 1/10] END criterion=entropy, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.740) f1: (train=1.000, test=0.774) total time=   2.1s\n",
      "[CV 2/10] END criterion=entropy, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.864) balanced_accuracy: (train=1.000, test=0.748) f1: (train=1.000, test=0.784) total time=   2.2s\n",
      "[CV 3/10] END criterion=entropy, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.740) f1: (train=1.000, test=0.774) total time=   2.1s\n",
      "[CV 4/10] END criterion=entropy, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.740) f1: (train=1.000, test=0.775) total time=   2.1s\n",
      "[CV 5/10] END criterion=entropy, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.863) balanced_accuracy: (train=1.000, test=0.747) f1: (train=1.000, test=0.782) total time=   2.1s\n",
      "[CV 6/10] END criterion=entropy, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.743) f1: (train=1.000, test=0.777) total time=   2.1s\n",
      "[CV 7/10] END criterion=entropy, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.740) f1: (train=1.000, test=0.773) total time=   2.1s\n",
      "[CV 8/10] END criterion=entropy, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.861) balanced_accuracy: (train=1.000, test=0.743) f1: (train=1.000, test=0.779) total time=   2.0s\n",
      "[CV 9/10] END criterion=entropy, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.748) f1: (train=1.000, test=0.782) total time=   2.0s\n",
      "[CV 10/10] END criterion=entropy, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.752) f1: (train=1.000, test=0.785) total time=   2.0s\n",
      "[CV 1/10] END criterion=entropy, max_features=log2, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.855) balanced_accuracy: (train=1.000, test=0.738) f1: (train=1.000, test=0.771) total time=   1.1s\n",
      "[CV 2/10] END criterion=entropy, max_features=log2, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.863) balanced_accuracy: (train=1.000, test=0.747) f1: (train=1.000, test=0.783) total time=   1.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/10] END criterion=entropy, max_features=log2, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.856) balanced_accuracy: (train=1.000, test=0.739) f1: (train=1.000, test=0.772) total time=   1.1s\n",
      "[CV 4/10] END criterion=entropy, max_features=log2, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.740) f1: (train=1.000, test=0.774) total time=   1.1s\n",
      "[CV 5/10] END criterion=entropy, max_features=log2, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.861) balanced_accuracy: (train=1.000, test=0.745) f1: (train=1.000, test=0.779) total time=   1.1s\n",
      "[CV 6/10] END criterion=entropy, max_features=log2, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.742) f1: (train=1.000, test=0.776) total time=   1.1s\n",
      "[CV 7/10] END criterion=entropy, max_features=log2, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.741) f1: (train=1.000, test=0.775) total time=   1.1s\n",
      "[CV 8/10] END criterion=entropy, max_features=log2, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.742) f1: (train=1.000, test=0.776) total time=   1.1s\n",
      "[CV 9/10] END criterion=entropy, max_features=log2, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.861) balanced_accuracy: (train=1.000, test=0.747) f1: (train=1.000, test=0.781) total time=   1.1s\n",
      "[CV 10/10] END criterion=entropy, max_features=log2, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.753) f1: (train=1.000, test=0.785) total time=   1.1s\n",
      "[CV 1/10] END criterion=entropy, max_features=log2, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.856) balanced_accuracy: (train=1.000, test=0.739) f1: (train=1.000, test=0.772) total time=   1.1s\n",
      "[CV 2/10] END criterion=entropy, max_features=log2, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.865) balanced_accuracy: (train=1.000, test=0.749) f1: (train=1.000, test=0.785) total time=   1.1s\n",
      "[CV 3/10] END criterion=entropy, max_features=log2, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.740) f1: (train=1.000, test=0.774) total time=   1.1s\n",
      "[CV 4/10] END criterion=entropy, max_features=log2, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.738) f1: (train=1.000, test=0.772) total time=   1.2s\n",
      "[CV 5/10] END criterion=entropy, max_features=log2, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.861) balanced_accuracy: (train=1.000, test=0.745) f1: (train=1.000, test=0.780) total time=   1.2s\n",
      "[CV 6/10] END criterion=entropy, max_features=log2, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.742) f1: (train=1.000, test=0.776) total time=   1.1s\n",
      "[CV 7/10] END criterion=entropy, max_features=log2, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.855) balanced_accuracy: (train=1.000, test=0.739) f1: (train=1.000, test=0.771) total time=   1.1s\n",
      "[CV 8/10] END criterion=entropy, max_features=log2, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.741) f1: (train=1.000, test=0.776) total time=   1.1s\n",
      "[CV 9/10] END criterion=entropy, max_features=log2, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.860) balanced_accuracy: (train=1.000, test=0.746) f1: (train=1.000, test=0.779) total time=   1.1s\n",
      "[CV 10/10] END criterion=entropy, max_features=log2, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.753) f1: (train=1.000, test=0.785) total time=   1.3s\n",
      "[CV 1/10] END criterion=entropy, max_features=log2, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.856) balanced_accuracy: (train=1.000, test=0.739) f1: (train=1.000, test=0.773) total time=   1.3s\n",
      "[CV 2/10] END criterion=entropy, max_features=log2, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.864) balanced_accuracy: (train=1.000, test=0.747) f1: (train=1.000, test=0.784) total time=   1.3s\n",
      "[CV 3/10] END criterion=entropy, max_features=log2, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.739) f1: (train=1.000, test=0.773) total time=   1.4s\n",
      "[CV 4/10] END criterion=entropy, max_features=log2, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.740) f1: (train=1.000, test=0.775) total time=   1.3s\n",
      "[CV 5/10] END criterion=entropy, max_features=log2, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.863) balanced_accuracy: (train=1.000, test=0.747) f1: (train=1.000, test=0.783) total time=   1.4s\n",
      "[CV 6/10] END criterion=entropy, max_features=log2, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.742) f1: (train=1.000, test=0.775) total time=   1.3s\n",
      "[CV 7/10] END criterion=entropy, max_features=log2, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.740) f1: (train=1.000, test=0.773) total time=   1.4s\n",
      "[CV 8/10] END criterion=entropy, max_features=log2, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.860) balanced_accuracy: (train=1.000, test=0.743) f1: (train=1.000, test=0.778) total time=   1.2s\n",
      "[CV 9/10] END criterion=entropy, max_features=log2, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.750) f1: (train=1.000, test=0.783) total time=   1.4s\n",
      "[CV 10/10] END criterion=entropy, max_features=log2, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.752) f1: (train=1.000, test=0.785) total time=   1.3s\n",
      "[CV 1/10] END criterion=entropy, max_features=log2, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.855) balanced_accuracy: (train=1.000, test=0.738) f1: (train=1.000, test=0.771) total time=   2.4s\n",
      "[CV 2/10] END criterion=entropy, max_features=log2, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.864) balanced_accuracy: (train=1.000, test=0.747) f1: (train=1.000, test=0.783) total time=   2.2s\n",
      "[CV 3/10] END criterion=entropy, max_features=log2, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.856) balanced_accuracy: (train=1.000, test=0.739) f1: (train=1.000, test=0.772) total time=   2.2s\n",
      "[CV 4/10] END criterion=entropy, max_features=log2, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.739) f1: (train=1.000, test=0.774) total time=   2.2s\n",
      "[CV 5/10] END criterion=entropy, max_features=log2, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.861) balanced_accuracy: (train=1.000, test=0.745) f1: (train=1.000, test=0.780) total time=   2.1s\n",
      "[CV 6/10] END criterion=entropy, max_features=log2, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.740) f1: (train=1.000, test=0.774) total time=   2.2s\n",
      "[CV 7/10] END criterion=entropy, max_features=log2, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.742) f1: (train=1.000, test=0.776) total time=   2.2s\n",
      "[CV 8/10] END criterion=entropy, max_features=log2, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.743) f1: (train=1.000, test=0.777) total time=   2.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 9/10] END criterion=entropy, max_features=log2, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.748) f1: (train=1.000, test=0.782) total time=   2.1s\n",
      "[CV 10/10] END criterion=entropy, max_features=log2, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.863) balanced_accuracy: (train=1.000, test=0.752) f1: (train=1.000, test=0.785) total time=   2.1s\n",
      "[CV 1/10] END criterion=entropy, max_features=log2, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.856) balanced_accuracy: (train=1.000, test=0.739) f1: (train=1.000, test=0.772) total time=   2.2s\n",
      "[CV 2/10] END criterion=entropy, max_features=log2, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.865) balanced_accuracy: (train=1.000, test=0.748) f1: (train=1.000, test=0.784) total time=   2.1s\n",
      "[CV 3/10] END criterion=entropy, max_features=log2, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.856) balanced_accuracy: (train=1.000, test=0.739) f1: (train=1.000, test=0.772) total time=   2.1s\n",
      "[CV 4/10] END criterion=entropy, max_features=log2, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.736) f1: (train=1.000, test=0.771) total time=   2.1s\n",
      "[CV 5/10] END criterion=entropy, max_features=log2, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.861) balanced_accuracy: (train=1.000, test=0.744) f1: (train=1.000, test=0.779) total time=   2.1s\n",
      "[CV 6/10] END criterion=entropy, max_features=log2, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.742) f1: (train=1.000, test=0.776) total time=   2.1s\n",
      "[CV 7/10] END criterion=entropy, max_features=log2, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.856) balanced_accuracy: (train=1.000, test=0.740) f1: (train=1.000, test=0.773) total time=   2.1s\n",
      "[CV 8/10] END criterion=entropy, max_features=log2, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.860) balanced_accuracy: (train=1.000, test=0.742) f1: (train=1.000, test=0.777) total time=   2.1s\n",
      "[CV 9/10] END criterion=entropy, max_features=log2, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.861) balanced_accuracy: (train=1.000, test=0.747) f1: (train=1.000, test=0.781) total time=   2.1s\n",
      "[CV 10/10] END criterion=entropy, max_features=log2, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.863) balanced_accuracy: (train=1.000, test=0.753) f1: (train=1.000, test=0.786) total time=   2.1s\n",
      "[CV 1/10] END criterion=entropy, max_features=log2, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.856) balanced_accuracy: (train=1.000, test=0.739) f1: (train=1.000, test=0.772) total time=   2.1s\n",
      "[CV 2/10] END criterion=entropy, max_features=log2, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.864) balanced_accuracy: (train=1.000, test=0.748) f1: (train=1.000, test=0.784) total time=   2.1s\n",
      "[CV 3/10] END criterion=entropy, max_features=log2, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.856) balanced_accuracy: (train=1.000, test=0.739) f1: (train=1.000, test=0.772) total time=   2.1s\n",
      "[CV 4/10] END criterion=entropy, max_features=log2, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.738) f1: (train=1.000, test=0.773) total time=   2.1s\n",
      "[CV 5/10] END criterion=entropy, max_features=log2, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.746) f1: (train=1.000, test=0.781) total time=   2.1s\n",
      "[CV 6/10] END criterion=entropy, max_features=log2, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.743) f1: (train=1.000, test=0.777) total time=   2.1s\n",
      "[CV 7/10] END criterion=entropy, max_features=log2, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.741) f1: (train=1.000, test=0.775) total time=   2.1s\n",
      "[CV 8/10] END criterion=entropy, max_features=log2, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.860) balanced_accuracy: (train=1.000, test=0.743) f1: (train=1.000, test=0.778) total time=   2.1s\n",
      "[CV 9/10] END criterion=entropy, max_features=log2, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.861) balanced_accuracy: (train=1.000, test=0.748) f1: (train=1.000, test=0.781) total time=   2.1s\n",
      "[CV 10/10] END criterion=entropy, max_features=log2, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.861) balanced_accuracy: (train=1.000, test=0.751) f1: (train=1.000, test=0.783) total time=   2.1s\n",
      "[CV 1/10] END criterion=log_loss, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.855) balanced_accuracy: (train=1.000, test=0.738) f1: (train=1.000, test=0.771) total time=   1.1s\n",
      "[CV 2/10] END criterion=log_loss, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.863) balanced_accuracy: (train=1.000, test=0.747) f1: (train=1.000, test=0.783) total time=   1.1s\n",
      "[CV 3/10] END criterion=log_loss, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.856) balanced_accuracy: (train=1.000, test=0.739) f1: (train=1.000, test=0.772) total time=   1.1s\n",
      "[CV 4/10] END criterion=log_loss, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.740) f1: (train=1.000, test=0.774) total time=   1.1s\n",
      "[CV 5/10] END criterion=log_loss, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.861) balanced_accuracy: (train=1.000, test=0.745) f1: (train=1.000, test=0.779) total time=   1.1s\n",
      "[CV 6/10] END criterion=log_loss, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.742) f1: (train=1.000, test=0.776) total time=   1.1s\n",
      "[CV 7/10] END criterion=log_loss, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.741) f1: (train=1.000, test=0.775) total time=   1.1s\n",
      "[CV 8/10] END criterion=log_loss, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.742) f1: (train=1.000, test=0.776) total time=   1.1s\n",
      "[CV 9/10] END criterion=log_loss, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.861) balanced_accuracy: (train=1.000, test=0.747) f1: (train=1.000, test=0.781) total time=   1.1s\n",
      "[CV 10/10] END criterion=log_loss, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.753) f1: (train=1.000, test=0.785) total time=   1.1s\n",
      "[CV 1/10] END criterion=log_loss, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.856) balanced_accuracy: (train=1.000, test=0.739) f1: (train=1.000, test=0.772) total time=   1.1s\n",
      "[CV 2/10] END criterion=log_loss, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.865) balanced_accuracy: (train=1.000, test=0.749) f1: (train=1.000, test=0.785) total time=   1.1s\n",
      "[CV 3/10] END criterion=log_loss, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.740) f1: (train=1.000, test=0.774) total time=   1.1s\n",
      "[CV 4/10] END criterion=log_loss, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.738) f1: (train=1.000, test=0.772) total time=   1.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/10] END criterion=log_loss, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.861) balanced_accuracy: (train=1.000, test=0.745) f1: (train=1.000, test=0.780) total time=   1.1s\n",
      "[CV 6/10] END criterion=log_loss, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.742) f1: (train=1.000, test=0.776) total time=   1.0s\n",
      "[CV 7/10] END criterion=log_loss, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.855) balanced_accuracy: (train=1.000, test=0.739) f1: (train=1.000, test=0.771) total time=   1.1s\n",
      "[CV 8/10] END criterion=log_loss, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.741) f1: (train=1.000, test=0.776) total time=   1.1s\n",
      "[CV 9/10] END criterion=log_loss, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.860) balanced_accuracy: (train=1.000, test=0.746) f1: (train=1.000, test=0.779) total time=   1.1s\n",
      "[CV 10/10] END criterion=log_loss, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.753) f1: (train=1.000, test=0.785) total time=   1.1s\n",
      "[CV 1/10] END criterion=log_loss, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.856) balanced_accuracy: (train=1.000, test=0.740) f1: (train=1.000, test=0.773) total time=   1.2s\n",
      "[CV 2/10] END criterion=log_loss, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.864) balanced_accuracy: (train=1.000, test=0.749) f1: (train=1.000, test=0.785) total time=   1.1s\n",
      "[CV 3/10] END criterion=log_loss, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.856) balanced_accuracy: (train=1.000, test=0.738) f1: (train=1.000, test=0.772) total time=   1.2s\n",
      "[CV 4/10] END criterion=log_loss, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.856) balanced_accuracy: (train=1.000, test=0.736) f1: (train=1.000, test=0.771) total time=   1.2s\n",
      "[CV 5/10] END criterion=log_loss, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.863) balanced_accuracy: (train=1.000, test=0.747) f1: (train=1.000, test=0.782) total time=   1.2s\n",
      "[CV 6/10] END criterion=log_loss, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.742) f1: (train=1.000, test=0.776) total time=   1.2s\n",
      "[CV 7/10] END criterion=log_loss, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.856) balanced_accuracy: (train=1.000, test=0.739) f1: (train=1.000, test=0.773) total time=   1.2s\n",
      "[CV 8/10] END criterion=log_loss, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.860) balanced_accuracy: (train=1.000, test=0.743) f1: (train=1.000, test=0.778) total time=   1.2s\n",
      "[CV 9/10] END criterion=log_loss, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.861) balanced_accuracy: (train=1.000, test=0.747) f1: (train=1.000, test=0.781) total time=   1.2s\n",
      "[CV 10/10] END criterion=log_loss, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.752) f1: (train=1.000, test=0.785) total time=   1.1s\n",
      "[CV 1/10] END criterion=log_loss, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.855) balanced_accuracy: (train=1.000, test=0.738) f1: (train=1.000, test=0.771) total time=   2.0s\n",
      "[CV 2/10] END criterion=log_loss, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.864) balanced_accuracy: (train=1.000, test=0.747) f1: (train=1.000, test=0.783) total time=   2.2s\n",
      "[CV 3/10] END criterion=log_loss, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.856) balanced_accuracy: (train=1.000, test=0.739) f1: (train=1.000, test=0.772) total time=   2.1s\n",
      "[CV 4/10] END criterion=log_loss, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.739) f1: (train=1.000, test=0.774) total time=   2.1s\n",
      "[CV 5/10] END criterion=log_loss, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.861) balanced_accuracy: (train=1.000, test=0.745) f1: (train=1.000, test=0.780) total time=   2.1s\n",
      "[CV 6/10] END criterion=log_loss, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.740) f1: (train=1.000, test=0.774) total time=   2.1s\n",
      "[CV 7/10] END criterion=log_loss, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.742) f1: (train=1.000, test=0.776) total time=   2.4s\n",
      "[CV 8/10] END criterion=log_loss, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.743) f1: (train=1.000, test=0.777) total time=   2.3s\n",
      "[CV 9/10] END criterion=log_loss, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.748) f1: (train=1.000, test=0.782) total time=   2.4s\n",
      "[CV 10/10] END criterion=log_loss, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.863) balanced_accuracy: (train=1.000, test=0.752) f1: (train=1.000, test=0.785) total time=   2.3s\n",
      "[CV 1/10] END criterion=log_loss, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.856) balanced_accuracy: (train=1.000, test=0.739) f1: (train=1.000, test=0.772) total time=   2.1s\n",
      "[CV 2/10] END criterion=log_loss, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.865) balanced_accuracy: (train=1.000, test=0.748) f1: (train=1.000, test=0.784) total time=   2.2s\n",
      "[CV 3/10] END criterion=log_loss, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.856) balanced_accuracy: (train=1.000, test=0.739) f1: (train=1.000, test=0.772) total time=   2.2s\n",
      "[CV 4/10] END criterion=log_loss, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.736) f1: (train=1.000, test=0.771) total time=   2.2s\n",
      "[CV 5/10] END criterion=log_loss, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.861) balanced_accuracy: (train=1.000, test=0.744) f1: (train=1.000, test=0.779) total time=   2.2s\n",
      "[CV 6/10] END criterion=log_loss, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.742) f1: (train=1.000, test=0.776) total time=   2.2s\n",
      "[CV 7/10] END criterion=log_loss, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.856) balanced_accuracy: (train=1.000, test=0.740) f1: (train=1.000, test=0.773) total time=   2.0s\n",
      "[CV 8/10] END criterion=log_loss, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.860) balanced_accuracy: (train=1.000, test=0.742) f1: (train=1.000, test=0.777) total time=   2.1s\n",
      "[CV 9/10] END criterion=log_loss, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.861) balanced_accuracy: (train=1.000, test=0.747) f1: (train=1.000, test=0.781) total time=   2.1s\n",
      "[CV 10/10] END criterion=log_loss, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.863) balanced_accuracy: (train=1.000, test=0.753) f1: (train=1.000, test=0.786) total time=   2.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/10] END criterion=log_loss, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.856) balanced_accuracy: (train=1.000, test=0.740) f1: (train=1.000, test=0.773) total time=   2.2s\n",
      "[CV 2/10] END criterion=log_loss, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.864) balanced_accuracy: (train=1.000, test=0.747) f1: (train=1.000, test=0.783) total time=   2.3s\n",
      "[CV 3/10] END criterion=log_loss, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.740) f1: (train=1.000, test=0.774) total time=   2.2s\n",
      "[CV 4/10] END criterion=log_loss, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.738) f1: (train=1.000, test=0.772) total time=   2.1s\n",
      "[CV 5/10] END criterion=log_loss, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.747) f1: (train=1.000, test=0.782) total time=   2.1s\n",
      "[CV 6/10] END criterion=log_loss, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.860) balanced_accuracy: (train=1.000, test=0.743) f1: (train=1.000, test=0.778) total time=   2.1s\n",
      "[CV 7/10] END criterion=log_loss, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.742) f1: (train=1.000, test=0.775) total time=   2.1s\n",
      "[CV 8/10] END criterion=log_loss, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.860) balanced_accuracy: (train=1.000, test=0.742) f1: (train=1.000, test=0.777) total time=   2.2s\n",
      "[CV 9/10] END criterion=log_loss, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.748) f1: (train=1.000, test=0.782) total time=   2.2s\n",
      "[CV 10/10] END criterion=log_loss, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.753) f1: (train=1.000, test=0.785) total time=   2.1s\n",
      "[CV 1/10] END criterion=log_loss, max_features=log2, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.855) balanced_accuracy: (train=1.000, test=0.738) f1: (train=1.000, test=0.771) total time=   1.2s\n",
      "[CV 2/10] END criterion=log_loss, max_features=log2, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.863) balanced_accuracy: (train=1.000, test=0.747) f1: (train=1.000, test=0.783) total time=   1.2s\n",
      "[CV 3/10] END criterion=log_loss, max_features=log2, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.856) balanced_accuracy: (train=1.000, test=0.739) f1: (train=1.000, test=0.772) total time=   1.2s\n",
      "[CV 4/10] END criterion=log_loss, max_features=log2, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.740) f1: (train=1.000, test=0.774) total time=   1.1s\n",
      "[CV 5/10] END criterion=log_loss, max_features=log2, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.861) balanced_accuracy: (train=1.000, test=0.745) f1: (train=1.000, test=0.779) total time=   1.2s\n",
      "[CV 6/10] END criterion=log_loss, max_features=log2, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.742) f1: (train=1.000, test=0.776) total time=   1.1s\n",
      "[CV 7/10] END criterion=log_loss, max_features=log2, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.741) f1: (train=1.000, test=0.775) total time=   1.2s\n",
      "[CV 8/10] END criterion=log_loss, max_features=log2, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.742) f1: (train=1.000, test=0.776) total time=   1.2s\n",
      "[CV 9/10] END criterion=log_loss, max_features=log2, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.861) balanced_accuracy: (train=1.000, test=0.747) f1: (train=1.000, test=0.781) total time=   1.2s\n",
      "[CV 10/10] END criterion=log_loss, max_features=log2, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.753) f1: (train=1.000, test=0.785) total time=   1.2s\n",
      "[CV 1/10] END criterion=log_loss, max_features=log2, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.856) balanced_accuracy: (train=1.000, test=0.739) f1: (train=1.000, test=0.772) total time=   1.2s\n",
      "[CV 2/10] END criterion=log_loss, max_features=log2, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.865) balanced_accuracy: (train=1.000, test=0.749) f1: (train=1.000, test=0.785) total time=   1.1s\n",
      "[CV 3/10] END criterion=log_loss, max_features=log2, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.740) f1: (train=1.000, test=0.774) total time=   1.2s\n",
      "[CV 4/10] END criterion=log_loss, max_features=log2, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.738) f1: (train=1.000, test=0.772) total time=   1.1s\n",
      "[CV 5/10] END criterion=log_loss, max_features=log2, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.861) balanced_accuracy: (train=1.000, test=0.745) f1: (train=1.000, test=0.780) total time=   1.2s\n",
      "[CV 6/10] END criterion=log_loss, max_features=log2, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.742) f1: (train=1.000, test=0.776) total time=   1.1s\n",
      "[CV 7/10] END criterion=log_loss, max_features=log2, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.855) balanced_accuracy: (train=1.000, test=0.739) f1: (train=1.000, test=0.771) total time=   1.2s\n",
      "[CV 8/10] END criterion=log_loss, max_features=log2, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.741) f1: (train=1.000, test=0.776) total time=   1.2s\n",
      "[CV 9/10] END criterion=log_loss, max_features=log2, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.860) balanced_accuracy: (train=1.000, test=0.746) f1: (train=1.000, test=0.779) total time=   1.2s\n",
      "[CV 10/10] END criterion=log_loss, max_features=log2, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.753) f1: (train=1.000, test=0.785) total time=   1.2s\n",
      "[CV 1/10] END criterion=log_loss, max_features=log2, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.740) f1: (train=1.000, test=0.773) total time=   1.2s\n",
      "[CV 2/10] END criterion=log_loss, max_features=log2, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.865) balanced_accuracy: (train=1.000, test=0.749) f1: (train=1.000, test=0.785) total time=   1.2s\n",
      "[CV 3/10] END criterion=log_loss, max_features=log2, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.856) balanced_accuracy: (train=1.000, test=0.738) f1: (train=1.000, test=0.771) total time=   1.2s\n",
      "[CV 4/10] END criterion=log_loss, max_features=log2, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.738) f1: (train=1.000, test=0.772) total time=   1.2s\n",
      "[CV 5/10] END criterion=log_loss, max_features=log2, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.746) f1: (train=1.000, test=0.781) total time=   1.2s\n",
      "[CV 6/10] END criterion=log_loss, max_features=log2, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.743) f1: (train=1.000, test=0.777) total time=   1.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 7/10] END criterion=log_loss, max_features=log2, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.742) f1: (train=1.000, test=0.775) total time=   1.2s\n",
      "[CV 8/10] END criterion=log_loss, max_features=log2, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.742) f1: (train=1.000, test=0.777) total time=   1.1s\n",
      "[CV 9/10] END criterion=log_loss, max_features=log2, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.863) balanced_accuracy: (train=1.000, test=0.749) f1: (train=1.000, test=0.784) total time=   1.1s\n",
      "[CV 10/10] END criterion=log_loss, max_features=log2, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.752) f1: (train=1.000, test=0.785) total time=   1.1s\n",
      "[CV 1/10] END criterion=log_loss, max_features=log2, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.855) balanced_accuracy: (train=1.000, test=0.738) f1: (train=1.000, test=0.771) total time=   2.0s\n",
      "[CV 2/10] END criterion=log_loss, max_features=log2, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.864) balanced_accuracy: (train=1.000, test=0.747) f1: (train=1.000, test=0.783) total time=   2.1s\n",
      "[CV 3/10] END criterion=log_loss, max_features=log2, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.856) balanced_accuracy: (train=1.000, test=0.739) f1: (train=1.000, test=0.772) total time=   2.1s\n",
      "[CV 4/10] END criterion=log_loss, max_features=log2, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.739) f1: (train=1.000, test=0.774) total time=   2.1s\n",
      "[CV 5/10] END criterion=log_loss, max_features=log2, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.861) balanced_accuracy: (train=1.000, test=0.745) f1: (train=1.000, test=0.780) total time=   2.1s\n",
      "[CV 6/10] END criterion=log_loss, max_features=log2, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.740) f1: (train=1.000, test=0.774) total time=   2.1s\n",
      "[CV 7/10] END criterion=log_loss, max_features=log2, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.742) f1: (train=1.000, test=0.776) total time=   2.1s\n",
      "[CV 8/10] END criterion=log_loss, max_features=log2, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.743) f1: (train=1.000, test=0.777) total time=   2.1s\n",
      "[CV 9/10] END criterion=log_loss, max_features=log2, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.748) f1: (train=1.000, test=0.782) total time=   2.1s\n",
      "[CV 10/10] END criterion=log_loss, max_features=log2, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.863) balanced_accuracy: (train=1.000, test=0.752) f1: (train=1.000, test=0.785) total time=   2.1s\n",
      "[CV 1/10] END criterion=log_loss, max_features=log2, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.856) balanced_accuracy: (train=1.000, test=0.739) f1: (train=1.000, test=0.772) total time=   2.1s\n",
      "[CV 2/10] END criterion=log_loss, max_features=log2, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.865) balanced_accuracy: (train=1.000, test=0.748) f1: (train=1.000, test=0.784) total time=   2.1s\n",
      "[CV 3/10] END criterion=log_loss, max_features=log2, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.856) balanced_accuracy: (train=1.000, test=0.739) f1: (train=1.000, test=0.772) total time=   2.0s\n",
      "[CV 4/10] END criterion=log_loss, max_features=log2, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.736) f1: (train=1.000, test=0.771) total time=   2.1s\n",
      "[CV 5/10] END criterion=log_loss, max_features=log2, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.861) balanced_accuracy: (train=1.000, test=0.744) f1: (train=1.000, test=0.779) total time=   2.1s\n",
      "[CV 6/10] END criterion=log_loss, max_features=log2, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.742) f1: (train=1.000, test=0.776) total time=   2.1s\n",
      "[CV 7/10] END criterion=log_loss, max_features=log2, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.856) balanced_accuracy: (train=1.000, test=0.740) f1: (train=1.000, test=0.773) total time=   2.0s\n",
      "[CV 8/10] END criterion=log_loss, max_features=log2, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.860) balanced_accuracy: (train=1.000, test=0.742) f1: (train=1.000, test=0.777) total time=   2.1s\n",
      "[CV 9/10] END criterion=log_loss, max_features=log2, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.861) balanced_accuracy: (train=1.000, test=0.747) f1: (train=1.000, test=0.781) total time=   1.9s\n",
      "[CV 10/10] END criterion=log_loss, max_features=log2, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.863) balanced_accuracy: (train=1.000, test=0.753) f1: (train=1.000, test=0.786) total time=   2.1s\n",
      "[CV 1/10] END criterion=log_loss, max_features=log2, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.856) balanced_accuracy: (train=1.000, test=0.739) f1: (train=1.000, test=0.772) total time=   2.1s\n",
      "[CV 2/10] END criterion=log_loss, max_features=log2, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.864) balanced_accuracy: (train=1.000, test=0.748) f1: (train=1.000, test=0.784) total time=   2.1s\n",
      "[CV 3/10] END criterion=log_loss, max_features=log2, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.856) balanced_accuracy: (train=1.000, test=0.738) f1: (train=1.000, test=0.772) total time=   2.1s\n",
      "[CV 4/10] END criterion=log_loss, max_features=log2, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.740) f1: (train=1.000, test=0.775) total time=   2.2s\n",
      "[CV 5/10] END criterion=log_loss, max_features=log2, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.745) f1: (train=1.000, test=0.780) total time=   2.4s\n",
      "[CV 6/10] END criterion=log_loss, max_features=log2, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.742) f1: (train=1.000, test=0.776) total time=   2.2s\n",
      "[CV 7/10] END criterion=log_loss, max_features=log2, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.741) f1: (train=1.000, test=0.775) total time=   2.4s\n",
      "[CV 8/10] END criterion=log_loss, max_features=log2, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.861) balanced_accuracy: (train=1.000, test=0.744) f1: (train=1.000, test=0.779) total time=   2.1s\n",
      "[CV 9/10] END criterion=log_loss, max_features=log2, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.863) balanced_accuracy: (train=1.000, test=0.749) f1: (train=1.000, test=0.783) total time=   2.2s\n",
      "[CV 10/10] END criterion=log_loss, max_features=log2, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.751) f1: (train=1.000, test=0.784) total time=   2.2s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=StratifiedKFold(n_splits=10, random_state=None, shuffle=False),\n",
       "             estimator=ExtraTreesClassifier(n_estimators=150, n_jobs=-1,\n",
       "                                            random_state=30),\n",
       "             param_grid={&#x27;criterion&#x27;: [&#x27;gini&#x27;, &#x27;entropy&#x27;, &#x27;log_loss&#x27;],\n",
       "                         &#x27;max_features&#x27;: [&#x27;sqrt&#x27;, &#x27;log2&#x27;],\n",
       "                         &#x27;n_estimators&#x27;: [100, 200], &#x27;n_jobs&#x27;: [-1],\n",
       "                         &#x27;random_state&#x27;: [50, 100, None]},\n",
       "             refit=&#x27;balanced_accuracy&#x27;, return_train_score=True,\n",
       "             scoring={&#x27;accuracy&#x27;: &#x27;accuracy&#x27;,\n",
       "                      &#x27;balanced_accuracy&#x27;: &#x27;balanced_accuracy&#x27;,\n",
       "                      &#x27;f1&#x27;: &#x27;f1_macro&#x27;},\n",
       "             verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=StratifiedKFold(n_splits=10, random_state=None, shuffle=False),\n",
       "             estimator=ExtraTreesClassifier(n_estimators=150, n_jobs=-1,\n",
       "                                            random_state=30),\n",
       "             param_grid={&#x27;criterion&#x27;: [&#x27;gini&#x27;, &#x27;entropy&#x27;, &#x27;log_loss&#x27;],\n",
       "                         &#x27;max_features&#x27;: [&#x27;sqrt&#x27;, &#x27;log2&#x27;],\n",
       "                         &#x27;n_estimators&#x27;: [100, 200], &#x27;n_jobs&#x27;: [-1],\n",
       "                         &#x27;random_state&#x27;: [50, 100, None]},\n",
       "             refit=&#x27;balanced_accuracy&#x27;, return_train_score=True,\n",
       "             scoring={&#x27;accuracy&#x27;: &#x27;accuracy&#x27;,\n",
       "                      &#x27;balanced_accuracy&#x27;: &#x27;balanced_accuracy&#x27;,\n",
       "                      &#x27;f1&#x27;: &#x27;f1_macro&#x27;},\n",
       "             verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: ExtraTreesClassifier</label><div class=\"sk-toggleable__content\"><pre>ExtraTreesClassifier(n_estimators=150, n_jobs=-1, random_state=30)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ExtraTreesClassifier</label><div class=\"sk-toggleable__content\"><pre>ExtraTreesClassifier(n_estimators=150, n_jobs=-1, random_state=30)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=10, random_state=None, shuffle=False),\n",
       "             estimator=ExtraTreesClassifier(n_estimators=150, n_jobs=-1,\n",
       "                                            random_state=30),\n",
       "             param_grid={'criterion': ['gini', 'entropy', 'log_loss'],\n",
       "                         'max_features': ['sqrt', 'log2'],\n",
       "                         'n_estimators': [100, 200], 'n_jobs': [-1],\n",
       "                         'random_state': [50, 100, None]},\n",
       "             refit='balanced_accuracy', return_train_score=True,\n",
       "             scoring={'accuracy': 'accuracy',\n",
       "                      'balanced_accuracy': 'balanced_accuracy',\n",
       "                      'f1': 'f1_macro'},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extra = ExtraTreesClassifier( n_jobs=-1, n_estimators=150, random_state=30)\n",
    "\n",
    "# Create the parameter grids\n",
    "parameter_grid = {\n",
    "    \"n_estimators\": [100, 200],\n",
    "    \"criterion\": ['gini', 'entropy', 'log_loss'],\n",
    "    \"max_features\": ['sqrt', 'log2'],\n",
    "    \"n_jobs\":[-1],\n",
    "   # \"bootstrap\":[True,False],\n",
    "    \"random_state\": [ 50, 100, None],\n",
    "   # \"warm_start\": [True, False],\n",
    "    \n",
    "}\n",
    "\n",
    "# Create Stratified folds\n",
    "# primi tentativi n_splits = 5 per limitare i tempi di esecuzione della gridSearch poi aumentato\n",
    "cross_validation = StratifiedKFold(n_splits=10)\n",
    "cross_validation.get_n_splits(train_data, np.ravel(y_train))\n",
    "\n",
    "# Create the scoring dictionary\n",
    "SCORING = {\n",
    "    \"accuracy\": \"accuracy\",\n",
    "    \"balanced_accuracy\": \"balanced_accuracy\",\n",
    "    \"f1\": \"f1_macro\",\n",
    "}\n",
    "\n",
    "# Create and fit the GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=extra,\n",
    "    param_grid=parameter_grid,\n",
    "    cv=cross_validation,\n",
    "    verbose=3,\n",
    "    scoring=SCORING,\n",
    "    return_train_score=True,\n",
    "    refit=\"balanced_accuracy\",\n",
    ")\n",
    "\n",
    "grid_search.fit(train_data, np.ravel(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e5c00f24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.7443125339355887\n",
      "Best parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 100, 'n_jobs': -1, 'random_state': 50}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>ExtraTreesClassifier(n_jobs=-1, random_state=50)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" checked><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ExtraTreesClassifier</label><div class=\"sk-toggleable__content\"><pre>ExtraTreesClassifier(n_jobs=-1, random_state=50)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "ExtraTreesClassifier(n_jobs=-1, random_state=50)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Best score: {}\".format(grid_search.best_score_))\n",
    "print(\"Best parameters: {}\".format(grid_search.best_params_))\n",
    "\n",
    "best_dtc = grid_search.best_estimator_\n",
    "best_dtc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "19c3a08d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.858244570480011"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model = best_dtc\n",
    "my_model.fit(train_data, np.ravel(y_train))\n",
    "my_model.score(test_data, np.ravel(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e54eb0a",
   "metadata": {},
   "source": [
    "Risultato accuracy su testSet in base all'algoritmo utilizzato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b9e27e5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3UAAAIoCAYAAADOacK9AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAACWQUlEQVR4nOzdd1xW5f/H8dcNMgTFQS5caGlqiloZjtJIERcqFu4yR6mZOytzp+Uoc5RlqSlmopWC2684KjNXlpllaZa5TXGgoMg4vz/OzzsJMETw3MD7+Xjw6NznPuNzbvDEm+s612UzDMNAREREREREciQnqwsQERERERGRzFOoExERERERycEU6kRERERERHIwhToREREREZEcTKFOREREREQkB1OoExERERERycEU6kRERERERHIwhToREREREZEcTKFOREREREQkB1OoE5Ec46effsJms+Hi4sKpU6esLkdu8u233zJ27FguXryYred5//33WbBgQZrvHTt2jBdeeIHKlSuTP39+ihYtSo0aNXjuuec4duzYbZ/rl19+YezYsRw5cuTOiv6XI0eOYLPZ0r0OgBkzZmCz2Vi/fn2628yZMwebzcby5cuzpC5fX1+effbZLDlWdrPZbIwdO/a290vrs1+wYAE2my3Lvs8Z+f5mt39/L0+ePMnYsWPZu3evZTWJSPZSqBORHGPu3LkAJCYmsnDhQourkZt9++23jBs3zrJQd/z4cR588EGioqIYMmQIa9eu5eOPP6ZTp07s3r2bP/7447bP9csvvzBu3LgsD3UZ0bVrV9zc3Pj444/T3Wb+/PkUK1aM4ODgLDlnREQEo0aNypJjibX+/b08efIk48aNU6gTycXyWV2AiEhGxMfH8+mnn1KzZk3OnTvHxx9/zCuvvGJ1WWm6evUq7u7u2Gw2q0vJM+bMmcO5c+fYtWsXFSpUsK9v27Ytr732GsnJyRZWd/u8vb1p06YNkZGRREdH4+3tneL9X3/9le3btzN06FBcXFzu6FxXr14lf/781K5d+46OczPDMLh27Rr58+fPsmPKf8uO76WI5AxqqRORHOHGL7e9evWiW7duHDx4kG+++SbVdvHx8bz++utUrVoVd3d3vL29CQgI4Ntvv7Vvk5yczLvvvkutWrXInz8/hQsXpm7duqxcudK+TXrdu/7drelG160NGzbQo0cPihUrhoeHB/Hx8fz+++90796dSpUq4eHhQenSpQkODuann35KddyLFy8ydOhQKlasiJubG8WLF6dFixb8+uuvGIZBpUqVCAoKSrXflStXKFSoEP369bvl5/f555/j7+9PoUKF8PDwoGLFivTo0SPVdfy7VerLL7/EZrPx5ZdfpnvssWPHMmzYMAAqVKiAzWZLtc/SpUupV68enp6eFChQgKCgIH744YcUx/njjz/o2LEjPj4+uLm5UaJECRo3bmxvXfD19eXnn3/mq6++sp/D19cXgOjoaJycnChevHiaNTo5pfzf3XfffUfr1q0pWrQo7u7u1K5dm88++yzF5xEaGgpAQECA/Xy36lJ3O9/vjOjZsyfXr19n8eLFqd6bP38+gP17OG7cOPz9/SlatCheXl48+OCDzJs3D8MwUuzn6+tLq1atWL58ObVr18bd3Z1x48bZ37v5Z/vatWsMHTqUWrVqUahQIYoWLUq9evVYsWJFqnpsNhsvvvgis2fPpmrVqri5uREWFgbAoUOH6Ny5M8WLF8fNzY2qVasya9asDH0GMTExPPfcc3h7e1OgQAGaNWvGwYMH09z2Ts6TEXf6/V2xYgV+fn64ublRsWJFZsyYwdixY1P98efatWsMHz6cChUq4OrqSunSpenXr1+qVvCMfi+//PJL6tSpA0D37t3tP8s37m/PPvssBQoU4NdffyUoKAhPT09KlSrFpEmTANixYwePPvoonp6eVK5c2f59vdn+/ftp06YNRYoUwd3dnVq1aqW5nYhkH7XUiUiOMG/ePNzc3OjSpQvnz59n4sSJzJs3j0cffdS+TWJiIs2bN2fr1q0MGjSIJ554gsTERHbs2MHRo0epX78+YP4Ss2jRInr27Mnrr7+Oq6sr33///R11s+vRowctW7bkk08+ITY2FhcXF06ePIm3tzeTJk2iWLFinD9/nrCwMPz9/fnhhx+4//77Abh8+TKPPvooR44c4ZVXXsHf358rV67w9ddfc+rUKapUqUL//v0ZNGgQhw4dolKlSvbzLly4kJiYmFuGuu3bt9OhQwc6dOjA2LFjcXd356+//mLz5s2Zvt6b9erVi/Pnz/Puu++yfPlySpUqBUC1atUAePPNNxk5ciTdu3dn5MiRXL9+nbfeeovHHnuMXbt22bdr0aIFSUlJTJkyhXLlynHu3Dm+/fZb+y+zERERPPXUUxQqVIj3338fADc3NwDq1avHrFmzaNeuHUOGDKFevXp4eXmlWe+WLVto1qwZ/v7+zJ49m0KFCrFkyRI6dOhAXFwczz77LC1btuTNN9/ktddeY9asWTz44IMA3Hvvvel+Dhn9fmdUkyZNKF++PB9//DH9+/e3r09KSuKTTz6hbt269s/uyJEj9O7dm3LlygHmL+L9+/fnxIkTjB49OsVxv//+ew4cOMDIkSOpUKECnp6eaZ4/Pj6e8+fP89JLL1G6dGmuX7/Oxo0badeuHfPnz+eZZ55JsX1kZCRbt25l9OjRlCxZkuLFi/PLL79Qv359ypUrx9SpUylZsiT/+9//GDBgAOfOnWPMmDHpXr9hGLRt25Zvv/2W0aNHU6dOHbZt20bz5s1TbXsn58moO/n+rl+/nnbt2tGwYUOWLl1KYmIib7/9NmfOnEnzmjdt2sTw4cN57LHH2LdvH2PGjGH79u1s377d/jMPGftePvjgg8yfP9/+769ly5YAlClTxr5NQkIC7dq1o0+fPgwbNozFixczfPhwYmJiWLZsGa+88gplypTh3Xff5dlnn6V69eo89NBDAPz222/Ur1+f4sWLM3PmTLy9vVm0aBHPPvssZ86c4eWXX76jz11EMsgQEXFwR44cMZycnIyOHTva1zVq1Mjw9PQ0YmJi7OsWLlxoAMacOXPSPdbXX39tAMaIESNueU7AGDNmTKr15cuXN7p162Z/PX/+fAMwnnnmmf+8jsTEROP69etGpUqVjMGDB9vXv/766wZgREVFpbtvTEyMUbBgQWPgwIEp1lerVs0ICAi45XnffvttAzAuXryY7jY3ruPPP/9MsX7Lli0GYGzZsuWW53jrrbfS3P/o0aNGvnz5jP79+6dYf/nyZaNkyZJG+/btDcMwjHPnzhmAMX369Fue54EHHjAaNWqUan1ycrLRu3dvw8nJyQAMm81mVK1a1Rg8eHCqmqpUqWLUrl3bSEhISLG+VatWRqlSpYykpCTDMAzj888/z9C1pye97/eff/5pAMb8+fP/8xhjxowxAOP777+3r1u1atUtf86TkpKMhIQE4/XXXze8vb2N5ORk+3vly5c3nJ2djd9++y3Vfv/+2U7rehISEoyePXsatWvXTvEeYBQqVMg4f/58ivVBQUFGmTJljEuXLqVY/+KLLxru7u6ptr/ZunXrDMCYMWNGivVvvPFGqn+fGT1PWp99ej/7/+V2vr916tQxypYta8THx9vXXb582fD29jZu/lVs/fr1BmBMmTIlxbmWLl1qAMZHH31kX3c738vdu3en+zPXrVs3AzCWLVtmX5eQkGAUK1Ys1c9edHS04ezsbAwZMsS+rmPHjoabm5tx9OjRFMdt3ry54eHhccv7johkHXW/FBGHN3/+fJKTk1N0F+zRowexsbEsXbrUvm7dunW4u7un2O7f1q1bB/Cf3RVv15NPPplqXWJiIm+++SbVqlXD1dWVfPny4erqyqFDhzhw4ECKmipXrkyTJk3SPX7BggXp3r07CxYsIDY2FoDNmzfzyy+/8OKLL96ythtdr9q3b89nn33GiRMnMnOJmfK///2PxMREnnnmGRITE+1f7u7uNGrUyN5Fs2jRotx777289dZbvPPOO/zwww+39RyczWZj9uzZ/PHHH7z//vt0796dhIQEpk2bxgMPPMBXX30FmF3ofv31V7p06QKQoqYWLVpw6tQpfvvtt0xda0a/37eje/fuODk5pRgwZf78+Xh6etKhQwf7us2bN9OkSRMKFSqEs7MzLi4ujB49mujoaP7+++8Ux/Tz86Ny5coZOv/nn39OgwYNKFCgAPny5cPFxYV58+aleT1PPPEERYoUsb++du0amzZtIiQkBA8Pj1Sf9bVr19ixY0e6596yZQuA/Xt1Q+fOnVO8vtPzZFRmv7+xsbF89913tG3bFldXV/v6AgUKpBrk5kbr+b9HIQ0NDcXT05NNmzalWH8738tbsdlstGjRwv46X7583HfffZQqVSrF83lFixalePHi/PXXXylqbty4MWXLlk1xzGeffZa4uDi2b99+x/WJyH9TqBMRh5acnMyCBQvw8fHhoYce4uLFi1y8eJEmTZrg6enJvHnz7NuePXsWHx+fVM9P3ezs2bM4OztTsmTJLK3zRpfDmw0ZMoRRo0bRtm1bVq1axc6dO9m9ezc1a9bk6tWrKWq6uStUevr378/ly5f59NNPAXjvvfcoU6YMbdq0ueV+DRs2JDIy0h6uypQpQ/Xq1QkPD7/Nq7x9N7qX1alTBxcXlxRfS5cu5dy5c4D5S+WmTZsICgpiypQpPPjggxQrVowBAwZw+fLlDJ+vfPny9O3bl3nz5nHo0CGWLl3KtWvX7M/83ajnpZdeSlXPCy+8AGCv6XZl9Pt9O8qXL0/jxo1ZvHgx8fHxnDt3jtWrVxMaGkrBggUB2LVrF02bNgXMAWO2bdvG7t27GTFiBECqc6f1s5qW5cuX0759e0qXLs2iRYvYvn07u3fvpkePHly7di3V9v8+bnR0NImJibz77rupPusbAeJWn3V0dDT58uVLNUjMv//t3ul5Miqz398LFy5gGAYlSpRI9d6/19245mLFiqVYb7PZKFmyJNHR0SnWZ/R7+V88PDxwd3dPsc7V1ZWiRYum2tbV1TXF9z86OjrNOnx8fOzvi0j20zN1IuLQNm7caP+r8L9/uQPz2aFffvmFatWqUaxYMb755huSk5PTDXbFihUjKSmJ06dP3/IXIjc3N+Lj41OtT+8XlLRGuly0aBHPPPMMb775Zor1586do3DhwilqOn78eLq13HDffffRvHlzZs2aRfPmzVm5ciXjxo3D2dn5P/dt06YNbdq0IT4+nh07djBx4kQ6d+6Mr68v9erVs/9C9+9rvtNfhu+55x4AvvjiC8qXL3/LbcuXL28P6QcPHuSzzz5j7NixXL9+ndmzZ2fq/O3bt2fixIns378/RT3Dhw+nXbt2ae5zu8++3ZDR7/ft6tmzJ1FRUaxYsYKTJ09y/fp1evbsaX9/yZIluLi4sHr16hS/mEdGRqZ5vIyOyrpo0SIqVKjA0qVLU+yT1r+LtI5bpEgRnJ2defrpp9NtGb95pNJ/8/b2JjExMdXon6dPn87S82RUZr+/RYoUwWazpXp+DlJfy41rPnv2bIpgZxgGp0+ftre63+AII+x6e3unOW/oyZMngX/+zYlI9lJLnYg4tHnz5uHk5ERkZCRbtmxJ8fXJJ58A2LumNW/enGvXrt1yhMIbgyx88MEHtzyvr68v+/btS7Fu8+bNXLlyJcO122y2FIMaAKxZsyZV98fmzZtz8ODBDA1cMnDgQPbt20e3bt1wdnbmueeey3A9YIbVRo0aMXnyZAD7CJQ3RpH89zXfPCLofx0XUrcKBQUFkS9fPg4fPszDDz+c5ldaKleuzMiRI6lRowbff/99ivOk1SqS3mT0V65c4dixY/ZWg/vvv59KlSrx448/plvPjRaw9K4pPRn9ft+utm3b4u3tzccff8z8+fOpXLlyigGCbDYb+fLlSxHur169av/3kVk2mw1XV9cUweH06dNpjn6ZFg8PDwICAvjhhx/w8/NL87NO6w81NwQEBADYW6Zv+PdooHd6nozK7PfX09OThx9+mMjISK5fv25ff+XKFVavXp1i28aNGwNmgLzZsmXLiI2Ntb9/u273Z/l2NG7cmM2bN9tD3A0LFy7Ew8ODunXrZvk5RSQ1tdSJiMOKjo5mxYoVBAUFpdvFcNq0aSxcuJCJEyfSqVMn5s+fT58+ffjtt98ICAggOTmZnTt3UrVqVTp27Mhjjz3G008/zYQJEzhz5gytWrXCzc2NH374AQ8PD/sog08//TSjRo1i9OjRNGrUiF9++YX33nuPQoUKZbj+Vq1asWDBAqpUqYKfnx979uzhrbfeStXVctCgQSxdupQ2bdrw6quv8sgjj3D16lW++uorWrVqZf/lFiAwMJBq1aqxZcsWunbtmu4Q/jcbPXo0x48fp3HjxpQpU4aLFy8yY8YMXFxcaNSoEWB2j7z//vt56aWXSExMpEiRIkRERKQ5bURaatSoAcCMGTPo1q0bLi4u3H///fj6+vL6668zYsQI/vjjD5o1a0aRIkU4c+YMu3btwtPTk3HjxrFv3z5efPFFQkNDqVSpEq6urmzevJl9+/bx6quvpjjPkiVLWLp0KRUrVsTd3Z0aNWrwxhtvsG3bNjp06GCfquLPP//kvffeIzo6mrfeest+jA8//JDmzZsTFBTEs88+S+nSpTl//jwHDhzg+++/5/PPPwegevXqAHz00UcULFgQd3d3KlSokG5AyOj3+3bdGPX13XffxTAM+1DzN7Rs2ZJ33nmHzp078/zzzxMdHc3bb7+dKoDcrhvD5b/wwgs89dRTHDt2jPHjx1OqVCkOHTqUoWPMmDGDRx99lMcee4y+ffvi6+vL5cuX+f3331m1atUt/5DRtGlTGjZsyMsvv0xsbCwPP/ww27ZtSzOs3sl5MupOvr+vv/46LVu2JCgoiIEDB5KUlMRbb71FgQIFOH/+vH27wMBAgoKCeOWVV4iJiaFBgwb20S9r167N008/nana7733XvLnz8+nn35K1apVKVCgAD4+PvY/dtyJMWPGsHr1agICAhg9ejRFixbl008/Zc2aNUyZMuW27pkicgcsHqhFRCRd06dPNwAjMjIy3W1mz56dYuS2q1evGqNHjzYqVapkuLq6Gt7e3sYTTzxhfPvtt/Z9kpKSjGnTphnVq1c3XF1djUKFChn16tUzVq1aZd8mPj7eePnll42yZcsa+fPnNxo1amTs3bs33dEvd+/enaq2CxcuGD179jSKFy9ueHh4GI8++qixdetWo1GjRqlGcLxw4YIxcOBAo1y5coaLi4tRvHhxo2XLlsavv/6a6rhjx441AGPHjh0Z+hxXr15tNG/e3ChdurTh6upqFC9e3GjRooWxdevWFNsdPHjQaNq0qeHl5WUUK1bM6N+/v7FmzZoMjwA5fPhww8fHxz4C5c37REZGGgEBAYaXl5fh5uZmlC9f3njqqaeMjRs3GoZhGGfOnDGeffZZo0qVKoanp6dRoEABw8/Pz5g2bZqRmJhoP86RI0eMpk2bGgULFjQAo3z58oZhGMaOHTuMfv36GTVr1jSKFi1qODs7G8WKFTOaNWtmrF27NlWtP/74o9G+fXujePHihouLi1GyZEnjiSeeMGbPnp1iu+nTpxsVKlQwnJ2d/3PEyox+v29n9Mub6wUMZ2dn4+TJk6ne//jjj43777/fcHNzMypWrGhMnDjRmDdvXqpRHcuXL2+0bNkyzXOkNfrlpEmTDF9fX8PNzc2oWrWqMWfOHPuInDcDjH79+qV53D///NPo0aOHUbp0acPFxcUoVqyYUb9+fWPChAn/ed0XL140evToYRQuXNjw8PAwAgMDjV9//TXN0Wkzcp47Gf3yTr+/ERERRo0aNQxXV1ejXLlyxqRJk4wBAwYYRYoUSbHd1atXjVdeecUoX7684eLiYpQqVcro27evceHChRTb3e73Mjw83KhSpYrh4uKS4vPr1q2b4enpmeoYjRo1Mh544IE0j/3v8/70009GcHCwUahQIcPV1dWoWbPmbf18i8idsxnGv2YmFRERh/bwww9js9nYvXu31aWISCYlJCRQq1YtSpcuzYYNG6wuR0RyOHW/FBHJAWJiYti/fz+rV69mz549REREWF2SiNyGnj17EhgYSKlSpTh9+jSzZ8/mwIEDzJgxw+rSRCQXUKgTEckBvv/+ewICAvD29mbMmDG0bdvW6pJE5DZcvnyZl156ibNnz+Li4sKDDz7I2rVrbzk/pYhIRqn7pYiIiIiISA6mKQ1ERERERERyMIcMdVeuXGHQoEH4+Pjg7u5OrVq1WLJkSYb23bJlC4GBgRQvXpwCBQrg5+fHzJkzSUpKsm9z5MgRbDZbul/NmjVLccyEhATGjRuHr68vbm5uVKlShXfffTdLr1lERERERCQzHPKZunbt2rF7924mTZpE5cqVWbx4MZ06dSI5OZnOnTunu9/GjRsJCgqiYcOGzJkzB09PT1auXMnAgQM5fPiw/WHkUqVKsX379lT7R0ZGMnnyZEJCQlKsf+GFF/jkk08YP348derU4X//+x8DBw7k8uXLvPbaa1l78SIiIiIiIrfB4Z6pW7t2LS1btrQHuRuaNm3Kzz//zNGjR3F2dk5z365du/LFF18QHR2Np6enfX1QUBA7duzg0qVLtzx3QEAAu3bt4tSpU3h5eQHw888/2ye2HT58uH3b559/nkWLFnH8+HGKFi2aoWtLTk7m5MmTFCxYEJvNlqF9REREREQk9zEMg8uXL+Pj44OT0x12oLRwjrw09erVyyhQoICRkJCQYv3ixYsNwNi2bVu6+z777LNGwYIFjaSkpBTrb0wweyu///67YbPZjGeffTbF+gkTJhiAcerUqRTrv/32WwMwPv3004xclmEYhnHs2DED0Je+9KUvfelLX/rSl770pS8DMI4dO5bhPJEeh+t+uX//fqpWrUq+fClL8/Pzs79fv379NPft06cP4eHhDBgwgNdeew0PDw9WrVpFREQEEydOvOV5P/74YwzDoFevXqnqKVasGCVLlky3nvTEx8cTHx9vf238f6Pon3/+ScGCBW9ZT3ZLSEhgy5YtBAQE4OLiYmktIiJ5je7BIiLWcKT77+XLl6lQoUKW5AKHC3XR0dFUrFgx1fobXRyjo6PT3dff35/NmzcTGhrKrFmzAHB2dmbixIkMHTo03f2SkpIICwujSpUqNGjQIFU9aXWv9PT0xNXV9Zb1TJw4kXHjxqVav337djw8PNLd727x8PBg586dVpchIpIn6R4sImINR7n/xsXFAWTJY1kOF+rg1hd2q/f27NlDSEgI/v7+fPjhh3h6erJ582ZGjhzJtWvXGDVqVJr7rV+/nhMnTvDWW29laT3Dhw9nyJAh9tcxMTGULVuWpk2b2p/Zs0pCQgJRUVEEBgZa/lcKEZG8RvdgERFrONL9NyYmJsuO5XChztvbO83Wr/PnzwPcclCSfv36UaJECSIiIuyDqQQEBODk5MTYsWPp0qVLmq2A8+bNw8XFhWeeeSbNevbu3ZtqfWxsLNevX79lPW5ubri5uaVa7+LiYvkP0Q2OVIuISF6je7CIiDUc4f6bled3uHnqatSowYEDB0hMTEyx/qeffgKgevXq6e67d+9eHnrooVSjY9apU4fk5GQOHDiQap+///6b1atX07p1a4oXL55mPWfPnuX06dO3XY+IiIiIiEh2c7hQFxISwpUrV1i2bFmK9WFhYfj4+ODv75/uvj4+Pnz33XcpJhoH7HPSlSlTJtU+CxcuJCEhgZ49e6Z5zDZt2mCz2QgLC0uxfsGCBeTPnz/VROUiIiIiIiJ3k8N1v2zevDmBgYH07duXmJgY7rvvPsLDw1m/fj2LFi2yt8L17NmTsLAwDh8+TPny5QEYPHgwAwYMIDg4mN69e+Ph4cGmTZuYOnUqTZo0oWbNmqnON2/ePMqWLUtQUFCa9TzwwAP07NmTMWPG4OzsTJ06ddiwYQMfffQREyZMyPAcdSIiIiIiItnB4UIdwPLlyxkxYgSjR4/m/PnzVKlShfDwcDp27GjfJikpiaSkJPs0AQD9+/endOnSTJs2jV69enH16lV8fX0ZM2YMgwcPTnWeb7/9ll9//ZXRo0ffcsK/999/n9KlS/Puu+9y+vRpfH19mTFjBv3798/aCxcREREREblNNuPmVCTZKiYmhkKFCnHp0iWHGP1y7dq1tGjRwvKHREVE8hrdg0VErOFI99+szAYO90ydiIiIiIiIZJxCnYiIiIiISA6mUCciIiIiIpKDKdSJiIiIiIjkYAp1IiIiIiIiOZhCnYiIiIiISA6mUCciInI3JSVh++orSn/9NbavvoKkJKsrEhGRHE6hTkRE5G5Zvhx8fckXGMjD77xDvsBA8PU114uIiGSSQp2IiMjdsHw5PPUUHD+ecv2JE+Z6BTsREckkhToREZHsYhgQEwMHDkCfPubrtLYBGDRIXTFFRCRT8lldgIiISI6TkAB//w2nT5tfp06lvXz6NMTF/ffxDAOOHYOtW+Hxx7O9fBERyV0U6kREROCfVrX0AtrNy+fOpd3qlh43N4iP/+/tTp3KfP0iIpJnKdSJiEjudv262ap2q9a0G6+vXcv4cZ2coEQJKFUKSpY0v25evvG6RAn47jsICPjvY5YqlfnrFBGRPEuhTkREch7DgIsX/7tF7dQpiI6+vWN7eaUd0v697O0Nzs4ZO+Zjj0GZMuagKOm18JUta24nIiJymxTqRETEcVy/nnYLWlqtaxnpznhDvnxmi9l/hbWSJcHDI+uvy9kZZswwR7m02dIOds89l/GQKCIichOFOhERyV6GARcuZKz74/nzt3fsQoVu3Zp2Y9nb2+wuaaV27eCLL2DgwJTTGnh4mIOpTJ8OnTrBffdZVqKIiORMCnUiIpI5167BmTPpB7SblxMSMn7cfPn+uzXtxrNq+fNn3/Vlh3btoE0bErdsYe+6ddRq3px8detC48awaxcEB8P27VC4sNWViohIDqJQJyIi/0hONlvLMvKs2sWLt3fsIkXSD2g3LxcpYn2rWnZydsZo1IgTsbHUbNQIXFwgMhIeeQR+/RU6dIA1a8xwKyIikgH6P4aISF5w9WrGnlU7c+b2WtVcXW8d0G5+z80t+64vpytVClatggYNYMMGcyLy996zuioREckhFOpERHKq5GRzZMeMdH+8dOn2jl20aMaeVStSxBz4Q+5crVrw6admF81Zs6BqVejXz+qqREQkB1CoExFxNHFxGev+eOYMJCVl/Lhubv89TH/JklC8uFrVrNK2LUycCK++ag6oUqkSNG1qdVUiIuLgFOpERO6GpCQ4dy5jYe3y5ds79j33ZOxZtUKF1KqWE7z8Mhw4AGFh0L497NgBVapYXZWIiDgwhToRkTsRG3vrgHZj+e+/b69Vzd09Y90fS5QwB9qQ3MNmgw8/hMOH4ZtvoFUr2LnTnJZBREQkDQp1IiL/lpQEZ89mbF61K1cyflybDYoVy9jAIl5ealXLy9zcYPly8Pc3w92TT5oDqLi6Wl2ZiIg4IIU6Eck7Ll/OWPfHs2fNQUgyKn9+M5D9V8tasWJqVZOMK1bMHBGzfn346it44QWYM0dhX0REUlGoE5GcLTHR7Nr4X2Ht9Gmzq2RG2WzmgCEZGVikQAH9oi3Z44EHYMkSswvmvHnmiJhDh1pdlYiIOBiFOhFxPIZhtqplpPvj2bPm9hlVoEDG5lQrVkyTP4tjaN4c3nnHnLtu2DCoXBmCg62uSkREHIh+YxGRuychwWxVy8i8alevZvy4Tk7mgCHpBbSbXxcokH3XJ5JdBgwwR8T88EPo3Bm2bQM/P6urEhERB6FQJyJ3xjDMia0z8qzauXO3d+yCBf97mP6SJc0h/Z2ds+f6RByBzQbvvgu//w6bNpktdbt2mX/MEBGRPE+hTkTSdv26Obl1Rp5Vu3Yt48d1dv6nVe1Wz6qVKAGentl3fSI5jYsLfP451K0LBw9CSAhs3mxOfyEiInmaQp1IXmIYcPFixuZVi46+vWMXKvTfz6qVKmXOteXklC2XJ5LrFSlijohZty5s3w49e8KiRRqoR0Qkj1OoE8kN4uP/aVX7r8B2/XrGj5svX/pdH29+XaIEeHhk3/WJyD8qV4YvvoCgIFi8GKpVgxEjrK5KREQspFAn4qgMA86fz9izahcu3N6xCxfO2LNqRYuqVU3EET3xBLz3HvTpAyNHwv33w1NPWV2ViIhYRKFO5G67du2/R3688ZWQkPHjurhkrPtjiRJ6BkckN+jd2xwRc8YMeOYZ8PWFhx+2uioREbGAQp1IVkhONlvVMjKv2sWLt3fsokUzFtaKFNFzNSJ5zdSp5qAp69ZBmzbmiJilS1tdlYiI3GUKdSK3cvVqxro/njkDiYkZP66r660D2o3lEiXAzS37rk9EcjZnZ1iyBOrXh59/NoPd11/rGVcRkTxGoU7ynuRkc760jIS1mJjbO7a3d/oB7ebXhQurVU1EsoaXlzki5iOPwJ49ZlfMzz7T87AiInmIQp3kHnFxGev+eOYMJCVl/LhubmYY+6+wVry42QInInK3VagAERHQuDEsWwajR8OECVZXJSIid4lCnTi2pCSzVS29gHbz8uXLt3fsYsVu3Zp2Y9nLS61qIuL4Hn0U5syBbt3gjTegalXo0sXqqkRE5C5QqMuLkpKwffUVpb/+GpunJwQEmM9l3E1XrmSs++Pff5vdJTMqf/6MPatWvLg5WqSISG7yzDPmiJiTJpkTk1esCPXqWV2ViIhkM4W6vGb5chg4kHzHj/MwwDvvQJky5pDY7drd2bGTkswQlpGwFhub8ePabGarWkbCWsGCalUTkbztjTfg118hMhLatjVHxCxf3uqqREQkGynU5SXLl5uT0xpGyvUnTpjrv/gidbAzDLNV7VYB7cby2bO316rm4ZGxZ9WKFYN8+lEVEckQJyf45BN47DHYuxeCg2HbNvOPXiIikivpN+W8IikJBg5MHejgn3U9esDGjf+0tt0IbHFxGT+Pk5PZtTEjz6oVKJA11yYiIikVKGCOiFmnDvz0E3TubLbc3e2u9iIiclco1OUVW7fC8eO33ubSJfjgg7TfK1jw1gHtxnKxYvqlQUTEEZQpAytWQKNGsHo1vPIKvP221VWJiEg2UKjLK06dyth2bduaQ2LfHNZKlFCrmohITvTII7BgAXTsCFOnmiNi9uxpdVUiIpLFFOryilKlMrbdwIHw+OPZWoqIiNxFHTqYA6eMHQt9+sC99+o+LyKSyzhZXYDcJY89ZnbFSW9kSJsNypY1txMRkdxl9GiztS4xEZ58En7/3eqKREQkCynU5RXOzua0BZA62N14PX26nocTEcmNbDb4+GOzO+b58+aImBcvWl2ViIhkEYW6vKRdO3PagtKlU64vUybt6QxERCT3yJ/fHAGzTBmzO2b79mbLnYiI5HgKdXlNu3Zw5AiJUVF8N2QIiVFR8OefCnQiInlBqVLmVAeenhAVBYMGWV2RiIhkAYW6vMjZGaNRI040bIjRqJG6XIqI5CW1asGiRWaXzFmzzC8REcnRFOpERETymrZtYeJEc3ngQNiwwdJyRETkzijUiYiI5EUvvwzdukFSkvl83YEDVlckIiKZpFAnIiKSF9ls8OGH5lQ2ly6ZI2JGR1tdlYiIZIJCnYiISF7l5gbLlkGFCnD4sDlo1vXrVlclIiK3SaFOREQkLytWzBwR08sLvv4a+vYFw7C6KhERuQ0KdSIiInndAw/A0qXg5GROUv7OO1ZXJCIit0GhTkRERKBZM5g2zVweNsxsvRMRkRxBoU5ERERM/ftD795m98vOnWHfPqsrEhGRDFCoExEREZPNBu++C40bw5Ur5oiYZ85YXZWIiPwHhToRERH5h4sLfP45VK4MR49CSAhcu2Z1VSIicgsOGequXLnCoEGD8PHxwd3dnVq1arFkyZIM7btlyxYCAwMpXrw4BQoUwM/Pj5kzZ5KUlJRq29jYWEaPHk3lypVxc3PD29ubgIAADh06lGK733//naeffppy5cqRP39+7r33XoYMGUK05vMREZHcqEgRWL3a/O/27dCzp0bEFBFxYPmsLiAt7dq1Y/fu3UyaNInKlSuzePFiOnXqRHJyMp07d053v40bNxIUFETDhg2ZM2cOnp6erFy5koEDB3L48GFmzJhh3/bKlSsEBARw8uRJXn31Vfz8/Lh06RLffvstcXFx9u3Onj1L3bp18fLyYvz48ZQrV44ffviBMWPGsGXLFvbs2YOTk0NmYxERkcyrVAm++AKCgmDxYqhaFUaOtLoqERFJg8OFurVr1xIVFWUPcgABAQH89ddfDBs2jA4dOuDs7JzmvgsWLMDFxYXVq1fj6ekJQJMmTfjtt99YsGBBilA3cuRIDhw4wL59+6hYsaJ9fevWrVMcc8WKFURHR7N06VIaN25sryc+Pp7XXnuNH3/8kdq1a2fpZyAiIuIQnngCZs0yB08ZNQqqVIGnnrK6KhER+ReHa2KKiIigQIEChIaGpljfvXt3Tp48yc6dO9Pd18XFBVdXV/Lnz59ifeHChXF3d7e/jouLY+7cuYSGhqYIdOkdE6BQoUKpjgmkOK6IiEiu8/zzMGiQufzMM/Ddd5aWIyIiqTlcS93+/fupWrUq+fKlLM3Pz8/+fv369dPct0+fPoSHhzNgwABee+01PDw8WLVqFREREUycONG+3Z49e4iNjaVSpUr07duXJUuWEBsbi5+fH+PGjaNly5b2bdu2bUu5cuUYOnQo77//PuXLl+f7779n0qRJBAcHU7Vq1XSvJT4+nvj4ePvrmJgYABISEkhISLj9DycL3Ti/1XWIiORFOe4ePHEizr/+itP69Rht2pC4bRuULm11VSIit82R7r9ZWYPDhbro6Og0W8+KFi1qfz89/v7+bN68mdDQUGbNmgWAs7MzEydOZOjQofbtTpw4AcDkyZOpUaMGCxcuxMnJialTpxIcHMy6desICgoCzBa6HTt28OSTT1K9enX7MUJDQ/nkk09ueS0TJ05k3LhxqdZv2LABDw+PW+57t0RFRVldgohInpWT7sH5nnmGx375Ba+jR4lt3JhvJk4kyc3N6rJERDLFEe6/N4/jcaccLtQB2Gy2TL23Z88eQkJC8Pf358MPP8TT05PNmzczcuRIrl27xqhRowBITk4GwNXVlXXr1lGwYEHAfFauUqVKjB8/3h7qLly4QJs2bYiLi+PTTz+lbNmy7N+/n/Hjx9O6dWvWrFmTqlXxhuHDhzNkyBD765iYGMqWLUvTpk3x8vK6vQ8liyUkJBAVFUVgYKC9i6mIiNwdOfYe/NBDGA0aUPiPP2ixZAlJ4eGgwcJEJAdxpPvvjV58WcHhQp23t3earXHnz58H/mmxS0u/fv0oUaIEERER9sFUAgICcHJyYuzYsXTp0oWKFSvi7e0NQP369e2BDsDDw4NGjRoRGRlpXzd58mT27t3LX3/9RalSpQB47LHHqFKlCk888QSffvop3bp1S7MeNzc33NL4K6aLi4vlP0Q3OFItIiJ5TY67B1euDBER0LgxThEROI0fDxMmWF2ViMhtc4T7b1ae3+H+vFajRg0OHDhAYmJiivU//fQTQIoukP+2d+9eHnrooVSjY9apU4fk5GQOHDgA/PN8XloMw0gxRcHevXspXbq0PdDdfEwwn/ETERHJMx59FObMMZffeAMWLbK2HhERcbxQFxISwpUrV1i2bFmK9WFhYfj4+ODv75/uvj4+Pnz33XepJhrfvn07AGXKlAGgVKlS1KtXj23btqVo9oyLi+Orr76ibt26KY55/Phx+3N46R1TREQkz3jmGXj1VXO5Z09zgnIREbGMw4W65s2bExgYSN++fZkzZw5btmzh+eefZ/369UyZMsXeCtezZ0/y5cvHX3/9Zd938ODB7N+/n+DgYFasWEFUVBSvvvoqU6ZMoUmTJtSsWdO+7dtvv83ly5cJCgoiMjKSFStW0KxZM86dO8f48ePt2/Xr1w8nJycCAwNZuHAhW7Zs4d1336Vr166UKFGCLl263L0PR0RExFG88Qa0bQvXr5v/ven/xyIicnc5XKgDWL58OU8//TSjR4+mWbNm7Ny5k/Dw8BQBKikpiaSkJAzDsK/r378/y5Yt4/Lly/Tq1YuQkBBWr17NmDFjUjwnB+bzdJs2bcLNzY0uXbrQuXNnXFxc+PLLL6lXr559u4ceeogdO3ZQpUoVRowYQfPmzZk+fTqtW7dm9+7d3HPPPdn+eYiIiDgcJyf45BOoVQv+/htatYLLl62uSkQkT7IZN6ciyVYxMTEUKlSIS5cuOcTol2vXrqVFixaWPyQqIpLX5Kp78PHjUKcOnD4NLVvCihXwr2fbRUQchSPdf7MyGzhkS52IiIjkEGXKwMqV4O4Oa9bAK69YXZGISJ6jUCciIiJ3pk4dCAszl6dOhXnzrK1HRCSPUagTERGRO9e+PYwday736QNffmllNSIieYpCnYiIiGSN0aOhY0dITIQnn4Tff7e6IhGRPEGhTkRERLKGzQYffwyPPALnz0NwMFy8aHVVIiK5nkKdiIiIZJ38+SEy0hxA5ddfzW6ZiYlWVyUikqsp1ImIiEjWKlUKVq0CT0+IioKBA62uSEQkV1OoExERkaxXqxZ8+qnZJfP992HWLKsrEhHJtRTqREREJHu0aQOTJpnLAwfChg3W1iMikksp1ImIiEj2GTYMunWDpCQIDYUDB6yuSEQk11GoExERkexjs8GHH8Jjj0FMDLRqBdHRVlclIpKrKNSJiIhI9nJzg+XLoUIF+OMPaNcOrl+3uioRkVxDoU5ERESy3z33wOrV4OUFX38NffuCYVhdlYhIrqBQJyIiIndHtWqwdCk4OZmTlE+danVFIiK5gkKdiIiI3D3NmsG0aebyyy+b89mJiMgdUagTERGRu6t/f+jTx+x+2bkz7NtndUUiIjmaQp2IiIjcXTYbzJwJjRvDlSsQHAxnzlhdlYhIjqVQJyIiInefiwt8/jlUrgxHj0LbtnDtmtVViYjkSAp1IiIiYo0iRcwRMYsUgR07oGdPjYgpIpIJCnUiIiJinUqVYNkyyJcPFi+GN96wuiIRkRxHoU5ERESsFRAAs2aZy6NGmd0yRUQkwxTqRERExHrPPw+DBpnL3brBd99ZWo6ISE6iUCciIiKO4e23oUULuHoV2rSBEyesrkhEJEdQqBMRERHH4OwM4eHwwANw8iS0bg2xsVZXJSLi8BTqRERExHF4ecGqVXDPPfD99/DMM5CcbHVVIiIOTaFOREREHEuFChAZCa6usHw5jB5tdUUiIg5NoU5EREQcT4MGMGeOufzGG7BokbX1iIg4MIU6ERERcUzPPAOvvmou9+wJ335rbT0iIg5KoU5EREQc1xtvQEgIXL8ObdvCX39ZXZGIiMNRqBMRERHH5eQEn3wCtWrB2bPQqhVcvmx1VSIiDkWhTkRERBybp6c5ImbJkrB/P3TqBElJVlclIuIwFOpERETE8ZUpAytXgrs7rFkDL79sdUUiIg5DoU5ERERyhjp1ICzMXH7nHZg719p6REQchEKdiIiI5Bzt28O4ceZy377w5ZeWliMi4ggU6kRERCRnGTUKOnaExER48kn4/XerKxIRsZRCnYiIiOQsNht8/DH4+8P58+aImBcvWl2ViIhlFOpEREQk58mfHyIjoWxZ+O03s1tmYqLVVYmIWEKhTkRERHKmkiXNETE9PSEqCgYOtLoiERFLKNSJiIhIzlWrFnz6qdkl8/334b33rK5IROSuU6gTERGRnK1NG5g0yVweOBA2bLC2HhGRu0yhTkRERHK+YcPg2WchORlCQ+HAAasrEhG5axTqREREJOez2WD2bHjsMYiJMUfEPHfO6qpERO4KhToRERHJHdzcYPlyqFAB/vjDnMPu+nWrqxIRyXYKdSIiIpJ73HMPrF4NXl7w9dfQpw8YhtVViYhkK4U6ERERyV2qVYOlS8HJCebPh6lTra5IRCRbKdSJiIhI7tOsGUybZi6//LI5n52ISC6lUCciIiK5U//+/3S/7NwZ9u2zuiIRkWyhUCciIiK5k80GM2dC48YQGwvBwXDmjNVViYhkOYU6ERERyb1cXODzz6FyZTh6FNq2hWvXrK5KRCRLKdSJiIhI7lakiDkiZpEisGMH9OihETFFJFdRqBMREZHcr1IlWLYM8uWD8HB44w2rKxIRyTIKdSIiIpI3BATA+++by6NGmd0yRURyAYU6ERERyTueew4GDTKXu3WD776ztBwRkaygUCciIiJ5y9tvQ4sWcPUqtG4NJ05YXZGIyB1RqBMREZG8xdnZfK7ugQfg1Ckz2MXGWl2ViEimKdSJiIhI3uPlBatWwT33wPffwzPPQHKy1VWJiGSKQp2IiIjkTRUqQGQkuLrC8uXm4CkiIjmQQp2IiIjkXQ0awNy55vKbb8KiRdbWIyKSCQp1IiIikrc9/TQMH24u9+wJ335rbT0iIrdJoU5ERERkwgQICYHr16FtWzhyxOqKREQyTKFORERExMkJPvkEateGs2chOBhiYqyuSkQkQxwy1F25coVBgwbh4+ODu7s7tWrVYsmSJRnad8uWLQQGBlK8eHEKFCiAn58fM2fOJCkpKdW2sbGxjB49msqVK+Pm5oa3tzcBAQEcOnQo1bb79+8nNDSUYsWK4ebmhq+vLy+88MIdX6uIiIg4CE9PWLkSSpaE/fuhc2dI4/cHERFHk8/qAtLSrl07du/ezaRJk6hcuTKLFy+mU6dOJCcn07lz53T327hxI0FBQTRs2JA5c+bg6enJypUrGThwIIcPH2bGjBn2ba9cuUJAQAAnT57k1Vdfxc/Pj0uXLvHtt98SFxeX4rhbtmyhZcuWPPbYY8yePZt77rmHo0eP8sMPP2TbZyAiIiIWKFPGDHYNG8KaNfDyyzB1qtVViYjcksOFurVr1xIVFWUPcgABAQH89ddfDBs2jA4dOuDs7JzmvgsWLMDFxYXVq1fj6ekJQJMmTfjtt99YsGBBilA3cuRIDhw4wL59+6hYsaJ9fevWrVMcMy4uji5duvDEE0+watUqbDab/b2nn346y65bREREHESdOhAWBh06wDvvQNWq0KuX1VWJiKTL4bpfRkREUKBAAUJDQ1Os7969OydPnmTnzp3p7uvi4oKrqyv58+dPsb5w4cK4u7vbX8fFxTF37lxCQ0NTBLq0fP7555w6dYphw4alCHQiIiKSi7VvD+PGmct9+8KXX1pajojIrThcqNu/fz9Vq1YlX76UjYh+fn7299PTp08frl+/zoABAzh58iQXL17kk08+ISIigpdfftm+3Z49e4iNjaVSpUr07duXIkWK4OrqysMPP8yaNWtSHPPrr78GICkpiUcffRRXV1eKFClCp06dOHnyZFZdtoiIiDiaUaOgY0dITIQnn4Tff7e6IhGRNDlc98vo6Og0W8+KFi1qfz89/v7+bN68mdDQUGbNmgWAs7MzEydOZOjQofbtTpw4AcDkyZOpUaMGCxcuxMnJialTpxIcHMy6desICgpKse2TTz7J888/z/jx4zl48CAjRoygUaNG/Pjjj3h4eKRZT3x8PPHx8fbXMf8/ilZCQgIJCQkZ/kyyw43zW12HiEhepHtwDvLhhzj/8QdOu3ZhtGxJ4tatUKSI1VWJSCY50v03K2twuFAH3LKb463e27NnDyEhIfj7+/Phhx/i6enJ5s2bGTlyJNeuXWPUqFEAJCcnA+Dq6sq6desoWLAgYD67V6lSJcaPH28PdTe27dChA5MnT7ZvV7JkSdq2bcvixYvplU4/+4kTJzLuRteNm2zYsCHdIHi3RUVFWV2CiEiepXtwzuDWty8N//gDj4MHudC0KTtGjcLI55C/QolIBjnC/fffgzPeCYe7I3l7e6fZGnf+/Hngnxa7tPTr148SJUoQERFhH0wlICAAJycnxo4dS5cuXahYsSLe3t4A1K9f3x7oADw8PGjUqBGRkZEp6gHsIe+GoKAgbDYb33//fbr1DB8+nCFDhthfx8TEULZsWZo2bYqXl1e6+90NCQkJREVFERgYiIuLi6W1iIjkNboH50DVq2M8/jjFf/yRlhs3kjxzptUViUgmONL9NyYL58J0uFBXo0YNwsPDSUxMTPFc3U8//QRA9erV09137969dOrUKdXomHXq1CE5OZkDBw5QsWJF+/N5aTEMAyenfx419PPzu+UceTdv+29ubm64ubmlWu/i4mL5D9ENjlSLiEheo3twDvLww/DppxASgvPs2Tg/8AC8+KLVVYlIJjnC/Tcrz+9wA6WEhIRw5coVli1blmJ9WFgYPj4++Pv7p7uvj48P3333XaqJxrdv3w5AmTJlAChVqhT16tVj27ZtKRJyXFwcX331FXXr1k1Rj81mY926dSmOuW7dOgzDSLGtiIiI5GJt2sCkSebywIHwv/9ZW4+IyP9zuJa65s2bExgYSN++fYmJieG+++4jPDyc9evXs2jRInsrXM+ePQkLC+Pw4cOUL18egMGDBzNgwACCg4Pp3bs3Hh4ebNq0ialTp9KkSRNq1qxpP8/bb79NQEAAQUFBvPLKK9hsNqZOncq5c+cYP368fbsqVarQr18/3n//fQoWLEjz5s05ePAgI0eOpHbt2rRv3/7ufkAiIiJinWHD4NdfYf58c9qDHTvMeexERCzkcKEOYPny5YwYMYLRo0dz/vx5qlSpQnh4OB07drRvk5SURFJSEoZh2Nf179+f0qVLM23aNHr16sXVq1fx9fVlzJgxDB48OMU56tevz6ZNmxg5ciRdunQBoG7dunz55ZfUq1cvxbbTp0+nTJkyzJ07l3fffZd77rmHjh078uabb+Lq6pqNn4SIiIg4FJsNPvjAnN5g61Zo1Qp27oR77rG6MhHJw2zGzalIslVMTAyFChXi0qVLDjFQytq1a2nRooXl/YlFRPIa3YNzgXPn4JFH4M8/oWFDiIoC/aFXxOE50v03K7OBwz1TJyIiIuLw7rkHVq8GLy/4+mvo0wf0d3IRsYhCnYiIiEhmVKsGS5eCk5P5jN3UqVZXJCJ5lEKdiIiISGY1awbTppnLL78MK1daW4+I5EkKdSIiIiJ3on//f7pfdu4MP/5odUUiksco1ImIiIjcCZsNZs6Exo0hNhaCg+H0aaurEpE8RKFORERE5E65uMDnn0PlynDsGLRtC9euWV2ViOQRCnUiIiIiWaFIEXNEzCJFzLnrevTQiJgiclco1ImIiIhklUqVYNkyyJcPwsNhwgSrKxKRPEChTkRERCQrBQTA+++by6NHm90yRUSykUKdiIiISFZ77jkYPNhc7tYNvvvO2npEJFdTqBMRERHJDm+9BS1awNWr0Lo1HD9udUUikksp1ImIiIhkB2dn87m66tXh1Ckz2MXGWl2ViORCCnUiIiIi2cXLC1atgmLF4Icf4JlnIDnZ6qpEJJdRqBMRERHJTr6+EBEBrq6wfDmMGmV1RSKSyyjUiYiIiGS3Bg1g7lxz+c034ZNPrK1HRHIVhToRERGRu+Hpp2H4cHO5Vy/49ltr6xGRXEOhTkRERORumTABQkLg+nVo2xaOHLG6IhHJBRTqRERERO4WJyez62Xt2nD2LAQHQ0yM1VWJSA6nUCciIiJyN3l6wsqVUKoU7N8PnTtDUpLVVYlIDqZQJyIiInK3lSkDK1aAuzusWQMvv2x1RSKSgynUiYiIiFihTh0ICzOX33nnn9ExRURuk0KdiIiIiFXat4dx48zlvn1hyxZr6xGRHEmhTkRERMRKo0ZBp06QmAhPPgmHDlldkYjkMAp1IiIiIlay2WDePPD3hwsXzBExL1ywuioRyUEU6kRERESslj8/REZC2bLw229mt8yEBKurEpEcQqFORERExBGULAmrVplTHmzcCAMHgmFYXZWI5AAKdSIiIiKOomZNWLzY7JL5wQcwa5bVFYlIDqBQJyIiIuJIWreGSZPM5YED4X//s7YeEXF4CnUiIiIijmbYMOjeHZKTzefrfvnF6opExIEp1ImIiIg4GpsNZs+Gxx6DmBhzRMxz56yuSkQclEKdiIiIiCNydYXly6FCBfjjD2jXDq5ft7oqEXFAmQp15/SXIhEREZHsd889sHo1eHnB1q3Qp49GxBSRVDIV6sqUKUOHDh2IiorK6npERERE5GbVqsHSpeDkBPPnw9tvW12RiDiYTIU6Pz8/Pv/8c5o1a0aFChWYMGECJ06cyOraRERERASgWTOYPt1cfuUVWLnS0nJExLFkKtTt2rWLffv28eKLL3L58mVGjx6Nr68vrVu3ZuXKlSQnJ2d1nSIiIiJ524sv/tP9snNn+PFHqysSEQeR6YFSqlevzowZMzh58iSLFy+mUaNGrFmzhpCQEMqWLcuIESP4448/srJWERERkbzLZoOZM6FxY4iNNUfEPH3a6qpExAHc8eiXrq6udOzYkY0bN3L48GFGjBhBUlISkyZNonLlygQGBrJs2TIMPdQrIiIicmdcXODzz6FyZTh2DNq2hatXra5KRCyWZVMaGIbB/v372bdvH9HR0RiGQalSpfjqq69o3749tWrV4tChQ1l1OhEREZG8qUgRc0TMIkVg507o2VMjYorkcXcc6v78809GjhxJ2bJladOmDevWraNt27Zs2LCBY8eO8ddffzF06FB++eUX+vbtmxU1i4iIiORtlSrBsmWQLx+Eh8OECVZXJCIWypeZnRISEli2bBlz587lyy+/JDk5mQoVKvDGG2/Qo0cPihcvbt+2VKlSTJkyhcuXL/PJJ59kWeEiIiIieVpAALz/Pjz/PIweDfffD+3bW12ViFggU6HOx8eH8+fP4+zsTNu2benduzeBgYG33Kd8+fLExcVlqkgRERERScNzz8GBAzBtGnTrBhUqQJ06VlclIndZprpfFihQgAkTJnDs2DG++OKL/wx0AC+88AJ//vlnZk4nIiIiIul56y1o0QKuXYM2beD4casrEpG7LFMtdX/88Qc2m+229vHy8sLLyyszpxMRERGR9Dg7m8/VNWgA+/dD69awdSt4elpdmYjcJZlqqYuJiWHfvn3pdqeMjY1l3759xMTE3FFxIiIiIpIBXl6wahUUKwY//ADPPAPJyVZXJSJ3SaZC3euvv079+vVJSkpK8/2kpCQaNGjAG2+8cUfFiYiIiEgG+fpCRAS4usLy5TBqlNUVichdkqlQt379epo2bUrBggXTfN/Ly4ugoCDWrl17R8WJiIiIyG1o0ADmzjWX33wTNPK4SJ6QqVB39OhRKlWqdMtt7r33Xo4ePZqpokREREQkk55+GoYPN5d79YJt26ytR0SyXaZCnc1mIz4+/pbbxMfHp9s9U0RERESy0YQJ0K4dXL8OISFw5IjVFYlINspUqKtatSrr16/HMIw0309OTmbdunXcf//9d1SciIiIiGSCkxMsXAi1a8PZsxAcDBrATiTXylSo69y5MwcPHqRHjx5cunQpxXuXLl2iR48e/P7773Tt2jVLihQRERGR2+TpCStXQqlS5lQHnTuDelGJ5EqZmqfuhRdeYPny5YSFhbFixQrq1KlD6dKlOXHiBLt37+bixYs0bNiQF198MavrFREREZGMKlMGVqyAhg1hzRoYNgzeecfqqkQki2Wqpc7FxYUNGzbw0ksvkZycTFRUFAsWLCAqKork5GSGDRvG//73P1xcXLK6XhERERG5HXXqQFiYuTxtGsyZY209IpLlMtVSB+Dm5saUKVOYNGkSv/76KxcvXqRw4cLcf//9ODs7Z2WNIiIiInIn2reHX3+FMWPghRfgvvsgIMDqqkQki2Q61N3g5OREtWrVsqIWEREREckuo0aZwS48HJ58EnbuhP+YokpEcoZMdb8UERERkRzGZoN588DfHy5cgFatzP+KSI6X6Za6y5cv895777Fx40ZOnjyZ5rx1NpuNw4cP31GBIiIiIpJF8ueHyEh45BE4eBBCQ2HdOtA4CCI5WqZC3dmzZ6lfvz6HDx/Gy8uLmJgYChUqxPXr17l69SoAPj4+GihFRERExNGULAmrVkGDBrBpEwwcCLNmmS15IpIjZar75dixYzl8+DALFy7kwv832w8ePJjY2Fh27tzJI488gq+vLz///HOWFisiIiIiWaBmTVi82AxyH3wA771ndUUicgcyFerWrl1L48aN6dq1K7Z//VWnTp06rFu3jiNHjjB27NisqFFEREREslrr1jB5srk8aBCsX29pOSKSeZkKdadOnaJ27dr2187OzvZulwBFihShefPmfP7553deoYiIiIhkj5degu7dITkZOnSAX36xuiIRyYRMhbpChQqRkJBgf12kSBGOHz+eYhsvLy/OnDlzZ9WJiIiISPax2WD2bHjsMYiJgeBgOHfO6qpE5DZlKtRVrFiRI0eO2F/Xrl2bqKgozp8/D8DVq1dZtWoV5cqVy5IiRURERCSbuLrC8uVQsSL88Qe0awdpjGouIo4rU6GuadOmbNq0ibi4OAB69+7N33//Tc2aNQkNDaV69eocPnyYZ599NlNFXblyhUGDBuHj44O7uzu1atViyZIlGdp3y5YtBAYGUrx4cQoUKICfnx8zZ84kKSkp1baxsbGMHj2aypUr4+bmhre3NwEBARw6dCjd42/cuBGbzYbNZuOc/pIlIiIiucE995gjYnp5wdat0LcvGIbVVYlIBmVqSoM+ffpQrVo14uLi8PDwoF27drz11ltMmDCBZcuWkT9/foYMGcKwYcMyVVS7du3YvXs3kyZNonLlyixevJhOnTqRnJxM586d091v48aNBAUF0bBhQ+bMmYOnpycrV65k4MCBHD58mBkzZti3vXLlCgEBAZw8eZJXX30VPz8/Ll26xLfffmsPq/925coVnnvuOXx8fDh58mSmrk1ERETEIVWrBkuXQsuWMH8+VK0KmfxdTkTuLpthZN2fYZKSkjh37hzFixdPNSpmRq1du5aWLVvag9wNTZs25eeff+bo0aM4OzunuW/Xrl354osviI6OxtPT074+KCiIHTt2cOnSJfu6QYMGMXfuXPbt20fFihUzVNuLL77It99+S8uWLZkwYQJnz57lnnvuyfC13ZjP79KlS3h5eWV4v+yQkJDA2rVradGiheYTFBG5y3QPFof27rswYID5vF1kpDlKpkgu4Uj336zMBpnqftmjRw+mT5+ear2zszMlSpTIdKADiIiIoECBAoSGhqZY3717d06ePMnOnTvT3dfFxQVXV1fy58+fYn3hwoVxd3e3v46Li2Pu3LmEhoZmONBt3bqVjz76iLlz56YbKkVERERyvBdf/Kf7ZefO8OOPVlckIv8hU90vFy9eTIkSJbK6FgD2799P1apVyZcvZWl+fn729+vXr5/mvn369CE8PJwBAwbw2muv4eHhwapVq4iIiGDixIn27fbs2UNsbCyVKlWib9++LFmyhNjYWPz8/Bg3bhwtW7ZMcdyrV6/Ss2dPBg0axIMPPsjKlSszdC3x8fHE3/SgcUxMDGD+heDm0UOtcOP8VtchIpIX6R4sDu/tt3H+7TecNm/GCA4mcds2KFnS6qpE7pgj3X+zsoZMhbr77ruPU6dOZVkRN4uOjk6z9axo0aL299Pj7+/P5s2bCQ0NZdasWYDZejhx4kSGDh1q3+7EiRMATJ48mRo1arBw4UKcnJyYOnUqwcHBrFu3jqCgIPv2o0aNIikpiXHjxt3WtUycODHNfTZs2ICHh8dtHSu7REVFWV2CiEiepXuwODKXHj1o+OuvFDh2jMtNmrBt/HiS3dysLkskSzjC/Te9cTwyI1OhrmfPnrz55pucOHGC0qVLZ1kxN9yq++at3tuzZw8hISH4+/vz4Ycf4unpyebNmxk5ciTXrl1j1KhRACQnJwPg6urKunXrKFiwIAABAQFUqlSJ8ePH20Pdrl27mD59OuvXr0/VrfO/DB8+nCFDhthfx8TEULZsWZo2beoQz9RFRUURGBhoeX9iEZG8RvdgyTFq18Z49FGKHjxIy+XLSVq40HzWTiSHcqT7741efFkhU6EuJCSETZs2Ub9+fV5++WXq1KmT7rN0tztXnbe3d5qtcTfmwLvRYpeWfv36UaJECSIiIuzPvQUEBODk5MTYsWPp0qULFStWxNvbG4D69evbAx2Ah4cHjRo1IjIy0r6uR48etGvXjocffpiLFy8CcO3aNcD8Rri5uaU4xs3c3NxwS+MvWi4uLpb/EN3gSLWIiOQ1ugeLw6tWDZYtg6ZNcVq6FKcHHoD//yO5SE7mCPffrDx/pkJdxYoVsdlsGIbBgAED0t3OZrORmJh4W8euUaMG4eHhJCYmpniu7qeffgKgevXq6e67d+9eOnXqlGogkzp16pCcnMyBAweoWLGi/fm8tBiGgZPTP+PH/Pzzz/z88898/vnnqba99957qVmzJnv37s3o5YmIiIjkLAEB8P778PzzMHo03H8/tG9vdVUicpNMhbpnnnnmjka4vJWQkBDmzJnDsmXL6NChg319WFgYPj4++Pv7p7uvj48P3333HUlJSSmC3fbt2wEoU6YMAKVKlaJevXps27aNmJgYe1fIuLg4vvrqK+rWrWvfd8uWLanOs2DBAsLCwoiMjMyW7qciIiIiDuW55+DAAZg2Dbp1gwoVoE4dq6sSkf+XqVC3YMGCLC7jH82bNycwMJC+ffsSExPDfffdR3h4OOvXr2fRokX2sNazZ0/CwsI4fPgw5cuXB2Dw4MEMGDCA4OBgevfujYeHB5s2bWLq1Kk0adKEmjVr2s/z9ttvExAQQFBQEK+88go2m42pU6dy7tw5xo8fb9/u8ccfT1Xjl19+CUCDBg1ua546ERERkRzrrbfgt99g7Vpo0wZ27YL//4O5iFgrU/PUZbfly5fz9NNPM3r0aJo1a8bOnTsJDw+nS5cu9m2SkpJISkri5rnT+/fvz7Jly7h8+TK9evUiJCSE1atXM2bMmBTPyYH5PN2mTZtwc3OjS5cudO7cGRcXF7788kvq1at3ty5VREREJGdwdobwcKheHU6dMiclj421uioRAWzGzalIslVWzhp/pxISEli7di0tWrSw/CFREZG8RvdgydGOHIFHHoGzZ6FdO/j8c3ByyHYCkVQc6f6bldkg0wOlZITNZuPw4cOZOYWIiIiIOCJfX4iIgCeegOXLYeRIePNNq6sSydMy9WeV5ORkDMNI9XXx4kWOHDnCkSNHiI+Pt88HJyIiIiK5SIMGMHeuuTxxInzyibX1iORxmWqpO3LkyC3fGzJkCGfOnHGImdpFREREJBs8/bQ5IubEidCrF1SsaIY9EbnrsrwDtK+vL0uXLuXChQuMGDEiqw8vIiIiIo5iwgTzubrr1yEkxHzeTkTuumx5qtXFxYXAwEA+++yz7Di8iIiIiDgCJydYuBAefNAcOKVVK4iJsboqkTwn24YqiouL4/z589l1eBERERFxBJ6esGIFlCoFP/8MnTpBUpLVVYnkKdkS6r7++mvCw8O5//77s+PwIiIiIuJIypQxg527uzk5+bBhVlckkqdkaqCUJ554Is31iYmJnDhxgiNHjmAYBiNHjryj4kREREQkh6hTx+yK2b49TJsGVavCc89ZXZVInpCpUPfll1+mud5ms1GkSBECAwMZPHgwQUFBd1KbiIiIiOQkoaHw+uswejS88ALcdx8EBFhdlUiul6lQp/nnRERERCRNI0eaUx2Eh8OTT8LOnVCpktVVieRq2TZQioiIiIjkQTYbzJsH/v5w4YI5IuaFC1ZXJZKrZSrUXbp0iX379hEXF5fm+7Gxsezbt48YDWkrIiIikvfkzw+RkVC2LBw8aHbLTEiwuiqRXCtToe7111+nfv36JKUzXG1SUhINGjTgjTfeuKPiRERERCSHKlkSVq0ypzzYtAkGDADDsLoqkVwpU6Fu/fr1NG3alIIFC6b5vpeXF0FBQaxdu/aOihMRERGRHKxmTVi82OySOXs2vPee1RWJ5EqZCnVHjx6l0n888Hrvvfdy9OjRTBUlIiIiIrlE69YwebK5PGgQrF9vaTkiuVGmQp3NZiM+Pv6W28THx6fbPVNERERE8pCXXoLu3SE5GTp0gF9+sboikVwlU6GuatWqrF+/HiOdftHJycmsW7eO+++//46KExEREZFc4Eb3y8ceg5gYc0TMc+esrkok18hUqOvcuTMHDx6kR48eXLp0KcV7ly5dokePHvz+++907do1S4oUERERkRzO1RWWL4eKFeHPP6FdO/iPnl8ikjGZmnz8hRdeYPny5YSFhbFixQrq1KlD6dKlOXHiBLt37+bixYs0bNiQF198MavrFREREZGc6p57zBEx69WDrVuhTx/4+GOzJU9EMi1TLXUuLi5s2LCBl156ieTkZKKioliwYAFRUVEkJyczbNgw/ve//+Hi4pLV9YqIiIhITlatGnz2GTg5wYIF8PbbVlckkuNlKtQBuLm5MWXKFM6fP8/+/fv55ptv2L9/P9HR0UyePBk3N7esrFNEREREcougIJg+3Vx+5RVYudLSckRyukx1v7yZk5MT1apVy4paRERERCSvePFFOHAAPvgAOneGb76BWrWsrkokR8pUS90vv/zCzJkzOXv2bJrv//3338ycOZMDBw7cUXEiIiIikkvZbDBjBjRpArGx5nx2p09bXZVIjpSpUDdp0iQmT56Mt7d3mu97e3vz1ltvMWXKlDsqTkRERERyMRcX8/m6ypXh2DFo2xauXrW6KpEcJ1OhbuvWrTRu3Bgnp7R3d3Z2pnHjxnz99dd3VJyIiIiI5HJFisDq1eZ/d+6Enj0hnbmQRSRtmQp1p0+fpmzZsrfcpnTp0pw6dSpTRYmIiIhIHlKpkjmHXb58EB4O48dbXZFIjpKpUOfp6cnff/99y23+/vtv3N3dM1WUiIiIiOQxjz9uDpoCMGaM2S1TRDIkU6HuoYceIjIykosXL6b5/oULF4iIiODBBx+8k9pEREREJC/p1QsGDzaXu3WD3butrUckh8hUqOvXrx/R0dEEBASkem7uq6++IiAggAsXLvDiiy9mSZEiIiIikke89Ra0bAnXrkGbNnD8uNUViTi8TIW61q1b89JLL/Hjjz8SEBCAh4cHFStWxMPDgyeeeIJ9+/YxdOhQ2rZtm8XlioiIiEiu5uwMixdD9epw6pQ51UFsrNVViTi0TIU6gClTprB69WqaNWtGgQIFOH78OAUKFKB58+asWbOGKVOmkJiYmJW1ioiIiEhe4OUFq1ZBsWLwww/w9NOQnGx1VSIOK9OhDqBFixasWbOGv//+m+vXr/P333+zevVqypcvz9ChQylTpkxW1SkiIiIieYmvL0REgKur+d+RI62uSMRh3VGou9mVK1eYO3cu9erVo0aNGkybNi3dgVRERERERP5TgwYwb565PHEiLFxobT0iDuqOQ90333xDjx49KFWqFL1792bnzp3UqlWLmTNncvLkyayoUURERETyqq5d4bXXzOXnnoNvvrG2HhEHlC8zO505c4awsDA+/vhjDh06hGEYlCxZktjYWJ555hkWLFiQxWWKiIiISJ41fjz8+qs5QXlIiDnVga+v1VWJOIwMt9QlJyezatUq2rZtS9myZXn11Vc5evQo7du3Z82aNRw7dgwAV1fXbCtWRERERPIgJyez6+WDD8K5c9CqFcTEWF2ViMPIcEtdmTJlOHPmDAANGjTgmWeeoX379nh5eWVbcSIiIiIiAHh6wooV8Mgj8PPP0KkTrFxpToEgksdluKXu9OnT2Gw2XnrpJVauXEmvXr0U6ERERETk7ilTxgx27u6wdi0MG2Z1RSIOIcOhrmvXrri7u/P2229TqlQpQkNDWblypeaiExEREZG7p06df0bBnDYN5syxth4RB5DhULdw4UJOnTrF+++/T40aNVi2bBkhISGULFmSF198kR07dmRnnSIiIiIiptBQeP11c/mFF2DLFmvrEbHYbU1pULBgQXr37s2uXbvYt28f/fv3x2az8f7779OgQQNsNhu//fYbR48eza56RURERETMycg7dYLERHjySTh40OqKRCyT6XnqqlevzvTp0zl58iRLliwhMDAQm83G1q1bqVixIoGBgYSHh2dlrSIiIiIiJpvNnJjc3x8uXIDgYPO/InnQHU8+7uLiQvv27Vm/fj1Hjhxh7NixlCtXjk2bNtG1a9esqFFEREREJLX8+SEyEsqWNVvqQkMhIcHqqkTuujsOdTcrU6YMo0eP5o8//mDDhg106NAhKw8vIiIiIpJSyZKwerU55cGmTTBgABiG1VWJ3FVZGupu1qRJExYvXpxdhxcRERERMfn5weLFZpfM2bPhvfesrkjkrsq2UCciIiIicte0bg2TJ5vLgwbB+vWWliNyNynUiYiIiEju8NJL0L07JCdDhw7wyy9WVyRyVyjUiYiIiEjucKP7ZcOGEBMDrVrB2bNWVyWS7RTqRERERCT3cHWFZcugYkX4809o1w7i462uSiRbKdSJiIiISO5yzz2wahV4ecE330CfPhoRU3I1hToRERERyX2qVYPPPgMnJ1iwAN56y+qKRLKNQp2IiIiI5E5BQTBjhrn86quwYoW19YhkE4U6EREREcm9+vWDvn3N7pddusDevVZXJJLlFOpEREREJPey2czWuiZNIDbWnM/u9GmrqxLJUgp1IiIiIpK7ubiYz9fdfz8cOwZt2sDVq1ZXJZJlFOpEREREJPcrUsQcEbNIEdi1C3r00IiYkmso1ImIiIhI3lCpEixfDvnywZIlMH681RWJZAmFOhERERHJOx5/HD74wFweM8bslimSwynUiYiIiEje0qsXDBliLnfrZnbHFMnBFOpEREREJO+ZMgVatoRr18yBU44ft7oikUxTqBMRERGRvMfZGRYvhurVzSkOWrc2pzwQyYEcMtRduXKFQYMG4ePjg7u7O7Vq1WLJkiUZ2nfLli0EBgZSvHhxChQogJ+fHzNnziQpKSnVtrGxsYwePZrKlSvj5uaGt7c3AQEBHDp0yL7Nnj176NevHzVq1KBgwYKUKFGCJk2asHnz5iy7XhERERGxgJeXOSJmsWLwww/QtSskJ1tdlchtc8hQ165dO8LCwhgzZgzr1q2jTp06dOrUicWLF99yv40bN9KkSRMSExOZM2cOkZGRPP744wwcOJAhN/pN/78rV67w+OOPM2/ePPr378+GDRuYP38+/v7+xMXF2bcLDw9n165d9OjRgxUrVjB37lzc3Nxo3LgxCxcuzJbrFxEREZG7xNcXIiLA1RUiI2HkSKsrErltNsNwrAk61q5dS8uWLVm8eDGdOnWyr2/atCk///wzR48exdnZOc19u3btyhdffEF0dDSenp729UFBQezYsYNLly7Z1w0aNIi5c+eyb98+KlasmG49f//9N8WLF0+xLikpiQcffJDY2Fh+//33DF9bTEwMhQoV4tKlS3h5eWV4v+yQkJDA2rVradGiBS4uLpbWIiKS1+geLOKAFi2Cp582l8PC4JlnrK1HsoUj3X+zMhs4XEtdREQEBQoUIDQ0NMX67t27c/LkSXbu3Jnuvi4uLri6upI/f/4U6wsXLoy7u7v9dVxcHHPnziU0NPSWgQ5IFegAnJ2deeihhzh27FhGLklEREREHF3XrvDaa+byc8/BN99YW4/IbchndQH/tn//fqpWrUq+fClL8/Pzs79fv379NPft06cP4eHhDBgwgNdeew0PDw9WrVpFREQEEydOtG+3Z88eYmNjqVSpEn379mXJkiXExsbi5+fHuHHjaNmy5S1rTExMZOvWrTzwwAO33C4+Pp74+Hj765iYGMD8C0FCQsIt981uN85vdR0iInmR7sEiDmr0aJx/+QWnyEiMkBASt22DChWsrkqykCPdf7OyBocLddHR0Wm2nhUtWtT+fnr8/f3ZvHkzoaGhzJo1CzBb1SZOnMjQoUPt2504cQKAyZMnU6NGDRYuXIiTkxNTp04lODiYdevWERQUlO55xo4dy++//05kZOQtr2XixImMGzcu1foNGzbg4eFxy33vlqioKKtLEBHJs3QPFnE8zh078ui+fRT+4w+uBgayddIkEh3k9zbJOo5w/715HI875XChDsBms2XqvT179hASEoK/vz8ffvghnp6ebN68mZEjR3Lt2jVGjRoFQPL/j2rk6urKunXrKFiwIAABAQFUqlSJ8ePHpxvq5s6dyxtvvMHQoUNp06bNLa9j+PDhKQZoiYmJoWzZsjRt2tQhnqmLiooiMDDQ8v7EIiJ5je7BIg7O3x+jfn28jh6l+SefkLR8uTkFguR4jnT/vdGLLys4XKjz9vZOszXu/PnzwD8tdmnp168fJUqUICIiwj6YSkBAAE5OTowdO5YuXbpQsWJFvL29Aahfv7490AF4eHjQqFGjdFvg5s+fT+/evXn++ed56623/vNa3NzccHNzS7XexcXF8h+iGxypFhGRvEb3YBEH5esLK1fCY4/htG4dTsOHw7RpVlclWcgR7r9ZeX6HGyilRo0aHDhwgMTExBTrf/rpJwCqV6+e7r579+7loYceSjU6Zp06dUhOTubAgQPAP8/npcUwDJycUn8s8+fPp1evXnTr1o3Zs2ffssVQRERERHK4hx+GG9NXTZ8OH31kaTkit+JwoS4kJIQrV66wbNmyFOvDwsLw8fHB398/3X19fHz47rvvUk00vn37dgDKlCkDQKlSpahXrx7btm1L0ewZFxfHV199Rd26dVPsv2DBAnr16kXXrl2ZO3euAp2IiIhIXhAaCq+/bi736wdbtlhbj0g6HK77ZfPmzQkMDKRv377ExMRw3333ER4ezvr161m0aJG9Fa5nz56EhYVx+PBhypcvD8DgwYMZMGAAwcHB9O7dGw8PDzZt2sTUqVNp0qQJNWvWtJ/n7bffJiAggKCgIF555RVsNhtTp07l3LlzjB8/3r7d559/Ts+ePalVqxa9e/dm165dKeqtXbt2ml0sRURERCQXGDkSfv0VFi+GJ5+EHTugcmWrqxJJweFCHcDy5csZMWIEo0eP5vz581SpUoXw8HA6duxo3yYpKYmkpCRunju9f//+lC5dmmnTptGrVy+uXr2Kr68vY8aMYfDgwSnOUb9+fTZt2sTIkSPp0qULAHXr1uXLL7+kXr169u3WrFlDcnIy33//PQ0aNEhV659//omvr28WfwIiIiIi4hBsNpg3Dw4fhp07ITjYDHZFilhdmYidzbg5FUm2yspZ4+9UQkICa9eupUWLFpY/JCoiktfoHiySA50+DY88AseOQePGsG4d6N9vjuNI99+szAYO90ydiIiIiIjDKVkSVq8GT0/YtAkGDAC1jYiDUKgTEREREckIPz/z2TqbDWbPhnfftboiEUChTkREREQk41q3hsmTzeXBg81umCIWU6gTEREREbkdL70E3btDcjJ06AA//2x1RZLHKdSJiIiIiNyOG90vGzaEy5fNETHPnrW6KsnDFOpERERERG6XqyssWwYVK8Kff0K7dhAfb3VVkkcp1ImIiIiIZMY998CqVeDlBd98A336aERMsYRCnYiIiIhIZlWrBp99Bk5OsGABvPWW1RVJHqRQJyIiIiJyJ4KCYMYMc/nVVyEy0tJyJO9RqBMRERERuVMvvggvvGB2v+zSBfbutboiyUMU6kREREREssL06dCkCcTFmSNinj5tdUWSRyjUiYiIiIhkBRcX+PxzuP9+OH4c2rSBq1etrkryAIU6EREREZGsUrgwrF4NRYrArl3Qo4dGxJRsp1AnIiIiIpKV7rsPli+HfPlgyRIYP97qiiSXU6gTEREREclqjz8OH3xgLo8ZY057IJJNFOpERERERLJDr14wZIi53K2b2R1TJBso1ImIiIiIZJcpU6BlS7h2zRw45dgxqyuSXEihTkREREQkuzg7w+LFUL26OcVB69YQG2t1VZLLKNSJiIiIiGQnLy9YtQqKFTMnJe/aFZKTra5KchGFOhERERGR7ObrC5GR4Opq/nfECIsLktxEoU5ERERE5G6oXx/mzTOXJ02ChQutrUdyDYU6EREREZG7pWtXeO01c/m55+Cbb6ytR3IFhToRERERkbtp/Hh48km4fh1CQuDPP62uSHI4hToRERERkbvJyQnCwuDBB+HcOQgOhpgYq6uSHEyhTkRERETkbvP0hJUroVQp+Pln6NgRkpKsrkpyKIU6ERERERErlC5tBrv8+WHdOnjpJasrkhxKoU5ERERExCoPP2x2xQSYPh0++sjSciRnUqgTEREREbFSaCi8/rq53K8fbN5sbT2S4yjUiYiIiIhYbeRI6NwZEhPhqafg4EGrK5IcRKFORERERMRqNps5MXndunDhgjki5oULVlclOYRCnYiIiIiII3B3h8hIKFvWbKl76ilISLC6KskBFOpERERERBxFiRKwerU55cHmzdC/PxiG1VWJg1OoExERERFxJH5+EB5udsn88EN4912rKxIHp1AnIiIiIuJogoNhyhRzefBgcx47kXQo1ImIiIiIOKKhQ6F7d0hOhg4d4Oefra5IHJRCnYiIiIiII7LZYPZsaNgQLl82W+/OnrW6KnFACnUiIiIiIo7K1RWWLYOKFeHPP6FdO4iPt7oqcTAKdSIiIiIijuyee8wRMb284JtvoHdvjYgpKSjUiYiIiIg4uqpV4bPPwMkJwsLgrbesrkgciEKdiIiIiEhOEBQEM2aYy6++ak5ULoJCnYiIiIhIzvHii/DCC2b3yy5dYO9eqysSB6BQJyIiIiKSk8yYAU2aQFycOSLmqVNWVyQWU6gTEREREclJ8uWDzz+H+++H48ehbVu4etXqqsRCCnUiIiIiIjlN4cLmiJhFi8KuXdCjh0bEzMMU6kREREREcqL77jPnsMuXD5Ysgddft7oisYhCnYiIiIhITvX44/DBB+by2LGwdKmV1YhFFOpERERERHKyXr1gyBBz+dlnze6Ykqco1ImIiIiI5HRTpkCrVnDtGrRpA8eOWV2R3EUKdSIiIiIiOZ2zMyxeDNWrw+nT0Lo1XLlidVVylyjUiYiIiIjkBgULwqpVUKyYOSn5009DcrLVVcldoFAnIiIiIpJb+PpCZCS4upr/HTHC4oLkblCoExERERHJTerXh3nzzOVJkyAszNp6JNsp1ImIiIiI5DZdu8Jrr5nLzz0H33xjbT2SrRTqRERERERyo/Hj4cknISEBQkLgzz+trkiyiUKdiIiIiEhu5ORkdr188EE4dw6CgyEmxuqqJBso1ImIiIiI5FaenrByJZQqBT//DB07QmKi1VVJFlOoExERERHJzUqXNoNd/vywbh0MG2Z1RZLFFOpERERERHK7hx+GhQvN5enT4aOPLC1HspZCnYiIiIhIXvDUU+bgKQD9+sHmzdbWI1lGoU5EREREJK8YMQI6dzafq3vySTh40OqKJAso1ImIiIiI5BU2mzkxed26cPEitGoFFy5YXZXcIYcMdVeuXGHQoEH4+Pjg7u5OrVq1WLJkSYb23bJlC4GBgRQvXpwCBQrg5+fHzJkzSUpKSrVtbGwso0ePpnLlyri5ueHt7U1AQACHDh1KsV1CQgLjxo3D19cXNzc3qlSpwrvvvpsl1yoiIiIicle5u0NkJJQrB4cOmd0yExKsrkruQD6rC0hLu3bt2L17N5MmTaJy5cosXryYTp06kZycTOfOndPdb+PGjQQFBdGwYUPmzJmDp6cnK1euZODAgRw+fJgZM2bYt71y5QoBAQGcPHmSV199FT8/Py5dusS3335LXFxciuO+8MILfPLJJ4wfP546derwv//9j4EDB3L58mVee+21bPscRERERESyRYkSsGoV1K9vPlvXvz988IHZkic5jsOFurVr1xIVFWUPcgABAQH89ddfDBs2jA4dOuDs7JzmvgsWLMDFxYXVq1fj6ekJQJMmTfjtt99YsGBBilA3cuRIDhw4wL59+6hYsaJ9fevWrVMc8+eff2bevHm88cYbDPv/4V8ff/xxoqOjmTBhAn369KFo0aJZ+hmIiIiIiGQ7Pz8ID4c2beDDD6FqVRg40OqqJBMcrvtlREQEBQoUIDQ0NMX67t27c/LkSXbu3Jnuvi4uLri6upI/f/4U6wsXLoy7u7v9dVxcHHPnziU0NDRFoEtLZGQkhmHQvXv3VPVcvXqV9evXZ/TSREREREQcS3AwTJliLg8ZYs5jJzmOw4W6/fv3U7VqVfLlS9mI6OfnZ38/PX369OH69esMGDCAkydPcvHiRT755BMiIiJ4+eWX7dvt2bOH2NhYKlWqRN++fSlSpAiurq48/PDDrFmzJlU9xYoVo2TJkrddj4iIiIiIwxs6FHr0gORk6NABfv7Z6orkNjlc98vo6Og0W89udHGMjo5Od19/f382b95MaGgos2bNAsDZ2ZmJEycydOhQ+3YnTpwAYPLkydSoUYOFCxfi5OTE1KlTCQ4OZt26dQQFBdnPl1b3Sk9PT1xdXW9ZT3x8PPHx8fbXMTExgDnwSoLFD6PeOL/VdYiI5EW6B4uIw5k5E+dDh3DauhUjOJjEb76BYsWsrirLOdL9NytrcLhQB2C7xQOat3pvz549hISE4O/vz4cffoinpyebN29m5MiRXLt2jVGjRgGQnJwMgKurK+vWraNgwYKA+exepUqVGD9+vD3U3Uk9EydOZNy4canWb9iwAQ8Pj3T3u5uioqKsLkFEJM/SPVhEHInrc8/R8OBBPP/8k5gmTfj29ddJdnGxuqxs4Qj3338PzngnHC7UeXt7p9n6df78eYBbDkrSr18/SpQoQUREhH0wlYCAAJycnBg7dixdunShYsWKeHt7A1C/fn17oAPw8PCgUaNGREZGpqhn7969qc4VGxvL9evXb1nP8OHDGTJkiP11TEwMZcuWpWnTpnh5eaW7392QkJBAVFQUgYGBuOTSf6wiIo5K92ARcVg1a2I0bIj3gQO0XLmSpLlzc9WImI50/73Riy8rOFyoq1GjBuHh4SQmJqZ4ru6nn34CoHr16unuu3fvXjp16pRqdMw6deqQnJzMgQMHqFixov15uLQYhoGT0z+PGtaoUYMlS5Zw+vTpFM/VZaQeNzc33NzcUq13cXGx/IfoBkeqRUQkr9E9WEQcjp8ffPYZtGiB0yef4PTAA/DKK1ZXleUc4f6bled3uIFSQkJCuHLlCsuWLUuxPiwsDB8fH/z9/dPd18fHh++++y7VROPbt28HoEyZMgCUKlWKevXqsW3bthQJOS4ujq+++oq6deva17Vp0wabzUZYWFiKYy5YsID8+fPTrFmzzF2oiIiIiIgjatoUpk83l4cPNycqF4fmcC11zZs3JzAwkL59+xITE8N9991HeHg469evZ9GiRfZWuJ49exIWFsbhw4cpX748AIMHD2bAgAEEBwfTu3dvPDw82LRpE1OnTqVJkybUrFnTfp63336bgIAAgoKCeOWVV7DZbEydOpVz584xfvx4+3YPPPAAPXv2ZMyYMTg7O1OnTh02bNjARx99xIQJEzRHnYiIiIjkPi++CAcOwPvvQ5cu8M03ULu21VVJOhwu1AEsX76cESNGMHr0aM6fP0+VKlUIDw+nY8eO9m2SkpJISkrCMAz7uv79+1O6dGmmTZtGr169uHr1Kr6+vowZM4bBgwenOEf9+vXZtGkTI0eOpEuXLgDUrVuXL7/8knr16qXY9v3336d06dK8++67nD59Gl9fX2bMmEH//v2z8VMQEREREbHQjBlw8CBs3AitW8OuXVCqlNVVSRpsxs2pSLJVTEwMhQoV4tKlSw4xUMratWtp0aKF5f2JRUTyGt2DRSTHuHgR6taF336DRx6BL7+E/PmtrirTHOn+m5XZwOGeqRMREREREQdRuDCsXg1Fi5otdd27g9qEHI5CnYiIiIiIpO+++2DZMsiXD5Yuhddft7oi+ReFOhERERERubXHH4fZs83lsWPNcCcOQ6FORERERET+W8+eMGSIufzss2Z3THEICnUiIiIiIpIxU6ZAq1Zw7Rq0aQPHjlldkaBQJyIiIiIiGeXsDIsXQ40acPq0OdXBlStWV5XnKdSJiIiIiEjGFSwIq1ZB8eKwdy88/TQkJ1tdVZ6mUCciIiIiIrenfHmIiABXV4iMhBEjrK4oT1OoExERERGR21e/Pnz8sbk8aRKEhVlbTx6mUCciIiIiIpnTpcs/rXTPPQfffGNtPXmUQp2IiIiIiGTe66/Dk09CQgKEhMAff1hdUZ6jUCciIiIiIpnn5GR2vXzwQTh3DoKDISbG6qryFIU6ERERERG5M56esHIl+PjAL79Ax46QmGh1VXmGQp2IiIiIiNy50qVhxQrInx/WrYOXXrK6ojxDoU5ERERERLLGww/DwoXm8owZ8OGH1taTRyjUiYiIiIhI1nnqKRg/3lzu1w82b7a2njxAoU5ERERERLLWiBHQuTMkJZkjYx48aHVFuZpCnYiIiIiIZC2bDebNg7p14eJFaNUKzp+3uqpcS6FORERERESynrs7REZCuXJw6BCEhppz2UmWU6gTEREREZHsUaIErFoFBQqYz9b17w+GYXVVuY5CnYiIiIiIZB8/P1i82OyS+eGHMHOm1RXlOgp1IiIiIiKSvYKDYcoUc3nIEHMeO8kyCnUiIiIiIpL9hg6FHj0gORk6dICff7a6olxDoU5ERERERLKfzQYffAANG8Lly2br3dmzVleVKyjUiYiIiIjI3eHqCsuWQcWK8OefEBIC8fFWV5XjKdSJiIiIiMjdc889sHo1FCoE27bB889rRMw7pFAnIiIiIiJ3V9Wq8Nln4OwMCxf+M4iKZIpCnYiIiIiI3H1Nm8KMGeby8OHmROWSKQp1IiIiIiJijX794IUXzO6XXbrADz9YXVGOpFAnIiIiIiLWmTEDAgMhLg5at4ZTp6yuKMdRqBMREREREevky2c+X3f//XD8OLRtC1evWl1VjqJQJyIiIiIi1ipc2BwRs2hR2LULunfXiJi3QaFORERERESsd9995hx2+fLB0qUwbpzVFeUYCnUiIiIiIuIYHn8cZs82l8eNgyVLLC0np1CoExERERERx9GzJwwdai537252x5RbUqgTERERERHHMnkytGoF166ZI2IeO2Z1RQ5NoU5ERERERByLszMsXgw1asCZMxAcDFeuWF2Vw1KoExERERERx1OwIKxaBcWLw48/wtNPQ3Ky1VU5JIU6ERERERFxTOXLQ0QEuLpCZCS89prVFTkkhToREREREXFc9evDxx+by5Mnw4IFlpbjiBTqRERERETEsXXpAiNGmMvPPw/ffGNtPQ5GoU5ERERERBzf66/Dk09CQgKEhMAff1hdkcNQqBMREREREcfn5ARhYfDgg3DunDki5qVLVlflEBTqREREREQkZ/D0hJUrwccHfvkFOnaExESrq7KcQp2IiIiIiOQcpUubwS5/fli/Hl56yeqKLKdQJyIiIiIiOctDD8HChebyjBnw4YfW1mMxhToREREREcl5nnoKxo83l/v1g02brK3HQgp1IiIiIiKSM40YYU53kJRkhryDB62uyBIKdSIiIiIikjPZbDB3LtStCxcvQqtWcP681VXddQp1IiIiIiKSc7m7Q2QklCsHhw5BaKg5l10eolAnIiIiIiI5W4kSsGoVFCgAmzfDiy+CYVhd1V2jUCciIiIiIjmfnx8sXmx2yfzoI5g50+qK7hqFOhERERERyR2Cg+Gtt8zlIUNg3Tpr67lLFOpERERERCT3GDIEevSA5GTo0AH277e6omynUCciIiIiIrmHzQYffACNGsHly2br3dmzVleVrRTqREREREQkd3F1hWXL4N574cgRCAmBuDhsX31F6a+/xvbVV+bcdrmEQp2IiIiIiOQ+3t7miJiFCsG2bVCsGPkCA3n4nXfIFxgIvr6wfLnVVWYJhToREREREcmdqlaFAQPM5bi4lO+dOAFPPZUrgp1CnYiIiIiI5E5JSTB/ftrv3ZjHbtCgHN8VU6FORERERERyp61b4fjx9N83DDh2zNwuB1OoExERERGR3OnUqazdzkEp1ImIiIiISO5UqlTWbuegHDLUXblyhUGDBuHj44O7uzu1atViyZIlGdp3y5YtBAYGUrx4cQoUKICfnx8zZ84k6V/9ZB9//HFsNluqr2bNmqU65u+//87TTz9NuXLlyJ8/P/feey9DhgwhOjo6S65XRERERESywWOPQZky5tx1abHZoGxZc7scLJ/VBaSlXbt27N69m0mTJlG5cmUWL15Mp06dSE5OpnPnzunut3HjRoKCgmjYsCFz5szB09OTlStXMnDgQA4fPsyMGTNSbF+xYkU+/fTTFOsKFy6c4vXZs2epW7cuXl5ejB8/nnLlyvHDDz8wZswYtmzZwp49e3BycshsLCIiIiKStzk7w4wZ5iiXNts/g6PAP0Fv+nRzuxzM4ULd2rVriYqKsgc5gICAAP766y+GDRtGhw4dcE7nQ1+wYAEuLi6sXr0aT09PAJo0acJvv/3GggULUoW6/PnzU7du3VvWs2LFCqKjo1m6dCmNGze21xMfH89rr73Gjz/+SO3ate/0skVEREREJDu0awdffAEDB6YcNKVMGTPQtWtnWWlZxeGamCIiIihQoAChoaEp1nfv3p2TJ0+yc+fOdPd1cXHB1dWV/Pnzp1hfuHBh3N3dM1WPi4sLAIUKFUp1TCDTxxURERERkbukXTs4coTEqCi+GzKExKgo+PPPXBHowAFb6vbv30/VqlXJly9laX5+fvb369evn+a+ffr0ITw8nAEDBvDaa6/h4eHBqlWriIiIYOLEiam2P3z4MEWLFiUmJoby5cvTsWNHRo4cmSIUtm3blnLlyjF06FDef/99ypcvz/fff8+kSZMIDg6matWq6V5LfHw88fHx9tcxMTEAJCQkkJCQkPEPJRvcOL/VdYiI5EW6B4uIWCOhfn1OxMZSrX59jORkSE62rpYs/H+Aw4W66OhoKlasmGp90aJF7e+nx9/fn82bNxMaGsqsWbMAcHZ2ZuLEiQwdOjTFto8++igdOnSgSpUqXL16lXXr1jFlyhS++eYbtmzZYn9OrlChQuzYsYMnn3yS6tWr2/cPDQ3lk08+ueW1TJw4kXHjxqVav2HDBjw8PG65790SFRVldQkiInmW7sEiItZwhPtvXFxclh3L4UIdgC290Wn+4709e/YQEhKCv78/H374IZ6enmzevJmRI0dy7do1Ro0aZd92woQJKfZt0aIFvr6+vPTSS6xYsYKQkBAALly4QJs2bYiLi+PTTz+lbNmy7N+/n/Hjx9O6dWvWrFmTqlXxhuHDhzNkyBD765iYGMqWLUvTpk3x8vLK0GeRXRISEoiKiiIwMNDexVRERO4O3YNFRKzhSPffG734soLDhTpvb+80W+POnz8P/NNil5Z+/fpRokQJIiIi7IOpBAQE4OTkxNixY+nSpUuarYA3dO3alZdeeokdO3bYQ93kyZPZu3cvf/31F6X+f/6Kxx57jCpVqvDEE0/w6aef0q1btzSP5+bmhpubW6r1Li4ulv8Q3eBItYiI5DW6B4uIWMMR7r9ZeX6HGyilRo0aHDhwgMTExBTrf/rpJ4AUXSD/be/evTz00EOpRsesU6cOycnJHDhwIEM13DxFwd69eyldurQ90N18TDCf8RMREREREbGKw4W6kJAQrly5wrJly1KsDwsLw8fHB39//3T39fHx4bvvvks10fj27dsBKFOmzC3PHRYWBpBimgMfHx+OHz/OiRMnMnVMERERERGR7ORw3S+bN29OYGAgffv2JSYmhvvuu4/w8HDWr1/PokWL7K1wPXv2JCwsjMOHD1O+fHkABg8ezIABAwgODqZ37954eHiwadMmpk6dSpMmTahZsyYAW7du5Y033iAkJISKFSty7do11q1bx0cffcQTTzxBcHCwvZ5+/frx6aefEhgYyKuvvmp/pm7ChAmUKFGCLl263P0PSURERERE5P85XKgDWL58OSNGjGD06NGcP3+eKlWqEB4eTseOHe3bJCUlkZSUhHHTrPD9+/endOnSTJs2jV69enH16lV8fX0ZM2YMgwcPtm9XqlQpnJ2dGT9+POfOncNms1GpUiVef/11hg4dmqL75UMPPcSOHTsYP348I0aM4OzZs5QuXZrWrVszevRo7rnnnrvzoYiIiIiIiKTBZtyciiRbxcTEUKhQIS5duuQQo1+uXbuWFi1aWP6QqIhIXqN7sIiINRzp/puV2cDhnqkTERERERGRjFOoExERERERycEU6kRERERERHIwhToREREREZEcTKFOREREREQkB3PIKQ1yqxsDjcbExFhciTnyT1xcHDExMZaP/CMiktfoHiwiYg1Huv/eyARZMRmBQt1ddPnyZQDKli1rcSUiIiIiIuIILl++TKFChe7oGJqn7i5KTk7m5MmTFCxYEJvNZmktMTExlC1blmPHjlk+Z56ISF6je7CIiDUc6f5rGAaXL1/Gx8cHJ6c7eypOLXV3kZOTE2XKlLG6jBS8vLws/4EWEcmrdA8WEbGGo9x/77SF7gYNlCIiIiIiIpKDKdSJiIiIiIjkYAp1eZSbmxtjxozBzc3N6lJERPIc3YNFRKyRW++/GihFREREREQkB1NLnYiIiIiISA6mUCciIiIiIpKDKdSJiIiIiIjkYAp1/2HBggXYbDb7l7u7OyVLliQgIICJEyfy999/Z9u5jxw5gs1mY8GCBbe137PPPouvr2+21JQRY8eOTfGZpff1+OOPW1ajiDiOf99n8+XLR6lSpejYsSOHDh2ypKYb9zFH9cMPP9CoUSMKFSqEzWZj+vTpVpeUyuLFix2yLhHJPv++n//768svv8zwseLi4hg7duxt7ZNVcuLvspp8PIPmz59PlSpVSEhI4O+//+abb75h8uTJvP322yxdupQmTZpk+TlLlSrF9u3buffee29rv1GjRjFw4MAsryejevXqRbNmzeyvT506Rbt27ejfvz+dO3e2r3eECR9FxHHcuM9eu3aNbdu28cYbb7BlyxZ+/fVXihQpYnV5DqVHjx7ExsayZMkSihQpYukf8tKzePFi9u/fz6BBg6wuRUTushv383+rVq1aho8RFxfHuHHjAO56eMqJv8sq1GVQ9erVefjhh+2vn3zySQYPHsyjjz5Ku3btOHToECVKlMjSc7q5uVG3bt3b3u92Q2BWK1OmDGXKlLG/PnLkCADlypW75fUkJCTY/0ovInnPzffZxx9/nKSkJMaMGUNkZCTdu3e3uDrHsn//fp577jmaN2+eJcfT/VdEstK/f2++G+Li4vDw8MiSY+XE32XV/fIOlCtXjqlTp3L58mU+/PBD+/rvvvuO1q1bU7RoUdzd3alduzafffZZqv1PnDjB888/T9myZXF1dcXHx4ennnqKM2fOAGl3vzx79qx9Hzc3N4oVK0aDBg3YuHGjfZu0ul9eu3aN4cOHU6FCBVxdXSldujT9+vXj4sWLKbbz9fWlVatWrF+/ngcffJD8+fNTpUoVPv744/9r7+6jorjOP4B/B9hd3hdWhUWqQHylrQhJxRcUpNSCoodKEZAoEOwxoXrSGEwUEyVGaxXbqiWJWqX4gvUt4htUbFwR06oNHg1RUY94fFcUQQVRlMX7+8MfE9ddBASDa76fc/hjn7n37p3R88zcnTt3Wn/AnrBv3z5IkoS1a9ciJSUF7u7uUKlUKC0tBQDs2bMHISEhcHR0hK2tLQICAqDT6YzaOXPmDOLi4uDi4gKVSgVvb298/vnnbdpXImofDRcEDTmxtrYWKSkp8PX1hVqthkajwcCBA7F9+3ajupIkYfLkyVi7di28vb1ha2uLvn37Ijc316hsXl4efH19oVKp4OXlhT//+c8m+9PSPJqbmws/Pz/Y2NjA29tb/u5Vq1bB29sbdnZ28Pf3x+HDh5t9TBqmNun1eixdulSeAtTg+PHjiIiIgLOzM6ytreHr64vVq1cbtNEW+bepc9HQoUORl5eHCxcuGExVIiLasGEDJEnCZ599ZhBPS0uDpaUlvvrqK5w/fx6dOnUCAMyePVvOIYmJiQC+nx555MgRREVFwdnZWb6pcfjwYcTGxsLT0xM2Njbw9PTE2LFjceHChTbdj5ftWpY/ybXSiBEjYGlpif379wMACgoKEBYWhv79+2PZsmVQq9XYsGEDYmJicO/ePfk/45UrV9CvXz/U1dVhxowZ8PHxQUVFBXbv3o1bt241etdv/PjxOHLkCP74xz+iZ8+euH37No4cOYKKiopG+yiEwG9+8xvodDqkpqZiyJAh+O6775CWloaDBw/i4MGDBi9gLC4uRkpKCqZPnw5XV1esXLkSEyZMQPfu3REYGNh2Bw9AamoqBg4ciGXLlsHCwgIuLi7Izs5GfHw8IiIisHr1aigUCixfvhyhoaHYvXs3QkJCAAAlJSUYNGiQPLjWarXYvXs33n33Xdy8eRNpaWlt2lci+mGdO3cOANCzZ08AwIMHD1BZWYmpU6fC3d0dDx8+xJ49exAZGYmsrCzEx8cb1M/Ly0NRURE+/fRT2NvbIz09HaNHj8bp06fx2muvAQB0Oh0iIiIwcOBAbNiwAfX19UhPT5cHkg2eJ4+mpqbio48+glqtxuzZsxEZGYnU1FTodDrMmzcPkiRh2rRpGDlyJM6dOwcbG5smj0l4eDgOHjyIgQMHIioqCikpKfK206dPY9CgQXBxccHf/vY3dOjQAdnZ2UhMTMT169fx4YcfGrTVmvzb1Lnoiy++wMSJE3H27Fls3bq1Wf/eRPTqqK+vh16vN4hJkgRLS0vExsaisLAQKSkpGDBgAH7xi19g7969mDt3LmbMmIFhw4bhwYMHyM/PR1hYGCZMmIDf/e53ACAP9BpERkYiNjYW77zzDmpqagA8vinSq1cvxMbGQqPR4Nq1a1i6dCn69euHkpISdOzYsU339aW5lhX0TFlZWQKAKCoqarSMq6ur8Pb2FkII0bt3b+Hn5yfq6uoMyowcOVK4ubmJ+vp6IYQQSUlJQqFQiJKSkkbbPXfunAAgsrKy5Ji9vb147733ntnnhIQE4eHhIX/Oz88XAER6erpBuY0bNwoA4u9//7sc8/DwENbW1uLChQty7P79+0Kj0Yi33377md/b1H4sXLhQjhUUFAgAIjAw0KBsTU2N0Gg0YtSoUQbx+vp60bdvX+Hv7y/HQkNDxU9+8hNx584dg7KTJ08W1tbWorKy8rn6S0Q/rIY8e+jQIVFXVyeqq6tFfn6+0Gq1IjAw0CifNtDr9aKurk5MmDBB+Pn5GWwDIFxdXUVVVZUcKysrExYWFuJPf/qTHOvfv7/o3LmzuH//vhyrqqoSGo1GPHmKbGketbGxEZcvX5Zj3377rQAg3NzcRE1NjRzftm2bACB27NjR3MMl79+kSZMMYrGxsUKlUomLFy8axIcPHy5sbW3F7du3hRBtk3+bcy4KDw83OBcR0auvIZ+b+rO0tJTL1dbWCj8/P+Hl5SVKSkqEq6urCAoKEnq9Xi5TXl4uAIi0tDSj70lLSxMAxKxZs5rsk16vF3fv3hV2dnZiyZIlz7Vf5nAty+mXbUAIAQAoLS3FqVOn8OabbwIA9Hq9/DdixAhcu3YNp0+fBgDs2rULwcHB8Pb2btF3+fv7Y9WqVZg7dy4OHTqEurq6Juvs3bsXAOS7hA3GjBkDOzs7o1vBvr6+6Nq1q/zZ2toaPXv2bPPb1sDjZxOfdODAAVRWViIhIcHg+D169AhhYWEoKipCTU0NamtrodPpMHr0aNja2hod69raWhw6dKjN+0tEL86AAQOgUCjg4OCAsLAwODs7Y/v27QbPJmzevBkBAQGwt7eHlZUVFAoFMjMzcfLkSaP2goOD4eDgIH92dXWFi4uLnMtqampQVFSEyMhIWFtby+UcHBwwatQog7aeJ4+6u7vLnxty/dChQw2e+WiIt0V+3bt3L0JCQtClSxeDeGJiIu7du4eDBw8axJ83/wLPdy4ioh+PNWvWoKioyODvf//7n7xdpVJh06ZNqKiowOuvvw4hBNavXw9LS8sWfc/TeQwA7t69i2nTpqF79+6wsrKClZUV7O3tUVNTY/Jc0Vovy7Usp1+2Uk1NDSoqKtCnTx95us7UqVMxdepUk+Vv3rwJ4PHzCE8+gNlcGzduxNy5c7Fy5UrMnDkT9vb2GD16NNLT06HVak3WqaiogJWVldEta0mSoNVqjaZudujQwagNlUqF+/fvt7i/TXFzczP43HAMo6KiGq1TWVkJCwsL6PV6ZGRkICMjw2S5hmNNROZhzZo18Pb2RnV1NTZu3Ijly5dj7Nix2LVrFwAgJycH0dHRGDNmDD744ANotVpYWVlh6dKlJp/7bSqX3bp1C48ePTKZO5+OtTSPajQag89KpfKZ8draWuMD0kIVFRVGORUAOnfuLG9/0vPmXzs7u+c6FxHRj4e3t3eTC6V0794dQ4YMQV5eHpKTk03mr6aYqhMXFwedToeZM2eiX79+cHR0hCRJGDFixCt9LctBXSvl5eWhvr4eQ4cOlefopqamIjIy0mT5Xr16AXg8J/jy5cst/r6OHTti8eLFWLx4MS5evIgdO3Zg+vTpuHHjBvLz803W6dChA/R6PcrLyw0uSIQQKCsrQ79+/Vrcj7by9IPzDccwIyOj0dWFXF1dodfrYWlpifHjx2PSpEkmy3l5ebVtZ4nohXryIiA4OBj19fVYuXIlvvzyS0RFRSE7OxteXl7YuHGjQe548ODBc32fs7MzJElCWVmZ0banYy9zHm3QoUMHXLt2zSh+9epVADB6juR5829D2Zaei4iInrRy5Urk5eXB398fn332GWJiYtC/f/8WtfF0Hrtz5w5yc3ORlpaG6dOny/GGZ7JfhJflWpaDula4ePEipk6dCrVajbfffhudOnVCjx49UFxcjHnz5j2z7vDhw7F27VqcPn1aHui1VNeuXTF58mTodDr897//bbRcSEgI0tPTkZ2djSlTpsjxLVu2oKamRn5Y82UQEBAAJycnlJSUYPLkyY2WUyqVCA4OxtGjR+Hj4yP/2k1Er4709HRs2bIFs2bNQmRkJCRJglKpNDiBlpWVmVz9sjkaVp/MycnBwoUL5SmY1dXV2Llzp0FZc8ijISEh2Lp1K65evSrfnQMe3wG1tbVt8hU5zc2/T2vsXPSiZngQkfk7duwY3n33XcTHx2PFihUYNGgQYmJicPToUfm9pA2LT7Ukj0iSBCGEwcJVwOMBZH19fdvtwDO017UsB3XNdPz4cXme640bN/D1118jKysLlpaW2Lp1q/zL7fLlyzF8+HCEhoYiMTER7u7uqKysxMmTJ3HkyBFs3rwZAPDpp59i165dCAwMxIwZM9CnTx/cvn0b+fn5eP/9902+sPHOnTsIDg5GXFwcevfuDQcHBxQVFSE/P7/RO4MAMGzYMISGhmLatGmoqqpCQECAvGqbn58fxo8f/2IO2nOwt7dHRkYGEhISUFlZiaioKLi4uKC8vBzFxcUoLy/H0qVLAQBLlizB4MGDMWTIECQnJ8PT0xPV1dUoLS3Fzp075WdgiMg8OTs7IzU1FR9++CH++c9/YuTIkcjJycHvf/97REVF4dKlS5gzZw7c3Nxw5syZ5/qOOXPmICwsDMOGDUNKSgrq6+uxYMEC2NnZGfyqaw55NC0tDbm5uQgODsasWbOg0Wiwbt065OXlIT09HWq1+pn1m5t/m3su6tOnD3JycrB06VK88cYbsLCw+MHfW0VE7aPhuvlp3bp1g62tLaKjo+Hl5YUvvvgCSqUSmzZtwuuvv4633noL27ZtA/D4+WYPDw9s374dISEh0Gg06Nixo9Fru57k6OiIwMBALFy4UC5bWFiIzMxMODk5vZidfUq7Xcs2e0mVH6mnV/FRKpXCxcVFBAUFiXnz5okbN24Y1SkuLhbR0dHCxcVFKBQKodVqxS9/+UuxbNkyg3KXLl0SSUlJQqvVCoVCITp37iyio6PF9evXhRDGq1/W1taKd955R/j4+AhHR0dhY2MjevXqJdLS0gxWU3t69UshHq9gOW3aNOHh4SEUCoVwc3MTycnJ4tatWwblPDw8RHh4uNE+BQUFiaCgoJYfQPHsFYM2b95ssk5hYaEIDw8XGo1GKBQK4e7uLsLDw43Knzt3TiQlJQl3d3ehUChEp06dxKBBg8TcuXOfq69E9MN71irD9+/fF127dhU9evQQer1ezJ8/X3h6egqVSiW8vb3FihUr5FXQngQTq0MK8TjHJSQkGMR27NghfHx8hFKpFF27dhXz58832WZr86ipPpnKj83R2P4dO3ZMjBo1SqjVaqFUKkXfvn0NVlAWovX5t7nnosrKShEVFSWcnJyEJElGx5OIXj3PWv0SgFixYoUYN26csLW1FSdOnDCou3nzZgFALFq0SI7t2bNH+Pn5CZVKJQDI+bshR5eXlxv14fLly+K3v/2tcHZ2Fg4ODiIsLEwcP37cZP5vLnO4lpWE+P+lG4mIiIiIiMjs8JUGREREREREZozP1FGLmZoj/SQLCwtYWPD3AiKilhBCNPkgv6WlpdFKa0RE1DKv4rWsefWWXgoKheKZf0lJSe3dRSIis1NYWNhkfl29enV7d5OIyOy9iteyvFNHLVZUVPTM7U+/C4mIiJr2xhtvNJlf+f5NIqLWexWvZblQChERERERkRnj9EsiIiIiIiIzxkEdERERERGRGeOgjoiIiIiIyIxxUEdERERERGTGOKgjIqIfFU9PT3h6erZ3N4y8rP0iIqKXHwd1RET0yoiPj4ckSdBqtU2+XNYcfPLJJ5AkCfv27WvvrhAR0UuMgzoiInolVFVVYcuWLZAkCdevX0deXl57d6lFdDoddDpde3eDiIjMEAd1RET0Sli/fj3u3buHlJQUSJKEzMzM9u5Si3Tr1g3dunVr724QEZEZ4qCOiIheCZmZmVAqlUhNTUVAQAD+9a9/4dq1a82uf/PmTUycOBEuLi6wtbVFv379sHXrVqxatQqSJGHVqlVGdXJzcxEcHAy1Wg0bGxv4+vpi8eLFqK+vNyh3/vx5SJKExMREnDp1CpGRkejYsSMkScL58+cBGD9TN3ToUMyePRsAEBwcDEmSIEmSQZmGOnfu3EFycjLc3NxgZ2eHwMBAHDlyBABQVlaGhIQEeb9CQ0NRWlpq8hgcOHAA4eHh0Gg0sLa2Ru/evfHJJ5/g3r17zT6ORET0w7Nq7w4QERG11rFjx1BUVITRo0dDo9EgPj4e//nPf7B69WpMnz69yfp3795FUFAQSkpKMHjwYAwePBhXrlzB2LFj8etf/9pknSVLluC9996DRqNBXFwc7OzssHPnTkyZMgVff/01vvzyS0iSZFCntLQUAwYMwM9+9jMkJCSgsrISSqXSZPuJiYkAgMLCQiQkJMiDOScnJ4NyDx8+xLBhw1BbW4uYmBhcv34dmzZtwq9+9SscOHAAYWFh0Gq1GDduHEpLS7Fz506MHDkSJ06cgKWlpdzOli1bEBsbC6VSiZiYGLi4uGDPnj2YPXs2/v3vf6OgoAAqlarJY0lERO1AEBERmbk//OEPAoDIyckRQghx+/ZtYW1tLXr06GFU1sPDQ3h4eBjEPv74YwFATJo0ySBeUFAgAAgAIisrS46fPXtWWFlZCRcXF3Hx4kU5/uDBAxEUFCQAiLVr18rxc+fOye3MnDnT5D6Y6ldaWpoAIAoKChqtA0CMGTNG1NXVyfH58+cLAMLJyUlMmTJFPHr0SN6WnJxscKyEEKKqqko4OTkJlUoliouL5fijR49EXFycACDmzJljsg9ERNT+OP2SiIjM2sOHD5GdnQ1nZ2eEh4cDANRqNSIiInDmzBns37+/yTays7OhUqmQlpZmEB86dChCQ0ONyq9btw56vR4pKSno0qWLHFcqlZg/fz4AmJyuqdVq8fHHH7dk95pl4cKFsLL6fvJNXFwcAECv12POnDkGdwzHjh0LACguLpZj27Ztw+3bt5GUlAQfHx85LkkS5s+fDysrK5P7Q0RELwcO6oiIyKxt27YNFRUViImJMZjKGB8fDwD4xz/+8cz6VVVVOH/+PLp3745OnToZbR80aJBR7OjRowAeD/qeNmDAANjY2ODbb7812ta3b99Gp1s+LycnJ3h4eBjE3NzcAAA9evSAnZ2dyW1XrlyRY8/any5duqBbt244e/Ysqqur27LrRETURjioIyIis9YwaBs/frxBPDQ0FFqtFps3b0ZVVVWj9Ru2mRrQAYCrq2ujdUxtAwAXFxfcuXOnWW21llqtNoo13LVzdHRsdFtdXZ0ca2p/tFqtQTkiInq5cFBHRERm69KlS/jqq68AAAEBAfIKkZIkwcrKCmVlZbh37x42bNjQaBsNA5/y8nKT269fv95oHVPbAODGjRsmB1RPL5zysmhqfxripvaJiIjaH1e/JCIis5WVlYVHjx5h8ODB6NWrl9H2hw8fYu3atcjMzMTEiRNNtuHo6AhPT0+UlpaivLzc6I7dgQMHjOr4+flh69at2LdvH/z9/Q22ffPNN7h//z4GDhzYij17rGF1yqdfkdDW/Pz8AAD79u1DdHS0wbYrV67g7NmzeO211+Dg4PBC+0FERM+Hd+qIiMgsCSGQlZUFSZKwZs0arFy50uhvzZo18PPzwzfffIPjx4832tabb76JBw8eyO+Fa7Bv3z7s3r3bqHxcXBysrKzw17/+FVevXpXjdXV18isUGl5J0BoajQYAcPny5Va39SwRERFQq9XIysrCiRMn5LgQAqmpqairq2uT/SEioheDd+qIiMgs6XQ6nD9/HsHBwfDy8mq03FtvvYWjR48iMzMTixYtMllm2rRp2LJlCz7//HN89913GDx4MC5fvoxNmzZh1KhR2LlzJywsvv8dtFu3bliwYAFSUlLg4+OD6Oho2NnZITc3F6dOnUJERATGjRvX6n1seOn4Rx99hFOnTkGtVkOtViM5ObnVbT/J0dERK1aswNixY9G/f3/ExMSgU6dO0Ol0OHz4MPz9/fHBBx+06XcSEVHb4Z06IiIyS5mZmQCApKSkZ5aLi4uDUqlEdnY2Hj58aLKMg4MD9u/fjwkTJuDkyZNYtGgRSkpKsH79egQFBQEwfp7s/fffx/bt2/Hzn/8c2dnZyMjIgEKhwF/+8heTLx5/Hj/96U+RlZUFjUaDRYsWITU1FQsWLGh1u6aMGTMGBQUFCAwMRE5ODhYtWoSqqirMnDkTe/fuhbW19Qv5XiIiaj1JCCHauxNEREQvq3HjxmHdunUoKSmBt7d3e3eHiIjICO/UERERAbh27ZpRrLCwEBs2bECvXr04oCMiopcWn6kjIiICMGLECNjY2MDX1xd2dnYoKSlBfn4+LC0tkZGR0d7dIyIiahSnXxIREQFYvHgx1q1bh7Nnz6K6uhpOTk4ICAhAamoq+vfv397dIyIiahQHdURERERERGaMz9QRERERERGZMQ7qiIiIiIiIzBgHdURERERERGaMgzoiIiIiIiIzxkEdERERERGRGeOgjoiIiIiIyIxxUEdERERERGTGOKgjIiIiIiIyY/8H8itWo4uArqgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "algoritmo=[\"Decision_Tree\",\"Random_forest\",\"Extra_Tree\"]\n",
    "accuracy=[0.8686,0.8695,0.8582]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(algoritmo, accuracy, marker='o', linestyle='-', color='r')\n",
    "plt.title(' Accuracy su testSet al Variare dell algoritmo')\n",
    "plt.xlabel('Algoritmo')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.grid(True)\n",
    "plt.xticks(algoritmo)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2cac543",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
