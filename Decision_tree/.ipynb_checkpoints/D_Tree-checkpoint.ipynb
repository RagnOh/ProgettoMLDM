{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86789fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "#importo libreria panda per leggere ed elaborare csv\n",
    "import pandas as pd\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"decision_trees\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
    "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)\n",
    "\n",
    "from sklearn.model_selection import (\n",
    "    GridSearchCV,\n",
    "    StratifiedKFold,\n",
    "    cross_val_score,\n",
    "    train_test_split,\n",
    ")\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ff2e821",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=pd.read_csv('/Users/ragno/Documents/Progetti/Mldm/ProgettoMLDM/Dataset/train_data.csv')\n",
    "test_data=pd.read_csv('/Users/ragno/Documents/Progetti/Mldm/ProgettoMLDM/Dataset/test_data.csv')\n",
    "y_train=pd.read_csv('/Users/ragno/Documents/Progetti/Mldm/ProgettoMLDM/Dataset/train_y.csv')\n",
    "y_test=pd.read_csv('/Users/ragno/Documents/Progetti/Mldm/ProgettoMLDM/Dataset/test_y.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34e752bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "column = ['criterion', 'max_depth', 'ccp_alpha', 'min_samples_leaf', 'min_samples_split', 'accuracy']\n",
    "column_bar = ['try', 'Parameter_changed', 'Accuracy']\n",
    "\n",
    "def plot_depthsVSaccuracy(depths, ccp_alpha, title):\n",
    "  accs = pd.DataFrame(columns=column)\n",
    "  for d in depths:\n",
    "    tree_clf = DecisionTreeClassifier(criterion='log_loss',max_depth=d, min_samples_leaf=4, ccp_alpha=ccp_alpha,min_samples_split=8 )\n",
    "    tree_clf.fit(train_data, y_train)\n",
    "    testset_score = tree_clf.score(test_data, y_test)\n",
    "    row = pd.DataFrame(data=[['log_loss', d, ccp_alpha, 4, 8 ,testset_score]], columns=column)\n",
    "    accs = pd.concat([accs, row])\n",
    "\n",
    "  # plot\n",
    "  fig, ax = plt.subplots()\n",
    "  ax.plot(accs.max_depth, accs.accuracy)\n",
    "\n",
    "  ax.set(xlabel='Max depth', ylabel='Accuracy',\n",
    "        title=title)\n",
    "  ax.grid()\n",
    "  plt.show()\n",
    "\n",
    "### Create a single row equivalent to a single try for decision tree\n",
    "def create_bar_row(criterion, depth, leaf, ccp, split, attempt, parameter):\n",
    "  tree_clf = DecisionTreeClassifier(criterion=criterion,max_depth=depth, min_samples_leaf=leaf, ccp_alpha=ccp,min_samples_split=split )\n",
    "  tree_clf.fit(train_data, y_train)\n",
    "  testset_score = tree_clf.score(test_data, y_test)\n",
    "  row = pd.DataFrame(data=[[attempt, parameter, testset_score]], columns=column_bar)\n",
    "  return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "efa3b0b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAksAAAHLCAYAAADY5dxHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAAB4+ElEQVR4nO3dd1gUV9sG8HtZlt4EBKUIYi9gRSyxoGCLJkJiwVjRWGMv0diNiUZfY0k0MUbFmIjRKPYSVDQmdo0i9gaKoDTpSNmd7w/Cfq67VMEt3L/r4ko4M3PmeRiEhzNnzogEQRBARERERCrpqTsAIiIiIk3GYomIiIioCCyWiIiIiIrAYomIiIioCCyWiIiIiIrAYomIiIioCCyWiIiIiIrAYomIiIioCCyWiIiIiIrAYom0kp+fH4yNjZGcnFzoPp988gkkEglevHjx1ueLjIyESCRCUFDQW/elyqlTpyASiXDq1KkK6Z80Q2JiImbPno2GDRvC1NQUlpaWqF+/PgYPHozw8HD5fkFBQRCJRIV+vP594urqCpFIhDFjxiidr+D76o8//pC3FdVvwcfChQuV+kpISIChoSFEIhEuX75c4pzfzEVfXx9OTk4YPnw4nj17phRrwYdYLEbVqlXRu3dvlefr1KkTGjdurPKcCQkJSnkUxGFkZISoqKgS9efq6opevXoptBXEt2zZskJzVRXv33//jYCAANSoUQOGhoYwNTVFo0aNMG3aNNy5c0dlHqQ59NUdAFFZjBgxAnv37sX27dsxbtw4pe0pKSkICQlBr169YG9v/9bnq169Os6dO4datWq9dV+qNG/eHOfOnUPDhg0rpH9Sv/T0dLRu3Rrp6emYMWMGmjRpgqysLNy7dw979uzBtWvX4OHhoXDMli1bUL9+faW+VH2fbNq0CVOmTEG9evWKjOPcuXMq2/Py8jBkyBA8e/YMPXv2VNq+bds25OTkyM/VsmXLIs/zpoJcsrKy8Ndff2Hp0qU4ffo0bty4AVNTU/l+X3/9Nby9vZGbm4t///0XixYtQseOHXHt2jXUqVOnVOdUJTs7G3PnzsW2bdveqp9ly5Zh1KhRsLa2LnbfuXPn4quvvkKbNm0wd+5c1KlTB3l5eQgPD8fWrVvx7bffIi8vD2Kx+K1iogokEGmhvLw8wcHBQWjRooXK7T/88IMAQDhw4MBbn+fVq1dv1QepR0ZGhrpDULB582YBgHDy5EmV26VSqfz/t2zZIgAQLl26VGy/Li4uQps2bQRLS0vB399fYVtYWJgAQNi1a1ex/UyYMEEAIGzYsEHl9saNGwt2dnaCp6enYGlpKWRmZhbbZ1G5zJs3TwAg/Prrr0XGunXrVgGAMH/+fIX2jh07Co0aNVJ5zvj4eAGAsGDBAqU4unfvLujp6QnXrl0rtj8XFxfh/fffV2gDIPj4+Aj6+vrC1KlTi811+/btAgBhzJgxgkwmU4pVJpMJ33//vZCXl6cyF9IMvA1HWkksFmPo0KG4cuUKbty4obR9y5YtqF69Onr06IH4+HiMGzcODRs2hJmZGezs7NC5c2ecOXNG4ZiCW23Lly/HkiVLULNmTRgaGiIsLEzlbbgHDx5g+PDhqFOnDkxMTODo6IjevXsrxdOpU6dCb3cU9FfYbbj9+/ejTZs2MDExgbm5OXx9fZVGBhYuXAiRSISbN28iICAAlpaWsLe3R2BgIFJSUhT2FQQB69evR9OmTWFsbIwqVarg448/xqNHj4r9mpc0XwBITk7GtGnT4ObmBkNDQ9jZ2aFnz54Ktxuys7OxePFiNGjQAEZGRrCxsYG3tzfOnj2rcD1U3fp88xZLwdfg6tWr+Pjjj1GlShX5KODly5cxYMAAuLq6wtjYGK6urggICFB5K+bZs2cYNWoUnJ2dYWBgAAcHB3z88cd48eIF0tPTYWVlhdGjRysdFxkZCbFYjBUrVhT69UtMTASQP0qpip5e2X8cW1tbY9asWdizZw/Onz9f6uO3bduG7777DiNGjMCoUaOUtl+4cAEREREYPHgwPv30U6SkpGD37t1ljhcAWrduDQAqr8PrCkawyuN2OgDMnDkTNjY2+Pzzz8vcR7169TBixAisW7eu2PiXLFkCW1tbrFq1CiKRSGm7SCTC+PHjOaqk4VgskdYKDAyESCTC5s2bFdpv3bqFixcvYujQoRCLxUhKSgIALFiwAIcOHcKWLVvg5uaGTp06qZwjtHbtWpw8eRL/+9//cOTIEZW3QQAgJiYGNjY2WLZsGY4ePYp169ZBX18fXl5euHv3rny/9evX49y5cwofPj4+EIvFRd4y2b59Oz788ENYWFggODgYmzZtwsuXL9GpUyf8/fffSvt/9NFHqFu3Lnbv3o1Zs2Zh+/btmDJlisI+o0ePxuTJk+Hj44O9e/di/fr1uHnzJtq2bVvsL6OS5puWlob33nsPGzZswPDhw3HgwAH8+OOPqFu3LmJjYwHk3/Lp0aMHvvzyS/Tq1QshISEICgpC27Zt8eTJkyLjKIq/vz9q166NXbt24ccffwSQX8jUq1cPq1evxrFjx/DNN98gNjYWnp6eSEhIkB/77NkzeHp6IiQkBFOnTsWRI0ewevVqWFpa4uXLlzAzM0NgYCB+++03pSJ0/fr1MDAwQGBgYKGxtWnTBgAwZMgQ7N27V148FUUqlSIvL0/hQyqVqtx30qRJcHR0xMyZM4vt93X//vsvRo8eDU9PT6xbt07lPps2bQKQ/29uwIABMDExkbeV1YMHDwAAVatWLXK/x48fAwDq1q37VucrYG5ujrlz5+LYsWM4efJkmftZuHAhxGIx5s2bV+g+MTExuHXrFnx9fWFkZFTmc5EGUPfQFtHb6Nixo2Brayvk5OTI26ZNmyYAEO7du6fymLy8PCE3N1fo0qWL4OfnJ29//PixAECoVauWQn+vb9uyZUuhseTl5Qk5OTlCnTp1hClTphS634oVKwQAwk8//SRvK7gFERYWJghC/i0ZBwcHwd3dXeH2TFpammBnZye0bdtW3rZgwQIBgLB8+XKF84wbN04wMjKSD/2fO3dOACCsXLlSYb+nT58KxsbGwsyZMwuNuTT5Ll68WAAghIaGFnrsL7/8IgAQNm7cWOg+RX3N8cYtloKvwZu3agqLOz09XTA1NRXWrFkjbw8MDBQkEolw69atQo99+PChoKenJ6xatUrelpWVJdjY2AjDhw8v9tyLFy8WDAwMBAACAKFmzZrCmDFjhOvXryvsV3A7R9WHWCxW2Pf1W0UbN25UuP1c3G24+Ph4wcXFRahatarw5MkTlftkZGQIFhYWQuvWreVtQ4cOFUQikfDgwYNicy7I5fz580Jubq6QlpYmHDx4UKhatapgbm4uPH/+XCHW33//XcjNzRUyMzOFf/75R6hXr57QsGFD4eXLlwr9lvU23KVLl4Ts7GzBzc1NaNmypfzfR2luw40fP14QBEGYM2eOoKenJ79+b96GO3/+vABAmDVrllKMBT+HCj5U3aIjzcGRJdJqI0aMQEJCAvbv3w8gf8Ti119/Rfv27RUmg/74449o3rw5jIyMoK+vD4lEghMnTuD27dtKfX7wwQeQSCTFnjsvLw9ff/01GjZsCAMDA+jr68PAwAD3799X2S8ABAcHY+bMmZg7dy4+/fTTQvu+e/cuYmJiMHjwYIXbM2ZmZvjoo49w/vx5ZGZmKsX9Og8PD7x69QpxcXEAgIMHD0IkEmHQoEEKIxXVqlVDkyZNin0Sr6T5HjlyBHXr1oWPj0+hfR05cgRGRkZFjsSUxUcffaTUlp6ejs8//xy1a9eGvr4+9PX1YWZmhoyMDKW4vb290aBBg0L7d3NzQ69evbB+/XoIggAgfwQwMTERn332WbHxzZs3D0+ePMHmzZsxevRomJmZ4ccff0SLFi0QHBystP8vv/yCS5cuKXxcuHCh0P6HDx+Ohg0bYtasWZDJZEXGIpVKMWDAAERHR+P333+Hs7Ozyv127tyJ1NRUhWsVGBgIQRCwZcuWYnMu0Lp1a0gkEpibm6NXr16oVq0ajhw5ovQARv/+/SGRSGBiYoJ27dohNTUVhw4dgpWVVYnPVRwDAwMsWbIEly9fxs6dO8vcz8yZM2FtbV2mW3o2NjaQSCTyj7e9rUkVi8USabWPP/4YlpaW8h/ahw8fxosXLzBixAj5Pt9++y3Gjh0LLy8v7N69G+fPn8elS5fQvXt3ZGVlKfVZ2JySN02dOhXz5s1Dnz59cODAAVy4cAGXLl2SP+X0prCwMAwbNgxDhgzBl19+WWTfRc1vcXBwgEwmw8uXLxXabWxsFD43NDQEAHksL168gCAIsLe3V/ghLZFIcP78eYVbUm+Tb3x8PJycnIrsKz4+Hg4ODm81T0cVVV+vgQMH4vvvv8fIkSNx7NgxXLx4EZcuXULVqlVLHTeQf7vr/v37CA0NBQCsW7cObdq0QfPmzUsUo729PYYPH44ff/wR4eHhOH36NAwMDDBp0iSlfRs0aICWLVsqfLRo0aLQvsViMb7++mvcvHkTW7duLTKOmTNn4sSJE/jmm2/g7e1d6H6bNm2CkZERunfvjuTkZCQnJ8PDwwOurq4ICgoq9LbgmwoKv3///RcxMTEIDw9Hu3btlPb75ptvcOnSJZw+fRpz5szBixcv0KdPH2RnZyvsp6+vX+i58/LyAKDIP3oGDBiA5s2bY86cOcjNzS1RDm+ysLDA3LlzcfToUYSFhSltLyhAVc1rOnXqFC5duiS/XUyajUsHkFYzNjZGQEAANm7ciNjYWGzevBnm5ubo27evfJ9ff/0VnTp1wg8//KBwbFpamso+VU3CVOXXX3/FkCFD8PXXXyu0JyQkKP0VHB4ejj59+qBjx47YuHFjsX0XFD4Fc3xeFxMTAz09PVSpUqVEcRawtbWFSCTCmTNn5IXU61S1va6k+VatWhXR0dFF9lW1alX8/fffkMlkhRZMBXM83vwlWdRcnzevXUpKCg4ePIgFCxZg1qxZ8vbs7Gz5XLbSxA0AnTt3RuPGjfH999/DzMwMV69exa+//lrscYXp0KEDunbtir179yIuLg52dnZl7gsAPvzwQ7Rr1w4LFizATz/9pHKf4OBgfPvtt+jfvz+mTZtWaF/37t2Tz4+rUaOGyn2OHTumcqmBNxUUfsVxc3OT79ehQwcYGxtj7ty5+O677zB9+nT5fvb29rh06RIEQVC67gXrNxW1bIhIJMI333wDX1/fQr9OJTF27FisWbMGn3/+OcaOHauwzcHBAY0aNUJoaChevXqlMG+padOmAPJHPknzcWSJtN6IESMglUqxYsUKHD58WD4BtYBIJFIqBMLDwwtdb6akVPV76NAhhYX2AODJkyfo0aMH3NzcsHv37hLd4qtXrx4cHR2xfft2+e0eAMjIyMDu3bvlT8iVRq9evSAIAp49e6Y0WtGyZUu4u7sXeXxJ8+3Rowfu3btX5OTZHj164NWrV0Uu8mlvbw8jIyOFxRoBYN++fUXG+WbMgiAoxf3zzz8rjUr06NEDYWFhCpPVCzNx4kQcOnQIs2fPhr29vUJxXpgXL16ovDUmlUpx//59mJiYlNutpm+++QZPnz7F2rVrlbaFh4dj5MiRaNy4cbGTtAu2b9y4EWFhYQofhw8fhkQiUXrAorzNnDkTtWvXxrJlyxT+wPHx8UFqaiqOHj2qdMzOnTuhp6eHzp07F9m3j48PfH19sXjx4jIXLQW39C5duoRdu3YpbZ8zZw4SEhIwdepUhX/LpF04skRar2XLlvDw8MDq1ashCILCLTggv0j48ssvsWDBAnTs2BF3797F4sWLUbNmTflwfVn06tULQUFBqF+/Pjw8PHDlyhWsWLFC6VZOjx49kJycjO+//x43b95U2FarVi2VTwPp6elh+fLl+OSTT9CrVy+MHj0a2dnZWLFiBZKTk1WuHlycdu3aYdSoURg+fDguX76MDh06wNTUFLGxsfj777/h7u6u9JdxWfKdPHkyfv/9d3z44YeYNWsWWrVqhaysLJw+fRq9evWCt7c3AgICsGXLFowZMwZ3796Ft7c3ZDIZLly4gAYNGmDAgAHy+VWbN29GrVq10KRJE1y8eBHbt28vcc4WFhbo0KEDVqxYAVtbW7i6uuL06dPYtGmTUmGyePFiHDlyBB06dMAXX3wBd3d3JCcn4+jRo5g6darCU5GDBg3C7Nmz8ddff2Hu3LkwMDAoNpZt27Zhw4YNGDhwIDw9PWFpaYno6Gj8/PPPuHnzJubPn6/UT0REhMrv0cK+bwq0a9cOH374oVJh+fLlS/ktrc8//1zlsg9A/iibi4sLfvnlFzRo0AAjR45UuV/v3r2xf/9+xMfHF/tUW1lJJBJ8/fXX6NevH9asWYO5c+cCyF+hf/369ejXrx9mzZoFT09PZGVl4fDhw9i4cSMmTJgANze3Yvv/5ptv0KJFC8TFxaFRo0ZlijEgIED+9KyqbTdv3sRXX32F69evY9iwYahTpw5kMhmePn0qXxzT3Ny8TOemd0RtU8uJytGaNWsEAELDhg2VtmVnZwvTp08XHB0dBSMjI6F58+bC3r17haFDhwouLi7y/QqevlqxYoVSH6qezHr58qUwYsQIwc7OTjAxMRHee+894cyZM0LHjh2Fjh07yvdDIU81vd7fm0/DFdi7d6/g5eUlGBkZCaampkKXLl2Ef/75R2GfgifB4uPjFdoLnsx5/PixQvvmzZsFLy8vwdTUVDA2NhZq1aolDBkyRLh8+XLhX+BS5Fuw76RJk4QaNWoIEolEsLOzE95//33hzp078n2ysrKE+fPnC3Xq1BEMDAwEGxsboXPnzsLZs2fl+6SkpAgjR44U7O3tBVNTU6F3795CZGRkoU/Dvfk1EARBiI6OFj766COhSpUqgrm5udC9e3chIiJCcHFxEYYOHaqw79OnT4XAwEChWrVqgkQiERwcHIR+/foJL168UOp32LBhgr6+vhAdHV3k163ArVu3hGnTpgktW7YUqlatKujr6wtVqlQROnbsKGzbtk1h36KehsMbTxGqemKr4HxisVjhabiC77PiPoYOHSrs3btXACCsXr260JyOHj2q8glLVbkUt8BmcU/ueXl5CVWqVBGSk5PlbampqcLMmTPl30MmJiZCy5YthR9//FHp6bKi4hg4cKAAoNRPw73uzz//lH/9VJ3jr7/+Evr37y84OTkJEolEMDExERo2bCiMHTu22H97pH4iQeC4IBFRaeTk5MDV1RXvvffeWz1NRUTagbfhiIhKKD4+Hnfv3sWWLVvw4sULhUnjRKS7WCwREZXQoUOHMHz4cFSvXh3r168v8XIBRKTdeBuOiIiIqAhcOoCIiIioCCyWiIiIiIrAYomIiIioCJzg/ZZkMhliYmJgbm5e4tdkEBERkXoJgoC0tLQSvaeSxdJbiomJKfRt3URERKTZnj59WuxLtFksvaWCJeqfPn0KCwuLcu07NzcXf/75J7p27Vqi94lpG13PD9D9HJmf9tP1HJmf9quoHFNTU+Hs7FyiV81oZLGUnp6OuXPnYufOnUhKSkL9+vUxa9YsDBgwoNhjw8LC8PXXX+P69evIzMyEm5sbRo4cifHjx0MsFgMAIiMjUbNmzUL76Natm8qXM6pScOvNwsKiQoolExMTWFhY6OQ/Al3PD9D9HJmf9tP1HJmf9qvoHEsyhUYjiyV/f39cunQJy5YtQ926dbF9+3YEBARAJpNh4MCBhR53/PhxdOvWDR06dMDGjRthamqK/fv3Y9KkSXj48CHWrFkDAKhevbrKN87v3bsX33zzDfz8/CosNyIiItIuGlcsHT58GKGhofICCQC8vb0RFRWFGTNmoH///vIRojcFBQVBIpHg4MGDMDU1BQD4+Pjg7t27CAoKkhdLhoaGaN26tdLxs2fPhomJify8RERERBq3dEBISAjMzMzQt29fhfbhw4cjJiYGFy5cKPRYiUQCAwMDGBsbK7RbWVnByMioyPM+fPgQp0+fRr9+/cr9dhoRERFpL40rliIiItCgQQPo6ysOenl4eMi3F2bMmDHIycnBxIkTERMTg+TkZGzbtg0hISGYOXNmkefdvHkzBEHAyJEj3z4JIiIi0hkadxsuMTERbm5uSu3W1tby7YXx8vLCyZMn0bdvX6xbtw4AIBaLsXTpUkybNq3Q46RSKbZu3Yr69eujXbt2RcaXnZ2N7Oxs+eepqakA8ieg5ebmFnlsaRX0V979agpdzw/Q/RyZn/bT9RyZn/arqBxL05/GFUtA0TPTi9p25coV+Pn5wcvLCxs2bICpqSlOnjyJuXPn4tWrV5g3b57K444ePYpnz55hxYoVxca2dOlSLFq0SKn9zz//hImJSbHHl0VoaGiF9KspdD0/QPdzZH7aT9dzZH7ar7xzzMzMLPG+Glcs2djYqBw9SkpKAvD/I0yqjB8/Hvb29ggJCZFPAvf29oaenh4WLlyITz75ROWo1aZNmyCRSDBkyJBi45s9ezamTp0q/7xgnYauXbtWyNIBoaGh8PX11clHQnU9P0D3c2R+2k/Xc2R+2q+iciy4M1QSGlcsubu7Izg4GHl5eQrzlm7cuAEAaNy4caHHXrt2DQEBAUpPy3l6ekImk+H27dtKxVJcXBwOHjyIDz74AHZ2dsXGZ2hoCENDQ6V2iURSYd+oFdm3JtD1/ADdz5H5aT9dz5H5ab/yzrE0fWncBG8/Pz+kp6dj9+7dCu1bt26Fg4MDvLy8Cj3WwcEBly9fhlQqVWgvWFNJ1XLmv/zyC3JzczFixIhyiJ6IiIh0jcaNLPXo0QO+vr4YO3YsUlNTUbt2bQQHB+Po0aP49ddf5aNGI0aMwNatW/Hw4UO4uLgAAKZMmYKJEyeid+/eGD16NExMTHDixAmsXLkSPj4+aNKkidL5Nm3aBGdnZ3Tr1u2d5klERETaQeOKJQDYs2cP5syZg/nz58tfdxIcHKzwuhOpVAqpVApBEORtEyZMgKOjI1atWoWRI0ciKysLrq6uWLBgAaZMmaJ0nrNnz+LOnTuYP39+sW8cJiIiospJI4slMzMzrFmzRr7itipBQUEICgpSavf394e/v3+JztO2bVuFYouIiIjoTRxO0WBXnyQjR1r8fkRERFRxNHJkiYD07DwM2XIZgkyMsMzr6NXEEd717GBsoPq9eERERFQxWCxpqCeJmahqZoDo5Fc4HPEChyNewFgiRucGdnjfvToLJyIioneExZKGauhggZNT22PDriNIsayNozdfIPplFg6Fx+JQeCwLJyIioneExZIGE4lEqGEG9OxWF3Peb4gbz1Lyi6UbsSoLJ7+mjujSwK7IV8IQERFR6bBY0hIikQgeTlbwcLLCrB718wunG/nF0uuF09A2LpjfuxHEeiyYiIiIygOLJS2kUDh1zy+cQv59hqCzkdh6Lgrx6dn4tl9TGEl4a46IiOhtcekALVdQOC3o3QjfBTSDgVgPh288x5DNF5GSlavu8IiIiLQeiyUd0svDAUGBnjA31MfFx0no9+M5xKZkqTssIiIircZiSce0rWWLnWPawM7cEHdfpMF//Vnce5Gm7rCIiIi0FoslHdSgugX2jGuLWlVNEZvyCh//cBaXIpPUHRYREZFWYrGko5yqmOCPMW3RvIYVUl/l4ZOfL+BoxHN1h0VERKR1WCzpsCqmBvhtZGv4NLBHTp4M4367gm3no9QdFhERkVZhsaTjjA3E+HFQcwS0qgGZAMzbG4H/HbsLQRDUHRoREZFWYLFUCeiL9fC1X2NM8akLAPg+7AFm/hGOXKlMzZERERFpPhZLlYRIJMIknzpY6u8OPRGw60o0PvqBT8oREREVh8VSJRPQqgZ+GtwSFkb6CI9OQa+1f2Nd2APkcZSJiIhIJRZLlZBPQ3uETu2ILvXtkCOVYcWxu/DnKBMREZFKLJYqKXsLI/w8tCW+7deEo0xERERFYLFUiYlEIvg3d+IoExERURFYLBFHmYiIiIrAYokAcJSJiIioMCyWSEFho0zBF5+oOzQiIiK1YLFESlSNMs3bG4Hw6GR1h0ZERPTOsViiQhWMMr3vXh15MgFTfr+GrBypusMiIiJ6p1gsUZFEIhGW9GkMO3NDPIzPwDdH76g7JCIioneKxRIVq4qpAVb0bQIACDobib/uxas5IiIioneHxRKVSMe6VTG0jQsAYMYf15GcmaPmiIiIiN4NFktUYrN6NIBbVVO8SM3GnL0REARB3SERERFVOBZLVGLGBmKs7t8U+noiHAqPxb5rMeoOiYiIqMKxWKJS8XCywsQudQAA8/ZF4FlylpojIiIiqlgslqjUxnWqhWY1rJD2Kg/Td16HTMbbcUREpLtYLFGp6Yv1sKpfUxhLxDj3KBGb/3ms7pCIiIgqDIslKhNXW1PM69UQALD82F3cfc73xxERkW5isURlFtDKGZ3r2yEnT4bJv19Ddh5X9yYiIt3DYonKTCQSYdlH7rA2NcDt2FSsPn5f3SERERGVOxZL9FbszI3wtZ87AODH0w9xKTJJzRERERGVLxZL9Na6N66Gvi2cIAjAlN+vIe1VrrpDIiIiKjcslqhcLPigEZytjRH9MguLD9xSdzhERETlhsUSlQszQ318268pRCJg15Vo/HElWt0hERERlQsWS1RuPF2tMblLXQDAnJAbiHiWouaIiIiI3h6LJSpXEzrXRpf6dsjOk2H0tit4mZGj7pCIiIjeCoslKld6eiJ8278pXGxM8Cw5CxN3/AspX4dCRERajMUSlTtLYwk2DG4BY4kYZ+4n4NvQu+oOiYiIqMxYLFGFqF/NAss+yl9/aV3YQxy7+VzNEREREZUNiyWqMB82dURgu5oAgGk7r+NhfLqaIyIiIio9FktUoWb3rI9WNa2Rnp2HMduuID07T90hERERlQqLJapQErEe1g1sDnsLQ9yPS8fMP65DEDjhm4iItAeLJapwVc0Nsf6TFpCIRTh84zk2nnmk7pCIiIhKjMUSvRMtXKpgfu9GAIBlR+7g7IMENUdERERUMiyW6J0Z5FUDH7dwgkwAPgv+FzHJWeoOiYiIqFgsluidEYlEWNKnMRo7WiApIwcTdlxHrkzdURERERWNxRK9U0YSMX74pAWsTCQIf5aK3Y/5LUhERJqNv6nonXO2NsHaAc0gEgHn4vSw5WyUukMiIiIqFIslUosOdatium8dAMDXR+5i37Vnao6IiIhINY0sltLT0zF58mQ4ODjAyMgITZs2xY4dO0p0bFhYGHx9fWFnZwczMzN4eHhg7dq1kEqlSvtmZGRg/vz5qFu3LgwNDWFjYwNvb2/cv3+/vFMiFT59zxUdquVPWpq+6zr+uhev5oiIiIiU6as7AFX8/f1x6dIlLFu2DHXr1sX27dsREBAAmUyGgQMHFnrc8ePH0a1bN3To0AEbN26Eqakp9u/fj0mTJuHhw4dYs2aNfN/09HR4e3sjJiYGs2bNgoeHB1JSUnD27FlkZma+izQrPZFIBD9XGcxtHXAo4jnG/HoFO0a1hoeTlbpDIyIiktO4Yunw4cMIDQ2VF0gA4O3tjaioKMyYMQP9+/eHWCxWeWxQUBAkEgkOHjwIU1NTAICPjw/u3r2LoKAghWJp7ty5uH37NsLDw+Hm5iZv/+CDDyowO3qTngj45qPGSHmVh78fJGD4lkv4Y2xb1LQ1VXdoREREADTwNlxISAjMzMzQt29fhfbhw4cjJiYGFy5cKPRYiUQCAwMDGBsbK7RbWVnByMhI/nlmZiZ+/vln9O3bV6FQIvUw1NfDj4NboLGjBRIzcjBk8wXEpb5Sd1hEREQANHBkKSIiAg0aNIC+vmJoHh4e8u1t27ZVeeyYMWMQHByMiRMn4osvvoCJiQkOHDiAkJAQLF26VL7flStXkJGRgTp16mDs2LHYsWMHMjIy4OHhgUWLFuH9998vNL7s7GxkZ2fLP09NTQUA5ObmIjc3t8x5q1LQX3n3qylez89QIsHGQc3Qf+NFPEnKwpDNF7F9REuYG0nUHOXbqUzXUBfpen6A7ufI/LRfReVYmv5Egoa91bRu3bpwc3PD0aNHFdpjY2Ph4OCAr7/+GrNnzy70+LNnz6Jv376IiYkBAIjFYixduhQzZsyQ77Njxw4EBATAwsIC7u7u+Pzzz6Gnp4eVK1fi1KlTOHLkCLp166ay/4ULF2LRokVK7du3b4eJiUlZUqbXJLwCVkeIkZYrQm0LGcY0kEGiceOfRESk7TIzMzFw4ECkpKTAwsKiyH01bmQJyJ/4W5ZtV65cgZ+fH7y8vLBhwwaYmpri5MmTmDt3Ll69eoV58+YBAGSy/CewDAwMcOTIEZibmwPInxtVp04dfPnll4UWS7Nnz8bUqVPln6empsLZ2Rldu3Yt9otdWrm5uQgNDYWvry8kEu0eYVGlsPxatE7FJ5sv4UEqEJpWDWv6N4FYr/Drrskq6zXUFbqeH6D7OTI/7VdRORbcGSoJjSuWbGxskJiYqNSelJQEALC2ti702PHjx8Pe3h4hISHySeDe3t7Q09PDwoUL8cknn8DNzQ02NjYAgLZt28oLJQAwMTFBx44dsXfv3kLPYWhoCENDQ6V2iURSYd+oFdm3Jngzv6YuNtg4uCWGbbmEY7fi8OXhu1jSp3GRhbKmq2zXUNfoen6A7ufI/LRfeedYmr407gaHu7s7bt++jby8PIX2GzduAAAaN25c6LHXrl1DixYtlJ6W8/T0hEwmw+3btwH8//wnVQRBgJ6exn1ZKp22tW2xqn9TiETAbxeeYO2JB+oOiYiIKimNqwr8/PyQnp6O3bt3K7Rv3boVDg4O8PLyKvRYBwcHXL58WWkBynPnzgEAnJycAADVq1dHmzZt8M8//ygMw2VmZuL06dNo3bp1eaVDb+F9j+pY9EEjAMCq4/fw2wW+FoWIiN49jSuWevToAV9fX4wdOxYbN25EWFgYRo0ahaNHj2L58uXyUaMRI0ZAX18fUVH//wt0ypQpiIiIQO/evbFv3z6EhoZi1qxZWL58OXx8fNCkSRP5vv/73/+QlpaGbt26Ye/evdi3bx+6d++OhIQEfPnll+88b1JtSBtXTOhcGwAwb28E/rz5XM0RERFRZaNxxRIA7NmzB4MHD8b8+fPRvXt3XLhwAcHBwfjkk0/k+0ilUkilUrz+MN+ECROwe/dupKWlYeTIkfDz88PBgwexYMECpXlIbdu2xYkTJ2BoaIhPPvkEAwcOhEQiwalTp9CmTZt3lSqVwFTfuhjg6QyZAEz+/RruPC/5pDwiIqK3pXETvAHAzMwMa9asUVhx+01BQUEICgpSavf394e/v3+JzvPee+/h1KlTZYyS3hWRSIQlfRrjSVImzj5MxKe/XMb+8e+hiqmBukMjIqJKQCNHlojepC/Ww7qBzeFsbYynSVkYv/0q8qQydYdFRESVAIsl0hpVTA2wcUhLmBiIcfZhIpYcuq3ukIiIqBJgsURapX41C3zbrykAIOhsJHZeeqregIiISOexWCKt071xNUz2qQMAmLs3AleiXqo5IiIi0mUslkgrTexcB90a2SNHKsOYX6/gecordYdEREQ6isUSaSU9PRG+7dcU9ezNEZ+WjdHbLuNVrrT4A4mIiEqJxRJpLVNDfWwc0hJWJhJcj07B7D03FNbdIiIiKg8slkir1bAxwfqBzSHWEyHk32fY9PdjdYdEREQ6hsUSab22tW0x7/0GAICvD9/G6Xvxao6IiIh0CYsl0glD27qiX0snyARgwvareJyQoe6QiIhIR7BYIp0gEonwZZ/GaF7DCqmv8vDpL5eR9ipX3WEREZEOYLFEOsNQX4wfB7VANQsjPIhLx6w9N9QdEhER6QAWS6RT7CyMsGFwC4hEwKHwWEQl8nYcERG9HRZLpHOaOFuhQ52qAIAdfB0KERG9JRZLpJMCWtUAAOy6HI1cqUzN0RARkTZjsUQ6qUsDO9iaGSIhPRsnbr9QdzhERKTFWCyRTpKI9dCvpRMAYPtF3oojIqKyY7FEOqu/pzMA4Mz9eDxNylRzNEREpK1YLJHOcrExxXu1bSEIwM7LHF0iIqKyYbFEOm1Aq/zRpZ2XnyKPE72JiKgMWCyRTuvasBpsTA3wIjUbYXf5zjgiIio9Fkuk0wz09fBxi/yJ3jsuPlFzNEREpI1YLJHOK5joHXY3DjHJWWqOhoiItA2LJdJ5blXN0NrNGjJO9CYiojJgsUSVQsGK3jsvPYVUJqg5GiIi0iYslqhS6NaoGqxMJIhJeYW/7nGiNxERlRyLJaoUjCRi+DfLn+gdzIneRERUCiyWqNII+G/NpRN34hCX+krN0RARkbZgsUSVRh17c7R0qQKpTMCuK9HqDoeIiLQEiyWqVAomegdffAIZJ3oTEVEJsFiiSuV9j+qwMNJH9Mss/P0gQd3hEBGRFmCxRJWKkUQMv2aOAIAdlzjRm4iIisdiiSqdAK/8W3F/3nyB+LRsNUdDRESajsUSVTr1q1mgqbMV8mQCdl/lRG8iIioaiyWqlAb+N9F7x8UnEARO9CYiosKxWKJKqVeT6jAz1EdkYibOPUpUdzhERKTBWCxRpWRioI8PmzoAAIIv8uW6RERUOBZLVGkVrLl0LOI5kjJy1BwNERFpKhZLVGk1drSEu6MlcqQy7OFEbyIiKgSLJarUBvz3vrjtnOhNRESFYLFEldoHTRxgYiDGo/gMhN2NU3c4RESkgVgsUaVmbiTB4NYuAICVf97j6BIRESlhsUSV3uiOtWBqIMbNmFQcu/lc3eEQEZGGYbFElZ61qQFGvFcTAPBt6D1IZRxdIiKi/8diiQjAiPZusDDSx70X6TgYHqPucIiISIOwWCICYGksweiOtQAAq0LvIVcqU3NERESkKVgsEf1nWFtXWJsaIDIxk+suERGRHIslov+YGupjXKf80aW1Jx4gO0+q5oiIiEgTsFgies2g1i6wtzDEs+Qs/H6J74wjIiIWS0QKjCRifNa5DgDgu5MPkJXD0SUiosqOxRLRG/q3dIajlTHi07Lx6/kodYdDRERqxmKJ6A0G+nqY5JM/uvTD6YdIz85Tc0RERKROLJaIVPBv5oiatqZIysjBlr8fqzscIiJSIxZLRCroi/Uw+b/RpZ/OPEJKZq6aIyIiInVhsURUiN4eDqhnb460V3nYeOaRusMhIiI10chiKT09HZMnT4aDgwOMjIzQtGlT7Nixo0THhoWFwdfXF3Z2djAzM4OHhwfWrl0LqVTxqaZOnTpBJBIpfXTv3r0iUiItpKcnwtSudQEAm/95jMT0bDVHRERE6qCv7gBU8ff3x6VLl7Bs2TLUrVsX27dvR0BAAGQyGQYOHFjoccePH0e3bt3QoUMHbNy4Eaampti/fz8mTZqEhw8fYs2aNQr7u7m54bffflNos7KyqoiUSEt1bWgPd0dL3HiWgh9PP8Sc9xuqOyQiInrHNK5YOnz4MEJDQ+UFEgB4e3sjKioKM2bMQP/+/SEWi1UeGxQUBIlEgoMHD8LU1BQA4OPjg7t37yIoKEipWDI2Nkbr1q0rNiHSaiKRCNO61sWwLZfwy7kojGzvBnsLI3WHRURE75DG3YYLCQmBmZkZ+vbtq9A+fPhwxMTE4MKFC4UeK5FIYGBgAGNjY4V2KysrGBnxFxyVTce6VdHSpQqy82T4/uQDdYdDRETvmMaNLEVERKBBgwbQ11cMzcPDQ769bdu2Ko8dM2YMgoODMXHiRHzxxRcwMTHBgQMHEBISgqVLlyrt//DhQ1hbWyM1NRUuLi4YMGAA5s6dq1RsvS47OxvZ2f8/dyU1NRUAkJubi9zc8n1iqqC/8u5XU2hTfpO71MKgzZex49ITBLatAacqhX+PvE6bciwL5qf9dD1H5qf9KirH0vQnEgRBKO0JEhISYGtrW9rDSqRu3bpwc3PD0aNHFdpjY2Ph4OCAr7/+GrNnzy70+LNnz6Jv376IiYkBAIjFYixduhQzZsxQ2G/u3LlwdHRE/fr1kZWVhSNHjuDHH39E27ZtERYWBj091YNuCxcuxKJFi5Tat2/fDhMTk9KmS1pk3S093EvRg1dVGQbWlqk7HCIieguZmZkYOHAgUlJSYGFhUeS+ZRpZcnJywocffoiRI0fC19e3TEEWRSQSlWnblStX4OfnBy8vL2zYsAGmpqY4efIk5s6di1evXmHevHnyfZcsWaJwbM+ePeHq6orp06dj37598PPzU3mO2bNnY+rUqfLPU1NT4ezsjK5duxb7xS6t3NxchIaGwtfXFxKJpFz71gTall9192T0++kiLieK8eXA9qhpa1rsMdqWY2kxP+2n6zkyP+1XUTkW3BkqiTIVSx4eHti1axf++OMP1KhRAyNGjMDw4cPh6OhYlu4U2NjYIDExUak9KSkJAGBtbV3osePHj4e9vT1CQkLkk8C9vb2hp6eHhQsX4pNPPoGbm1uhxw8aNAjTp0/H+fPnCy2WDA0NYWhoqNQukUgq7Bu1IvvWBNqSXyu3quhS3w4n7sRhyZF72Drcs8ji/XXakmNZMT/tp+s5Mj/tV945lqavMk3wvnjxIsLDw/HZZ58hLS0N8+fPh6urKz744APs378fMlnZb1G4u7vj9u3byMtTfB/XjRs3AACNGzcu9Nhr166hRYsWSk/LeXp6QiaT4fbt2yWKobBbcERz3m8AA7Ee/roXj4PhseoOh4iI3oEyVwWNGzfGmjVrEBMTg+3bt6Njx444dOgQ/Pz84OzsjDlz5uDRo9Kveuzn54f09HTs3r1boX3r1q1wcHCAl5dXocc6ODjg8uXLSgtQnjt3DkD+7cOibN26FQC4nAAVyq2qGcZ71wYALDpwCylZujupkoiI8r31EIqBgQEGDBiA48eP4+HDh5gzZw6kUql8QUlfX1/s3r0bJZ1H3qNHD/j6+mLs2LHYuHEjwsLCMGrUKBw9ehTLly+XjxqNGDEC+vr6iIqKkh87ZcoUREREoHfv3ti3bx9CQ0Mxa9YsLF++HD4+PmjSpAkA4MyZM+jevTs2bNiA0NBQHDhwAOPGjcMXX3yBzp07o3fv3m/7ZSEdNqaTG9yqmiIhPRsrjt1RdzhERFTBym3pAEEQEBERgfDwcCQmJkIQBDg4OOD06dM4efIkGjdujD/++AN16tQptq89e/Zgzpw5mD9/PpKSklC/fn0EBwdjwIAB8n2kUimkUqlCETZhwgQ4Ojpi1apVGDlyJLKysuDq6ooFCxZgypQp8v2qV68OsViML7/8EgkJCRCJRKhTpw4WL16MadOm8TYcFclQX4yv+rgjYON5/HbhCfyaOaGFSxV1h0VERBXkrYulx48fY9OmTQgKCkJsbCz09fXRp08fjB49Gj4+PoiNjcWqVauwatUqjB07FsePHy+2TzMzM6xZs0Zpxe3XBQUFISgoSKnd398f/v7+RfZfu3ZtHDp0qNg4iArTppYNPm7hhD+uRGNOyA0cmPAeJGIW2UREuqhMxVJubi52796Nn3/+GadOnYJMJkPNmjXx1VdfITAwEHZ2dvJ9q1evjuXLlyMtLQ3btm0rt8CJ1O2Lng1w4vYL3Hmehs1/P8bojrXUHRIREVWAMhVLDg4OSEpKglgslo8iFbfekouLCzIzM8sUJJEmsjY1wBc9G2DGH+FYdfweerpXh7M1FyYlItI1ZbpvYGZmhiVLluDp06f4448/SrQw5bhx4/D48eOynI5IY33cwgleNa3xKleG+fsiSvwgAxERaY8yjSw9evSoxIvxFbCwsCj3Fa6J1E0kEuErP3f0WPMXwu7G40jEc/R0r67usIiIqByVaWQpNTUV4eHhhd5Wy8jIQHh4eKmWEifSVrXtzDC2U/7aSwv330TqK669RESkS8pULC1evBht27ZVWvyxgFQqRbt27fDVV1+9VXBE2mJcp1qoaWuKuLRsrDx2V93hEBFROSpTsXT06FF07doV5ubmKrdbWFigW7duOHz48FsFR6QtjCRifNUn/1U8v5yPwrWnyeoNiIiIyk2ZiqUnT54Uu7hkrVq18OTJkzIFRaSN2ta2hX8zRwgC8MWeG8iTlv0diUREpDnKVCyJRCJkZ2cXuU92dnaht+mIdNWc9xvAykSCW7GpCDobqe5wiIioHJSpWGrQoAGOHj1a6GPSMpkMR44cQb169d4qOCJtY2NmiNk96gMAVv55DzHJWWqOiIiI3laZiqWBAwfi3r17CAwMREpKisK2lJQUBAYG4sGDBxg0aFC5BEmkTfq2cEYrV2tk5Uqx6OAdcOklIiLtVqZ1lsaNG4c9e/Zg69at2LdvHzw9PeHo6Ihnz57h0qVLSE5ORocOHfDZZ5+Vd7xEGk9PT4Sv/Bqj59ozOHk3Hq51RXhf3UEREVGZlWlkSSKR4M8//8T06dMhk8kQGhqKoKAghIaGQiaTYcaMGTh27BgkEkl5x0ukFerYm2N0h/x3xe2J1ENWDufvERFpqzK/Jt3Q0BDLly9HUlISIiIi8PfffyMiIgKJiYn45ptvYGhoWJ5xEmmdzzrXhqOVEZJzRPjpDF/1Q0SkrcpcLMk70NNDw4YN0bZtWzRs2BBisbg84iLSekYSMWZ1z3/IYePfkXiaxBdJExFpo7culoiocN0a2qGOhQzZeTJ8ffi2usMhIqIyKNMEbwBIS0vD999/j+PHjyMmJkbluksikQgPHz58qwCJtJlIJIJ/TRn+d0OMIxHP8c+DBLSrbavusIiIqBTKVCzFx8ejbdu2ePjwISwsLJCamgpLS0vk5OQgKyt/XRkHBwdO8CYC4GACDGzljG3nn2DRgZs4NLE9JGIO6hIRaYsy/cReuHAhHj58iF9++QUvX74EAEyZMgUZGRm4cOECWrVqBVdXV9y8ebNcgyXSVpM610IVEwnuvUjHr+ej1B0OERGVQpmKpcOHD6NLly4YNGgQRCKRwjZPT08cOXIEkZGRWLhwYXnESKT1LI0lmNEtf2Xvb0PvITG96NcFERGR5ihTsRQbG4tmzZrJPxeLxfLbbwBQpUoV9OjRA7t27Xr7CIl0RH9PZzRysEDaqzz878+76g6HiIhKqEzFkqWlJXJzc+WfV6lSBdHR0Qr7WFhY4MWLF28XHZEOEeuJsOiDRgCAHZee4kZ0SjFHEBGRJihTseTm5obIyEj5582aNUNoaCiSkpIAAFlZWThw4ABq1KhRLkES6YqWrtbo09QBggAs2B9R6MuoiYhIc5SpWOratStOnDiBzMz8RfZGjx6NuLg4NGnSBH379kXjxo3x8OFDDBs2rDxjJdIJs3o0gImBGFefJGPvtWfqDoeIiIpRpmJpzJgx2Lhxo7xY8vf3x4oVK5Ceno7du3fj+fPnmDp1KmbMmFGuwRLpgmqWRvisc20AwNLDd5CenafmiIiIqChlKpaqV6+O/v37w9b2/xfXmzZtGhISEhAbG4v09HSsWLGCrz4hKsSI92rCxcYEcWnZWBf2QN3hEBFREcpULAUGBmL16tVK7WKxGPb29krLCRCRIkN9Mea93xAAsOnMYzxOyFBzREREVJgyFUvbt2/nk25Eb6lLAzt0rFsVOVIZlhy8pe5wiIioEGUqlmrXro3Y2NjyjoWoUhGJRJjfuyH09UQ4cScOYXfi1B0SERGpUKZiacSIETh06BCePeOTPERvo1ZVMwS+VxMAsPjgLeTkydQcERERvalMxZKfnx+8vLzQtm1brFu3DhcvXkRUVBSePHmi9EFERZvQuTZszQzxOCEDW/55rO5wiIjoDfplOcjNzQ0ikQiCIGDixImF7icSiZCXx8eiiYpibiTBrB71MX3XdXx/8gEGt3GBiUGZ/mkSEVEFKNNP5CFDhvCJN6Jy5N/MEd+fvI/IxEwcCo9F35bO6g6JiIj+U6ZiKSgoqJzDIKrc9PRE6NvSGSuO3cXOy09ZLBERaZAyzVkiovL3cQsn6ImAS5Ev8SAuXd3hEBHRf1gsEWkIewsjdK5vBwDYdfmpmqMhIqICZZ7gXRIikQgPHz4syymIKqV+LZ1x/HYcdl+NxvRu9SAR8+8ZIiJ1K9NPYplMBkEQlD6Sk5MRGRmJyMhIZGdnQybjmjFEpeFd3w62ZoZISM/BSS5SSUSkEco0shQZGVnktqlTp+LFixcIDQ0ta1xElZJErIePWjhiw+lH2HnpKbo1qqbukIiIKr1yH+N3dXXF77//jpcvX2LOnDnl3T2Rzuv335NwYXfj8CL1lZqjISKiCpkQIZFI4Ovri507d1ZE90Q6rVZVM3i6VoFMAP64Eq3ucIiIKr0Kmz2amZmJpKSkiuqeSKcVjC7tvPwUMpmg5miIiCq3CimW/vrrLwQHB6NevXoV0T2RznvfozrMDPURlZiJC4/5RwcRkTqVaYJ3586dVbbn5eXh2bNniIyMhCAImDt37lsFR1RZmRjoo3eT6gi++BQ7Lz9Fm1o26g6JiKjSKlOxdOrUKZXtIpEIVapUga+vL6ZMmYJu3bq9TWxElVq/ls4IvvgUh2/EYuEHjWBpLFF3SERElVKZiiWun0RU8Zo6W6GevTnuvkjD/usxGNzaRd0hERFVSlwemEhDiUQi9PP8b6L3Jb7+hIhIXcpULKWkpCA8PByZmZkqt2dkZCA8PBypqalvFRxRZefXzBESsQg3nqXgZkyKusMhIqqUylQsLV68GG3btoVUKlW5XSqVol27dvjqq6/eKjiiys7a1ABdG+av4s3RJSIi9ShTsXT06FF07doV5ubmKrdbWFigW7duOHz48FsFR0SQ34rbey0Gr3JV/4FCREQVp0zF0pMnT1CnTp0i96lVqxaePHlSpqCI6P+9V9sWDpZGSMnKxbGbz9UdDhFRpVOmYkkkEiE7O7vIfbKzswu9TUdEJSfWE+Hj11b0JiKid6tMxVKDBg1w9OhRCILq1zDIZDIcOXKEK3gTlZO+LZwgEgH/PEjE0yTVD1YQEVHFKFOxNHDgQNy7dw+BgYFISVF8QiclJQWBgYF48OABBg0aVC5BElV2ztYmaFfLFgCwi6NLRETvVJmKpXHjxqF9+/bYunUratasiW7duiEwMBDdunVDzZo18csvv6B9+/b47LPPyhRUeno6Jk+eDAcHBxgZGaFp06bYsWNHiY4NCwuDr68v7OzsYGZmBg8PD6xdu7bIW4JZWVmoW7cuRCIR/ve//5UpZqKKVjDRe9eVaEj5cl0ionemTMWSRCLBn3/+ienTp0MmkyE0NBRBQUEIDQ2FTCbDjBkzcOzYMUgkZXs9g7+/P7Zu3YoFCxbgyJEj8PT0REBAALZv317kccePH4ePjw/y8vKwceNG7N27F506dcKkSZMwderUQo+bN28eMjIyyhQr0bvStaE9rEwkiE15hb/ux6s7HCKiSqNMrzsBAENDQyxfvhzLli3DnTt3kJycDCsrK9SrVw9isbjMAR0+fBihoaHYvn07AgICAADe3t6IiorCjBkz0L9//0L7DwoKgkQiwcGDB2FqagoA8PHxwd27dxEUFIQ1a9YoHXPx4kV89913+O2339C3b98yx01U0YwkYvRp6oigs5HYeekpvOvZqTskIqJK4a1fd6Knp4eGDRuibdu2aNiw4VsVSgAQEhICMzMzpcJl+PDhiImJwYULFwo9ViKRwMDAAMbGxgrtVlZWMDIyUto/JycHgYGBGD9+PFq2bPlWcRO9C/3/uxV3/PYLJKYX/UQqERGVjzIVS7du3cLatWsRH6/6VkBcXBzWrl2L27dvl7rviIgINGjQAPr6ioNeHh4e8u2FGTNmDHJycjBx4kTExMQgOTkZ27ZtQ0hICGbOnKm0/+LFi5GRkYEvv/yy1HESqUOD6hbwcLJErlRAyL/P1B0OEVGlUKbbcMuWLcOJEycKncBtY2ODFStW4N9//8WWLVtK1XdiYiLc3NyU2q2treXbC+Pl5YWTJ0+ib9++WLduHQBALBZj6dKlmDZtmsK+165dw/Lly3HgwAGYmpoWWvi9KTs7W2GNqYL33+Xm5iI3N7dEfZRUQX/l3a+m0PX8gIrJ8aNmDgiPTsGOi08wxMsJIpGo3PouLV2/hrqeH6D7OTI/7VdROZamvzIVS2fOnEGXLl2gp6d6YEosFqNLly7466+/ytJ9kT/8i9p25coV+Pn5wcvLCxs2bICpqSlOnjyJuXPn4tWrV5g3bx4AIC8vD4GBgejfvz+6detWqtiWLl2KRYsWKbX/+eefMDExKVVfJRUaGloh/WoKXc8PKN8cDfMAiZ4YD+IzsO73I3CzKLeuy0zXr6Gu5wfofo7MT/uVd46ZmSVfs65MxdLz58/h7Oxc5D6Ojo6IjY0tdd82NjYqR4+SkpIA/P8Ikyrjx4+Hvb09QkJC5HOnvL29oaenh4ULF+KTTz6Bm5sbVq9ejUePHmHnzp1ITk4G8P8jRK9evUJycjLMzc1Vzr+aPXu2wpN1qampcHZ2RteuXWFhUb6/tXJzcxEaGgpfX98yP1moyXQ9P6DicrwsvYk/rj7DXTjis55Nyq3f0tL1a6jr+QG6nyPz034VlWPB7/2SKFOxZGpqiri4uCL3iYuLUzmpujju7u4IDg5GXl6ewrylGzduAAAaN25c6LHXrl1DQECAUpHj6ekJmUyG27dvw83NDREREUhJSVH5frt58+Zh3rx5+Pfff9G0aVOl7YaGhjA0NFRql0gkFfaNWpF9awJdzw8o/xw/7VALf1x9hj9vvcDztFw4W1fMqGZJ6fo11PX8AN3Pkflpv/LOsTR9lWmCd4sWLbB37175qMybXr58iZCQEDRv3rzUffv5+SE9PR27d+9WaN+6dSscHBzg5eVV6LEODg64fPmy0gKU586dAwA4OTkBAGbNmoWwsDCFj+DgYAD5k8TDwsJQu3btUsdO9K7Uq2aO9nVsIROALf9EqjscIiKdVqZiafz48UhMTIS3t7fSvKTTp0/D29sbL1++LNMK3j169ICvry/Gjh2LjRs3IiwsDKNGjcLRo0exfPly+ajRiBEjoK+vj6ioKPmxU6ZMQUREBHr37o19+/YhNDQUs2bNwvLly+Hj44MmTfJvV9SvXx+dOnVS+GjdujUAoFatWujUqRPMzMzK8qUhemdGvFcTQP7LdVNf6e7kTiIidSvTbbgPPvgA06dPx//+9z94e3vD0NAQ1apVw/Pnz5GdnQ1BEDB9+nT06dOnTEHt2bMHc+bMwfz585GUlIT69esjODgYAwYMkO8jlUohlUoVXuY7YcIEODo6YtWqVRg5ciSysrLg6uqKBQsWYMqUKWWKhUhTdaxbFXXszHA/Lh07Lz3FyPbKT5ESEdHbK/MK3suXL0enTp2wbt06XLp0CdHR0bCyskLnzp0xfvx49OjRQ2neUUmZmZlhzZo1KlfcLhAUFISgoCCldn9/f/j7+5f6nK6urgqFF5GmE4lEGPFeTczacwNb/onEsLau0Be/9TqzRET0hrf6ydqzZ08cOnQIcXFxyMnJQVxcHA4ePAgXFxdMmzZNPkeIiCpGn2aOsDE1wLPkLBy9+Vzd4RAR6aRy+zM0PT0dP//8M9q0aQN3d3esWrWq0AngRFQ+jCRifNLaBQDw85nHao6GiEg3vXWx9PfffyMwMBDVq1fH6NGjceHCBTRt2hRr165FTExMecRIREUY3NoFBmI9XHuajCtRL9UdDhGRzinTnKUXL15g69at2Lx5M+7fvw9BEFCtWjVkZGRgyJAhKucSEVHFqGpuiD7NHLDzcjQ2/f0ILVxaqDskIiKdUuKRJZlMhgMHDqBPnz5wdnbGrFmz8OTJE/Tr1w+HDh3C06dPAQAGBgYVFiwRqTbivfwn4Y5GPMfTpJIv4U9ERMUr8ciSk5MTXrx4AQBo164dhgwZgn79+pX7Kz6IqPQKFqk8cz8BW/6JxPzeDdUdEhGRzijxyNLz588hEokwffp07N+/HyNHjmShRKRBCtZZ+v3SEy5SSURUjkpcLA0aNAhGRkb43//+h+rVq6Nv377Yv38/8vLyKjI+IiqhDnVsUcfODBk5Uuy89FTd4RAR6YwSF0u//PILYmNjsX79eri7u2P37t3w8/NDtWrV8Nlnn+H8+fMVGScRFaNgkUog/31xeVKZmiMiItINpVo6wNzcHKNHj8bFixcRHh6OCRMmQCQSYf369WjXrh1EIhHu3r2LJ0+eVFS8RFQELlJJRFT+yrzOUuPGjbF69WrExMRgx44d8PX1hUgkwpkzZ+Dm5gZfX18EBweXZ6xEVAwjiRiD/lukcuOZx3yFDxFROXjrRSklEgn69euHo0ePIjIyEgsXLkSNGjVw4sQJDBo0qDxiJKJSGNTaBQb6erj+NBlXn3CRSiKit1Wub910cnLC/Pnz8ejRI/z555/o379/eXZPRCVQ1dwQfZo6AAA2/c1XoBARva0Ke0W5j48Ptm/fXlHdE1ERuEglEVH5qbBiiYjUp2CRSpmQ/2QcERGVHYslIh3FRSqJiMoHiyUiHfX6IpW/X+QilUREZcViiUhHiUQijGyfv0hl0FkuUklEVFYsloh02IdN/3+RyoPhseoOh4hIK7FYItJhRhIxhrV1BQAsPngLcamv1BsQEZEWYrFEpONGdXRDw+oWSMrIwbRd1yGTcVVvIqLSYLFEpOMM9cVYG9AURhI9nLmfwIUqiYhKicUSUSVQ284c83o1BAAsP3YHEc9S1BwREZH2YLFEVEkMbFUDXRvaI1cqYOKOf5GZk6fukIiItAKLJaJKQiQS4ZuPPGBvYYhH8Rn48uBtdYdERKQVWCwRVSJVTA3wbb+mEImA4ItPcDTiubpDIiLSeCyWiCqZdrVtMapD/qtQZu0JR2xKlpojIiLSbCyWiCqhab714O5oieTMXEz9/TqkXE6AiKhQLJaIKiEDfT2sGdAUxhIxzj1KxE9/PVJ3SEREGovFElEl5VbVDAs/yF9OYOWfdxEenazegIiINBSLJaJKrF9LZ/R0r4Y8mYBJO64hI5vLCRARvYnFElElJhKJsNTPA9UtjfA4IQOLDtxUd0hERBqHxRJRJWdpIsGq/vnLCey8HI1D4bHqDomISKOwWCIitHazwbhOtQAAs/eE41kylxMgIirAYomIAACTfeqiibMVUl/lYdrOa5BxOQEiIgAslojoPxKxHtb+t5zA+UdJ2HHpqbpDIiLSCCyWiEjOxcYU07vVAwAsPXybq3sTEYHFEhG9YVhbVzR1tkJadh7mhkRAEHg7jogqNxZLRKRArCfC8o89IBGLcOJOHA7w6TgiquRYLBGRkrr25vjMuw4AYOH+m0hMz1ZzRERE6sNiiYhUGtupFurZmyMpIweLD95SdzhERGrDYomIVDLQ18M3H3tATwTsuxaDE7dfqDskIiK1YLFERIVq6myFEe/VBADMCYlA2qtcNUdERPTusVgioiJN9a0HFxsTPE99hWVH7qg7HCKid47FEhEVydhAjKX+7gCA3y48wflHiWqOiIjo3WKxRETFalvLFgGtagAAZu0Ox6tcqZojIiJ6d1gsEVGJzO5ZH/YWhohMzMSq4/fUHQ4R0TvDYomISsTCSIKv+uTfjtv41yOERyerNyAioneExRIRlZhPQ3v0buIAmQDM/CMcuVKZukMiIqpwLJaIqFQW9G6IKiYS3Hmeho1nItUdDhFRhWOxRESlYmtmiAW9GwEAvj/1EM8z1RwQEVEFY7FERKX2YVMHeNerilypgO0PxUjJ4mKVRKS7WCwRUamJRCJ85ecOM0N9RKWL0Gf9OVx7mqzusIiIKgSLJSIqEwcrY2wb3hI2hgKik1+h749nsfnvxxAEQd2hERGVKxZLRFRmjR0tMMNDim4N7ZArFbD44C2M3nYFKZm8LUdEukMji6X09HRMnjwZDg4OMDIyQtOmTbFjx44SHRsWFgZfX1/Y2dnBzMwMHh4eWLt2LaRSxRWH58yZg2bNmsHa2hpGRkZwc3PDqFGjEBUVVREpEeksY33guwFNsPjDRjAQ6+HPWy/w/ndneFuOiHSGRhZL/v7+2Lp1KxYsWIAjR47A09MTAQEB2L59e5HHHT9+HD4+PsjLy8PGjRuxd+9edOrUCZMmTcLUqVMV9k1OTkZAQAC2bt2Ko0ePYvr06Th48CC8vLyQmMh3XxGVhkgkwpA2rtg9ti1qWJsg+mUW+v54Fpt4W46IdIC+ugN40+HDhxEaGort27cjICAAAODt7Y2oqCjMmDED/fv3h1gsVnlsUFAQJBIJDh48CFNTUwCAj48P7t69i6CgIKxZs0a+77p16xSO7dSpE2rWrImePXti3759CAwMrKAMiXSXu5MlDk58D7N2h+Pwjef48uAtXHiUiBUfN4GliUTd4RERlYnGjSyFhITAzMwMffv2VWgfPnw4YmJicOHChUKPlUgkMDAwgLGxsUK7lZUVjIyMij131apVAQD6+hpXQxJpDQsjCdYNbK5wW67nWt6WIyLtpXHFUkREBBo0aKBUsHh4eMi3F2bMmDHIycnBxIkTERMTg+TkZGzbtg0hISGYOXOmymPy8vKQlZWFf//9F5MnT0bdunXh7+9ffgkRVUJv3pZ7lszbckSkvTRuCCUxMRFubm5K7dbW1vLthfHy8sLJkyfRt29f+W02sViMpUuXYtq0aUr7P3/+HNWrV1c4PiwsDGZmZoWeIzs7G9nZ2fLPU1NTAQC5ubnIzS3fJ4AK+ivvfjWFrucH6H6OxeVX394Ee8d64Yu9t3D05gt8efAWHsenYV7P+tDTE73LUMtE168foPs5Mj/tV1E5lqY/kaBhf+bVrVsXtWrVwpEjRxTaY2Nj4eDggKVLl2LWrFkqj71y5Qp69uwJLy8vjBo1Cqampjh58iSWL1+OuXPnYt68eQr75+Xl4dq1a8jOzsbt27exfPlyiEQinDp1SqGIet3ChQuxaNEipfbt27fDxMSkjFkT6TZBAE4/F2FvpB4EiOBVVYYBtWTQgnqJiHRUZmYmBg4ciJSUFFhYWBS5r8YVS23atIFUKsXFixcV2m/evInGjRtjw4YNGDVqlMpjW7dujczMTPz7778Kk8AXLFiAJUuW4P79+ypHrQpER0ejZs2aGDdunMJk8NepGllydnZGQkJCsV/s0srNzUVoaCh8fX0hkeje5Fhdzw/Q/RxLm9++azH4POQmpDIB77tXw4qPGkMi1rjZAHK6fv0A3c+R+Wm/isoxNTUVtra2JSqWNO42nLu7O4KDg5GXl6cwb+nGjRsAgMaNGxd67LVr1xAQEKD0tJynpydkMhlu375dZLHk5OQEBwcH3Lt3r9B9DA0NYWhoqNQukUgq7Bu1IvvWBLqeH6D7OZY0v489XWBqZICJO/7FoRvPkSMV8P3AZjDUV/2Eq6bQ9esH6H6OzE/7lXeOpelL4/6k8/PzQ3p6Onbv3q3QvnXrVjg4OMDLy6vQYx0cHHD58mWlBSjPnTsHIL8YKsqDBw8QHR2N2rVrlzF6IipOD/fq+GlwSxjo6yH01guM3HoZWTnS4g8kIlITjSuWevToAV9fX4wdOxYbN25EWFgYRo0ahaNHj2L58uXyUaMRI0ZAX19fYcXtKVOmICIiAr1798a+ffsQGhqKWbNmYfny5fDx8UGTJk0AAOHh4ejSpQt++OEHHDt2DKGhofj222/h7e0NGxsbTJ8+XS25E1UW3vXtsGWYJ4wlYpy5n4ChWy4iPTtP3WEREamkcbfhAGDPnj2YM2cO5s+fj6SkJNSvXx/BwcEYMGCAfB+pVAqpVKrwGPKECRPg6OiIVatWYeTIkcjKyoKrqysWLFiAKVOmyPezt7eHg4MDVq5cidjYWOTl5cHJyQm9evXCF198AWdn53eaL1Fl1K62LbaNaIXhWy7h4uMkDPr5ArYOb8XFK4lI42hksWRmZoY1a9YUOskayF+tOygoSKnd39+/2HWS7O3tsW3btrcNk4jeUktXa2z/tDUGb76Aa0+TEbDxPLaNaAUbM+V5gURE6qJxt+GIqHJxd7LEjlGtYWtmiFuxqRjw03nEpb5Sd1hERHIslohI7epXs8Dvo1ujmoUR7selo++Gc4h+manusIiIALBYIiINUauqGXaNaQNna2NEJWai34/n8CAuTd1hERGxWCIizeFsbYKdo9vAzdYUMSmv8P7av7Hxr0eQyjRq7VwiqmRYLBGRRqluaYzfR7dB+zq2yM6T4avDt9H3x7N4GJ+u7tCIqJJisUREGqequSF+CWyFZf7uMDPUx9Unyei55gxHmYhILVgsEZFGEolEGNCqBo5N6cBRJiJSKxZLRKTRHK2MOcpERGrFYomINB5HmYhInVgsEZHW4CgTEakDiyUi0iqFjTIN23IROXkydYdHRDqIxRIRaaWCUaZvPnKHiYEYZ+4n4IuQGwov1yYiKg8slohIa4lEIvT3rIH1nzSHWE+EP65EY13YA3WHRUQ6hsUSEWm9TvXssPCDRgCA//15D/uvx6g5IiLSJSyWiEgnDG7tgpHv1QQATN91HVeiktQcERHpChZLRKQzZvdsAN+G9sjJk+HTX64gKjFD3SERkQ5gsUREOkOsJ8KaAU3h7miJpIwcDA+6hJTMXHWHRURajsUSEekUEwN9bBraEg6WRngUn4HRv17mkgJE9FZYLBGRzrGzMMKmYZ4wM9TH+UdJmL2HSwoQUdmxWCIindSgugW+H9gMYj0Rdl/lkgJEVHYslohIZ725pMC+a8/UHBERaSMWS0Sk015fUmDGH+G4HMklBYiodFgsEZHOm92zAbr+t6TAqG1cUoCISofFEhHpPLGeCKtfX1JgyyW8SH2l7rCISEuwWCKiSqFgSQFHK2M8SsjARz+cxeMEjjARUfFYLBFRpWFnYYQdo1rD1cYE0S+z0PfHs4h4lqLusIhIw7FYIqJKxdnaBLvGtEUjBwskpOdgwE/ncfZhgrrDIiINxmKJiCqdquaGCB7VGl41rZGenYdhmy/haMRzdYdFRBqKxRIRVUoWRhJsDWyV/5ScVIZxv13BjotP1B0WEWkgFktEVGkZScRY/0lz9G/pDJkAzNpzA+vCHvDVKESkgMUSEVVq+mI9LPvIHWM71QIArDh2F0sO3YZMxoKJiPKxWCKiSk8kEuHz7vUx9/0GAIBNfz/G9F3XkSuVqTkyItIE+uoOgIhIU4xs74YqJgaYuTsce/59hqSMbLxvpe6oiEjdOLJERPSaj1o44afBLWCor4dT9xKw/rYYiRk56g6LiNSIxRIR0Ru6NLDHryO9YGGkj8dpIrz/3Vn8eZNLCxBVViyWiIhU8HS1xo6RrVDdWEBiRg5GbbuCGbuuI+1VrrpDI6J3jMUSEVEh6tibYZqHFCPfc4VIBOy6Eo3uq8/g3MNEdYdGRO8QiyUioiJI9IDPu9XF76PawNnaGM+SsxCw8Ty+PHgLr3Kl6g6PiN4BFktERCXQqqY1jkzqgIBWNQDkLy/Q67u/cSOaL+Il0nUsloiISsjMUB9L/d2xZZgnqpob4kFcOvzW/4M1x+9zTSYiHcZiiYiolLzr2+HPyR3wvnt15MkErDp+Dx//cBYP4tLVHRoRVQAWS0REZVDF1ADfD2yGNQOawsJIH9ejU/D+2jNYFXoPyZlcl4lIl7BYIiIqI5FIhA+bOuLPKR3Rvo4tsvNkWHPiPtotO4mlR24jLu2VukMkonLAYomI6C1VszTCL4Gt8P3AZqhfzRwZOVJsOP0I7b8Jw/x9EYh+manuEInoLbBYIiIqByKRCL08HHBkUntsGtoSzWpYITtPhl/ORaHTilOYvus6HsZr1pym7Dwpbsak4hVXQCAqEl+kS0RUjkQiEbo0sEfn+nY49zAR6049wD8PEvHHlWjsvhqNnu7VMb5TbTR0sHjnsSVl5OBK1EtcjkrC1aiXuB6dgpw8GaoaidGmwyvUsJW885iItAGLJSKiCiASidC2ti3a1rbF1ScvsT7sIY7ffoFD4bE4FB6LzvXtMKlLHTRxtqqQ8wuCgIfxGbgSlYTLkS9x5clLPIrPUNpPTwTEvxLhk02XEDyqNZyqmFRIPETajMUSEVEFa16jCn4e2hK3Y1Ox/tRDHAqPwck7cQi7G4fRHWphim8dGOqLy+VcFx4lYuOZx7gclYTkTOX32NW2M0NLlypo7lIFLV2qQA8yfPT9X3j6Mgv9N5zHjlGt4WzNgonodSyWiIjekQbVLfBdQDNM9a2L1cfvYd+1GPx4+iFO3Y3Dt/2avtWtuZcZOVh65DZ2Xo6WtxlJ9NDEyQotXKqgpWsVNK9RBVYmBgrH5ebmYmIjKbZEWSAyMRP9NpxD8Ket4WprWuZYiHQNiyUionespq0p1gxohh6Nq2NOyA3ceZ6GD9f9jSm+dTG6Qy2I9UQl7ksQBIT8+wxLDt1GUkb++k4BrWqgv6czGjlYQCIu/jkeK0PgtxGeGLLlMh7GZ6D/T+ew/dPWqFXVrMw5EukSPg1HRKQm3RtXw7EpHeDb0B65UgHLj95Fvw3nEJmgPLdIlUfx6fjk5wuYuvM6kjJyUNfeDLvHtsFSf3c0dbYqUaFUwM7cEDtGtUFdezO8SM1G/w3ncf9FWllTI9IpLJaIiNTI1swQPw1ugRUfe8DMUB9Xol6ix5oz+PV8FARBUHlMdp4Ua0/cR/c1Z3D2YSIM9fUws3s9HJzQHi1crMscS1VzQwR/2hr1q5kjIT0bA346jzvPU8vcH5GuYLFERKRmIpEIfVs64+jk9mjtZo2sXCnm7o3A0C2X8DxFcRXwC48S0XPNGXwbeg85eTK0r2OL0CkdMa5TbRjov/2PdBuz/IKpsaMFEjNyEPDTeUQ8S3nrfom0GecsERFpCKcqJtg+sjW2nI3EN0fv4K978ei2+i982acx2te2VZjAbWtmiPm9G6K3R3WIRCWf41QSVUwN8NuI1hiy+QKuR6dg4Mbz+HWkFzycrMr1PJQvK0eKh/HpuPciDfdepONBXBpSsnLhbG0CN1tTuNqawtXGFDVtTWFqqBu/ttOz82AsEZdqfp466cZXnYhIR+jpiTDivZroUMcWU3dex41nKZgY/C+MJWJk5eYvtT3QqwY+71YfliYVt4ikpYkE20Z6Ydjmi7j6JBmfbLyArSNaoXmNKhV2Tl2nqii69yIdT19mQtUd10uRL5Xa7MwN4WprKi+inK0M8TwTkMlU37LVJE+TMnH4RiwO3YhFeHQK9PVEcLAyhlOVgg8Thf/aWxhpTDGlkcVSeno65s6di507dyIpKQn169fHrFmzMGDAgGKPDQsLw9dff43r168jMzMTbm5uGDlyJMaPHw+xOH8dk9TUVHz33XcIDQ3FnTt3kJ6ejpo1a2LQoEGYNGkSjIyMKjpFIqIi1bE3x55xbfH9yQf4PuwBsnKlqGtvhqX+7m81L6k0LIwk+GWEF4ZvuYhLkS8xZNNF/DS4BdrUsin30Sxd9s+DBCw/dhfh0ckqiyIAsDY1QB07M9SxN0Nde3NYmRjgSWIGHiVkIDIhA5GJmUjKyEFcWjbi0rJx8XHSa0fr4+eHp9Gpnh0617fDe3VsYW6kGauxP03KxKEbsTj8X4H0ujyZgCdJmXiSpPrdiQXFlKOVEZCuhx6FffHeAY0slvz9/XHp0iUsW7YMdevWxfbt2xEQEACZTIaBAwcWetzx48fRrVs3dOjQARs3boSpqSn279+PSZMm4eHDh1izZg0A4MmTJ1i9ejUGDx6MqVOnwszMDGfOnMHChQsRGhqK0NBQ/iAgIrWTiPUwxbcuujeuhrvP09DTvXq5zEsqDTNDfWwNbIXAoEs4/ygJA3++AFszAzSvkb92UwsXazR2tCi3RTV1yYO4dCw9fBsn7sTJ2wqKorr25qhjb4Y6duaoa28GGzPDYvtLyczF48T84umx/CMdd2NTEJ+eg11XorHrSjT09UTwdLVG5/p28K5fFbWqmr3T32mFFUh6IsCrpg3e96iOrg3tIRUERL/MQvTLTEQnZeX/f3Imol9mISY5C7nS/y+mrAxEav29rHHF0uHDhxEaGiovkADA29sbUVFRmDFjBvr37y8fIXpTUFAQJBIJDh48CFPT/AXVfHx8cPfuXQQFBcmLpZo1ayIyMlK+DwB07twZpqammDFjBv755x+89957FZwpEVHJNKhugQbV3/275AqYGOhjy7BW+Hx3OI5GPEdCeg7+vPUCf956AQAw0NeDh6MlWrhWQUsXazSvYVWiX/66KikjB2uO38OvF55AKhOgryfCoNYuGNupFuwtyn7nwtJEgqYmVmj62itycnNzsf/gYdg28MJfD5IQdicOjxIycO5RIs49SsRXh2/D2doYnevZoVN9O7Rxs4GRpHwK2+w8KZIycpCYnoPEjBzcjk1VWSC1drNBT/fq6NaoGqqaK35fVLc0hqer8kipVCYgLu0Vol9mISo+DVevXS+XmMtK44qlkJAQmJmZoW/fvgrtw4cPx8CBA3HhwgW0bdtW5bESiQQGBgYwNjZWaLeyslK4tfZ6kfS6Vq1aAQCePn36NikQEekcYwMx1gY0w6tcKSKepfz3Qt6XuBL1EkkZObj83+cb8AgA4GZrikaOljCRiKEvFkEi1oNELIK+WA8Svf/+W9CmJ4KJgT66NLAr1yLrZUYOFh+8ifAHYhjUjEN3d4cKHZ3IzpPil7NRWHvyPtJe5QEAfBvaY3aP+nCrwAU+9fWAtrVs0LF+Nczr1RCRCRkIuxuHk3ficOFREp4mZWHruShsPRcFI4keHKyMYWIgholEH0YGYphIxDAxEMPYQAxj+f/rw8RAjFypDIkZOUj6ryBKzMhG0n+fp2XnqYzn9QKpe+NqsC3DNRXriVDd0hjVLY3R1NEckphrb/lVejsaVyxFRESgQYMG0NdXDM3Dw0O+vbBiacyYMQgODsbEiRPxxRdfwMTEBAcOHEBISAiWLl1a7LlPnjwJAGjUqNFbZkFEpJuMJGK0dLVGS1drjEb+CuKRiZm4HJkkL6AexKXjUUL+fJvSqGIiwfzeDdGnqeNbFzVhd+Iwc3c44tOyAYgwdvs1NHJ4hEld6sC3oX25Fk2CIOBIxHMsO3JHPv+mYXULzO3VAG1r2ZbbeUrK1dYUw21rYni7msjMycM/DxIRdjcOYXfiEJvySuULlctKX08Ea1MDWJsawMHKGJ3r25W5QNJkGlcsJSYmws3NTand2tpavr0wXl5eOHnyJPr27Yt169YBAMRiMZYuXYpp06YVed7w8HAsX74cfn5+8sJMlezsbGRnZ8s/T03NX7AtNzcXubnKL618GwX9lXe/mkLX8wN0P0fmp/3KI0cnSwM4NamGPk2qAQCSM3Px79NkPErIQG6eDLlSAbkyGfKkAnKlMuTJ8v+bKxXkbffi0vEwPgNTfr+OvVefYdEHDeBoZVzMmZVlZOdh6dF7+P2/JRbcbE1QQ5KOi4kS3IxJxahtV9CwujkmeNdCl/pV37pouh6dgqVH7uLKk2QA+U+rTfWpjT5NHSDWE1X4905x108iAjrVsUanOtZY+H49PIzPQGJGDrJypcjKkb72XxmycqTIzJXiVa4UmTn57eL/iiGb/woia1PJa/9vAAsjfZVfw/LMu6L+HZamP5FQ2BKxalK3bl3UqlULR44cUWiPjY2Fg4MDli5dilmzZqk89sqVK+jZsye8vLwwatQomJqa4uTJk1i+fDnmzp2LefPmqTwuMjISHTp0gLGxMc6dOycvzFRZuHAhFi1apNS+fft2mJjwTd1ERGUhlQEnY0U4+lQPeYIIBnoCeteQ4b1qAkr69PjDVOC3B2IkZucf0Km6DO87y2AgBtJzgbBYPZyJFSFblr/dyVRAdycZGlcRUNKaSSYA8a+AJ+ki3Hwpwr+J+RPuJXoCujgI6OwggyHnumuFzMxMDBw4ECkpKbCwKHpOoMYVS23atIFUKsXFixcV2m/evInGjRtjw4YNGDVqlMpjW7dujczMTPz7778Kk8AXLFiAJUuW4P79+0qjVlFRUejUqRNEIhH++usvODk5FRmfqpElZ2dnJCQkFPvFLq3c3FyEhobC19cXEolmPAZannQ9P0D3c2R+2k/TcnwUn4E5+27iclQyAKB5DSt89WFD1LYrfM5Pdp4Ma048wM//REIQAAdLI3zj3xit3ayV8kvKyMGWs1HYdv4JMnLy160qbKRJEAQ8T81GeHQKwp+l4MazVNx4lor0N+bq+DVzwJQutVHd8t0vO6Np168iVFSOqampsLW1LVGxpHG34dzd3REcHIy8vDyFeUs3btwAADRu3LjQY69du4aAgAClp+U8PT0hk8lw+/ZthWKpoFASBAGnTp0qtlACAENDQxgaKt+LlUgkFfaNWpF9awJdzw/Q/RyZn/bTlBzrOVhh5+i2+O3iEyw7fBtXnyTjw/Xn8Vnn2hjTsZbS0gk3Y1Iw9ffruPvfS3/7tnDCvN4NYfHGOkMF+dlbSTCrZ0OM6lgbP595hK1nI3ErNu2/OU0WGNrGFc9TXyE8OhnXnqYgIT0bbzKS6KGRgyU8nCzxUXMnNHa0rLgvSAlpyvWrSOWdY2n60rhiyc/PDxs3bsTu3bvRv39/efvWrVvh4OAALy+vQo91cHDA5cuXIZVKFQqmc+fOAYBCMfTkyRN06tQJUqkUp06dgouLSwVkQ0REpaWnJ8Lg1i7oUt8Oc/dG4OSdOHwbeg+Hb8Tim4880MTZCnlSGTb89Qirj99DrlSAjakBlvq7o2ujaiU6h7WpAWZ2r4+R7d3kRdPNmFTM3B2usJ9YT4R69uZo4mwJDycrNHGyQl17M+iL+WrVykTjiqUePXrA19cXY8eORWpqKmrXro3g4GAcPXoUv/76q7wIGjFiBLZu3YqHDx/KC50pU6Zg4sSJ6N27N0aPHg0TExOcOHECK1euhI+PD5o0aQIAiIuLg7e3N2JjY7Fp0ybExcUhLu7/Fw1zcnIq0SgTERFVHAcrY2wa2hL7r8dg0YFbuPM8DX7r/8GQNq4Ij07G1f8mVXdtaI+v/d3L9ATWm0XTPw8S4GpriiZOVmjibImG1S1hbMBJSJWdxhVLALBnzx7MmTMH8+fPl7/uJDg4WOF1J1KpFFKpFK9PuZowYQIcHR2xatUqjBw5EllZWXB1dcWCBQswZcoU+X63bt3Co0f5a4EMGjRI6fwLFizAwoULKy5BIiIqEZFIhA+bOqJ9napYfOAm9l6LQdDZSACAuaE+Fn7QCP7N336pgYKiiUgVjSyWzMzMsGbNGvmK26oEBQUhKChIqd3f3x/+/v5F9l8wT4mIiLSDtakBVg9ohg+bOWLJwVtwtjbBV37uZVpegKi0NLJYIiIiUsW7nh2869mpOwyqZDhDjYiIiKgILJaIiIiIisBiiYiIiKgILJaIiIiIisBiiYiIiKgILJaIiIiIisBiiYiIiKgILJaIiIiIisBiiYiIiKgILJaIiIiIisBiiYiIiKgILJaIiIiIisBiiYiIiKgILJaIiIiIiqCv7gC0nSAIAIDU1NRy7zs3NxeZmZlITU2FRCIp9/7VTdfzA3Q/R+an/XQ9R+an/Soqx4Lf2wW/x4vCYuktpaWlAQCcnZ3VHAkRERGVVlpaGiwtLYvcRySUpKSiQslkMsTExMDc3Bwikahc+05NTYWzszOePn0KCwuLcu1bE+h6foDu58j8tJ+u58j8tF9F5SgIAtLS0uDg4AA9vaJnJXFk6S3p6enBycmpQs9hYWGhs/8IAN3PD9D9HJmf9tP1HJmf9quIHIsbUSrACd5ERERERWCxRERERFQEFksazNDQEAsWLIChoaG6Q6kQup4foPs5Mj/tp+s5Mj/tpwk5coI3ERERURE4skRERERUBBZLREREREVgsURERERUBBZLapSWloaZM2eia9euqFq1KkQiERYuXKhy36tXr8LHxwdmZmawsrKCv78/Hj169G4DLoOS5jhs2DCIRCKlj/r167/7oEvo5MmTCAwMRP369WFqagpHR0d8+OGHuHLlitK+2nr9SpqjNl4/ALh27Rref/991KhRA8bGxrC2tkabNm3w66+/Ku2rjdewpPlp6/VT5eeff4ZIJIKZmZnSNm28hqoUlqM2XsdTp06pjFkkEuH8+fMK+6rz+nFRSjVKTEzETz/9hCZNmqBPnz74+eefVe53584ddOrUCU2bNsXOnTvx6tUrzJ8/H+3bt8e1a9dQtWrVdxx5yZU0RwAwNjbGyZMnldo01Q8//IDExERMmjQJDRs2RHx8PFauXInWrVvj2LFj6Ny5MwDtvn4lzRHQvusHAMnJyXB2dkZAQAAcHR2RkZGB3377DYMHD0ZkZCTmzp0LQHuvYUnzA7Tz+r3p2bNnmD59OhwcHJCSkqKwTVuv4ZuKyhHQ3uv49ddfw9vbW6GtcePG8v9X+/UTSG1kMpkgk8kEQRCE+Ph4AYCwYMECpf369u0r2NraCikpKfK2yMhIQSKRCDNnznxX4ZZJSXMcOnSoYGpq+o6jezsvXrxQaktLSxPs7e2FLl26yNu0+fqVNEdtvH5F8fLyEpydneWfa/M1VOXN/HTl+vXq1Uvo3bu3ynx05RoWlaM2XsewsDABgLBr164i91P39eNtODUqGGosSl5eHg4ePIiPPvpIYZl3FxcXeHt7IyQkpKLDfCslyVFb2dnZKbWZmZmhYcOGePr0KQDtv34lyVEX2draQl8/f+Bd26+hKq/npyt+/fVXnD59GuvXr1fapivXsKgcdZkmXD8WSxru4cOHyMrKgoeHh9I2Dw8PPHjwAK9evVJDZOUvKysL1apVg1gshpOTEz777DMkJSWpO6xSSUlJwdWrV9GoUSMAunn93syxgDZfP5lMhry8PMTHx2P9+vU4duwYPv/8cwC6cQ2Lyq+ANl+/uLg4TJ48GcuWLVP5rk5duIbF5VhAW6/j+PHjoa+vDwsLC3Tr1g1///23fJsmXD/d+tNCByUmJgIArK2tlbZZW1tDEAS8fPkS1atXf9ehlasmTZqgSZMm8nvUp0+fxqpVq3DixAlcunRJ5WRNTTR+/HhkZGRgzpw5AHTz+r2ZI6D912/cuHHYsGEDAMDAwABr167F6NGjAejGNSwqP0A3rl+9evUwduxYldt15RoWlSOgndfR0tISkyZNQqdOnWBjY4MHDx5gxYoV6NSpEw4dOoRu3bppxPVjsaQlirqVpQu3uaZMmaLwua+vL5o1a4aPP/4YGzduVNquiebNm4fffvsN3333HVq0aKGwTVeuX2E5avv1++KLLzBy5EjExcXhwIED+Oyzz5CRkYHp06fL99Hma1hcftp8/Xbv3o0DBw7g33//LfY6aOs1LGmO2ngdmzVrhmbNmsk/b9++Pfz8/ODu7o6ZM2eiW7du8m3qvH4sljScjY0NgP//y+h1SUlJEIlEsLKyesdRvRt+fn4wNTVVenxUEy1atAhLlizBV199hc8++0zerkvXr7AcC6NN169GjRqoUaMGAKBnz54AgNmzZ2Po0KE6cQ2Lyq+wp4i04fqlp6dj/PjxmDBhAhwcHJCcnAwAyMnJAZD/NKBEItHqa1jSHE1NTVUerw3X8U1WVlbo1asXfvzxR2RlZWnE9eOcJQ1Xq1YtGBsb48aNG0rbbty4gdq1a8PIyEgNkb0bgiBAT0+zv00XLVqEhQsXYuHChfjiiy8UtunK9Ssqx6Jow/VTpVWrVsjLy8OjR4905hq+7vX8iqLp1y8hIQEvXrzAypUrUaVKFflHcHAwMjIyUKVKFXzyySdafQ1LmmNRNP06qiL899pakUikEddPu756lZC+vj569+6NPXv2IC0tTd7+5MkThIWFwd/fX43RVaw//vgDmZmZaN26tbpDKdSXX36JhQsXYu7cuViwYIHSdl24fsXlWBhtuH6FCQsLg56eHtzc3HTiGr7p9fwKow3Xr1q1aggLC1P66NatG4yMjBAWFoYlS5Zo9TUsaY6F0Ybr+KaXL1/i4MGDaNq0KYyMjDTi+omEgvKN1OLIkSPIyMhAWloaAgMD0bdvX/Tr1w9A/nC5iYkJ7ty5A09PTzRv3hyzZs2SL8aVlJSkFYupFZdjfHw8Bg4ciAEDBqB27doQiUQ4ffo0Vq9ejVq1auHChQuFDjGr08qVKzF9+nR0795dZRFR8MNJm69fSXKMiorSyusHAKNGjYKFhQVatWoFe3t7JCQkYNeuXfj9998xY8YMLF++HID2XsOS5KfN168ww4YNwx9//IH09HR5m7Zew8K8maO2XseBAweiRo0aaNmyJWxtbXH//n2sXLkSDx8+xJEjR+Dj4wNAA65fha/kREVycXERAKj8ePz4sXy/y5cvC126dBFMTEwECwsLoU+fPsKDBw/UF3gpFJdjUlKS4OfnJ7i6ugrGxsaCgYGBUKdOHWHmzJlCcnKyusMvVMeOHQvN681/Wtp6/UqSo7ZeP0EQhM2bNwvt27cXbG1tBX19fcHKykro2LGjsG3bNqV9tfEaliQ/bb5+hSlscUZtvIaFeTNHbb2OS5cuFZo2bSpYWloKYrFYqFq1quDn5ydcvHhRaV91Xj+OLBEREREVgXOWiIiIiIrAYomIiIioCCyWiIiIiIrAYomIiIioCCyWiIiIiIrAYomIiIioCCyWiIiIiIrAYomIqBRcXV3h6uqq7jAUDBs2DCKRCJGRkeoOhUgnsVgiogoRGRkJkUgEkUgER0dHSKVSlfvduHFDvl/9+vXfcZTa4dSpUxCJRFi4cKG6QyGqlFgsEVGF0tfXR0xMDI4dO6Zy+6ZNm6Cvr/+OoyIiKjkWS0RUodq2bQtLS0ts3rxZaVtOTg5+++039OzZUw2RERGVDIslIqpQxsbG6N+/Pw4cOICEhASFbfv370dCQgKGDx+u8tiYmBgsWLAArVu3hp2dHQwNDeHq6opx48YhLi5OYd+7d+/CzMwMNWrUwMuXLxW23b59GyYmJnB1dUVKSkqJ4t63bx88PT1hbGwMe3t7fPrpp0r9vi4nJwfffvstmjdvDlNTU5ibm6N9+/bYv3+/0r4Fc4wePnyIpUuXonbt2jAyMkKdOnWwYsUKyGQy+b4LFy6Et7c3AGDRokXyW5aFzVFav349GjRoACMjI7i4uGDRokUK/RFR6bFYIqIKFxgYKB9Fet3mzZthZ2eHXr16qTzur7/+wsqVK2Fvb4+AgABMmDABtWrVwg8//IA2bdooFD716tXD6tWr8fTpU3z66afy9uzsbAQEBMjPb2lpWWy8v/zyC/r06YN79+5h8ODBGDp0KP755x/4+PggJydHaf/s7Gx069YN06ZNAwCMGDECgwYNQlRUFD788EN8//33Ks8zefJkfPvtt+jWrRvGjx+PvLw8zJw5E2PHjpXv06lTJwwdOhQA0LFjRyxYsED+YWVlpdDfjBkz5MXl6NGjAeQXW/PmzSs2ZyIqgkBEVAEeP34sABC6desmCIIgNGrUSPDw8JBvj46OFsRisTBt2jRBEAQBgFCvXj2FPl68eCGkpaUp9b1161YBgLBkyRKlbR9//LEAQPjpp58EQRCEyZMnCwCEBQsWlCjulJQUwcLCQjA1NRXu3r0rb8/JyRE6dOggABBcXFwUjvniiy8EAMLChQsFmUwmb09NTRVatmwpGBgYCM+ePZO3Dx06VAAg2NvbK7SnpaUJ7u7uAgDhr7/+kreHhYUVmUNBfzVr1hRiYmLk7fHx8YKVlZVgbm4uZGdnlyh/IlLGkSUieieGDx+O8PBwXLlyBQAQFBQEqVSKwMDAQo+xs7ODmZmZUvvgwYNhYWGB48ePK23buHEjnJ2dMXnyZKxduxZr1qxB27ZtSzy6snfvXqSmpiIwMBB169aVt0skEnz11VdK+8tkMvzwww+oXbs25s+fD5FIJN9mbm6O+fPnIycnB3v27FE6duLEiXBwcJB/bmZmhvnz5wMAtm7dWqJ4Xzdv3jxUr15d/rmtrS0+/PBDpKWl4e7du6Xuj4jy8REUInonBg8ejNmzZ2Pz5s1o0aIFgoKC4OXlhYYNGxZ53J49e7BhwwZcvXoVL1++VFiCICYmRml/Kysr/Pbbb/D29sakSZNgaWmJ3377DWKxuERxXr9+HQDQvn17pW1t2rRRenLv7t27ePnyJRwcHLBo0SKlY+Lj4wEAd+7cUdqm6hwFbdeuXStRvK9r3ry5UpuTkxMAIDk5udT9EVE+FktE9E7Y2dmhZ8+eCA4OxgcffIAHDx5g+vTpRR6zcuVKTJ8+HVWrVkXXrl3h5OQEY2NjAMDq1auRnZ2t8riWLVvCyckJUVFReP/990u1iGTBPCg7OzulbWKxGDY2NgptSUlJAICbN2/i5s2bhfabkZGh1KbqHHZ2dtDT0yvxRPTXqZqPVVDcFbbOFREVj8USEb0zgYGB2LdvH0aMGAFjY2MEBAQUum9eXh6+/PJLODg44Nq1a6hatap8myAIWL58eaHHTps2DVFRUbCxsUFwcDCGDh2Krl27lijGgoLjzaftgPyCIzExEY6OjvI2CwsLAMBHH32EP/74o0TnKBAXF4d69eoptclkshJNRCeid4NzlojonenZsyeqVauGZ8+e4aOPPpIXGqokJCQgJSUFrVu3ViiUAODy5cvIyspSedz+/fvxww8/wNvbGxcvXoSFhQWGDh0qvx1WnCZNmgAAzpw5o7Tt3LlzyMvLU2hr0KABLCwscPnyZeTm5pboHAVUnaOgrWnTpvK2gluIHB0iUg8WS0T0zujr62P//v0ICQlROVn6dXZ2djA2NsbVq1eRmZkpb3/58iUmTJig8pjY2FiMGDEC1tbW2LZtG9zc3PDDDz/g+fPnRU4kf92HH34ICwsLbN68Gffu3ZO35+bmYu7cuSpzGjt2LKKiojB9+nSVBVNERITKkaq1a9cqzLtKT0/H4sWLAQBDhgyRt1tbWwMAoqOjS5QDEZUv3oYjonfK09MTnp6exe6np6eHcePGYeXKlWjSpAl69+6N1NRUHDlyBC4uLgpPkQH5t+aGDh2KhIQE7N69W36rLCAgAEeOHMG2bdvw/fff47PPPivyvJaWlli7di2GDRsGT09PDBgwAJaWljh48CCMjY0VnjYrsGjRIly9ehVr167FoUOH0LFjR1StWhXPnj3DjRs3cP36dZw7d05pjpKnpyeaNGmC/v37w9DQEHv27EFkZCQ+/fRTdOjQQb5f/fr14eDggB07dsDExAROTk4QiUQYO3Ysb9cRvQvqXruAiHTTm+ssFQcq1lnKyckRvvrqK6FOnTqCoaGhUKNGDWHq1KlCWlqa4OLiorDe0YoVKwQAwsiRI5X6Tk1NFdzc3AQjIyPhxo0bJYonJCREaNGihWBoaCjY2dkJI0eOFJKSkpTOWyAvL0/YsGGD0K5dO8HCwkIeb/fu3YUffvhBSE9Pl+9bsC7SgwcPhK+//lpwc3MTDAwMhFq1agnffPONkJeXp9T/+fPnhY4dOwrm5uYCAAGA8PjxY4X+Cj5/3YIFCwQAQlhYWInyJiJlIkEQBPWVakRElc+wYcOwdetWPH78uFRP6hGRenDOEhEREVERWCwRERERFYHFEhEREVEROGeJiIiIqAgcWSIiIiIqAoslIiIioiKwWCIiIiIqAoslIiIioiKwWCIiIiIqAoslIiIioiKwWCIiIiIqAoslIiIioiKwWCIiIiIqwv8B4sc8oOyIMbgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "depths = np.linspace(10, 50, 41, dtype=int)\n",
    "\n",
    "plot_depthsVSaccuracy(depths, 0.0001, 'Variazione accuracy CON PRUNING') \n",
    "plot_depthsVSaccuracy(depths, 0.0, 'Variazione accuracy SENZA PRUNING') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c0ef8e4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  try  Parameter_changed  Accuracy\n",
      "0   1              start  0.831062\n",
      "0   2          max_depth  0.839224\n",
      "0   3   min_samples_leaf  0.851120\n",
      "0   4  min_samples_split  0.858798\n",
      "0   5          ccp_alpha  0.868965\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'Score sul testset durante il tuning dei parametri'}, xlabel='Accuracy', ylabel='Parameter_changed'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "df = pd.DataFrame(columns=column_bar)\n",
    "df = pd.concat([df, create_bar_row('entropy', 50, 1, 0.0, 20, 1, 'start')]) # try 1\n",
    "df = pd.concat([df, create_bar_row('entropy', 25, 1, 0.0, 20, 2, 'max_depth')]) # try 2\n",
    "df = pd.concat([df, create_bar_row('entropy', 25, 10, 0.0, 20, 3, 'min_samples_leaf')]) # try 3\n",
    "df = pd.concat([df, create_bar_row('entropy', 25, 10, 0.0, 40, 4, 'min_samples_split')]) # try 4\n",
    "df = pd.concat([df, create_bar_row('entropy', 25, 10, 0.0001, 40, 5, 'ccp_alpha')]) # try 5\n",
    "print(df)\n",
    "\n",
    "fig, axs = plt.subplots()\n",
    "axs.set_xlim([0.70,0.89])\n",
    "axs.set_title(\"Score sul testset durante il tuning dei parametri\")\n",
    "\n",
    "sns.barplot(data=df, x='Accuracy',y=\"Parameter_changed\",ax=axs, orient=\"h\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01d22692",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "algoritmo=[\"Start\",\"Max_depth\",\"min_samples_leaf\",\"min_samples_split\",\"ccp_alpha\"]\n",
    "accuracy=[0.8310,0.8392,0.8511,0.8587,0.8689]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(algoritmo, accuracy, marker='o', linestyle='-', color='r')\n",
    "plt.title(' Accuracy su testSet al variare dei parametri')\n",
    "plt.xlabel('Parametro variato')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.grid(True)\n",
    "plt.xticks(algoritmo)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80dd9533",
   "metadata": {},
   "source": [
    "Score su trainining set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "534cbc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "column = ['criterion', 'max_depth', 'ccp_alpha', 'min_samples_leaf', 'min_samples_split', 'accuracy']\n",
    "column_bar = ['try', 'Parameter_changed', 'Accuracy']\n",
    "\n",
    "def plot_depthsVSaccuracy(depths, ccp_alpha, title):\n",
    "  accs = pd.DataFrame(columns=column)\n",
    "  for d in depths:\n",
    "    tree_clf = DecisionTreeClassifier(criterion='log_loss',max_depth=d, min_samples_leaf=4, ccp_alpha=ccp_alpha,min_samples_split=8 )\n",
    "    tree_clf.fit(train_data, y_train)\n",
    "    testset_score = tree_clf.score(train_data, y_train)\n",
    "    row = pd.DataFrame(data=[['log_loss', d, ccp_alpha, 4, 8 ,testset_score]], columns=column)\n",
    "    accs = pd.concat([accs, row])\n",
    "\n",
    "  # plot\n",
    "  fig, ax = plt.subplots()\n",
    "  ax.plot(accs.max_depth, accs.accuracy)\n",
    "\n",
    "  ax.set(xlabel='Max depth', ylabel='Accuracy',\n",
    "        title=title)\n",
    "  ax.grid()\n",
    "  plt.show()\n",
    "    \n",
    "def create_bar_row(criterion, depth, leaf, ccp, split, attempt, parameter):\n",
    "  tree_clf = DecisionTreeClassifier(criterion=criterion,max_depth=depth, min_samples_leaf=leaf, ccp_alpha=ccp,min_samples_split=split )\n",
    "  tree_clf.fit(train_data, y_train)\n",
    "  testset_score = tree_clf.score(train_data, y_train)\n",
    "  row = pd.DataFrame(data=[[attempt, parameter, testset_score]], columns=column_bar)\n",
    "  return row    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "beacae7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  try  Parameter_changed  Accuracy\n",
      "0   1              start  0.913324\n",
      "0   2          max_depth  0.907271\n",
      "0   3   min_samples_leaf  0.889028\n",
      "0   4  min_samples_split  0.882500\n",
      "0   5          ccp_alpha  0.871589\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(columns=column_bar)\n",
    "df = pd.concat([df, create_bar_row('entropy', 50, 1, 0.0, 20, 1, 'start')]) # try 1\n",
    "df = pd.concat([df, create_bar_row('entropy', 25, 1, 0.0, 20, 2, 'max_depth')]) # try 2\n",
    "df = pd.concat([df, create_bar_row('entropy', 25, 10, 0.0, 20, 3, 'min_samples_leaf')]) # try 3\n",
    "df = pd.concat([df, create_bar_row('entropy', 25, 10, 0.0, 40, 4, 'min_samples_split')]) # try 4\n",
    "df = pd.concat([df, create_bar_row('entropy', 25, 10, 0.0001, 40, 5, 'ccp_alpha')]) # try 5\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "328fa9b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 288 candidates, totalling 1440 fits\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.782) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.870, test=0.866) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.785, test=0.777) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.740, test=0.738) f1: (train=0.783, test=0.780) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.784, test=0.781) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.872) balanced_accuracy: (train=0.741, test=0.748) f1: (train=0.783, test=0.790) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.782) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.870, test=0.866) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.785, test=0.777) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.740, test=0.738) f1: (train=0.783, test=0.780) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.784, test=0.781) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.872) balanced_accuracy: (train=0.741, test=0.748) f1: (train=0.783, test=0.790) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.782) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.870, test=0.866) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.785, test=0.777) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.740, test=0.738) f1: (train=0.783, test=0.780) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.784, test=0.781) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.872) balanced_accuracy: (train=0.741, test=0.748) f1: (train=0.783, test=0.790) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.782) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.870, test=0.866) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.785, test=0.777) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.740, test=0.738) f1: (train=0.783, test=0.780) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.784, test=0.781) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.872) balanced_accuracy: (train=0.741, test=0.748) f1: (train=0.783, test=0.790) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.782) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.870, test=0.866) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.785, test=0.777) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.740, test=0.738) f1: (train=0.783, test=0.780) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.784, test=0.781) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.872) balanced_accuracy: (train=0.741, test=0.748) f1: (train=0.783, test=0.790) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.782) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.870, test=0.866) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.785, test=0.777) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.740, test=0.738) f1: (train=0.783, test=0.780) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.784, test=0.781) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.872) balanced_accuracy: (train=0.741, test=0.748) f1: (train=0.783, test=0.790) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.785, test=0.782) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.742, test=0.735) f1: (train=0.784, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.737) f1: (train=0.782, test=0.779) total time=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.737) f1: (train=0.782, test=0.779) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.739, test=0.747) f1: (train=0.780, test=0.788) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.785, test=0.782) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.742, test=0.735) f1: (train=0.784, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.737) f1: (train=0.782, test=0.779) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.737) f1: (train=0.782, test=0.779) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.739, test=0.747) f1: (train=0.780, test=0.788) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.785, test=0.782) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.742, test=0.735) f1: (train=0.784, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.737) f1: (train=0.782, test=0.779) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.737) f1: (train=0.782, test=0.779) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.739, test=0.747) f1: (train=0.780, test=0.788) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.785, test=0.782) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.742, test=0.735) f1: (train=0.784, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.737) f1: (train=0.782, test=0.779) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.737) f1: (train=0.782, test=0.779) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.739, test=0.747) f1: (train=0.780, test=0.788) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.785, test=0.782) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.742, test=0.735) f1: (train=0.784, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.737) f1: (train=0.782, test=0.779) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.737) f1: (train=0.782, test=0.779) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.739, test=0.747) f1: (train=0.780, test=0.788) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.785, test=0.782) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.742, test=0.735) f1: (train=0.784, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.737) f1: (train=0.782, test=0.779) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.737) f1: (train=0.782, test=0.779) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.739, test=0.747) f1: (train=0.780, test=0.788) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.866) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.784, test=0.781) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.742, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.736) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.739, test=0.736) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.738, test=0.746) f1: (train=0.779, test=0.788) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.866) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.784, test=0.781) total time=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.742, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.736) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.739, test=0.736) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.738, test=0.746) f1: (train=0.779, test=0.788) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.866) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.784, test=0.781) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.742, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.736) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.739, test=0.736) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.738, test=0.746) f1: (train=0.779, test=0.788) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.866) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.784, test=0.781) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.742, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.736) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.739, test=0.736) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.738, test=0.746) f1: (train=0.779, test=0.788) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.866) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.784, test=0.781) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.742, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.736) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.739, test=0.736) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.738, test=0.746) f1: (train=0.779, test=0.788) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.866) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.784, test=0.781) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.742, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.736) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.739, test=0.736) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.738, test=0.746) f1: (train=0.779, test=0.788) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.866, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.866, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.866, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.866, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.866, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.866, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.871, test=0.868) balanced_accuracy: (train=0.745, test=0.741) f1: (train=0.787, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.870, test=0.866) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.741, test=0.739) f1: (train=0.784, test=0.781) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.782) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.872) balanced_accuracy: (train=0.743, test=0.750) f1: (train=0.784, test=0.791) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.871, test=0.868) balanced_accuracy: (train=0.745, test=0.741) f1: (train=0.787, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.870, test=0.866) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.741, test=0.739) f1: (train=0.784, test=0.781) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.782) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.872) balanced_accuracy: (train=0.743, test=0.750) f1: (train=0.784, test=0.791) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.871, test=0.868) balanced_accuracy: (train=0.745, test=0.741) f1: (train=0.787, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.870, test=0.866) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.741, test=0.739) f1: (train=0.784, test=0.781) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.782) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.872) balanced_accuracy: (train=0.743, test=0.750) f1: (train=0.784, test=0.791) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.871, test=0.868) balanced_accuracy: (train=0.745, test=0.741) f1: (train=0.787, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.870, test=0.866) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.741, test=0.739) f1: (train=0.784, test=0.781) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.782) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.872) balanced_accuracy: (train=0.743, test=0.750) f1: (train=0.784, test=0.791) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.871, test=0.868) balanced_accuracy: (train=0.745, test=0.741) f1: (train=0.787, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.870, test=0.866) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.741, test=0.739) f1: (train=0.784, test=0.781) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.782) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.872) balanced_accuracy: (train=0.743, test=0.750) f1: (train=0.784, test=0.791) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.871, test=0.868) balanced_accuracy: (train=0.745, test=0.741) f1: (train=0.787, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.870, test=0.866) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.741, test=0.739) f1: (train=0.784, test=0.781) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.782) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.872) balanced_accuracy: (train=0.743, test=0.750) f1: (train=0.784, test=0.791) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.784, test=0.777) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.740, test=0.738) f1: (train=0.782, test=0.780) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.742, test=0.738) f1: (train=0.784, test=0.780) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.872) balanced_accuracy: (train=0.741, test=0.749) f1: (train=0.782, test=0.790) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.784, test=0.777) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.740, test=0.738) f1: (train=0.782, test=0.780) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.742, test=0.738) f1: (train=0.784, test=0.780) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.872) balanced_accuracy: (train=0.741, test=0.749) f1: (train=0.782, test=0.790) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.784, test=0.777) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.740, test=0.738) f1: (train=0.782, test=0.780) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.742, test=0.738) f1: (train=0.784, test=0.780) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.872) balanced_accuracy: (train=0.741, test=0.749) f1: (train=0.782, test=0.790) total time=   0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.784, test=0.777) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.740, test=0.738) f1: (train=0.782, test=0.780) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.742, test=0.738) f1: (train=0.784, test=0.780) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.872) balanced_accuracy: (train=0.741, test=0.749) f1: (train=0.782, test=0.790) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.784, test=0.777) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.740, test=0.738) f1: (train=0.782, test=0.780) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.742, test=0.738) f1: (train=0.784, test=0.780) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.872) balanced_accuracy: (train=0.741, test=0.749) f1: (train=0.782, test=0.790) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.784, test=0.777) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.740, test=0.738) f1: (train=0.782, test=0.780) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.742, test=0.738) f1: (train=0.784, test=0.780) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.872) balanced_accuracy: (train=0.741, test=0.749) f1: (train=0.782, test=0.790) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.785, test=0.782) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.742, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.736) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.739, test=0.736) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.739, test=0.748) f1: (train=0.780, test=0.789) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.785, test=0.782) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.742, test=0.735) f1: (train=0.783, test=0.776) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.736) f1: (train=0.781, test=0.778) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.739, test=0.736) f1: (train=0.781, test=0.778) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.739, test=0.748) f1: (train=0.780, test=0.789) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.785, test=0.782) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.742, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.736) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.739, test=0.736) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.739, test=0.748) f1: (train=0.780, test=0.789) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.785, test=0.782) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.742, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.736) f1: (train=0.781, test=0.778) total time=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.739, test=0.736) f1: (train=0.781, test=0.778) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.739, test=0.748) f1: (train=0.780, test=0.789) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.785, test=0.782) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.742, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.736) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.739, test=0.736) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.739, test=0.748) f1: (train=0.780, test=0.789) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.785, test=0.782) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.742, test=0.735) f1: (train=0.783, test=0.776) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.736) f1: (train=0.781, test=0.778) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.739, test=0.736) f1: (train=0.781, test=0.778) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.739, test=0.748) f1: (train=0.780, test=0.789) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.866, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.866, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.866, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.866, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.866, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.866, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.871, test=0.868) balanced_accuracy: (train=0.745, test=0.741) f1: (train=0.787, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.870, test=0.866) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.741, test=0.739) f1: (train=0.784, test=0.781) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.782) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.872) balanced_accuracy: (train=0.743, test=0.750) f1: (train=0.784, test=0.791) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.871, test=0.868) balanced_accuracy: (train=0.745, test=0.741) f1: (train=0.787, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.870, test=0.866) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.741, test=0.739) f1: (train=0.784, test=0.781) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.782) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.872) balanced_accuracy: (train=0.743, test=0.750) f1: (train=0.784, test=0.791) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.871, test=0.868) balanced_accuracy: (train=0.745, test=0.741) f1: (train=0.787, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.870, test=0.866) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.741, test=0.739) f1: (train=0.784, test=0.781) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.782) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.872) balanced_accuracy: (train=0.743, test=0.750) f1: (train=0.784, test=0.791) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.871, test=0.868) balanced_accuracy: (train=0.745, test=0.741) f1: (train=0.787, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.870, test=0.866) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.741, test=0.739) f1: (train=0.784, test=0.781) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.782) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.872) balanced_accuracy: (train=0.743, test=0.750) f1: (train=0.784, test=0.791) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.871, test=0.868) balanced_accuracy: (train=0.745, test=0.741) f1: (train=0.787, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.870, test=0.866) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.741, test=0.739) f1: (train=0.784, test=0.781) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.782) total time=   0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.872) balanced_accuracy: (train=0.743, test=0.750) f1: (train=0.784, test=0.791) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.871, test=0.868) balanced_accuracy: (train=0.745, test=0.741) f1: (train=0.787, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.870, test=0.866) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.741, test=0.739) f1: (train=0.784, test=0.781) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.782) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.872) balanced_accuracy: (train=0.743, test=0.750) f1: (train=0.784, test=0.791) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.784, test=0.777) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.740, test=0.738) f1: (train=0.782, test=0.780) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.742, test=0.738) f1: (train=0.784, test=0.780) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.872) balanced_accuracy: (train=0.741, test=0.749) f1: (train=0.782, test=0.790) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.784, test=0.777) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.740, test=0.738) f1: (train=0.782, test=0.780) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.742, test=0.738) f1: (train=0.784, test=0.780) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.872) balanced_accuracy: (train=0.741, test=0.749) f1: (train=0.782, test=0.790) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.784, test=0.777) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.740, test=0.738) f1: (train=0.782, test=0.780) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.742, test=0.738) f1: (train=0.784, test=0.780) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.872) balanced_accuracy: (train=0.741, test=0.749) f1: (train=0.782, test=0.790) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.784, test=0.777) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.740, test=0.738) f1: (train=0.782, test=0.780) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.742, test=0.738) f1: (train=0.784, test=0.780) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.872) balanced_accuracy: (train=0.741, test=0.749) f1: (train=0.782, test=0.790) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.784, test=0.777) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.740, test=0.738) f1: (train=0.782, test=0.780) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.742, test=0.738) f1: (train=0.784, test=0.780) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.872) balanced_accuracy: (train=0.741, test=0.749) f1: (train=0.782, test=0.790) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.784, test=0.777) total time=   0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.740, test=0.738) f1: (train=0.782, test=0.780) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.742, test=0.738) f1: (train=0.784, test=0.780) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.872) balanced_accuracy: (train=0.741, test=0.749) f1: (train=0.782, test=0.790) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.785, test=0.782) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.742, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.736) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.739, test=0.736) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.739, test=0.748) f1: (train=0.780, test=0.789) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.785, test=0.782) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.742, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.736) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.739, test=0.736) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.739, test=0.748) f1: (train=0.780, test=0.789) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.785, test=0.782) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.742, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.736) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.739, test=0.736) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.739, test=0.748) f1: (train=0.780, test=0.789) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.785, test=0.782) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.742, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.736) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.739, test=0.736) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.739, test=0.748) f1: (train=0.780, test=0.789) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.785, test=0.782) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.742, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.736) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.739, test=0.736) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.739, test=0.748) f1: (train=0.780, test=0.789) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.785, test=0.782) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.742, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.736) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.739, test=0.736) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.739, test=0.748) f1: (train=0.780, test=0.789) total time=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.866, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.866, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.866, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.866, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.866, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.866, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.871, test=0.868) balanced_accuracy: (train=0.745, test=0.741) f1: (train=0.787, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.870, test=0.866) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.741, test=0.739) f1: (train=0.784, test=0.781) total time=   0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.782) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.872) balanced_accuracy: (train=0.743, test=0.750) f1: (train=0.784, test=0.791) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.871, test=0.868) balanced_accuracy: (train=0.745, test=0.741) f1: (train=0.787, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.870, test=0.866) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.741, test=0.739) f1: (train=0.784, test=0.781) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.782) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.872) balanced_accuracy: (train=0.743, test=0.750) f1: (train=0.784, test=0.791) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.871, test=0.868) balanced_accuracy: (train=0.745, test=0.741) f1: (train=0.787, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.870, test=0.866) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.741, test=0.739) f1: (train=0.784, test=0.781) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.782) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.872) balanced_accuracy: (train=0.743, test=0.750) f1: (train=0.784, test=0.791) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.871, test=0.868) balanced_accuracy: (train=0.745, test=0.741) f1: (train=0.787, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.870, test=0.866) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.741, test=0.739) f1: (train=0.784, test=0.781) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.782) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.872) balanced_accuracy: (train=0.743, test=0.750) f1: (train=0.784, test=0.791) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.871, test=0.868) balanced_accuracy: (train=0.745, test=0.741) f1: (train=0.787, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.870, test=0.866) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.741, test=0.739) f1: (train=0.784, test=0.781) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.782) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.872) balanced_accuracy: (train=0.743, test=0.750) f1: (train=0.784, test=0.791) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.871, test=0.868) balanced_accuracy: (train=0.745, test=0.741) f1: (train=0.787, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.870, test=0.866) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.741, test=0.739) f1: (train=0.784, test=0.781) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.782) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.872) balanced_accuracy: (train=0.743, test=0.750) f1: (train=0.784, test=0.791) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.784, test=0.777) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.740, test=0.738) f1: (train=0.782, test=0.780) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.742, test=0.738) f1: (train=0.784, test=0.780) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.872) balanced_accuracy: (train=0.741, test=0.749) f1: (train=0.782, test=0.790) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.784, test=0.777) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.740, test=0.738) f1: (train=0.782, test=0.780) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.742, test=0.738) f1: (train=0.784, test=0.780) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.872) balanced_accuracy: (train=0.741, test=0.749) f1: (train=0.782, test=0.790) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.784, test=0.777) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.740, test=0.738) f1: (train=0.782, test=0.780) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.742, test=0.738) f1: (train=0.784, test=0.780) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.872) balanced_accuracy: (train=0.741, test=0.749) f1: (train=0.782, test=0.790) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.784, test=0.777) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.740, test=0.738) f1: (train=0.782, test=0.780) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.742, test=0.738) f1: (train=0.784, test=0.780) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.872) balanced_accuracy: (train=0.741, test=0.749) f1: (train=0.782, test=0.790) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.784, test=0.777) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.740, test=0.738) f1: (train=0.782, test=0.780) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.742, test=0.738) f1: (train=0.784, test=0.780) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.872) balanced_accuracy: (train=0.741, test=0.749) f1: (train=0.782, test=0.790) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.784, test=0.777) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.740, test=0.738) f1: (train=0.782, test=0.780) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.742, test=0.738) f1: (train=0.784, test=0.780) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.872) balanced_accuracy: (train=0.741, test=0.749) f1: (train=0.782, test=0.790) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.785, test=0.782) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.742, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.736) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.739, test=0.736) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.739, test=0.748) f1: (train=0.780, test=0.789) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.785, test=0.782) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.742, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.736) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.739, test=0.736) f1: (train=0.781, test=0.778) total time=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.739, test=0.748) f1: (train=0.780, test=0.789) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.785, test=0.782) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.742, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.736) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.739, test=0.736) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.739, test=0.748) f1: (train=0.780, test=0.789) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.785, test=0.782) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.742, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.736) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.739, test=0.736) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.739, test=0.748) f1: (train=0.780, test=0.789) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.785, test=0.782) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.742, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.736) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.739, test=0.736) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.739, test=0.748) f1: (train=0.780, test=0.789) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.867) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.785, test=0.782) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.742, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.736) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.739, test=0.736) f1: (train=0.781, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.739, test=0.748) f1: (train=0.780, test=0.789) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.866, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.866, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.866, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.866, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.866, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=gini, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.866, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.746, test=0.743) f1: (train=0.787, test=0.784) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.870, test=0.866) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.786, test=0.778) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.782) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.871, test=0.868) balanced_accuracy: (train=0.744, test=0.741) f1: (train=0.787, test=0.783) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.873) balanced_accuracy: (train=0.744, test=0.752) f1: (train=0.785, test=0.793) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.746, test=0.743) f1: (train=0.787, test=0.784) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.870, test=0.866) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.786, test=0.778) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.782) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.871, test=0.868) balanced_accuracy: (train=0.744, test=0.741) f1: (train=0.787, test=0.783) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.873) balanced_accuracy: (train=0.744, test=0.752) f1: (train=0.785, test=0.793) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.746, test=0.743) f1: (train=0.787, test=0.784) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.870, test=0.866) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.786, test=0.778) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.782) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.871, test=0.868) balanced_accuracy: (train=0.744, test=0.741) f1: (train=0.787, test=0.783) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.873) balanced_accuracy: (train=0.744, test=0.752) f1: (train=0.785, test=0.793) total time=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.746, test=0.743) f1: (train=0.787, test=0.784) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.870, test=0.866) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.786, test=0.778) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.782) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.871, test=0.868) balanced_accuracy: (train=0.744, test=0.741) f1: (train=0.787, test=0.783) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.873) balanced_accuracy: (train=0.744, test=0.752) f1: (train=0.785, test=0.793) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.746, test=0.743) f1: (train=0.787, test=0.784) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.870, test=0.866) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.786, test=0.778) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.782) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.871, test=0.868) balanced_accuracy: (train=0.744, test=0.741) f1: (train=0.787, test=0.783) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.873) balanced_accuracy: (train=0.744, test=0.752) f1: (train=0.785, test=0.793) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.746, test=0.743) f1: (train=0.787, test=0.784) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.870, test=0.866) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.786, test=0.778) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.782) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.871, test=0.868) balanced_accuracy: (train=0.744, test=0.741) f1: (train=0.787, test=0.783) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.873) balanced_accuracy: (train=0.744, test=0.752) f1: (train=0.785, test=0.793) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.743, test=0.741) f1: (train=0.785, test=0.782) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.742, test=0.735) f1: (train=0.784, test=0.777) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.785, test=0.782) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.784, test=0.781) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.872) balanced_accuracy: (train=0.742, test=0.750) f1: (train=0.783, test=0.791) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.743, test=0.741) f1: (train=0.785, test=0.782) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.742, test=0.735) f1: (train=0.784, test=0.777) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.785, test=0.782) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.784, test=0.781) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.872) balanced_accuracy: (train=0.742, test=0.750) f1: (train=0.783, test=0.791) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.743, test=0.741) f1: (train=0.785, test=0.782) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.742, test=0.735) f1: (train=0.784, test=0.777) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.785, test=0.782) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.784, test=0.781) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.872) balanced_accuracy: (train=0.742, test=0.750) f1: (train=0.783, test=0.791) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.743, test=0.741) f1: (train=0.785, test=0.782) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.742, test=0.735) f1: (train=0.784, test=0.777) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.785, test=0.782) total time=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.784, test=0.781) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.872) balanced_accuracy: (train=0.742, test=0.750) f1: (train=0.783, test=0.791) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.743, test=0.741) f1: (train=0.785, test=0.782) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.742, test=0.735) f1: (train=0.784, test=0.777) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.785, test=0.782) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.784, test=0.781) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.872) balanced_accuracy: (train=0.742, test=0.750) f1: (train=0.783, test=0.791) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.743, test=0.741) f1: (train=0.785, test=0.782) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.742, test=0.735) f1: (train=0.784, test=0.777) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.785, test=0.782) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.784, test=0.781) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.872) balanced_accuracy: (train=0.742, test=0.750) f1: (train=0.783, test=0.791) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.737) f1: (train=0.781, test=0.779) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.738) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.740, test=0.749) f1: (train=0.781, test=0.789) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.737) f1: (train=0.781, test=0.779) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.738) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.740, test=0.749) f1: (train=0.781, test=0.789) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.737) f1: (train=0.781, test=0.779) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.738) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.740, test=0.749) f1: (train=0.781, test=0.789) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.737) f1: (train=0.781, test=0.779) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.738) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.740, test=0.749) f1: (train=0.781, test=0.789) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.737) f1: (train=0.781, test=0.779) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.738) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.740, test=0.749) f1: (train=0.781, test=0.789) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.737) f1: (train=0.781, test=0.779) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.738) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.740, test=0.749) f1: (train=0.781, test=0.789) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.780, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.865, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.780, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.865, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.780, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.865, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.780, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.865, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.780, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.865, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.780, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.865, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.749, test=0.745) f1: (train=0.790, test=0.786) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.746, test=0.738) f1: (train=0.788, test=0.780) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.789, test=0.785) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.788, test=0.784) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.870, test=0.873) balanced_accuracy: (train=0.746, test=0.754) f1: (train=0.788, test=0.795) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.749, test=0.745) f1: (train=0.790, test=0.786) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.746, test=0.738) f1: (train=0.788, test=0.780) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.789, test=0.785) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.788, test=0.784) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.870, test=0.873) balanced_accuracy: (train=0.746, test=0.754) f1: (train=0.788, test=0.795) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.749, test=0.745) f1: (train=0.790, test=0.786) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.746, test=0.738) f1: (train=0.788, test=0.780) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.789, test=0.785) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.788, test=0.784) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.870, test=0.873) balanced_accuracy: (train=0.746, test=0.754) f1: (train=0.788, test=0.795) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.749, test=0.745) f1: (train=0.790, test=0.786) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.746, test=0.738) f1: (train=0.788, test=0.780) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.789, test=0.785) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.788, test=0.784) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.870, test=0.873) balanced_accuracy: (train=0.746, test=0.754) f1: (train=0.788, test=0.795) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.749, test=0.745) f1: (train=0.790, test=0.786) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.746, test=0.738) f1: (train=0.788, test=0.780) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.789, test=0.785) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.788, test=0.784) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.870, test=0.873) balanced_accuracy: (train=0.746, test=0.754) f1: (train=0.788, test=0.795) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.749, test=0.745) f1: (train=0.790, test=0.786) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.746, test=0.738) f1: (train=0.788, test=0.780) total time=   0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.789, test=0.785) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.788, test=0.784) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.870, test=0.873) balanced_accuracy: (train=0.746, test=0.754) f1: (train=0.788, test=0.795) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.870, test=0.865) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.784, test=0.781) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.872) balanced_accuracy: (train=0.744, test=0.752) f1: (train=0.785, test=0.793) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.870, test=0.865) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.784, test=0.781) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.872) balanced_accuracy: (train=0.744, test=0.752) f1: (train=0.785, test=0.793) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.870, test=0.865) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.784, test=0.781) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.872) balanced_accuracy: (train=0.744, test=0.752) f1: (train=0.785, test=0.793) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.870, test=0.865) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.784, test=0.781) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.872) balanced_accuracy: (train=0.744, test=0.752) f1: (train=0.785, test=0.793) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.870, test=0.865) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.784, test=0.781) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.872) balanced_accuracy: (train=0.744, test=0.752) f1: (train=0.785, test=0.793) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.870, test=0.865) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.784, test=0.781) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.872) balanced_accuracy: (train=0.744, test=0.752) f1: (train=0.785, test=0.793) total time=   0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.737) f1: (train=0.781, test=0.779) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.738) f1: (train=0.783, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.740, test=0.749) f1: (train=0.781, test=0.789) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.737) f1: (train=0.781, test=0.779) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.738) f1: (train=0.783, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.740, test=0.749) f1: (train=0.781, test=0.789) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.737) f1: (train=0.781, test=0.779) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.738) f1: (train=0.783, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.740, test=0.749) f1: (train=0.781, test=0.789) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.737) f1: (train=0.781, test=0.779) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.738) f1: (train=0.783, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.740, test=0.749) f1: (train=0.781, test=0.789) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.737) f1: (train=0.781, test=0.779) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.738) f1: (train=0.783, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.740, test=0.749) f1: (train=0.781, test=0.789) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.737) f1: (train=0.781, test=0.779) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.738) f1: (train=0.783, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.740, test=0.749) f1: (train=0.781, test=0.789) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.780, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.865, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.780, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.737, test=0.734) f1: (train=0.780, test=0.777) total time=   1.4s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.779, test=0.776) total time=   1.6s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   2.9s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.780, test=0.776) total time=   3.9s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.779, test=0.776) total time=   2.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.737, test=0.731) f1: (train=0.780, test=0.773) total time=   4.1s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.872, test=0.870) balanced_accuracy: (train=0.747, test=0.742) f1: (train=0.789, test=0.785) total time=   5.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.872, test=0.870) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.790, test=0.786) total time=   8.5s\n",
      "[CV 2/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.872, test=0.867) balanced_accuracy: (train=0.746, test=0.738) f1: (train=0.789, test=0.780) total time=  16.4s\n",
      "[CV 1/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   1.2s\n",
      "[CV 2/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.779, test=0.772) total time=   1.4s\n",
      "[CV 5/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.866, test=0.870) balanced_accuracy: (train=0.733, test=0.741) f1: (train=0.776, test=0.784) total time=   1.8s\n",
      "[CV 3/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   2.6s\n",
      "[CV 3/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.735, test=0.732) f1: (train=0.779, test=0.775) total time=   4.6s\n",
      "[CV 2/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.737, test=0.730) f1: (train=0.780, test=0.773) total time=   1.3s\n",
      "[CV 2/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.737, test=0.731) f1: (train=0.780, test=0.774) total time=   2.2s\n",
      "[CV 5/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.866, test=0.871) balanced_accuracy: (train=0.733, test=0.742) f1: (train=0.776, test=0.785) total time=   2.1s\n",
      "[CV 2/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.737, test=0.731) f1: (train=0.780, test=0.773) total time=   4.2s\n",
      "[CV 4/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.872, test=0.870) balanced_accuracy: (train=0.747, test=0.742) f1: (train=0.790, test=0.785) total time=   5.4s\n",
      "[CV 1/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.872, test=0.870) balanced_accuracy: (train=0.748, test=0.744) f1: (train=0.790, test=0.786) total time=   7.2s\n",
      "[CV 3/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.873, test=0.870) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.790, test=0.786) total time=  17.3s\n",
      "[CV 3/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.737, test=0.733) f1: (train=0.780, test=0.775) total time=   1.2s\n",
      "[CV 4/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   1.3s\n",
      "[CV 1/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   2.4s\n",
      "[CV 1/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   2.6s\n",
      "[CV 4/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   3.3s\n",
      "[CV 1/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   1.4s\n",
      "[CV 4/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.737, test=0.735) f1: (train=0.779, test=0.778) total time=   1.4s\n",
      "[CV 1/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   2.2s\n",
      "[CV 5/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.787) total time=   4.2s\n",
      "[CV 2/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.873, test=0.868) balanced_accuracy: (train=0.747, test=0.739) f1: (train=0.790, test=0.781) total time=   5.2s\n",
      "[CV 1/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.872, test=0.870) balanced_accuracy: (train=0.748, test=0.744) f1: (train=0.790, test=0.786) total time=   8.7s\n",
      "[CV 4/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.872, test=0.870) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.789, test=0.784) total time=  16.6s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.732) f1: (train=0.779, test=0.775) total time=   1.6s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   1.6s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.866, test=0.870) balanced_accuracy: (train=0.733, test=0.742) f1: (train=0.776, test=0.785) total time=   1.9s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   2.4s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.733, test=0.743) f1: (train=0.776, test=0.786) total time=   4.4s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   1.7s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   1.3s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   2.4s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   4.5s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.783) total time=   5.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.744, test=0.741) f1: (train=0.787, test=0.784) total time=   8.5s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.785, test=0.782) total time=  17.1s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.870, test=0.874) balanced_accuracy: (train=0.741, test=0.751) f1: (train=0.784, test=0.794) total time=  13.8s\n",
      "[CV 1/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.778, test=0.776) total time=   1.4s\n",
      "[CV 4/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   1.4s\n",
      "[CV 5/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.866, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.776, test=0.787) total time=   2.2s\n",
      "[CV 2/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.780, test=0.773) total time=   4.3s\n",
      "[CV 5/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.733, test=0.743) f1: (train=0.777, test=0.786) total time=   4.4s\n",
      "[CV 1/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.744, test=0.740) f1: (train=0.787, test=0.783) total time=   4.9s\n",
      "[CV 2/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.872, test=0.867) balanced_accuracy: (train=0.745, test=0.737) f1: (train=0.788, test=0.779) total time=   8.9s\n",
      "[CV 5/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.870, test=0.874) balanced_accuracy: (train=0.742, test=0.750) f1: (train=0.785, test=0.793) total time=  17.8s\n",
      "[CV 3/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.732) f1: (train=0.779, test=0.775) total time=   1.4s\n",
      "[CV 2/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.736, test=0.729) f1: (train=0.779, test=0.772) total time=   1.6s\n",
      "[CV 4/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.778, test=0.775) total time=   1.5s\n",
      "[CV 1/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.735) f1: (train=0.779, test=0.778) total time=   2.5s\n",
      "[CV 1/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   4.5s\n",
      "[CV 2/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.780, test=0.773) total time=   4.2s\n",
      "[CV 1/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.735) f1: (train=0.779, test=0.778) total time=   2.1s\n",
      "[CV 3/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   4.1s\n",
      "[CV 4/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.779, test=0.777) total time=   4.8s\n",
      "[CV 2/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.872, test=0.867) balanced_accuracy: (train=0.744, test=0.736) f1: (train=0.787, test=0.779) total time=   3.7s\n",
      "[CV 3/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.786, test=0.783) total time=   9.1s\n",
      "[CV 1/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.744, test=0.741) f1: (train=0.787, test=0.784) total time=  15.3s\n",
      "[CV 5/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.870, test=0.874) balanced_accuracy: (train=0.742, test=0.751) f1: (train=0.785, test=0.794) total time=  17.0s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   1.2s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.735, test=0.735) f1: (train=0.778, test=0.778) total time=   1.3s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   2.0s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.780, test=0.772) total time=   3.9s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   4.3s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.872, test=0.867) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.787, test=0.779) total time=   5.1s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.870, test=0.874) balanced_accuracy: (train=0.741, test=0.750) f1: (train=0.784, test=0.793) total time=   8.2s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.787, test=0.778) total time=  18.6s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.866, test=0.869) balanced_accuracy: (train=0.732, test=0.741) f1: (train=0.775, test=0.784) total time=   1.4s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.737, test=0.731) f1: (train=0.780, test=0.773) total time=   2.0s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.779, test=0.776) total time=   2.2s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.776, test=0.786) total time=   4.3s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.866, test=0.871) balanced_accuracy: (train=0.733, test=0.742) f1: (train=0.776, test=0.785) total time=   1.4s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.776) total time=   1.3s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.866, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.776, test=0.787) total time=   2.3s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.780, test=0.773) total time=   4.3s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.779, test=0.777) total time=   4.5s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.744, test=0.740) f1: (train=0.787, test=0.783) total time=   5.4s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.786, test=0.783) total time=   8.7s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.744, test=0.741) f1: (train=0.787, test=0.784) total time=  19.0s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.779, test=0.776) total time=   1.3s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.776) total time=   1.2s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.779, test=0.776) total time=   2.0s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.780, test=0.772) total time=   2.4s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   4.3s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.736, test=0.729) f1: (train=0.779, test=0.772) total time=   1.2s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.776) total time=   2.2s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.779, test=0.776) total time=   2.0s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.866, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.786) total time=   4.3s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.872, test=0.867) balanced_accuracy: (train=0.745, test=0.737) f1: (train=0.788, test=0.779) total time=   6.3s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.741) f1: (train=0.786, test=0.784) total time=   9.7s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.744, test=0.741) f1: (train=0.787, test=0.783) total time=  20.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   1.2s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   1.3s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.786) total time=   2.2s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   2.2s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.733, test=0.743) f1: (train=0.776, test=0.786) total time=   3.8s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.776) total time=   1.4s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.737, test=0.730) f1: (train=0.780, test=0.772) total time=   1.3s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   1.4s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   1.9s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.778) total time=   4.0s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.782) total time=   5.3s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.744, test=0.740) f1: (train=0.787, test=0.783) total time=   8.5s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.785, test=0.782) total time=   8.7s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.744, test=0.740) f1: (train=0.786, test=0.783) total time=  18.0s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   3.9s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   4.2s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.776) total time=   1.0s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.737, test=0.731) f1: (train=0.780, test=0.773) total time=   2.1s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.779, test=0.776) total time=   4.4s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.741) f1: (train=0.786, test=0.783) total time=   5.5s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.870, test=0.875) balanced_accuracy: (train=0.742, test=0.752) f1: (train=0.785, test=0.795) total time=   5.8s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.787, test=0.779) total time=   8.9s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.783) total time=  17.2s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.866, test=0.870) balanced_accuracy: (train=0.733, test=0.742) f1: (train=0.776, test=0.785) total time=   1.1s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.778, test=0.775) total time=   1.2s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.866, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.776, test=0.787) total time=   2.0s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.778, test=0.776) total time=   2.0s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.779, test=0.776) total time=   4.4s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.864) balanced_accuracy: (train=0.735, test=0.729) f1: (train=0.778, test=0.771) total time=   1.3s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.866, test=0.870) balanced_accuracy: (train=0.733, test=0.742) f1: (train=0.776, test=0.785) total time=   1.4s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   2.2s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   4.2s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.777) total time=   4.7s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.744, test=0.740) f1: (train=0.787, test=0.783) total time=   5.6s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.870, test=0.874) balanced_accuracy: (train=0.742, test=0.751) f1: (train=0.785, test=0.794) total time=  10.3s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.785, test=0.782) total time=  15.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.865, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   1.3s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.786) total time=   1.6s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   2.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.735) f1: (train=0.780, test=0.778) total time=   4.2s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.786) total time=   1.2s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.786) total time=   1.9s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.735) f1: (train=0.779, test=0.778) total time=   3.9s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   3.7s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.871, test=0.875) balanced_accuracy: (train=0.746, test=0.753) f1: (train=0.788, test=0.795) total time=   4.6s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.872, test=0.870) balanced_accuracy: (train=0.746, test=0.743) f1: (train=0.789, test=0.785) total time=   5.7s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.871, test=0.875) balanced_accuracy: (train=0.744, test=0.753) f1: (train=0.787, test=0.796) total time=   8.1s\n",
      "[CV 2/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.872, test=0.867) balanced_accuracy: (train=0.746, test=0.738) f1: (train=0.789, test=0.780) total time=  15.9s\n",
      "[CV 3/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.779, test=0.776) total time=   2.3s\n",
      "[CV 2/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.780, test=0.773) total time=   4.2s\n",
      "[CV 3/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.737, test=0.733) f1: (train=0.780, test=0.775) total time=   1.4s\n",
      "[CV 4/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.737, test=0.735) f1: (train=0.779, test=0.778) total time=   1.2s\n",
      "[CV 3/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   1.9s\n",
      "[CV 4/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   4.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.872, test=0.870) balanced_accuracy: (train=0.748, test=0.743) f1: (train=0.791, test=0.785) total time=   5.3s\n",
      "[CV 1/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.872, test=0.870) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.790, test=0.785) total time=   7.1s\n",
      "[CV 3/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.872, test=0.870) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.789, test=0.785) total time=   8.4s\n",
      "[CV 5/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.871, test=0.875) balanced_accuracy: (train=0.745, test=0.753) f1: (train=0.787, test=0.796) total time=  12.7s\n",
      "[CV 2/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.779, test=0.772) total time=   1.4s\n",
      "[CV 3/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.737, test=0.734) f1: (train=0.780, test=0.777) total time=   1.1s\n",
      "[CV 4/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.780, test=0.777) total time=   2.2s\n",
      "[CV 2/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.737, test=0.730) f1: (train=0.780, test=0.773) total time=   2.3s\n",
      "[CV 1/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.737, test=0.735) f1: (train=0.780, test=0.777) total time=   4.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.737, test=0.733) f1: (train=0.780, test=0.775) total time=   1.3s\n",
      "[CV 4/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   1.3s\n",
      "[CV 4/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.780, test=0.777) total time=   1.7s\n",
      "[CV 4/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   2.1s\n",
      "[CV 1/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.735) f1: (train=0.779, test=0.778) total time=   4.1s\n",
      "[CV 3/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.872, test=0.870) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.790, test=0.786) total time=   5.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.872, test=0.870) balanced_accuracy: (train=0.747, test=0.742) f1: (train=0.790, test=0.785) total time=   8.3s\n",
      "[CV 1/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.872, test=0.870) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.790, test=0.785) total time=  16.6s\n",
      "[CV 4/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.872, test=0.870) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.789, test=0.785) total time=  15.8s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.777) total time=   1.4s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   1.3s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   2.1s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.778) total time=   4.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.782) total time=   5.2s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.744, test=0.740) f1: (train=0.787, test=0.783) total time=   8.5s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.783) total time=   8.6s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.744, test=0.740) f1: (train=0.786, test=0.783) total time=  17.5s\n",
      "[CV 3/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   2.4s\n",
      "[CV 3/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   4.2s\n",
      "[CV 2/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.864) balanced_accuracy: (train=0.735, test=0.729) f1: (train=0.778, test=0.771) total time=   1.2s\n",
      "[CV 2/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.736, test=0.729) f1: (train=0.779, test=0.772) total time=   1.3s\n",
      "[CV 5/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.866, test=0.869) balanced_accuracy: (train=0.732, test=0.741) f1: (train=0.775, test=0.784) total time=   1.3s\n",
      "[CV 2/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.780, test=0.772) total time=   2.1s\n",
      "[CV 4/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   4.3s\n",
      "[CV 4/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.741) f1: (train=0.786, test=0.783) total time=   5.5s\n",
      "[CV 4/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.783) total time=   5.9s\n",
      "[CV 2/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.787, test=0.779) total time=  10.2s\n",
      "[CV 4/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.783) total time=  15.8s\n",
      "[CV 3/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.779, test=0.776) total time=   1.5s\n",
      "[CV 5/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.866, test=0.869) balanced_accuracy: (train=0.732, test=0.741) f1: (train=0.775, test=0.784) total time=   1.5s\n",
      "[CV 2/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.737, test=0.731) f1: (train=0.780, test=0.773) total time=   2.1s\n",
      "[CV 5/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.866, test=0.871) balanced_accuracy: (train=0.733, test=0.742) f1: (train=0.776, test=0.786) total time=   2.3s\n",
      "[CV 4/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   4.6s\n",
      "[CV 2/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.736, test=0.729) f1: (train=0.779, test=0.772) total time=   1.4s\n",
      "[CV 5/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.866, test=0.869) balanced_accuracy: (train=0.732, test=0.741) f1: (train=0.775, test=0.784) total time=   1.4s\n",
      "[CV 2/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.780, test=0.772) total time=   2.2s\n",
      "[CV 4/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   4.1s\n",
      "[CV 1/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.744, test=0.741) f1: (train=0.787, test=0.783) total time=   5.4s\n",
      "[CV 2/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.744, test=0.736) f1: (train=0.787, test=0.779) total time=   9.2s\n",
      "[CV 5/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.870, test=0.874) balanced_accuracy: (train=0.742, test=0.751) f1: (train=0.785, test=0.794) total time=   9.4s\n",
      "[CV 2/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.787, test=0.778) total time=  18.5s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.733, test=0.743) f1: (train=0.777, test=0.786) total time=   2.1s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   4.2s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.777) total time=   1.3s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.864) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.779, test=0.772) total time=   1.3s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.779, test=0.776) total time=   1.9s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   4.1s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.745, test=0.741) f1: (train=0.788, test=0.783) total time=   5.4s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.785, test=0.782) total time=   3.5s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.783) total time=   8.1s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.870, test=0.874) balanced_accuracy: (train=0.741, test=0.751) f1: (train=0.784, test=0.794) total time=  14.8s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.783) total time=  12.6s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.866, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.786) total time=   4.2s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.737, test=0.731) f1: (train=0.780, test=0.773) total time=   1.4s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.735) f1: (train=0.779, test=0.778) total time=   2.2s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.776, test=0.786) total time=   4.1s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.745, test=0.741) f1: (train=0.787, test=0.783) total time=   5.6s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.785, test=0.782) total time=   5.8s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.744, test=0.741) f1: (train=0.787, test=0.783) total time=   8.6s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.785, test=0.782) total time=  18.8s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.737, test=0.731) f1: (train=0.780, test=0.773) total time=   1.4s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   2.2s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   2.4s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.776, test=0.786) total time=   4.2s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.778, test=0.776) total time=   1.3s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   1.5s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.779, test=0.776) total time=   2.0s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.866, test=0.871) balanced_accuracy: (train=0.733, test=0.742) f1: (train=0.776, test=0.786) total time=   2.2s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.780, test=0.773) total time=   4.0s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.785, test=0.782) total time=   5.9s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.870, test=0.874) balanced_accuracy: (train=0.742, test=0.751) f1: (train=0.785, test=0.794) total time=   9.8s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.744, test=0.736) f1: (train=0.787, test=0.779) total time=  19.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.780, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.786) total time=   1.3s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.786) total time=   1.4s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   2.1s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.737, test=0.731) f1: (train=0.780, test=0.773) total time=   2.0s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.780, test=0.772) total time=   4.2s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.737, test=0.730) f1: (train=0.780, test=0.773) total time=   4.1s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.735) f1: (train=0.779, test=0.778) total time=   2.1s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.733, test=0.743) f1: (train=0.776, test=0.786) total time=   4.2s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.744, test=0.736) f1: (train=0.787, test=0.778) total time=   5.4s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.871, test=0.870) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.783) total time=   5.4s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.744, test=0.740) f1: (train=0.786, test=0.783) total time=   8.4s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.783) total time=  13.3s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.778, test=0.776) total time=   1.5s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.778, test=0.776) total time=   1.2s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.866, test=0.870) balanced_accuracy: (train=0.733, test=0.742) f1: (train=0.776, test=0.785) total time=   1.6s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.779, test=0.773) total time=   2.3s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.866, test=0.870) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.785) total time=   2.2s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   4.2s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.778, test=0.776) total time=   1.5s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.777) total time=   1.6s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.776) total time=   2.2s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.779, test=0.776) total time=   2.1s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.866, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.786) total time=   4.3s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.872, test=0.867) balanced_accuracy: (train=0.745, test=0.737) f1: (train=0.788, test=0.779) total time=   5.7s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.745, test=0.741) f1: (train=0.787, test=0.784) total time=   8.9s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.785, test=0.783) total time=  15.2s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.741) f1: (train=0.786, test=0.783) total time=  13.6s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.778) total time=   4.4s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.732) f1: (train=0.779, test=0.775) total time=   1.3s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.776) total time=   1.3s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.866, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.776, test=0.787) total time=   2.1s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.780, test=0.773) total time=   4.3s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.779, test=0.777) total time=   4.9s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.870, test=0.875) balanced_accuracy: (train=0.742, test=0.752) f1: (train=0.785, test=0.795) total time=   5.6s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.787, test=0.779) total time=   8.6s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.870, test=0.874) balanced_accuracy: (train=0.742, test=0.750) f1: (train=0.785, test=0.793) total time=  19.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.865, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.780, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.778) total time=   3.9s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.863) balanced_accuracy: (train=0.736, test=0.729) f1: (train=0.778, test=0.771) total time=   1.4s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.732) f1: (train=0.779, test=0.775) total time=   1.2s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   1.4s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   2.0s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.737, test=0.730) f1: (train=0.780, test=0.773) total time=   4.1s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.870, test=0.875) balanced_accuracy: (train=0.741, test=0.751) f1: (train=0.784, test=0.794) total time=   5.3s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.785, test=0.782) total time=   8.6s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.783) total time=   7.3s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.870, test=0.874) balanced_accuracy: (train=0.741, test=0.750) f1: (train=0.784, test=0.793) total time=  12.6s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.736, test=0.729) f1: (train=0.779, test=0.772) total time=   1.0s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.737, test=0.731) f1: (train=0.780, test=0.773) total time=   1.5s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.779, test=0.776) total time=   2.3s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.866, test=0.871) balanced_accuracy: (train=0.733, test=0.742) f1: (train=0.776, test=0.786) total time=   2.2s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.778) total time=   4.1s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.864) balanced_accuracy: (train=0.735, test=0.729) f1: (train=0.778, test=0.771) total time=   1.3s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.779, test=0.776) total time=   1.4s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.779, test=0.773) total time=   2.2s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.779, test=0.777) total time=   2.2s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   4.3s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.783) total time=   5.1s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.870, test=0.874) balanced_accuracy: (train=0.742, test=0.751) f1: (train=0.785, test=0.794) total time=   8.9s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.744, test=0.736) f1: (train=0.787, test=0.779) total time=  18.8s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.864) balanced_accuracy: (train=0.735, test=0.729) f1: (train=0.778, test=0.771) total time=   1.3s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.778, test=0.776) total time=   1.3s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.736, test=0.729) f1: (train=0.779, test=0.772) total time=   1.5s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.866, test=0.869) balanced_accuracy: (train=0.732, test=0.741) f1: (train=0.775, test=0.784) total time=   1.3s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.735) f1: (train=0.779, test=0.778) total time=   2.2s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.779, test=0.777) total time=   2.3s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.866, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.786) total time=   4.0s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.866, test=0.871) balanced_accuracy: (train=0.733, test=0.742) f1: (train=0.776, test=0.785) total time=   1.2s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.776) total time=   1.3s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   2.2s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   4.3s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.741) f1: (train=0.786, test=0.783) total time=   4.6s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.785, test=0.782) total time=   5.4s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.783) total time=   9.8s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.744, test=0.741) f1: (train=0.787, test=0.784) total time=  19.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.869, test=0.864) balanced_accuracy: (train=0.739, test=0.731) f1: (train=0.782, test=0.773) total time=   1.2s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   2.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.737, test=0.730) f1: (train=0.780, test=0.773) total time=   3.5s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.786) total time=   4.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.737, test=0.735) f1: (train=0.780, test=0.778) total time=   2.1s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.735) f1: (train=0.780, test=0.778) total time=   4.2s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.872, test=0.870) balanced_accuracy: (train=0.746, test=0.743) f1: (train=0.789, test=0.785) total time=   5.2s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.872, test=0.870) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.790, test=0.786) total time=   8.4s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.746, test=0.741) f1: (train=0.789, test=0.783) total time=  13.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.746, test=0.741) f1: (train=0.789, test=0.784) total time=  12.6s\n",
      "[CV 1/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.735) f1: (train=0.779, test=0.778) total time=   3.9s\n",
      "[CV 5/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.786) total time=   1.3s\n",
      "[CV 3/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.737, test=0.734) f1: (train=0.780, test=0.777) total time=   1.2s\n",
      "[CV 2/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.737, test=0.730) f1: (train=0.780, test=0.773) total time=   1.9s\n",
      "[CV 2/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.780, test=0.773) total time=   4.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.871, test=0.875) balanced_accuracy: (train=0.745, test=0.754) f1: (train=0.788, test=0.796) total time=   5.2s\n",
      "[CV 3/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.873, test=0.870) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.790, test=0.786) total time=   8.5s\n",
      "[CV 4/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.872, test=0.870) balanced_accuracy: (train=0.746, test=0.743) f1: (train=0.789, test=0.785) total time=   8.2s\n",
      "[CV 1/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.873, test=0.870) balanced_accuracy: (train=0.748, test=0.743) f1: (train=0.790, test=0.786) total time=  16.3s\n",
      "[CV 4/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.737, test=0.734) f1: (train=0.780, test=0.777) total time=   2.1s\n",
      "[CV 3/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.735, test=0.732) f1: (train=0.779, test=0.775) total time=   4.2s\n",
      "[CV 4/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.780, test=0.776) total time=   3.8s\n",
      "[CV 2/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.737, test=0.730) f1: (train=0.780, test=0.773) total time=   1.9s\n",
      "[CV 2/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.737, test=0.730) f1: (train=0.780, test=0.773) total time=   4.1s\n",
      "[CV 4/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.780, test=0.776) total time=   4.4s\n",
      "[CV 2/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.873, test=0.868) balanced_accuracy: (train=0.747, test=0.739) f1: (train=0.791, test=0.781) total time=   5.3s\n",
      "[CV 5/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.871, test=0.875) balanced_accuracy: (train=0.745, test=0.753) f1: (train=0.788, test=0.796) total time=   8.4s\n",
      "[CV 3/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.873, test=0.870) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.790, test=0.785) total time=  16.5s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.732) f1: (train=0.779, test=0.775) total time=   1.4s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   1.3s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.737, test=0.731) f1: (train=0.780, test=0.773) total time=   2.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.778) total time=   4.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   4.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.864) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.779, test=0.772) total time=   1.3s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.779, test=0.776) total time=   1.9s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.733, test=0.743) f1: (train=0.776, test=0.786) total time=   4.1s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.745, test=0.741) f1: (train=0.788, test=0.783) total time=   5.3s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.871, test=0.870) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.783) total time=   4.9s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.870, test=0.874) balanced_accuracy: (train=0.741, test=0.750) f1: (train=0.784, test=0.793) total time=   7.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.744, test=0.740) f1: (train=0.787, test=0.783) total time=  16.8s\n",
      "[CV 3/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.732) f1: (train=0.779, test=0.775) total time=   1.4s\n",
      "[CV 4/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   1.6s\n",
      "[CV 1/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.776) total time=   2.2s\n",
      "[CV 4/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   2.5s\n",
      "[CV 4/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.779, test=0.776) total time=   3.1s\n",
      "[CV 3/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.777) total time=   3.6s\n",
      "[CV 4/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.779, test=0.776) total time=   2.4s\n",
      "[CV 1/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   4.3s\n",
      "[CV 4/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.779, test=0.777) total time=   4.5s\n",
      "[CV 2/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.872, test=0.867) balanced_accuracy: (train=0.744, test=0.736) f1: (train=0.787, test=0.779) total time=   5.3s\n",
      "[CV 4/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.783) total time=  10.2s\n",
      "[CV 1/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.744, test=0.741) f1: (train=0.787, test=0.784) total time=  18.1s\n",
      "[CV 1/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.777) total time=   1.6s\n",
      "[CV 3/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.776) total time=   1.4s\n",
      "[CV 5/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.866, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.776, test=0.787) total time=   2.1s\n",
      "[CV 4/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.779, test=0.777) total time=   2.1s\n",
      "[CV 2/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.780, test=0.773) total time=   4.7s\n",
      "[CV 5/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.866, test=0.871) balanced_accuracy: (train=0.733, test=0.742) f1: (train=0.776, test=0.785) total time=   1.6s\n",
      "[CV 3/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.776) total time=   1.5s\n",
      "[CV 4/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   2.2s\n",
      "[CV 3/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   4.3s\n",
      "[CV 5/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.870, test=0.874) balanced_accuracy: (train=0.741, test=0.750) f1: (train=0.784, test=0.793) total time=   5.4s\n",
      "[CV 1/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.744, test=0.740) f1: (train=0.786, test=0.783) total time=   9.2s\n",
      "[CV 3/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.785, test=0.783) total time=   9.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.870, test=0.874) balanced_accuracy: (train=0.742, test=0.751) f1: (train=0.785, test=0.794) total time=  18.8s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.777) total time=   2.1s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.737, test=0.730) f1: (train=0.780, test=0.773) total time=   3.9s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.732) f1: (train=0.779, test=0.775) total time=   1.2s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   1.3s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.737, test=0.730) f1: (train=0.780, test=0.772) total time=   2.1s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.733, test=0.743) f1: (train=0.777, test=0.786) total time=   2.1s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.737, test=0.730) f1: (train=0.780, test=0.773) total time=   4.4s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.783) total time=   5.5s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.744, test=0.741) f1: (train=0.787, test=0.784) total time=   8.2s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.785, test=0.782) total time=  12.7s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.785, test=0.782) total time=  16.8s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.780, test=0.773) total time=   4.3s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.866, test=0.869) balanced_accuracy: (train=0.732, test=0.741) f1: (train=0.775, test=0.784) total time=   1.4s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.780, test=0.772) total time=   2.1s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   3.9s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.744, test=0.741) f1: (train=0.787, test=0.783) total time=   5.6s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.785, test=0.782) total time=   9.0s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.744, test=0.741) f1: (train=0.787, test=0.783) total time=  12.3s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.785, test=0.782) total time=  15.9s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   4.3s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.777) total time=   4.2s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.735) f1: (train=0.779, test=0.778) total time=   2.1s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   4.2s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.733, test=0.743) f1: (train=0.777, test=0.786) total time=   4.6s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.872, test=0.867) balanced_accuracy: (train=0.744, test=0.736) f1: (train=0.787, test=0.779) total time=   5.4s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.786, test=0.783) total time=  10.1s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.872, test=0.867) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.787, test=0.779) total time=  18.7s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.865, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.780, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.735, test=0.732) f1: (train=0.779, test=0.775) total time=   1.3s\n",
      "[CV 2/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.737, test=0.731) f1: (train=0.780, test=0.773) total time=   1.8s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.779, test=0.776) total time=   1.9s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.744) f1: (train=0.777, test=0.787) total time=   4.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.735, test=0.732) f1: (train=0.779, test=0.775) total time=   1.2s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.732) f1: (train=0.779, test=0.775) total time=   2.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.866, test=0.871) balanced_accuracy: (train=0.733, test=0.742) f1: (train=0.776, test=0.786) total time=   1.8s\n",
      "[CV 2/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.738, test=0.730) f1: (train=0.781, test=0.773) total time=   3.9s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.789, test=0.784) total time=   4.7s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.746, test=0.741) f1: (train=0.789, test=0.784) total time=   8.3s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.872, test=0.870) balanced_accuracy: (train=0.747, test=0.742) f1: (train=0.790, test=0.785) total time=  16.3s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.871, test=0.875) balanced_accuracy: (train=0.745, test=0.753) f1: (train=0.787, test=0.796) total time=  12.6s\n",
      "[CV 2/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.737, test=0.731) f1: (train=0.780, test=0.773) total time=   3.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.787) total time=   1.3s\n",
      "[CV 4/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.780, test=0.777) total time=   1.9s\n",
      "[CV 1/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.735) f1: (train=0.779, test=0.778) total time=   3.9s\n",
      "[CV 3/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   4.1s\n",
      "[CV 5/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.871, test=0.875) balanced_accuracy: (train=0.746, test=0.753) f1: (train=0.788, test=0.796) total time=   4.9s\n",
      "[CV 2/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.873, test=0.868) balanced_accuracy: (train=0.747, test=0.739) f1: (train=0.790, test=0.781) total time=   8.4s\n",
      "[CV 1/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.873, test=0.870) balanced_accuracy: (train=0.748, test=0.744) f1: (train=0.791, test=0.786) total time=  13.8s\n",
      "[CV 4/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.872, test=0.870) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.789, test=0.785) total time=  12.6s\n",
      "[CV 5/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.787) total time=   4.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.737, test=0.734) f1: (train=0.780, test=0.777) total time=   1.2s\n",
      "[CV 5/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.787) total time=   2.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.737, test=0.735) f1: (train=0.780, test=0.777) total time=   4.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.873, test=0.870) balanced_accuracy: (train=0.747, test=0.744) f1: (train=0.790, test=0.786) total time=   5.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.872, test=0.870) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.790, test=0.785) total time=   9.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.872, test=0.870) balanced_accuracy: (train=0.746, test=0.743) f1: (train=0.789, test=0.785) total time=   8.4s\n",
      "[CV 2/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.872, test=0.867) balanced_accuracy: (train=0.746, test=0.738) f1: (train=0.790, test=0.781) total time=  14.4s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.735) f1: (train=0.779, test=0.778) total time=   2.1s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.733, test=0.743) f1: (train=0.777, test=0.786) total time=   2.1s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.786) total time=   4.1s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.786) total time=   1.2s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.735, test=0.735) f1: (train=0.778, test=0.778) total time=   1.4s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.786) total time=   1.9s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.780, test=0.772) total time=   4.1s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   4.2s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.744, test=0.741) f1: (train=0.787, test=0.783) total time=   4.8s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.787, test=0.779) total time=   8.2s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.783) total time=  16.7s\n",
      "[CV 1/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.778, test=0.776) total time=   1.4s\n",
      "[CV 1/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.777) total time=   1.5s\n",
      "[CV 2/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.737, test=0.731) f1: (train=0.780, test=0.773) total time=   1.5s\n",
      "[CV 4/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.779, test=0.776) total time=   2.5s\n",
      "[CV 3/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.779, test=0.776) total time=   2.4s\n",
      "[CV 2/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.780, test=0.773) total time=   4.6s\n",
      "[CV 5/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.866, test=0.871) balanced_accuracy: (train=0.733, test=0.742) f1: (train=0.776, test=0.785) total time=   1.4s\n",
      "[CV 4/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.778, test=0.775) total time=   1.4s\n",
      "[CV 5/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.866, test=0.870) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.785) total time=   2.1s\n",
      "[CV 2/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.780, test=0.773) total time=   4.4s\n",
      "[CV 1/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.744, test=0.741) f1: (train=0.787, test=0.783) total time=   5.5s\n",
      "[CV 2/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.744, test=0.736) f1: (train=0.787, test=0.779) total time=   8.3s\n",
      "[CV 3/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.785, test=0.783) total time=   9.5s\n",
      "[CV 1/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.744, test=0.741) f1: (train=0.787, test=0.784) total time=  18.6s\n",
      "[CV 5/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.866, test=0.870) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.785) total time=   2.4s\n",
      "[CV 3/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   3.7s\n",
      "[CV 5/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.733, test=0.743) f1: (train=0.777, test=0.786) total time=   3.3s\n",
      "[CV 3/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   2.1s\n",
      "[CV 5/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.866, test=0.871) balanced_accuracy: (train=0.733, test=0.742) f1: (train=0.776, test=0.786) total time=   2.2s\n",
      "[CV 2/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.780, test=0.773) total time=   4.2s\n",
      "[CV 3/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.785, test=0.782) total time=   5.6s\n",
      "[CV 1/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.745, test=0.741) f1: (train=0.787, test=0.784) total time=   9.1s\n",
      "[CV 3/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.785, test=0.783) total time=  15.1s\n",
      "[CV 4/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.741) f1: (train=0.786, test=0.783) total time=  16.7s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   4.0s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.737, test=0.731) f1: (train=0.780, test=0.773) total time=   2.0s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   4.0s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   4.3s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.744, test=0.741) f1: (train=0.787, test=0.783) total time=   5.2s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.871, test=0.870) balanced_accuracy: (train=0.743, test=0.741) f1: (train=0.786, test=0.784) total time=   7.9s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.744, test=0.740) f1: (train=0.787, test=0.783) total time=  18.2s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   1.5s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.776) total time=   2.3s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   2.3s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.780, test=0.773) total time=   4.0s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.777) total time=   4.2s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.866, test=0.870) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.785) total time=   2.2s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.780, test=0.773) total time=   4.2s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.787, test=0.779) total time=   5.8s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.744, test=0.740) f1: (train=0.786, test=0.783) total time=   9.1s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.741) f1: (train=0.786, test=0.783) total time=   9.5s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.744, test=0.741) f1: (train=0.787, test=0.784) total time=  18.4s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.779, test=0.776) total time=   2.4s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   4.2s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.778, test=0.776) total time=   1.3s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.737, test=0.731) f1: (train=0.780, test=0.773) total time=   1.4s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.737, test=0.731) f1: (train=0.780, test=0.773) total time=   2.1s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.779, test=0.776) total time=   4.1s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.745, test=0.741) f1: (train=0.787, test=0.783) total time=   6.2s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.744, test=0.740) f1: (train=0.786, test=0.783) total time=  10.0s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.741) f1: (train=0.786, test=0.783) total time=   6.7s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.870, test=0.874) balanced_accuracy: (train=0.742, test=0.751) f1: (train=0.785, test=0.794) total time=  17.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.865, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.732) f1: (train=0.779, test=0.775) total time=   1.3s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.735) f1: (train=0.779, test=0.778) total time=   2.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.735, test=0.732) f1: (train=0.779, test=0.775) total time=   2.8s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   3.6s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.735) f1: (train=0.779, test=0.778) total time=   1.9s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.779, test=0.776) total time=   2.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.744) f1: (train=0.777, test=0.787) total time=   4.1s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.872, test=0.870) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.790, test=0.785) total time=   4.7s\n",
      "[CV 2/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.872, test=0.868) balanced_accuracy: (train=0.747, test=0.739) f1: (train=0.790, test=0.781) total time=   7.1s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.872, test=0.870) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.789, test=0.784) total time=   8.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.747, test=0.742) f1: (train=0.790, test=0.785) total time=  16.1s\n",
      "[CV 2/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.737, test=0.730) f1: (train=0.780, test=0.773) total time=   2.3s\n",
      "[CV 1/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.735) f1: (train=0.779, test=0.778) total time=   4.3s\n",
      "[CV 5/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.786) total time=   3.7s\n",
      "[CV 4/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.737, test=0.734) f1: (train=0.780, test=0.777) total time=   2.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.733, test=0.743) f1: (train=0.777, test=0.786) total time=   4.1s\n",
      "[CV 2/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.873, test=0.868) balanced_accuracy: (train=0.747, test=0.739) f1: (train=0.791, test=0.781) total time=   5.2s\n",
      "[CV 5/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.871, test=0.875) balanced_accuracy: (train=0.745, test=0.753) f1: (train=0.788, test=0.796) total time=   5.4s\n",
      "[CV 2/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.873, test=0.867) balanced_accuracy: (train=0.747, test=0.738) f1: (train=0.790, test=0.780) total time=   8.7s\n",
      "[CV 4/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.873, test=0.869) balanced_accuracy: (train=0.747, test=0.742) f1: (train=0.790, test=0.784) total time=  17.6s\n",
      "[CV 2/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.737, test=0.730) f1: (train=0.780, test=0.773) total time=   2.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   2.3s\n",
      "[CV 3/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   4.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   1.2s\n",
      "[CV 3/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.732) f1: (train=0.779, test=0.775) total time=   1.2s\n",
      "[CV 2/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.737, test=0.731) f1: (train=0.780, test=0.774) total time=   2.1s\n",
      "[CV 5/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.866, test=0.871) balanced_accuracy: (train=0.733, test=0.742) f1: (train=0.776, test=0.785) total time=   2.2s\n",
      "[CV 2/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.737, test=0.731) f1: (train=0.780, test=0.773) total time=   4.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.872, test=0.870) balanced_accuracy: (train=0.747, test=0.742) f1: (train=0.790, test=0.785) total time=   5.1s\n",
      "[CV 5/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.871, test=0.875) balanced_accuracy: (train=0.744, test=0.753) f1: (train=0.787, test=0.795) total time=   8.6s\n",
      "[CV 2/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.873, test=0.868) balanced_accuracy: (train=0.747, test=0.739) f1: (train=0.790, test=0.781) total time=  16.4s\n",
      "[CV 5/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.872, test=0.875) balanced_accuracy: (train=0.746, test=0.754) f1: (train=0.788, test=0.796) total time=  16.1s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.732) f1: (train=0.779, test=0.775) total time=   1.3s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.737, test=0.730) f1: (train=0.780, test=0.772) total time=   2.1s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.777) total time=   2.2s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   4.1s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.745, test=0.737) f1: (train=0.788, test=0.779) total time=   5.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.783) total time=   8.5s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.744, test=0.740) f1: (train=0.787, test=0.783) total time=  16.9s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.783) total time=  11.7s\n",
      "[CV 4/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   4.2s\n",
      "[CV 4/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.778, test=0.776) total time=   1.4s\n",
      "[CV 2/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.737, test=0.731) f1: (train=0.780, test=0.773) total time=   1.2s\n",
      "[CV 2/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.737, test=0.731) f1: (train=0.780, test=0.773) total time=   2.2s\n",
      "[CV 3/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   4.1s\n",
      "[CV 3/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.777) total time=   4.4s\n",
      "[CV 5/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.870, test=0.874) balanced_accuracy: (train=0.742, test=0.752) f1: (train=0.785, test=0.794) total time=   5.2s\n",
      "[CV 3/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.786, test=0.783) total time=   6.8s\n",
      "[CV 4/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.787, test=0.783) total time=  17.6s\n",
      "[CV 1/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.778, test=0.776) total time=   1.4s\n",
      "[CV 2/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.864) balanced_accuracy: (train=0.735, test=0.729) f1: (train=0.778, test=0.771) total time=   1.4s\n",
      "[CV 5/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.866, test=0.871) balanced_accuracy: (train=0.733, test=0.742) f1: (train=0.776, test=0.785) total time=   1.4s\n",
      "[CV 1/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.776) total time=   1.4s\n",
      "[CV 3/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   2.2s\n",
      "[CV 1/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.778, test=0.776) total time=   2.5s\n",
      "[CV 1/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.778) total time=   4.6s\n",
      "[CV 4/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.778, test=0.776) total time=   1.5s\n",
      "[CV 2/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.737, test=0.731) f1: (train=0.780, test=0.773) total time=   1.3s\n",
      "[CV 3/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   2.2s\n",
      "[CV 5/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.776, test=0.786) total time=   4.2s\n",
      "[CV 2/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.787, test=0.779) total time=   5.5s\n",
      "[CV 3/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.785, test=0.782) total time=   5.8s\n",
      "[CV 1/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.744, test=0.741) f1: (train=0.787, test=0.783) total time=   9.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.785, test=0.782) total time=  18.4s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.737, test=0.730) f1: (train=0.780, test=0.772) total time=   2.2s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.779, test=0.776) total time=   2.0s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.778) total time=   4.0s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   4.0s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   2.0s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   2.1s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.786) total time=   4.2s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.745, test=0.737) f1: (train=0.788, test=0.779) total time=   5.3s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.783) total time=   8.2s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.744, test=0.740) f1: (train=0.787, test=0.783) total time=  18.2s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.864) balanced_accuracy: (train=0.735, test=0.729) f1: (train=0.778, test=0.771) total time=   1.2s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.777) total time=   1.7s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.776) total time=   1.5s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.735) f1: (train=0.779, test=0.778) total time=   2.2s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.779, test=0.777) total time=   2.5s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   4.1s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.778, test=0.776) total time=   1.4s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.866, test=0.870) balanced_accuracy: (train=0.733, test=0.742) f1: (train=0.776, test=0.785) total time=   1.3s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.779, test=0.776) total time=   2.1s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.866, test=0.871) balanced_accuracy: (train=0.733, test=0.742) f1: (train=0.776, test=0.786) total time=   2.4s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.780, test=0.773) total time=   3.9s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.785, test=0.782) total time=   5.2s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.741) f1: (train=0.786, test=0.784) total time=   7.1s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.785, test=0.783) total time=   9.3s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.870, test=0.874) balanced_accuracy: (train=0.742, test=0.751) f1: (train=0.785, test=0.794) total time=  18.6s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   2.5s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   4.2s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.733, test=0.743) f1: (train=0.777, test=0.786) total time=   4.0s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.780, test=0.772) total time=   2.0s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   4.2s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.744, test=0.741) f1: (train=0.787, test=0.783) total time=   6.0s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.785, test=0.782) total time=   9.8s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.870, test=0.874) balanced_accuracy: (train=0.742, test=0.751) f1: (train=0.785, test=0.794) total time=   8.5s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.787, test=0.778) total time=  15.7s\n",
      "[CV 4/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.741) f1: (train=0.786, test=0.783) total time=   5.8s\n",
      "[CV 3/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.785, test=0.782) total time=   9.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.741) f1: (train=0.786, test=0.783) total time=   9.1s\n",
      "[CV 1/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.744, test=0.741) f1: (train=0.787, test=0.784) total time=  18.6s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   2.4s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   3.9s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.786) total time=   1.2s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.786) total time=   1.2s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.779, test=0.776) total time=   2.0s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.777) total time=   2.1s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   4.2s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.739) f1: (train=0.786, test=0.782) total time=   5.5s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.870, test=0.874) balanced_accuracy: (train=0.741, test=0.751) f1: (train=0.784, test=0.794) total time=   8.0s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.787, test=0.778) total time=  18.1s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.732) f1: (train=0.779, test=0.775) total time=   1.3s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.779, test=0.776) total time=   1.4s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.778, test=0.775) total time=   1.4s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.866, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.776, test=0.787) total time=   2.1s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.778, test=0.776) total time=   2.3s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   4.3s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.732) f1: (train=0.779, test=0.775) total time=   1.4s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   1.4s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   2.4s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   4.1s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.777) total time=   4.3s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.870, test=0.874) balanced_accuracy: (train=0.742, test=0.752) f1: (train=0.785, test=0.794) total time=   5.6s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.872, test=0.867) balanced_accuracy: (train=0.745, test=0.737) f1: (train=0.788, test=0.779) total time=   8.6s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.787, test=0.783) total time=  18.5s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.777) total time=   1.5s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.776) total time=   1.5s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.779, test=0.773) total time=   2.2s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.866, test=0.870) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.785) total time=   2.3s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.780, test=0.773) total time=   4.3s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.777) total time=   1.3s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.778, test=0.775) total time=   1.3s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   2.1s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.776, test=0.786) total time=   4.2s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.786, test=0.783) total time=   6.2s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.744, test=0.736) f1: (train=0.787, test=0.779) total time=   8.5s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.785, test=0.783) total time=  10.2s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.744, test=0.741) f1: (train=0.787, test=0.784) total time=  16.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.780, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.737, test=0.736) f1: (train=0.780, test=0.778) total time=   1.3s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.732) f1: (train=0.779, test=0.775) total time=   1.9s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.735) f1: (train=0.779, test=0.778) total time=   4.2s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.737, test=0.734) f1: (train=0.780, test=0.777) total time=   1.1s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.779, test=0.778) total time=   1.1s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.866, test=0.870) balanced_accuracy: (train=0.732, test=0.741) f1: (train=0.775, test=0.785) total time=   1.2s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.737, test=0.734) f1: (train=0.780, test=0.777) total time=   1.8s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.786) total time=   3.8s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.872, test=0.870) balanced_accuracy: (train=0.748, test=0.743) f1: (train=0.790, test=0.785) total time=   5.1s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.871, test=0.875) balanced_accuracy: (train=0.744, test=0.753) f1: (train=0.787, test=0.796) total time=   4.8s\n",
      "[CV 2/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.872, test=0.867) balanced_accuracy: (train=0.746, test=0.738) f1: (train=0.789, test=0.780) total time=   8.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.746, test=0.741) f1: (train=0.789, test=0.784) total time=  15.5s\n",
      "[CV 3/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.732) f1: (train=0.779, test=0.775) total time=   1.1s\n",
      "[CV 4/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.737, test=0.735) f1: (train=0.779, test=0.778) total time=   1.3s\n",
      "[CV 1/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.737, test=0.734) f1: (train=0.779, test=0.777) total time=   1.9s\n",
      "[CV 5/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.866, test=0.871) balanced_accuracy: (train=0.733, test=0.742) f1: (train=0.776, test=0.785) total time=   2.2s\n",
      "[CV 3/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   4.1s\n",
      "[CV 4/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   1.2s\n",
      "[CV 1/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   1.3s\n",
      "[CV 5/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.787) total time=   2.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.737, test=0.730) f1: (train=0.780, test=0.773) total time=   4.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.780, test=0.776) total time=   4.4s\n",
      "[CV 1/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.873, test=0.869) balanced_accuracy: (train=0.748, test=0.742) f1: (train=0.791, test=0.784) total time=   4.9s\n",
      "[CV 3/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.873, test=0.870) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.790, test=0.785) total time=   6.7s\n",
      "[CV 4/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.872, test=0.870) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.789, test=0.784) total time=  13.8s\n",
      "[CV 3/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.872, test=0.870) balanced_accuracy: (train=0.746, test=0.743) f1: (train=0.789, test=0.785) total time=  16.4s\n",
      "[CV 1/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   1.2s\n",
      "[CV 5/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.787) total time=   1.2s\n",
      "[CV 5/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.787) total time=   2.1s\n",
      "[CV 3/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.735, test=0.732) f1: (train=0.779, test=0.775) total time=   3.9s\n",
      "[CV 5/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.786) total time=   4.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.873, test=0.869) balanced_accuracy: (train=0.748, test=0.742) f1: (train=0.791, test=0.784) total time=   3.8s\n",
      "[CV 3/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.873, test=0.870) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.790, test=0.785) total time=   8.2s\n",
      "[CV 1/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.873, test=0.870) balanced_accuracy: (train=0.748, test=0.744) f1: (train=0.791, test=0.786) total time=  16.5s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   1.2s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.737, test=0.730) f1: (train=0.780, test=0.772) total time=   1.3s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   1.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   2.3s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.777) total time=   2.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   4.2s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.732) f1: (train=0.779, test=0.775) total time=   1.3s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.786) total time=   1.1s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   2.1s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.733, test=0.743) f1: (train=0.777, test=0.786) total time=   2.1s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.737, test=0.730) f1: (train=0.780, test=0.773) total time=   4.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.739) f1: (train=0.786, test=0.782) total time=   5.2s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.870, test=0.874) balanced_accuracy: (train=0.741, test=0.751) f1: (train=0.784, test=0.794) total time=   8.4s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.787, test=0.778) total time=  12.8s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.785, test=0.782) total time=  13.5s\n",
      "[CV 2/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.780, test=0.773) total time=   4.5s\n",
      "[CV 4/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.779, test=0.777) total time=   4.2s\n",
      "[CV 3/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   2.1s\n",
      "[CV 5/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.776, test=0.786) total time=   4.3s\n",
      "[CV 2/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.787, test=0.779) total time=   5.5s\n",
      "[CV 1/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.744, test=0.740) f1: (train=0.786, test=0.783) total time=   8.9s\n",
      "[CV 5/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.870, test=0.874) balanced_accuracy: (train=0.742, test=0.751) f1: (train=0.785, test=0.794) total time=   9.5s\n",
      "[CV 2/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.787, test=0.778) total time=  18.4s\n",
      "[CV 2/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.780, test=0.772) total time=   2.4s\n",
      "[CV 5/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.776, test=0.786) total time=   4.6s\n",
      "[CV 3/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.732) f1: (train=0.779, test=0.775) total time=   1.2s\n",
      "[CV 1/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.776) total time=   1.3s\n",
      "[CV 5/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.866, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.776, test=0.787) total time=   2.1s\n",
      "[CV 2/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.780, test=0.773) total time=   4.3s\n",
      "[CV 1/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.745, test=0.741) f1: (train=0.787, test=0.783) total time=   5.9s\n",
      "[CV 4/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.783) total time=   5.8s\n",
      "[CV 5/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.870, test=0.874) balanced_accuracy: (train=0.742, test=0.751) f1: (train=0.785, test=0.794) total time=   8.7s\n",
      "[CV 2/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.872, test=0.867) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.787, test=0.779) total time=  14.5s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   1.3s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.732) f1: (train=0.779, test=0.775) total time=   1.2s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.864) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.779, test=0.772) total time=   1.3s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.779, test=0.776) total time=   2.0s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   2.2s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   4.0s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   4.0s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.786) total time=   2.0s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.778) total time=   4.2s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.786) total time=   4.2s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.870, test=0.874) balanced_accuracy: (train=0.742, test=0.751) f1: (train=0.784, test=0.793) total time=   3.6s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.787, test=0.779) total time=   8.5s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.783) total time=  18.2s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.866, test=0.871) balanced_accuracy: (train=0.733, test=0.742) f1: (train=0.776, test=0.785) total time=   1.3s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.776) total time=   1.4s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   2.1s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   2.3s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.779, test=0.776) total time=   3.9s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.779, test=0.777) total time=   4.1s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   1.9s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   4.2s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.733, test=0.743) f1: (train=0.777, test=0.786) total time=   4.2s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.872, test=0.867) balanced_accuracy: (train=0.744, test=0.736) f1: (train=0.787, test=0.779) total time=   5.5s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.783) total time=   8.5s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.870, test=0.874) balanced_accuracy: (train=0.742, test=0.750) f1: (train=0.785, test=0.793) total time=  13.5s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.870, test=0.874) balanced_accuracy: (train=0.742, test=0.751) f1: (train=0.785, test=0.794) total time=  15.5s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.780, test=0.773) total time=   4.1s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.779, test=0.773) total time=   2.3s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.779, test=0.777) total time=   2.2s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   4.2s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.783) total time=   6.1s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.745, test=0.741) f1: (train=0.787, test=0.784) total time=  10.3s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.785, test=0.783) total time=  14.0s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.785, test=0.782) total time=   9.6s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.865, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 2/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.780, test=0.773) total time=   1.3s\n",
      "[CV 2/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.737, test=0.731) f1: (train=0.780, test=0.773) total time=   1.8s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.786) total time=   4.5s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.732) f1: (train=0.779, test=0.775) total time=   1.2s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   1.6s\n",
      "[CV 2/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.738, test=0.731) f1: (train=0.781, test=0.773) total time=   1.9s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.779, test=0.776) total time=   4.2s\n",
      "[CV 2/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.872, test=0.867) balanced_accuracy: (train=0.747, test=0.739) f1: (train=0.790, test=0.781) total time=   4.9s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.871, test=0.875) balanced_accuracy: (train=0.745, test=0.753) f1: (train=0.787, test=0.796) total time=   8.6s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.873, test=0.870) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.790, test=0.785) total time=  13.3s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.746, test=0.741) f1: (train=0.789, test=0.784) total time=  12.3s\n",
      "[CV 5/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.787) total time=   4.3s\n",
      "[CV 3/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.732) f1: (train=0.779, test=0.775) total time=   1.3s\n",
      "[CV 1/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   1.9s\n",
      "[CV 3/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.779, test=0.776) total time=   2.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.787) total time=   3.9s\n",
      "[CV 2/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.873, test=0.868) balanced_accuracy: (train=0.747, test=0.739) f1: (train=0.790, test=0.781) total time=   4.9s\n",
      "[CV 4/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.872, test=0.870) balanced_accuracy: (train=0.747, test=0.742) f1: (train=0.790, test=0.785) total time=   8.4s\n",
      "[CV 1/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.872, test=0.870) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.790, test=0.785) total time=  17.1s\n",
      "[CV 5/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.872, test=0.875) balanced_accuracy: (train=0.746, test=0.754) f1: (train=0.788, test=0.796) total time=  13.3s\n",
      "[CV 3/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   3.1s\n",
      "[CV 1/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   1.1s\n",
      "[CV 1/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.737, test=0.734) f1: (train=0.779, test=0.777) total time=   2.1s\n",
      "[CV 4/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   4.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.872, test=0.870) balanced_accuracy: (train=0.748, test=0.743) f1: (train=0.791, test=0.785) total time=   5.2s\n",
      "[CV 4/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.872, test=0.870) balanced_accuracy: (train=0.746, test=0.743) f1: (train=0.789, test=0.786) total time=   3.8s\n",
      "[CV 4/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.872, test=0.870) balanced_accuracy: (train=0.747, test=0.742) f1: (train=0.790, test=0.785) total time=   6.6s\n",
      "[CV 5/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.871, test=0.875) balanced_accuracy: (train=0.744, test=0.752) f1: (train=0.787, test=0.795) total time=  16.5s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.776) total time=   1.4s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.786) total time=   1.2s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.786) total time=   1.3s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   2.3s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.867, test=0.870) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.786) total time=   2.1s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   4.1s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   4.2s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.737, test=0.731) f1: (train=0.780, test=0.773) total time=   2.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   4.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.870, test=0.875) balanced_accuracy: (train=0.741, test=0.751) f1: (train=0.784, test=0.794) total time=   5.1s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.786, test=0.778) total time=   8.3s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.785, test=0.782) total time=   8.7s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.870, test=0.874) balanced_accuracy: (train=0.741, test=0.750) f1: (train=0.784, test=0.793) total time=  15.3s\n",
      "[CV 3/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   2.5s\n",
      "[CV 5/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.866, test=0.870) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.785) total time=   2.3s\n",
      "[CV 5/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.776, test=0.786) total time=   3.4s\n",
      "[CV 5/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.733, test=0.743) f1: (train=0.777, test=0.786) total time=   4.3s\n",
      "[CV 1/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.778, test=0.776) total time=   2.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   4.2s\n",
      "[CV 5/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.870, test=0.874) balanced_accuracy: (train=0.741, test=0.750) f1: (train=0.784, test=0.793) total time=   5.5s\n",
      "[CV 5/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.870, test=0.875) balanced_accuracy: (train=0.742, test=0.752) f1: (train=0.785, test=0.795) total time=   5.8s\n",
      "[CV 1/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.744, test=0.741) f1: (train=0.787, test=0.783) total time=   8.7s\n",
      "[CV 2/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.872, test=0.867) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.787, test=0.779) total time=  16.2s\n",
      "[CV 4/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.778, test=0.776) total time=   1.4s\n",
      "[CV 4/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   1.4s\n",
      "[CV 1/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.776) total time=   2.2s\n",
      "[CV 3/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   2.4s\n",
      "[CV 2/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.780, test=0.773) total time=   4.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.779, test=0.777) total time=   4.3s\n",
      "[CV 5/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.866, test=0.870) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.785) total time=   2.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.778) total time=   4.3s\n",
      "[CV 3/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.786, test=0.783) total time=   5.5s\n",
      "[CV 5/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.870, test=0.875) balanced_accuracy: (train=0.742, test=0.752) f1: (train=0.785, test=0.795) total time=   5.8s\n",
      "[CV 2/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.787, test=0.779) total time=   8.8s\n",
      "[CV 4/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.783) total time=  18.1s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   1.3s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   2.2s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.867, test=0.870) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.786) total time=   2.2s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   3.8s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.786) total time=   4.0s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.867, test=0.870) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.786) total time=   2.2s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   4.1s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.783) total time=   5.2s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.870, test=0.874) balanced_accuracy: (train=0.741, test=0.751) f1: (train=0.784, test=0.794) total time=   5.5s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.744, test=0.736) f1: (train=0.787, test=0.779) total time=   8.1s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.785, test=0.782) total time=  13.1s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.870, test=0.874) balanced_accuracy: (train=0.741, test=0.751) f1: (train=0.784, test=0.794) total time=  16.1s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.736, test=0.729) f1: (train=0.779, test=0.772) total time=   1.4s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.778, test=0.775) total time=   1.4s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.778, test=0.776) total time=   2.1s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   4.1s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.870, test=0.874) balanced_accuracy: (train=0.741, test=0.750) f1: (train=0.784, test=0.793) total time=   5.5s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.744, test=0.736) f1: (train=0.787, test=0.779) total time=   9.0s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.870, test=0.874) balanced_accuracy: (train=0.742, test=0.751) f1: (train=0.785, test=0.794) total time=   9.7s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.787, test=0.778) total time=  18.5s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.866, test=0.871) balanced_accuracy: (train=0.733, test=0.742) f1: (train=0.776, test=0.786) total time=   2.5s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   4.2s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.779, test=0.776) total time=   1.3s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.866, test=0.869) balanced_accuracy: (train=0.732, test=0.741) f1: (train=0.775, test=0.784) total time=   1.3s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.778, test=0.776) total time=   2.1s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.780, test=0.773) total time=   4.5s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.870, test=0.874) balanced_accuracy: (train=0.741, test=0.750) f1: (train=0.784, test=0.793) total time=   4.5s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.783) total time=   5.8s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.744, test=0.741) f1: (train=0.787, test=0.783) total time=  10.2s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.783) total time=  11.8s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.741) f1: (train=0.786, test=0.783) total time=   9.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.870) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.786) total time=   1.2s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.737, test=0.735) f1: (train=0.780, test=0.778) total time=   1.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.867, test=0.872) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.787) total time=   1.9s\n",
      "[CV 2/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.737, test=0.731) f1: (train=0.780, test=0.773) total time=   4.3s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.870) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.786) total time=   1.3s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.737, test=0.735) f1: (train=0.780, test=0.778) total time=   1.3s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.867, test=0.872) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.787) total time=   2.1s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.737, test=0.735) f1: (train=0.780, test=0.778) total time=   3.7s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.873, test=0.870) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.790, test=0.786) total time=   4.9s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.746, test=0.741) f1: (train=0.788, test=0.783) total time=   4.6s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.872, test=0.870) balanced_accuracy: (train=0.747, test=0.742) f1: (train=0.790, test=0.785) total time=   7.1s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.872, test=0.870) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.789, test=0.785) total time=  16.2s\n",
      "[CV 5/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.786) total time=   1.1s\n",
      "[CV 1/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   1.3s\n",
      "[CV 3/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.780, test=0.776) total time=   2.1s\n",
      "[CV 2/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.737, test=0.730) f1: (train=0.780, test=0.773) total time=   2.4s\n",
      "[CV 1/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.737, test=0.735) f1: (train=0.780, test=0.777) total time=   4.2s\n",
      "[CV 1/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   1.3s\n",
      "[CV 2/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.738, test=0.731) f1: (train=0.781, test=0.774) total time=   1.2s\n",
      "[CV 2/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.737, test=0.730) f1: (train=0.780, test=0.773) total time=   1.9s\n",
      "[CV 3/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.735, test=0.732) f1: (train=0.779, test=0.775) total time=   4.1s\n",
      "[CV 5/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.786) total time=   4.2s\n",
      "[CV 2/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.873, test=0.868) balanced_accuracy: (train=0.747, test=0.739) f1: (train=0.791, test=0.781) total time=   4.9s\n",
      "[CV 4/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.872, test=0.870) balanced_accuracy: (train=0.747, test=0.742) f1: (train=0.790, test=0.785) total time=   6.7s\n",
      "[CV 5/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.871, test=0.875) balanced_accuracy: (train=0.744, test=0.752) f1: (train=0.787, test=0.795) total time=  17.5s\n",
      "[CV 1/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   1.5s\n",
      "[CV 2/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.738, test=0.731) f1: (train=0.781, test=0.774) total time=   1.2s\n",
      "[CV 3/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.780, test=0.776) total time=   2.4s\n",
      "[CV 5/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.866, test=0.871) balanced_accuracy: (train=0.733, test=0.742) f1: (train=0.776, test=0.785) total time=   2.2s\n",
      "[CV 2/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.780, test=0.773) total time=   3.9s\n",
      "[CV 2/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.737, test=0.730) f1: (train=0.780, test=0.773) total time=   1.3s\n",
      "[CV 2/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.779, test=0.772) total time=   1.2s\n",
      "[CV 3/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.780, test=0.776) total time=   2.1s\n",
      "[CV 1/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.735) f1: (train=0.779, test=0.778) total time=   4.1s\n",
      "[CV 3/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   4.1s\n",
      "[CV 5/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.871, test=0.875) balanced_accuracy: (train=0.746, test=0.753) f1: (train=0.788, test=0.796) total time=   3.7s\n",
      "[CV 2/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.873, test=0.868) balanced_accuracy: (train=0.747, test=0.739) f1: (train=0.790, test=0.781) total time=   8.2s\n",
      "[CV 3/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.873, test=0.870) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.790, test=0.786) total time=  16.8s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.863) balanced_accuracy: (train=0.736, test=0.729) f1: (train=0.778, test=0.771) total time=   1.4s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.777) total time=   1.3s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.864) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.779, test=0.772) total time=   1.1s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.737, test=0.730) f1: (train=0.780, test=0.772) total time=   2.3s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.737, test=0.731) f1: (train=0.780, test=0.773) total time=   2.1s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.778) total time=   4.1s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.786) total time=   3.2s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.737, test=0.731) f1: (train=0.780, test=0.773) total time=   1.9s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   4.3s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.744, test=0.736) f1: (train=0.787, test=0.778) total time=   5.3s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.785, test=0.782) total time=   5.1s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.744, test=0.740) f1: (train=0.786, test=0.783) total time=   8.4s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.783) total time=  17.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.736, test=0.729) f1: (train=0.779, test=0.772) total time=   1.5s\n",
      "[CV 3/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.776) total time=   1.6s\n",
      "[CV 1/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.735) f1: (train=0.779, test=0.778) total time=   2.3s\n",
      "[CV 4/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.779, test=0.777) total time=   2.3s\n",
      "[CV 5/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.866, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.786) total time=   4.5s\n",
      "[CV 5/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.866, test=0.870) balanced_accuracy: (train=0.733, test=0.742) f1: (train=0.776, test=0.785) total time=   1.3s\n",
      "[CV 3/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   2.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.779, test=0.777) total time=   2.1s\n",
      "[CV 1/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   4.3s\n",
      "[CV 3/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.785, test=0.782) total time=   5.4s\n",
      "[CV 5/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.870, test=0.874) balanced_accuracy: (train=0.742, test=0.751) f1: (train=0.785, test=0.794) total time=   8.6s\n",
      "[CV 2/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.744, test=0.736) f1: (train=0.787, test=0.779) total time=  17.7s\n",
      "[CV 3/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.785, test=0.782) total time=  13.3s\n",
      "[CV 5/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.866, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.786) total time=   4.5s\n",
      "[CV 3/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.779, test=0.776) total time=   1.4s\n",
      "[CV 2/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.779, test=0.773) total time=   2.2s\n",
      "[CV 1/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   4.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.777) total time=   4.4s\n",
      "[CV 5/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.870, test=0.874) balanced_accuracy: (train=0.742, test=0.752) f1: (train=0.785, test=0.794) total time=   5.4s\n",
      "[CV 4/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.783) total time=   7.3s\n",
      "[CV 5/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.870, test=0.874) balanced_accuracy: (train=0.742, test=0.750) f1: (train=0.785, test=0.793) total time=  13.1s\n",
      "[CV 3/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.785, test=0.782) total time=  17.6s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.786) total time=   4.0s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.866, test=0.870) balanced_accuracy: (train=0.733, test=0.742) f1: (train=0.776, test=0.785) total time=   1.3s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.737, test=0.731) f1: (train=0.780, test=0.773) total time=   1.9s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=10, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   4.1s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.744, test=0.740) f1: (train=0.786, test=0.783) total time=   5.1s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.786, test=0.778) total time=   8.8s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.870, test=0.874) balanced_accuracy: (train=0.741, test=0.751) f1: (train=0.784, test=0.794) total time=   9.0s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=10, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.744, test=0.736) f1: (train=0.787, test=0.778) total time=  16.4s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.780, test=0.772) total time=   2.3s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.780, test=0.773) total time=   3.7s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=40, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.733, test=0.743) f1: (train=0.777, test=0.786) total time=   4.0s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   2.1s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=40, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.778) total time=   4.3s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.786, test=0.783) total time=   5.5s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.783) total time=   5.5s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.870, test=0.874) balanced_accuracy: (train=0.742, test=0.751) f1: (train=0.785, test=0.794) total time=   8.6s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=40, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.872, test=0.867) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.787, test=0.779) total time=  13.3s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.778, test=0.776) total time=   1.4s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.732) f1: (train=0.779, test=0.775) total time=   1.5s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.866, test=0.871) balanced_accuracy: (train=0.733, test=0.742) f1: (train=0.776, test=0.785) total time=   1.3s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   1.4s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.776) total time=   1.8s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.737, test=0.731) f1: (train=0.780, test=0.773) total time=   2.3s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.780, test=0.773) total time=   4.3s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=None, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.779, test=0.777) total time=   4.1s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.866, test=0.870) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.785) total time=   2.0s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=None, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.778) total time=   4.2s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.787, test=0.779) total time=   4.5s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.870, test=0.874) balanced_accuracy: (train=0.742, test=0.752) f1: (train=0.785, test=0.794) total time=   5.7s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.872, test=0.867) balanced_accuracy: (train=0.745, test=0.737) f1: (train=0.788, test=0.779) total time=   8.7s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.787, test=0.783) total time=  14.1s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=None, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.870, test=0.874) balanced_accuracy: (train=0.742, test=0.751) f1: (train=0.785, test=0.794) total time=   8.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.749, test=0.745) f1: (train=0.790, test=0.786) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.746, test=0.738) f1: (train=0.788, test=0.780) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.789, test=0.785) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.788, test=0.784) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.870, test=0.873) balanced_accuracy: (train=0.746, test=0.754) f1: (train=0.788, test=0.795) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.749, test=0.745) f1: (train=0.790, test=0.786) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.746, test=0.738) f1: (train=0.788, test=0.780) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.789, test=0.785) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.788, test=0.784) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.870, test=0.873) balanced_accuracy: (train=0.746, test=0.754) f1: (train=0.788, test=0.795) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.749, test=0.745) f1: (train=0.790, test=0.786) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.746, test=0.738) f1: (train=0.788, test=0.780) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.789, test=0.785) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.788, test=0.784) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.870, test=0.873) balanced_accuracy: (train=0.746, test=0.754) f1: (train=0.788, test=0.795) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.749, test=0.745) f1: (train=0.790, test=0.786) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.746, test=0.738) f1: (train=0.788, test=0.780) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.789, test=0.785) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.788, test=0.784) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.870, test=0.873) balanced_accuracy: (train=0.746, test=0.754) f1: (train=0.788, test=0.795) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.749, test=0.745) f1: (train=0.790, test=0.786) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.746, test=0.738) f1: (train=0.788, test=0.780) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.789, test=0.785) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.788, test=0.784) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.870, test=0.873) balanced_accuracy: (train=0.746, test=0.754) f1: (train=0.788, test=0.795) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.749, test=0.745) f1: (train=0.790, test=0.786) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.746, test=0.738) f1: (train=0.788, test=0.780) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.789, test=0.785) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.788, test=0.784) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.870, test=0.873) balanced_accuracy: (train=0.746, test=0.754) f1: (train=0.788, test=0.795) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.870, test=0.865) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.784, test=0.781) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.872) balanced_accuracy: (train=0.744, test=0.752) f1: (train=0.785, test=0.793) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.870, test=0.865) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.784, test=0.781) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.872) balanced_accuracy: (train=0.744, test=0.752) f1: (train=0.785, test=0.793) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.870, test=0.865) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.784, test=0.781) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.872) balanced_accuracy: (train=0.744, test=0.752) f1: (train=0.785, test=0.793) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.870, test=0.865) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.784, test=0.781) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.872) balanced_accuracy: (train=0.744, test=0.752) f1: (train=0.785, test=0.793) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.870, test=0.865) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.784, test=0.781) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.872) balanced_accuracy: (train=0.744, test=0.752) f1: (train=0.785, test=0.793) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.870, test=0.865) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.784, test=0.781) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.872) balanced_accuracy: (train=0.744, test=0.752) f1: (train=0.785, test=0.793) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.737) f1: (train=0.781, test=0.779) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.738) f1: (train=0.783, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.740, test=0.749) f1: (train=0.781, test=0.789) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.737) f1: (train=0.781, test=0.779) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.738) f1: (train=0.783, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.740, test=0.749) f1: (train=0.781, test=0.789) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.737) f1: (train=0.781, test=0.779) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.738) f1: (train=0.783, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.740, test=0.749) f1: (train=0.781, test=0.789) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.737) f1: (train=0.781, test=0.779) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.738) f1: (train=0.783, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.740, test=0.749) f1: (train=0.781, test=0.789) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.737) f1: (train=0.781, test=0.779) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.738) f1: (train=0.783, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.740, test=0.749) f1: (train=0.781, test=0.789) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.737) f1: (train=0.781, test=0.779) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.738) f1: (train=0.783, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.740, test=0.749) f1: (train=0.781, test=0.789) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.780, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.865, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.780, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.865, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.780, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.865, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.780, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.865, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.780, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.865, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.780, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.865, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.749, test=0.745) f1: (train=0.790, test=0.786) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.746, test=0.738) f1: (train=0.788, test=0.780) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.789, test=0.785) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.788, test=0.784) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.870, test=0.873) balanced_accuracy: (train=0.746, test=0.754) f1: (train=0.788, test=0.795) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.749, test=0.745) f1: (train=0.790, test=0.786) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.746, test=0.738) f1: (train=0.788, test=0.780) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.789, test=0.785) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.788, test=0.784) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.870, test=0.873) balanced_accuracy: (train=0.746, test=0.754) f1: (train=0.788, test=0.795) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.749, test=0.745) f1: (train=0.790, test=0.786) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.746, test=0.738) f1: (train=0.788, test=0.780) total time=   0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.789, test=0.785) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.788, test=0.784) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.870, test=0.873) balanced_accuracy: (train=0.746, test=0.754) f1: (train=0.788, test=0.795) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.749, test=0.745) f1: (train=0.790, test=0.786) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.746, test=0.738) f1: (train=0.788, test=0.780) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.789, test=0.785) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.788, test=0.784) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.870, test=0.873) balanced_accuracy: (train=0.746, test=0.754) f1: (train=0.788, test=0.795) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.749, test=0.745) f1: (train=0.790, test=0.786) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.746, test=0.738) f1: (train=0.788, test=0.780) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.789, test=0.785) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.788, test=0.784) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.870, test=0.873) balanced_accuracy: (train=0.746, test=0.754) f1: (train=0.788, test=0.795) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.749, test=0.745) f1: (train=0.790, test=0.786) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.746, test=0.738) f1: (train=0.788, test=0.780) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.789, test=0.785) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.788, test=0.784) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.870, test=0.873) balanced_accuracy: (train=0.746, test=0.754) f1: (train=0.788, test=0.795) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.870, test=0.865) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.784, test=0.781) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.872) balanced_accuracy: (train=0.744, test=0.752) f1: (train=0.785, test=0.793) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.870, test=0.865) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.784, test=0.781) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.872) balanced_accuracy: (train=0.744, test=0.752) f1: (train=0.785, test=0.793) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.870, test=0.865) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.784, test=0.781) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.872) balanced_accuracy: (train=0.744, test=0.752) f1: (train=0.785, test=0.793) total time=   0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.870, test=0.865) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.784, test=0.781) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.872) balanced_accuracy: (train=0.744, test=0.752) f1: (train=0.785, test=0.793) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.870, test=0.865) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.784, test=0.781) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.872) balanced_accuracy: (train=0.744, test=0.752) f1: (train=0.785, test=0.793) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.870, test=0.865) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.784, test=0.781) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.872) balanced_accuracy: (train=0.744, test=0.752) f1: (train=0.785, test=0.793) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.737) f1: (train=0.781, test=0.779) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.738) f1: (train=0.783, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.740, test=0.749) f1: (train=0.781, test=0.789) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.783, test=0.776) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.737) f1: (train=0.781, test=0.779) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.738) f1: (train=0.783, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.740, test=0.749) f1: (train=0.781, test=0.789) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.737) f1: (train=0.781, test=0.779) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.738) f1: (train=0.783, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.740, test=0.749) f1: (train=0.781, test=0.789) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.737) f1: (train=0.781, test=0.779) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.738) f1: (train=0.783, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.740, test=0.749) f1: (train=0.781, test=0.789) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.737) f1: (train=0.781, test=0.779) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.738) f1: (train=0.783, test=0.780) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.740, test=0.749) f1: (train=0.781, test=0.789) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.737) f1: (train=0.781, test=0.779) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.738) f1: (train=0.783, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.740, test=0.749) f1: (train=0.781, test=0.789) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.780, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.865, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.780, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.865, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.780, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.865, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.780, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.865, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.780, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.865, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.780, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=entropy, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.865, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.746, test=0.743) f1: (train=0.787, test=0.784) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.870, test=0.866) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.786, test=0.778) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.782) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.871, test=0.868) balanced_accuracy: (train=0.744, test=0.741) f1: (train=0.787, test=0.783) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.873) balanced_accuracy: (train=0.744, test=0.752) f1: (train=0.785, test=0.793) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.746, test=0.743) f1: (train=0.787, test=0.784) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.870, test=0.866) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.786, test=0.778) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.782) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.871, test=0.868) balanced_accuracy: (train=0.744, test=0.741) f1: (train=0.787, test=0.783) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.873) balanced_accuracy: (train=0.744, test=0.752) f1: (train=0.785, test=0.793) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.746, test=0.743) f1: (train=0.787, test=0.784) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.870, test=0.866) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.786, test=0.778) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.782) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.871, test=0.868) balanced_accuracy: (train=0.744, test=0.741) f1: (train=0.787, test=0.783) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.873) balanced_accuracy: (train=0.744, test=0.752) f1: (train=0.785, test=0.793) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.746, test=0.743) f1: (train=0.787, test=0.784) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.870, test=0.866) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.786, test=0.778) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.782) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.871, test=0.868) balanced_accuracy: (train=0.744, test=0.741) f1: (train=0.787, test=0.783) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.873) balanced_accuracy: (train=0.744, test=0.752) f1: (train=0.785, test=0.793) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.746, test=0.743) f1: (train=0.787, test=0.784) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.870, test=0.866) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.786, test=0.778) total time=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.782) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.871, test=0.868) balanced_accuracy: (train=0.744, test=0.741) f1: (train=0.787, test=0.783) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.873) balanced_accuracy: (train=0.744, test=0.752) f1: (train=0.785, test=0.793) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.746, test=0.743) f1: (train=0.787, test=0.784) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.870, test=0.866) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.786, test=0.778) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.782) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.871, test=0.868) balanced_accuracy: (train=0.744, test=0.741) f1: (train=0.787, test=0.783) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.873) balanced_accuracy: (train=0.744, test=0.752) f1: (train=0.785, test=0.793) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.743, test=0.741) f1: (train=0.785, test=0.782) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.742, test=0.735) f1: (train=0.784, test=0.777) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.785, test=0.782) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.784, test=0.781) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.872) balanced_accuracy: (train=0.742, test=0.750) f1: (train=0.783, test=0.791) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.743, test=0.741) f1: (train=0.785, test=0.782) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.742, test=0.735) f1: (train=0.784, test=0.777) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.785, test=0.782) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.784, test=0.781) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.872) balanced_accuracy: (train=0.742, test=0.750) f1: (train=0.783, test=0.791) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.743, test=0.741) f1: (train=0.785, test=0.782) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.742, test=0.735) f1: (train=0.784, test=0.777) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.785, test=0.782) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.784, test=0.781) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.872) balanced_accuracy: (train=0.742, test=0.750) f1: (train=0.783, test=0.791) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.743, test=0.741) f1: (train=0.785, test=0.782) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.742, test=0.735) f1: (train=0.784, test=0.777) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.785, test=0.782) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.784, test=0.781) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.872) balanced_accuracy: (train=0.742, test=0.750) f1: (train=0.783, test=0.791) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.743, test=0.741) f1: (train=0.785, test=0.782) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.742, test=0.735) f1: (train=0.784, test=0.777) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.785, test=0.782) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.784, test=0.781) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.872) balanced_accuracy: (train=0.742, test=0.750) f1: (train=0.783, test=0.791) total time=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.743, test=0.741) f1: (train=0.785, test=0.782) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.742, test=0.735) f1: (train=0.784, test=0.777) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.785, test=0.782) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.784, test=0.781) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.872) balanced_accuracy: (train=0.742, test=0.750) f1: (train=0.783, test=0.791) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.737) f1: (train=0.781, test=0.779) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.738) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.740, test=0.749) f1: (train=0.781, test=0.789) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.737) f1: (train=0.781, test=0.779) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.738) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.740, test=0.749) f1: (train=0.781, test=0.789) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.737) f1: (train=0.781, test=0.779) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.738) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.740, test=0.749) f1: (train=0.781, test=0.789) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.737) f1: (train=0.781, test=0.779) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.738) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.740, test=0.749) f1: (train=0.781, test=0.789) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.737) f1: (train=0.781, test=0.779) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.738) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.740, test=0.749) f1: (train=0.781, test=0.789) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.737) f1: (train=0.781, test=0.779) total time=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.738) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.740, test=0.749) f1: (train=0.781, test=0.789) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.780, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.865, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.780, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.865, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.780, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.865, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.780, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.865, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.780, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.865, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.780, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=10, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.865, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.749, test=0.745) f1: (train=0.790, test=0.786) total time=   0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.746, test=0.738) f1: (train=0.788, test=0.780) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.789, test=0.785) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.788, test=0.784) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.870, test=0.873) balanced_accuracy: (train=0.746, test=0.754) f1: (train=0.788, test=0.795) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.749, test=0.745) f1: (train=0.790, test=0.786) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.746, test=0.738) f1: (train=0.788, test=0.780) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.789, test=0.785) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.788, test=0.784) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.870, test=0.873) balanced_accuracy: (train=0.746, test=0.754) f1: (train=0.788, test=0.795) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.749, test=0.745) f1: (train=0.790, test=0.786) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.746, test=0.738) f1: (train=0.788, test=0.780) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.789, test=0.785) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.788, test=0.784) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.870, test=0.873) balanced_accuracy: (train=0.746, test=0.754) f1: (train=0.788, test=0.795) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.749, test=0.745) f1: (train=0.790, test=0.786) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.746, test=0.738) f1: (train=0.788, test=0.780) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.789, test=0.785) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.788, test=0.784) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.870, test=0.873) balanced_accuracy: (train=0.746, test=0.754) f1: (train=0.788, test=0.795) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.749, test=0.745) f1: (train=0.790, test=0.786) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.746, test=0.738) f1: (train=0.788, test=0.780) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.789, test=0.785) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.788, test=0.784) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.870, test=0.873) balanced_accuracy: (train=0.746, test=0.754) f1: (train=0.788, test=0.795) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.749, test=0.745) f1: (train=0.790, test=0.786) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.746, test=0.738) f1: (train=0.788, test=0.780) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.789, test=0.785) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.788, test=0.784) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.870, test=0.873) balanced_accuracy: (train=0.746, test=0.754) f1: (train=0.788, test=0.795) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.870, test=0.865) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.784, test=0.781) total time=   0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.872) balanced_accuracy: (train=0.744, test=0.752) f1: (train=0.785, test=0.793) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.870, test=0.865) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.784, test=0.781) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.872) balanced_accuracy: (train=0.744, test=0.752) f1: (train=0.785, test=0.793) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.870, test=0.865) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.784, test=0.781) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.872) balanced_accuracy: (train=0.744, test=0.752) f1: (train=0.785, test=0.793) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.870, test=0.865) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.784, test=0.781) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.872) balanced_accuracy: (train=0.744, test=0.752) f1: (train=0.785, test=0.793) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.870, test=0.865) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.784, test=0.781) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.872) balanced_accuracy: (train=0.744, test=0.752) f1: (train=0.785, test=0.793) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.870, test=0.865) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.784, test=0.781) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.872) balanced_accuracy: (train=0.744, test=0.752) f1: (train=0.785, test=0.793) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.737) f1: (train=0.781, test=0.779) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.738) f1: (train=0.783, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.740, test=0.749) f1: (train=0.781, test=0.789) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.737) f1: (train=0.781, test=0.779) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.738) f1: (train=0.783, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.740, test=0.749) f1: (train=0.781, test=0.789) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.737) f1: (train=0.781, test=0.779) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.738) f1: (train=0.783, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.740, test=0.749) f1: (train=0.781, test=0.789) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.737) f1: (train=0.781, test=0.779) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.738) f1: (train=0.783, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.740, test=0.749) f1: (train=0.781, test=0.789) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.737) f1: (train=0.781, test=0.779) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.738) f1: (train=0.783, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.740, test=0.749) f1: (train=0.781, test=0.789) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.737) f1: (train=0.781, test=0.779) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.738) f1: (train=0.783, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.740, test=0.749) f1: (train=0.781, test=0.789) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.780, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.865, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.780, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.865, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.780, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.865, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.780, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.865, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.780, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.865, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.780, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=20, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.865, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.749, test=0.745) f1: (train=0.790, test=0.786) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.746, test=0.738) f1: (train=0.788, test=0.780) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.789, test=0.785) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.788, test=0.784) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.870, test=0.873) balanced_accuracy: (train=0.746, test=0.754) f1: (train=0.788, test=0.795) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.749, test=0.745) f1: (train=0.790, test=0.786) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.746, test=0.738) f1: (train=0.788, test=0.780) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.789, test=0.785) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.788, test=0.784) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.870, test=0.873) balanced_accuracy: (train=0.746, test=0.754) f1: (train=0.788, test=0.795) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.749, test=0.745) f1: (train=0.790, test=0.786) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.746, test=0.738) f1: (train=0.788, test=0.780) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.789, test=0.785) total time=   0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.788, test=0.784) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.870, test=0.873) balanced_accuracy: (train=0.746, test=0.754) f1: (train=0.788, test=0.795) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.749, test=0.745) f1: (train=0.790, test=0.786) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.746, test=0.738) f1: (train=0.788, test=0.780) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.789, test=0.785) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.788, test=0.784) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.870, test=0.873) balanced_accuracy: (train=0.746, test=0.754) f1: (train=0.788, test=0.795) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.749, test=0.745) f1: (train=0.790, test=0.786) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.746, test=0.738) f1: (train=0.788, test=0.780) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.789, test=0.785) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.788, test=0.784) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.870, test=0.873) balanced_accuracy: (train=0.746, test=0.754) f1: (train=0.788, test=0.795) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.749, test=0.745) f1: (train=0.790, test=0.786) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.746, test=0.738) f1: (train=0.788, test=0.780) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.789, test=0.785) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.788, test=0.784) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.870, test=0.873) balanced_accuracy: (train=0.746, test=0.754) f1: (train=0.788, test=0.795) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.870, test=0.865) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.784, test=0.781) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.872) balanced_accuracy: (train=0.744, test=0.752) f1: (train=0.785, test=0.793) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.870, test=0.865) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.784, test=0.781) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.872) balanced_accuracy: (train=0.744, test=0.752) f1: (train=0.785, test=0.793) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.870, test=0.865) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.784, test=0.781) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.872) balanced_accuracy: (train=0.744, test=0.752) f1: (train=0.785, test=0.793) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.870, test=0.865) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.784, test=0.781) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.872) balanced_accuracy: (train=0.744, test=0.752) f1: (train=0.785, test=0.793) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.870, test=0.865) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.784, test=0.781) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.872) balanced_accuracy: (train=0.744, test=0.752) f1: (train=0.785, test=0.793) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.870, test=0.865) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.784, test=0.781) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.872) balanced_accuracy: (train=0.744, test=0.752) f1: (train=0.785, test=0.793) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.737) f1: (train=0.781, test=0.779) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.738) f1: (train=0.783, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.740, test=0.749) f1: (train=0.781, test=0.789) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.737) f1: (train=0.781, test=0.779) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.738) f1: (train=0.783, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.740, test=0.749) f1: (train=0.781, test=0.789) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.737) f1: (train=0.781, test=0.779) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.738) f1: (train=0.783, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.740, test=0.749) f1: (train=0.781, test=0.789) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.737) f1: (train=0.781, test=0.779) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.738) f1: (train=0.783, test=0.780) total time=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.740, test=0.749) f1: (train=0.781, test=0.789) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.737) f1: (train=0.781, test=0.779) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.738) f1: (train=0.783, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.740, test=0.749) f1: (train=0.781, test=0.789) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.737) f1: (train=0.781, test=0.779) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.738) f1: (train=0.783, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.740, test=0.749) f1: (train=0.781, test=0.789) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.780, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.865, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.780, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.865, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.780, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.865, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.780, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.865, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.780, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.865, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.780, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=30, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.865, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.749, test=0.745) f1: (train=0.790, test=0.786) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.746, test=0.738) f1: (train=0.788, test=0.780) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.789, test=0.785) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.788, test=0.784) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=30; accuracy: (train=0.870, test=0.873) balanced_accuracy: (train=0.746, test=0.754) f1: (train=0.788, test=0.795) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.749, test=0.745) f1: (train=0.790, test=0.786) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.746, test=0.738) f1: (train=0.788, test=0.780) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.789, test=0.785) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.788, test=0.784) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=50; accuracy: (train=0.870, test=0.873) balanced_accuracy: (train=0.746, test=0.754) f1: (train=0.788, test=0.795) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.749, test=0.745) f1: (train=0.790, test=0.786) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.746, test=0.738) f1: (train=0.788, test=0.780) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.789, test=0.785) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.788, test=0.784) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=20, min_samples_split=6, random_state=None; accuracy: (train=0.870, test=0.873) balanced_accuracy: (train=0.746, test=0.754) f1: (train=0.788, test=0.795) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.749, test=0.745) f1: (train=0.790, test=0.786) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.746, test=0.738) f1: (train=0.788, test=0.780) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.789, test=0.785) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.788, test=0.784) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=30; accuracy: (train=0.870, test=0.873) balanced_accuracy: (train=0.746, test=0.754) f1: (train=0.788, test=0.795) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.749, test=0.745) f1: (train=0.790, test=0.786) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.746, test=0.738) f1: (train=0.788, test=0.780) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.789, test=0.785) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.788, test=0.784) total time=   0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=50; accuracy: (train=0.870, test=0.873) balanced_accuracy: (train=0.746, test=0.754) f1: (train=0.788, test=0.795) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.749, test=0.745) f1: (train=0.790, test=0.786) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.746, test=0.738) f1: (train=0.788, test=0.780) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.789, test=0.785) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.788, test=0.784) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=20, min_samples_split=8, random_state=None; accuracy: (train=0.870, test=0.873) balanced_accuracy: (train=0.746, test=0.754) f1: (train=0.788, test=0.795) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.870, test=0.865) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.784, test=0.781) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.872) balanced_accuracy: (train=0.744, test=0.752) f1: (train=0.785, test=0.793) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.870, test=0.865) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.784, test=0.781) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.872) balanced_accuracy: (train=0.744, test=0.752) f1: (train=0.785, test=0.793) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.870, test=0.865) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.784, test=0.781) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=50, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.872) balanced_accuracy: (train=0.744, test=0.752) f1: (train=0.785, test=0.793) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.870, test=0.865) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.784, test=0.781) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.872) balanced_accuracy: (train=0.744, test=0.752) f1: (train=0.785, test=0.793) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.870, test=0.865) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.784, test=0.781) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.872) balanced_accuracy: (train=0.744, test=0.752) f1: (train=0.785, test=0.793) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.745, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.870, test=0.865) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.786, test=0.778) total time=   0.3s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.870, test=0.868) balanced_accuracy: (train=0.744, test=0.742) f1: (train=0.786, test=0.783) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.868) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.784, test=0.781) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=50, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.872) balanced_accuracy: (train=0.744, test=0.752) f1: (train=0.785, test=0.793) total time=   0.3s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.737) f1: (train=0.781, test=0.779) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.738) f1: (train=0.783, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.740, test=0.749) f1: (train=0.781, test=0.789) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.737) f1: (train=0.781, test=0.779) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.738) f1: (train=0.783, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.740, test=0.749) f1: (train=0.781, test=0.789) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.737) f1: (train=0.781, test=0.779) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.738) f1: (train=0.783, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=100, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.740, test=0.749) f1: (train=0.781, test=0.789) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.737) f1: (train=0.781, test=0.779) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.738) f1: (train=0.783, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.740, test=0.749) f1: (train=0.781, test=0.789) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.737) f1: (train=0.781, test=0.779) total time=   0.3s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.738) f1: (train=0.783, test=0.780) total time=   0.3s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.740, test=0.749) f1: (train=0.781, test=0.789) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.740, test=0.739) f1: (train=0.782, test=0.780) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.741, test=0.735) f1: (train=0.783, test=0.776) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.739, test=0.737) f1: (train=0.781, test=0.779) total time=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.741, test=0.738) f1: (train=0.783, test=0.780) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=100, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.740, test=0.749) f1: (train=0.781, test=0.789) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.780, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=30; accuracy: (train=0.865, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.780, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=50; accuracy: (train=0.865, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.780, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=200, min_samples_split=6, random_state=None; accuracy: (train=0.865, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.780, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=30; accuracy: (train=0.865, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.780, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=50; accuracy: (train=0.865, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n",
      "[CV 1/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.780, test=0.778) total time=   0.2s\n",
      "[CV 2/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.739, test=0.732) f1: (train=0.781, test=0.774) total time=   0.2s\n",
      "[CV 3/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.777) total time=   0.2s\n",
      "[CV 4/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.738, test=0.737) f1: (train=0.779, test=0.778) total time=   0.2s\n",
      "[CV 5/5] END ccp_alpha=0.0001, criterion=log_loss, max_depth=None, min_samples_leaf=200, min_samples_split=8, random_state=None; accuracy: (train=0.865, test=0.870) balanced_accuracy: (train=0.735, test=0.744) f1: (train=0.777, test=0.786) total time=   0.2s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False),\n",
       "             estimator=DecisionTreeClassifier(min_samples_leaf=50,\n",
       "                                              min_samples_split=50,\n",
       "                                              random_state=10),\n",
       "             param_grid={&#x27;ccp_alpha&#x27;: [0.0001],\n",
       "                         &#x27;criterion&#x27;: [&#x27;gini&#x27;, &#x27;entropy&#x27;, &#x27;log_loss&#x27;],\n",
       "                         &#x27;max_depth&#x27;: [10, 20, 30, None],\n",
       "                         &#x27;min_samples_leaf&#x27;: [20, 50, 100, 200],\n",
       "                         &#x27;min_samples_split&#x27;: [6, 8],\n",
       "                         &#x27;random_state&#x27;: [30, 50, None]},\n",
       "             refit=&#x27;balanced_accuracy&#x27;, return_train_score=True,\n",
       "             scoring={&#x27;accuracy&#x27;: &#x27;accuracy&#x27;,\n",
       "                      &#x27;balanced_accuracy&#x27;: &#x27;balanced_accuracy&#x27;,\n",
       "                      &#x27;f1&#x27;: &#x27;f1_macro&#x27;},\n",
       "             verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False),\n",
       "             estimator=DecisionTreeClassifier(min_samples_leaf=50,\n",
       "                                              min_samples_split=50,\n",
       "                                              random_state=10),\n",
       "             param_grid={&#x27;ccp_alpha&#x27;: [0.0001],\n",
       "                         &#x27;criterion&#x27;: [&#x27;gini&#x27;, &#x27;entropy&#x27;, &#x27;log_loss&#x27;],\n",
       "                         &#x27;max_depth&#x27;: [10, 20, 30, None],\n",
       "                         &#x27;min_samples_leaf&#x27;: [20, 50, 100, 200],\n",
       "                         &#x27;min_samples_split&#x27;: [6, 8],\n",
       "                         &#x27;random_state&#x27;: [30, 50, None]},\n",
       "             refit=&#x27;balanced_accuracy&#x27;, return_train_score=True,\n",
       "             scoring={&#x27;accuracy&#x27;: &#x27;accuracy&#x27;,\n",
       "                      &#x27;balanced_accuracy&#x27;: &#x27;balanced_accuracy&#x27;,\n",
       "                      &#x27;f1&#x27;: &#x27;f1_macro&#x27;},\n",
       "             verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(min_samples_leaf=50, min_samples_split=50,\n",
       "                       random_state=10)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(min_samples_leaf=50, min_samples_split=50,\n",
       "                       random_state=10)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False),\n",
       "             estimator=DecisionTreeClassifier(min_samples_leaf=50,\n",
       "                                              min_samples_split=50,\n",
       "                                              random_state=10),\n",
       "             param_grid={'ccp_alpha': [0.0001],\n",
       "                         'criterion': ['gini', 'entropy', 'log_loss'],\n",
       "                         'max_depth': [10, 20, 30, None],\n",
       "                         'min_samples_leaf': [20, 50, 100, 200],\n",
       "                         'min_samples_split': [6, 8],\n",
       "                         'random_state': [30, 50, None]},\n",
       "             refit='balanced_accuracy', return_train_score=True,\n",
       "             scoring={'accuracy': 'accuracy',\n",
       "                      'balanced_accuracy': 'balanced_accuracy',\n",
       "                      'f1': 'f1_macro'},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "#GRID SEARCH\n",
    "tree_clf = DecisionTreeClassifier(max_features=None,max_depth=None, random_state=10, min_samples_leaf=50,min_samples_split=50)\n",
    "\n",
    "parameter_grid = {\n",
    "    \"max_depth\": [10, 20, 30, None],\n",
    "    \"criterion\": ['gini', 'entropy', 'log_loss'],\n",
    "    'random_state': [30, 50, None],\n",
    "    'min_samples_leaf':[20, 50, 100, 200],\n",
    "    'ccp_alpha': [.0001],\n",
    "    'min_samples_split': [6, 8 ]\n",
    "}\n",
    "\n",
    "# Create Stratified folds\n",
    "cross_validation = StratifiedKFold(n_splits=5)\n",
    "cross_validation.get_n_splits(train_data, y_train)\n",
    "\n",
    "# Create the scoring dictionary\n",
    "SCORING = {\n",
    "    \"accuracy\": \"accuracy\",\n",
    "    \"balanced_accuracy\": \"balanced_accuracy\",\n",
    "    \"f1\": \"f1_macro\",\n",
    "}\n",
    "\n",
    "# Create and fit the GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=tree_clf,\n",
    "    param_grid=parameter_grid,\n",
    "    cv=cross_validation,\n",
    "    verbose=3,\n",
    "    scoring=SCORING,\n",
    "    return_train_score=True,\n",
    "    refit=\"balanced_accuracy\",\n",
    ")\n",
    "\n",
    "grid_search.fit(train_data,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "62d3ccd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.7443202990579671\n",
      "Best parameters: {'ccp_alpha': 0.0001, 'criterion': 'entropy', 'max_depth': 20, 'min_samples_leaf': 20, 'min_samples_split': 6, 'random_state': 30}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(ccp_alpha=0.0001, criterion=&#x27;entropy&#x27;, max_depth=20,\n",
       "                       min_samples_leaf=20, min_samples_split=6,\n",
       "                       random_state=30)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" checked><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(ccp_alpha=0.0001, criterion=&#x27;entropy&#x27;, max_depth=20,\n",
       "                       min_samples_leaf=20, min_samples_split=6,\n",
       "                       random_state=30)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.0001, criterion='entropy', max_depth=20,\n",
       "                       min_samples_leaf=20, min_samples_split=6,\n",
       "                       random_state=30)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Best score: {}\".format(grid_search.best_score_))\n",
    "print(\"Best parameters: {}\".format(grid_search.best_params_))\n",
    "\n",
    "best_dtc = grid_search.best_estimator_\n",
    "best_dtc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e0da7fcb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8686194494397566"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model =best_dtc\n",
    "my_model.fit(train_data, y_train)\n",
    "my_model.score(test_data,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5722cc90",
   "metadata": {},
   "source": [
    "RANDOM FOREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "07321942",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b318752",
   "metadata": {},
   "outputs": [],
   "source": [
    "column = ['criterion', 'max_depth', 'max_features', 'n_estimators', 'random_state', 'accuracy']\n",
    "column_bar = ['try', 'Parameter_changed', 'Accuracy']\n",
    "\n",
    "### Create a single row equivalent to a single try for decision tree\n",
    "def create_bar_row(criterion, depth, feature, stimatori,random, attempt, parameter):\n",
    "  rf = RandomForestClassifier(criterion=criterion,max_depth=depth, max_features=feature,n_estimators=stimatori, random_state=random )\n",
    "  rf.fit(train_data, np.ravel(y_train))\n",
    "  testset_score = rf.score(test_data, y_test)\n",
    "  row = pd.DataFrame(data=[[attempt, parameter, testset_score]], columns=column_bar)\n",
    "  return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "080a26fd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  try Parameter_changed  Accuracy\n",
      "0   1             start  0.867029\n",
      "0   2         max_depth  0.867720\n",
      "0   3      max_features  0.867236\n",
      "0   4      n_estimators  0.868204\n",
      "0   5      random_state  0.867513\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'Score sul testset durante il tuning dei parametri'}, xlabel='Accuracy', ylabel='Parameter_changed'>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.DataFrame(columns=column_bar)\n",
    "df = pd.concat([df, create_bar_row('gini', None, 20, 40, 2,1, 'start')]) # try 1\n",
    "df = pd.concat([df, create_bar_row('gini', 40, 20, 40, 5,2, 'max_depth')]) # try 2\n",
    "df = pd.concat([df, create_bar_row('gini', 40, None, 40, 5,3, 'max_features')]) # try 3\n",
    "df = pd.concat([df, create_bar_row('gini', 40, None, 100, 5,4, 'n_estimators')]) # try 4\n",
    "df = pd.concat([df, create_bar_row('gini', 40, None, 100, 10,5, 'random_state')]) # try 5\n",
    "print(df)\n",
    "\n",
    "fig, axs = plt.subplots()\n",
    "axs.set_xlim([0.70,0.89])\n",
    "axs.set_title(\"Score sul testset durante il tuning dei parametri\")\n",
    "\n",
    "sns.barplot(data=df, x='Accuracy',y=\"Parameter_changed\",ax=axs, orient=\"h\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d044b92",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "algoritmo=[\"Start\",\"Max_depth\",\"Max_features\",\"n_estimators\",\"random_state\"]\n",
    "accuracy=[0.8670,0.8677,0.8672,0.8682,0.8675]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(algoritmo, accuracy, marker='o', linestyle='-', color='r')\n",
    "plt.title(' Accuracy su testSet al Variare dei parametri')\n",
    "plt.xlabel('Parametro variato')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.grid(True)\n",
    "plt.xticks(algoritmo)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cabb51e",
   "metadata": {},
   "source": [
    "Prove valutate su training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "56b47fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "column = ['criterion', 'max_depth', 'max_features', 'n_estimators', 'random_state', 'accuracy']\n",
    "column_bar = ['try', 'Parameter_changed', 'Accuracy']\n",
    "\n",
    "### Create a single row equivalent to a single try for decision tree\n",
    "def create_bar_row(criterion, depth, feature, stimatori,random, attempt, parameter):\n",
    "  rf = RandomForestClassifier(criterion=criterion,max_depth=depth, max_features=feature,n_estimators=stimatori, random_state=random )\n",
    "  rf.fit(train_data, np.ravel(y_train))\n",
    "  testset_score = rf.score(train_data, y_train)\n",
    "  row = pd.DataFrame(data=[[attempt, parameter, testset_score]], columns=column_bar)\n",
    "  return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8f9c78b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  try Parameter_changed  Accuracy\n",
      "0   1             start  0.998824\n",
      "0   2         max_depth  0.998625\n",
      "0   3      max_features  0.998651\n",
      "0   4      n_estimators  0.999939\n",
      "0   5      random_state  0.999965\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(columns=column_bar)\n",
    "df = pd.concat([df, create_bar_row('gini', None, 20, 40, 2,1, 'start')]) # try 1\n",
    "df = pd.concat([df, create_bar_row('gini', 40, 20, 40, 5,2, 'max_depth')]) # try 2\n",
    "df = pd.concat([df, create_bar_row('gini', 40, None, 40, 5,3, 'max_features')]) # try 3\n",
    "df = pd.concat([df, create_bar_row('gini', 40, None, 100, 5,4, 'n_estimators')]) # try 4\n",
    "df = pd.concat([df, create_bar_row('gini', 40, None, 100, 10,5, 'random_state')]) # try 5\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c6bd8475",
   "metadata": {},
   "outputs": [],
   "source": [
    "column = ['criterion', 'max_depth', 'max_features', 'n_estimators', 'random_state', 'accuracy']\n",
    "\n",
    "def plot_nEstimatorVSaccuracy(nEstimators,title):\n",
    "  accs = pd.DataFrame(columns=column)\n",
    "  for e in nEstimators:\n",
    "    rt = RandomForestClassifier(n_jobs=-1,criterion='gini',max_depth=40, max_features=None, n_estimators=e, random_state=10 )\n",
    "    rt.fit(train_data, np.ravel(y_train))\n",
    "    testset_score = rt.score(test_data, np.ravel(y_test) )\n",
    "    row = pd.DataFrame(data=[['gini',40, None,e, 10, testset_score]], columns=column)\n",
    "    accs = pd.concat([accs, row])\n",
    "\n",
    "  # plot\n",
    "  fig, ax = plt.subplots()\n",
    "  ax.plot(accs.n_estimators, accs.accuracy)\n",
    "\n",
    "  ax.set(xlabel='n_estimators', ylabel='Accuracy',\n",
    "        title=title)\n",
    "  ax.grid()\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9616697a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_estimators = np.linspace(10, 50, 51, dtype=int)\n",
    "\n",
    "plot_nEstimatorVSaccuracy(n_estimators,  'Variazione accuracy aumentando numero estimatori') # with pruning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aada8db8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 243 candidates, totalling 1215 fits\n",
      "[CV 5/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.786) total time=   1.2s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.866, test=0.870) balanced_accuracy: (train=0.732, test=0.741) f1: (train=0.775, test=0.785) total time=   1.1s\n",
      "[CV 2/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.738, test=0.731) f1: (train=0.781, test=0.773) total time=   1.9s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.780, test=0.776) total time=   3.6s\n",
      "[CV 2/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.737, test=0.731) f1: (train=0.780, test=0.774) total time=   1.3s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.737, test=0.734) f1: (train=0.780, test=0.777) total time=   1.2s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   2.2s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.735, test=0.732) f1: (train=0.779, test=0.775) total time=   3.9s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.786) total time=   4.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.872, test=0.868) balanced_accuracy: (train=0.747, test=0.739) f1: (train=0.790, test=0.781) total time=   4.3s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.872, test=0.870) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.789, test=0.785) total time=   8.2s\n",
      "[CV 2/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.873, test=0.868) balanced_accuracy: (train=0.747, test=0.739) f1: (train=0.790, test=0.781) total time=  16.3s\n",
      "[CV 1/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   1.3s\n",
      "[CV 3/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.737, test=0.734) f1: (train=0.780, test=0.777) total time=   1.2s\n",
      "[CV 5/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.787) total time=   2.2s\n",
      "[CV 4/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   2.4s\n",
      "[CV 4/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   4.2s\n",
      "[CV 2/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.779, test=0.772) total time=   1.3s\n",
      "[CV 5/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.866, test=0.870) balanced_accuracy: (train=0.733, test=0.741) f1: (train=0.776, test=0.784) total time=   1.2s\n",
      "[CV 1/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   2.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   4.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.873, test=0.870) balanced_accuracy: (train=0.747, test=0.744) f1: (train=0.790, test=0.786) total time=   5.1s\n",
      "[CV 3/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.872, test=0.870) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.790, test=0.786) total time=   5.2s\n",
      "[CV 1/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.872, test=0.870) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.790, test=0.785) total time=   8.8s\n",
      "[CV 3/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.873, test=0.870) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.790, test=0.785) total time=  12.3s\n",
      "[CV 2/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.737, test=0.730) f1: (train=0.780, test=0.773) total time=   1.4s\n",
      "[CV 5/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.786) total time=   1.4s\n",
      "[CV 1/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   1.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.866, test=0.870) balanced_accuracy: (train=0.733, test=0.741) f1: (train=0.776, test=0.784) total time=   1.3s\n",
      "[CV 3/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   2.1s\n",
      "[CV 2/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.737, test=0.730) f1: (train=0.780, test=0.773) total time=   4.1s\n",
      "[CV 2/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.737, test=0.731) f1: (train=0.780, test=0.773) total time=   3.9s\n",
      "[CV 1/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   1.8s\n",
      "[CV 3/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.779, test=0.776) total time=   2.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   3.9s\n",
      "[CV 1/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.873, test=0.870) balanced_accuracy: (train=0.748, test=0.744) f1: (train=0.791, test=0.786) total time=   5.2s\n",
      "[CV 3/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.873, test=0.870) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.790, test=0.786) total time=   8.6s\n",
      "[CV 5/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.871, test=0.875) balanced_accuracy: (train=0.744, test=0.753) f1: (train=0.787, test=0.796) total time=   7.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.873, test=0.870) balanced_accuracy: (train=0.748, test=0.743) f1: (train=0.790, test=0.786) total time=  16.7s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.779, test=0.776) total time=   2.2s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.780, test=0.772) total time=   4.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.737, test=0.730) f1: (train=0.780, test=0.773) total time=   3.4s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.866, test=0.870) balanced_accuracy: (train=0.733, test=0.742) f1: (train=0.776, test=0.785) total time=   1.3s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.867, test=0.870) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.786) total time=   2.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.737, test=0.730) f1: (train=0.780, test=0.773) total time=   4.1s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.783) total time=   5.1s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.870, test=0.874) balanced_accuracy: (train=0.741, test=0.751) f1: (train=0.784, test=0.794) total time=   5.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.744, test=0.736) f1: (train=0.787, test=0.779) total time=   7.2s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.785, test=0.782) total time=  16.9s\n",
      "[CV 4/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.778, test=0.776) total time=   1.4s\n",
      "[CV 5/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.866, test=0.870) balanced_accuracy: (train=0.733, test=0.742) f1: (train=0.776, test=0.785) total time=   1.5s\n",
      "[CV 2/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.779, test=0.773) total time=   2.5s\n",
      "[CV 2/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.780, test=0.772) total time=   2.4s\n",
      "[CV 1/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.778) total time=   4.5s\n",
      "[CV 3/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.732) f1: (train=0.779, test=0.775) total time=   1.3s\n",
      "[CV 1/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.776) total time=   1.2s\n",
      "[CV 1/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.735) f1: (train=0.779, test=0.778) total time=   2.4s\n",
      "[CV 4/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.779, test=0.776) total time=   4.2s\n",
      "[CV 1/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.745, test=0.741) f1: (train=0.787, test=0.783) total time=   5.7s\n",
      "[CV 3/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.785, test=0.782) total time=   5.8s\n",
      "[CV 5/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.870, test=0.874) balanced_accuracy: (train=0.742, test=0.751) f1: (train=0.785, test=0.794) total time=  10.3s\n",
      "[CV 3/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.870, test=0.869) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.785, test=0.782) total time=  16.5s\n",
      "[CV 5/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.866, test=0.870) balanced_accuracy: (train=0.733, test=0.742) f1: (train=0.776, test=0.785) total time=   1.5s\n",
      "[CV 2/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.779, test=0.773) total time=   2.2s\n",
      "[CV 4/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   2.5s\n",
      "[CV 4/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.779, test=0.776) total time=   3.9s\n",
      "[CV 1/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.778, test=0.776) total time=   1.1s\n",
      "[CV 1/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.777) total time=   1.4s\n",
      "[CV 4/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.778, test=0.775) total time=   1.4s\n",
      "[CV 1/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.778, test=0.776) total time=   2.1s\n",
      "[CV 2/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.780, test=0.773) total time=   4.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.737, test=0.731) f1: (train=0.780, test=0.774) total time=   1.4s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.737, test=0.734) f1: (train=0.780, test=0.777) total time=   2.1s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.737, test=0.735) f1: (train=0.780, test=0.778) total time=   4.3s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   1.1s\n",
      "[CV 2/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.869, test=0.864) balanced_accuracy: (train=0.739, test=0.731) f1: (train=0.782, test=0.773) total time=   1.3s\n",
      "[CV 2/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.737, test=0.731) f1: (train=0.780, test=0.773) total time=   2.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   4.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.872, test=0.868) balanced_accuracy: (train=0.747, test=0.739) f1: (train=0.790, test=0.781) total time=   4.9s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.872, test=0.870) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.789, test=0.785) total time=   4.3s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.871, test=0.875) balanced_accuracy: (train=0.745, test=0.752) f1: (train=0.788, test=0.795) total time=   7.3s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.871, test=0.875) balanced_accuracy: (train=0.744, test=0.753) f1: (train=0.787, test=0.795) total time=  16.4s\n",
      "[CV 3/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.737, test=0.733) f1: (train=0.780, test=0.775) total time=   1.2s\n",
      "[CV 4/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   1.3s\n",
      "[CV 1/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   2.1s\n",
      "[CV 4/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.737, test=0.734) f1: (train=0.780, test=0.777) total time=   2.5s\n",
      "[CV 4/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   3.3s\n",
      "[CV 4/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.780, test=0.776) total time=   3.9s\n",
      "[CV 5/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.787) total time=   2.2s\n",
      "[CV 3/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   3.9s\n",
      "[CV 4/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.873, test=0.870) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.790, test=0.785) total time=   5.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.872, test=0.870) balanced_accuracy: (train=0.746, test=0.743) f1: (train=0.789, test=0.786) total time=   5.1s\n",
      "[CV 5/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.871, test=0.875) balanced_accuracy: (train=0.745, test=0.753) f1: (train=0.788, test=0.796) total time=   8.6s\n",
      "[CV 2/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.873, test=0.868) balanced_accuracy: (train=0.747, test=0.739) f1: (train=0.791, test=0.782) total time=  15.9s\n",
      "[CV 5/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.787) total time=   1.3s\n",
      "[CV 2/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.737, test=0.731) f1: (train=0.780, test=0.774) total time=   2.4s\n",
      "[CV 5/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.787) total time=   2.4s\n",
      "[CV 4/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   3.9s\n",
      "[CV 5/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.786) total time=   3.9s\n",
      "[CV 2/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.737, test=0.730) f1: (train=0.780, test=0.773) total time=   1.9s\n",
      "[CV 3/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   4.1s\n",
      "[CV 5/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.871, test=0.875) balanced_accuracy: (train=0.745, test=0.754) f1: (train=0.788, test=0.796) total time=   5.1s\n",
      "[CV 2/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.873, test=0.868) balanced_accuracy: (train=0.747, test=0.739) f1: (train=0.790, test=0.781) total time=   7.8s\n",
      "[CV 3/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.872, test=0.870) balanced_accuracy: (train=0.746, test=0.742) f1: (train=0.789, test=0.785) total time=   7.1s\n",
      "[CV 5/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.871, test=0.875) balanced_accuracy: (train=0.745, test=0.753) f1: (train=0.787, test=0.796) total time=  16.4s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.786) total time=   2.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   1.9s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.737, test=0.730) f1: (train=0.780, test=0.773) total time=   4.3s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.863) balanced_accuracy: (train=0.736, test=0.729) f1: (train=0.778, test=0.771) total time=   1.3s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   1.2s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.779, test=0.776) total time=   2.2s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.778) total time=   4.3s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   4.2s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.870, test=0.874) balanced_accuracy: (train=0.742, test=0.751) f1: (train=0.784, test=0.793) total time=   4.8s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.783) total time=   8.4s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.870, test=0.874) balanced_accuracy: (train=0.741, test=0.751) f1: (train=0.784, test=0.794) total time=  16.9s\n",
      "[CV 2/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.864) balanced_accuracy: (train=0.735, test=0.729) f1: (train=0.778, test=0.771) total time=   1.6s\n",
      "[CV 3/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.779, test=0.776) total time=   1.5s\n",
      "[CV 4/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.778, test=0.775) total time=   1.4s\n",
      "[CV 5/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.866, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.776, test=0.787) total time=   2.2s\n",
      "[CV 1/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   3.6s\n",
      "[CV 2/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.780, test=0.773) total time=   4.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.779, test=0.773) total time=   2.2s\n",
      "[CV 5/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.866, test=0.871) balanced_accuracy: (train=0.733, test=0.742) f1: (train=0.776, test=0.786) total time=   2.3s\n",
      "[CV 2/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.780, test=0.773) total time=   4.4s\n",
      "[CV 4/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.783) total time=   5.5s\n",
      "[CV 1/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.745, test=0.741) f1: (train=0.787, test=0.784) total time=   8.7s\n",
      "[CV 3/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.785, test=0.783) total time=  17.8s\n",
      "[CV 5/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.870, test=0.874) balanced_accuracy: (train=0.742, test=0.751) f1: (train=0.785, test=0.794) total time=  15.3s\n",
      "[CV 3/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.777) total time=   3.6s\n",
      "[CV 2/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.737, test=0.731) f1: (train=0.780, test=0.773) total time=   2.2s\n",
      "[CV 4/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.779, test=0.776) total time=   4.2s\n",
      "[CV 5/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.733, test=0.743) f1: (train=0.777, test=0.786) total time=   4.2s\n",
      "[CV 1/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.744, test=0.740) f1: (train=0.787, test=0.783) total time=   3.9s\n",
      "[CV 2/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.872, test=0.867) balanced_accuracy: (train=0.745, test=0.737) f1: (train=0.788, test=0.779) total time=   8.4s\n",
      "[CV 4/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.787, test=0.783) total time=  18.2s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.732) f1: (train=0.779, test=0.775) total time=   1.2s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.737, test=0.730) f1: (train=0.780, test=0.772) total time=   1.3s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.735, test=0.735) f1: (train=0.778, test=0.778) total time=   1.2s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.866, test=0.870) balanced_accuracy: (train=0.733, test=0.742) f1: (train=0.776, test=0.785) total time=   1.4s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.735) f1: (train=0.779, test=0.778) total time=   1.9s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.737, test=0.731) f1: (train=0.780, test=0.773) total time=   2.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.779, test=0.778) total time=   1.3s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.735) f1: (train=0.779, test=0.778) total time=   1.9s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.866, test=0.871) balanced_accuracy: (train=0.733, test=0.742) f1: (train=0.776, test=0.786) total time=   2.1s\n",
      "[CV 2/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.738, test=0.730) f1: (train=0.781, test=0.773) total time=   4.2s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.737, test=0.736) f1: (train=0.780, test=0.778) total time=   1.2s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.735) f1: (train=0.779, test=0.778) total time=   1.9s\n",
      "[CV 2/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.737, test=0.730) f1: (train=0.780, test=0.773) total time=   3.9s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.780, test=0.776) total time=   3.8s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.872, test=0.870) balanced_accuracy: (train=0.747, test=0.742) f1: (train=0.790, test=0.784) total time=   4.5s\n",
      "[CV 2/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.872, test=0.868) balanced_accuracy: (train=0.747, test=0.739) f1: (train=0.790, test=0.781) total time=   8.4s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.872, test=0.870) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.790, test=0.785) total time=  16.4s\n",
      "[CV 4/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   1.3s\n",
      "[CV 2/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.738, test=0.731) f1: (train=0.781, test=0.774) total time=   1.3s\n",
      "[CV 4/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.780, test=0.777) total time=   2.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   2.3s\n",
      "[CV 5/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.733, test=0.743) f1: (train=0.777, test=0.786) total time=   4.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   1.2s\n",
      "[CV 4/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   1.1s\n",
      "[CV 3/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.780, test=0.776) total time=   2.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   1.9s\n",
      "[CV 1/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.735) f1: (train=0.779, test=0.778) total time=   4.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.872, test=0.870) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.790, test=0.786) total time=   4.9s\n",
      "[CV 5/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.871, test=0.875) balanced_accuracy: (train=0.744, test=0.753) f1: (train=0.787, test=0.795) total time=   8.5s\n",
      "[CV 2/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.873, test=0.868) balanced_accuracy: (train=0.747, test=0.739) f1: (train=0.790, test=0.781) total time=  16.7s\n",
      "[CV 1/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   1.5s\n",
      "[CV 4/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   1.1s\n",
      "[CV 3/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.732) f1: (train=0.779, test=0.775) total time=   1.2s\n",
      "[CV 4/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.737, test=0.735) f1: (train=0.779, test=0.778) total time=   1.2s\n",
      "[CV 5/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.787) total time=   2.2s\n",
      "[CV 1/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.735) f1: (train=0.779, test=0.778) total time=   4.2s\n",
      "[CV 1/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.735) f1: (train=0.779, test=0.778) total time=   3.9s\n",
      "[CV 5/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.866, test=0.870) balanced_accuracy: (train=0.733, test=0.741) f1: (train=0.776, test=0.784) total time=   1.1s\n",
      "[CV 4/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.737, test=0.734) f1: (train=0.780, test=0.777) total time=   1.9s\n",
      "[CV 2/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.780, test=0.773) total time=   4.1s\n",
      "[CV 4/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.873, test=0.870) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.790, test=0.785) total time=   4.8s\n",
      "[CV 5/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.871, test=0.875) balanced_accuracy: (train=0.745, test=0.753) f1: (train=0.788, test=0.796) total time=   5.6s\n",
      "[CV 2/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.873, test=0.867) balanced_accuracy: (train=0.747, test=0.738) f1: (train=0.790, test=0.780) total time=   6.8s\n",
      "[CV 2/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.873, test=0.868) balanced_accuracy: (train=0.747, test=0.739) f1: (train=0.791, test=0.782) total time=  12.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.872, test=0.870) balanced_accuracy: (train=0.746, test=0.743) f1: (train=0.789, test=0.785) total time=  11.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   4.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   3.8s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.735) f1: (train=0.779, test=0.778) total time=   2.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   4.3s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.786) total time=   4.4s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.872, test=0.867) balanced_accuracy: (train=0.744, test=0.737) f1: (train=0.787, test=0.779) total time=   4.7s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=50, random_state=30; accuracy: (train=0.871, test=0.870) balanced_accuracy: (train=0.743, test=0.741) f1: (train=0.786, test=0.784) total time=   8.2s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.743, test=0.736) f1: (train=0.787, test=0.778) total time=  17.2s\n",
      "[CV 5/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.866, test=0.871) balanced_accuracy: (train=0.733, test=0.742) f1: (train=0.776, test=0.785) total time=   1.4s\n",
      "[CV 1/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.776) total time=   1.2s\n",
      "[CV 5/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.866, test=0.869) balanced_accuracy: (train=0.732, test=0.741) f1: (train=0.775, test=0.784) total time=   1.5s\n",
      "[CV 2/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.737, test=0.731) f1: (train=0.780, test=0.773) total time=   2.1s\n",
      "[CV 5/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.866, test=0.871) balanced_accuracy: (train=0.733, test=0.742) f1: (train=0.776, test=0.786) total time=   2.4s\n",
      "[CV 1/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   4.2s\n",
      "[CV 3/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.779, test=0.776) total time=   1.3s\n",
      "[CV 1/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.776) total time=   2.1s\n",
      "[CV 3/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.779, test=0.776) total time=   2.1s\n",
      "[CV 5/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.866, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.786) total time=   4.3s\n",
      "[CV 2/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.872, test=0.867) balanced_accuracy: (train=0.745, test=0.737) f1: (train=0.788, test=0.779) total time=   5.5s\n",
      "[CV 4/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.741) f1: (train=0.786, test=0.784) total time=   8.8s\n",
      "[CV 1/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.744, test=0.741) f1: (train=0.787, test=0.783) total time=  17.9s\n",
      "[CV 4/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.741) f1: (train=0.786, test=0.783) total time=  12.9s\n",
      "[CV 1/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   4.5s\n",
      "[CV 4/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   1.3s\n",
      "[CV 1/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.776) total time=   2.2s\n",
      "[CV 4/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.779, test=0.777) total time=   2.2s\n",
      "[CV 1/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=100, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   4.5s\n",
      "[CV 4/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.740) f1: (train=0.786, test=0.783) total time=   4.9s\n",
      "[CV 4/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.741) f1: (train=0.786, test=0.784) total time=   8.8s\n",
      "[CV 1/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.744, test=0.741) f1: (train=0.787, test=0.783) total time=  18.7s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.863) balanced_accuracy: (train=0.736, test=0.729) f1: (train=0.778, test=0.771) total time=   1.4s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.777) total time=   1.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.737, test=0.734) f1: (train=0.780, test=0.777) total time=   1.2s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   1.1s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.737, test=0.735) f1: (train=0.780, test=0.778) total time=   1.9s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.779, test=0.776) total time=   4.5s\n",
      "[CV 2/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.736, test=0.730) f1: (train=0.780, test=0.773) total time=   1.2s\n",
      "[CV 2/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.737, test=0.731) f1: (train=0.780, test=0.773) total time=   1.8s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   1.9s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.780, test=0.776) total time=   3.9s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.871, test=0.875) balanced_accuracy: (train=0.745, test=0.753) f1: (train=0.787, test=0.796) total time=   4.7s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.872, test=0.870) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.790, test=0.785) total time=   7.2s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.872, test=0.869) balanced_accuracy: (train=0.745, test=0.741) f1: (train=0.788, test=0.784) total time=   7.8s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.871, test=0.875) balanced_accuracy: (train=0.744, test=0.752) f1: (train=0.787, test=0.795) total time=  11.4s\n",
      "[CV 2/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.737, test=0.730) f1: (train=0.780, test=0.773) total time=   1.4s\n",
      "[CV 5/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=30, random_state=30; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.787) total time=   1.3s\n",
      "[CV 2/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.737, test=0.731) f1: (train=0.780, test=0.774) total time=   2.1s\n",
      "[CV 5/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.787) total time=   2.4s\n",
      "[CV 2/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.868, test=0.865) balanced_accuracy: (train=0.737, test=0.730) f1: (train=0.780, test=0.773) total time=   3.4s\n",
      "[CV 3/5] END criterion=gini, max_depth=40, max_features=sqrt, n_estimators=100, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   3.9s\n",
      "[CV 1/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.737, test=0.734) f1: (train=0.779, test=0.777) total time=   2.2s\n",
      "[CV 1/5] END criterion=gini, max_depth=40, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.737, test=0.735) f1: (train=0.780, test=0.777) total time=   4.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.873, test=0.870) balanced_accuracy: (train=0.748, test=0.744) f1: (train=0.791, test=0.786) total time=   4.9s\n",
      "[CV 2/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.873, test=0.868) balanced_accuracy: (train=0.747, test=0.739) f1: (train=0.790, test=0.781) total time=   8.6s\n",
      "[CV 5/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.871, test=0.875) balanced_accuracy: (train=0.744, test=0.753) f1: (train=0.787, test=0.796) total time=   8.6s\n",
      "[CV 2/5] END criterion=gini, max_depth=40, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.872, test=0.867) balanced_accuracy: (train=0.746, test=0.738) f1: (train=0.790, test=0.781) total time=  14.1s\n",
      "[CV 1/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.737, test=0.734) f1: (train=0.779, test=0.777) total time=   2.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.779, test=0.776) total time=   2.3s\n",
      "[CV 5/5] END criterion=gini, max_depth=None, max_features=sqrt, n_estimators=100, random_state=10; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.733, test=0.743) f1: (train=0.777, test=0.786) total time=   4.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.786) total time=   1.6s\n",
      "[CV 2/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.869, test=0.865) balanced_accuracy: (train=0.738, test=0.731) f1: (train=0.781, test=0.774) total time=   1.1s\n",
      "[CV 3/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   2.1s\n",
      "[CV 5/5] END criterion=gini, max_depth=None, max_features=log2, n_estimators=100, random_state=10; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.733, test=0.743) f1: (train=0.777, test=0.786) total time=   4.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.873, test=0.868) balanced_accuracy: (train=0.747, test=0.739) f1: (train=0.791, test=0.781) total time=   5.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=30, random_state=100; accuracy: (train=0.872, test=0.870) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.790, test=0.786) total time=   5.4s\n",
      "[CV 1/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.872, test=0.870) balanced_accuracy: (train=0.747, test=0.743) f1: (train=0.790, test=0.785) total time=   8.4s\n",
      "[CV 4/5] END criterion=gini, max_depth=None, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.873, test=0.869) balanced_accuracy: (train=0.747, test=0.742) f1: (train=0.790, test=0.784) total time=  16.5s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.735, test=0.735) f1: (train=0.778, test=0.778) total time=   1.2s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.779, test=0.776) total time=   2.1s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   2.4s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.866) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   4.1s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.776) total time=   1.3s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.737, test=0.730) f1: (train=0.780, test=0.772) total time=   1.3s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   2.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   2.3s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.867, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.786) total time=   4.3s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.744, test=0.740) f1: (train=0.786, test=0.783) total time=   4.9s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.785, test=0.782) total time=   8.5s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.870, test=0.874) balanced_accuracy: (train=0.741, test=0.751) f1: (train=0.784, test=0.794) total time=   8.5s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, max_features=None, n_estimators=100, random_state=100; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.744, test=0.736) f1: (train=0.787, test=0.778) total time=  17.2s\n",
      "[CV 1/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.778, test=0.776) total time=   2.5s\n",
      "[CV 3/5] END criterion=entropy, max_depth=40, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   4.6s\n",
      "[CV 1/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.867, test=0.867) balanced_accuracy: (train=0.735, test=0.734) f1: (train=0.778, test=0.777) total time=   1.2s\n",
      "[CV 3/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=30, random_state=100; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.776) total time=   1.3s\n",
      "[CV 4/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=50, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.777) total time=   2.1s\n",
      "[CV 1/5] END criterion=entropy, max_depth=40, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.779, test=0.778) total time=   4.3s\n",
      "[CV 3/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=30, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.742, test=0.740) f1: (train=0.786, test=0.783) total time=   5.5s\n",
      "[CV 3/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.742, test=0.739) f1: (train=0.785, test=0.782) total time=   8.6s\n",
      "[CV 4/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=50, random_state=100; accuracy: (train=0.871, test=0.869) balanced_accuracy: (train=0.743, test=0.741) f1: (train=0.786, test=0.783) total time=   9.2s\n",
      "[CV 5/5] END criterion=entropy, max_depth=40, max_features=None, n_estimators=100, random_state=30; accuracy: (train=0.870, test=0.874) balanced_accuracy: (train=0.742, test=0.751) f1: (train=0.785, test=0.794) total time=  15.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=30, random_state=100; accuracy: (train=0.868, test=0.864) balanced_accuracy: (train=0.737, test=0.731) f1: (train=0.780, test=0.773) total time=   1.5s\n",
      "[CV 4/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.779, test=0.776) total time=   2.1s\n",
      "[CV 3/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.779, test=0.776) total time=   2.5s\n",
      "[CV 3/5] END criterion=entropy, max_depth=None, max_features=sqrt, n_estimators=100, random_state=30; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.736, test=0.733) f1: (train=0.779, test=0.776) total time=   3.8s\n",
      "[CV 2/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.864) balanced_accuracy: (train=0.735, test=0.729) f1: (train=0.778, test=0.771) total time=   1.6s\n",
      "[CV 5/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=30, random_state=30; accuracy: (train=0.866, test=0.870) balanced_accuracy: (train=0.733, test=0.742) f1: (train=0.776, test=0.785) total time=   1.4s\n",
      "[CV 4/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=50, random_state=10; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.779, test=0.776) total time=   1.8s\n",
      "[CV 3/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=50, random_state=100; accuracy: (train=0.868, test=0.867) balanced_accuracy: (train=0.735, test=0.733) f1: (train=0.779, test=0.776) total time=   2.1s\n",
      "[CV 5/5] END criterion=entropy, max_depth=None, max_features=log2, n_estimators=100, random_state=30; accuracy: (train=0.866, test=0.871) balanced_accuracy: (train=0.734, test=0.743) f1: (train=0.777, test=0.786) total time=   4.2s\n",
      "[CV 2/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=30, random_state=30; accuracy: (train=0.872, test=0.867) balanced_accuracy: (train=0.745, test=0.737) f1: (train=0.788, test=0.779) total time=   5.6s\n",
      "[CV 5/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=50, random_state=10; accuracy: (train=0.870, test=0.874) balanced_accuracy: (train=0.742, test=0.751) f1: (train=0.785, test=0.794) total time=   9.1s\n",
      "[CV 2/5] END criterion=entropy, max_depth=None, max_features=None, n_estimators=100, random_state=10; accuracy: (train=0.871, test=0.867) balanced_accuracy: (train=0.744, test=0.736) f1: (train=0.787, test=0.779) total time=  18.4s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=10, max_features=sqrt, n_estimators=30, random_state=10; accuracy: (train=0.867, test=0.866) balanced_accuracy: (train=0.736, test=0.734) f1: (train=0.778, test=0.776) total time=   1.5s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False),\n",
       "             estimator=RandomForestClassifier(max_depth=100, max_features=None,\n",
       "                                              max_leaf_nodes=100,\n",
       "                                              n_estimators=50, n_jobs=-1,\n",
       "                                              random_state=100),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;criterion&#x27;: [&#x27;gini&#x27;, &#x27;entropy&#x27;, &#x27;log_loss&#x27;],\n",
       "                         &#x27;max_depth&#x27;: [10, 40, None],\n",
       "                         &#x27;max_features&#x27;: [&#x27;sqrt&#x27;, &#x27;log2&#x27;, None],\n",
       "                         &#x27;n_estimators&#x27;: [30, 50, 100],\n",
       "                         &#x27;random_state&#x27;: [10, 30, 100]},\n",
       "             refit=&#x27;balanced_accuracy&#x27;, return_train_score=True,\n",
       "             scoring={&#x27;accuracy&#x27;: &#x27;accuracy&#x27;,\n",
       "                      &#x27;balanced_accuracy&#x27;: &#x27;balanced_accuracy&#x27;,\n",
       "                      &#x27;f1&#x27;: &#x27;f1_macro&#x27;},\n",
       "             verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False),\n",
       "             estimator=RandomForestClassifier(max_depth=100, max_features=None,\n",
       "                                              max_leaf_nodes=100,\n",
       "                                              n_estimators=50, n_jobs=-1,\n",
       "                                              random_state=100),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;criterion&#x27;: [&#x27;gini&#x27;, &#x27;entropy&#x27;, &#x27;log_loss&#x27;],\n",
       "                         &#x27;max_depth&#x27;: [10, 40, None],\n",
       "                         &#x27;max_features&#x27;: [&#x27;sqrt&#x27;, &#x27;log2&#x27;, None],\n",
       "                         &#x27;n_estimators&#x27;: [30, 50, 100],\n",
       "                         &#x27;random_state&#x27;: [10, 30, 100]},\n",
       "             refit=&#x27;balanced_accuracy&#x27;, return_train_score=True,\n",
       "             scoring={&#x27;accuracy&#x27;: &#x27;accuracy&#x27;,\n",
       "                      &#x27;balanced_accuracy&#x27;: &#x27;balanced_accuracy&#x27;,\n",
       "                      &#x27;f1&#x27;: &#x27;f1_macro&#x27;},\n",
       "             verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=100, max_features=None, max_leaf_nodes=100,\n",
       "                       n_estimators=50, n_jobs=-1, random_state=100)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=100, max_features=None, max_leaf_nodes=100,\n",
       "                       n_estimators=50, n_jobs=-1, random_state=100)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False),\n",
       "             estimator=RandomForestClassifier(max_depth=100, max_features=None,\n",
       "                                              max_leaf_nodes=100,\n",
       "                                              n_estimators=50, n_jobs=-1,\n",
       "                                              random_state=100),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'criterion': ['gini', 'entropy', 'log_loss'],\n",
       "                         'max_depth': [10, 40, None],\n",
       "                         'max_features': ['sqrt', 'log2', None],\n",
       "                         'n_estimators': [30, 50, 100],\n",
       "                         'random_state': [10, 30, 100]},\n",
       "             refit='balanced_accuracy', return_train_score=True,\n",
       "             scoring={'accuracy': 'accuracy',\n",
       "                      'balanced_accuracy': 'balanced_accuracy',\n",
       "                      'f1': 'f1_macro'},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "rf = RandomForestClassifier( n_jobs=-1, n_estimators=50, max_depth=100,max_leaf_nodes=100, random_state=100, max_features=None)\n",
    "\n",
    "parameter_grid = {\n",
    "    \"n_estimators\": [30, 50, 100],\n",
    "    \"max_depth\": [10, 40, None],\n",
    "    \"max_features\": [\"sqrt\",\"log2\", None],\n",
    "    \"random_state\":[10,30,100],\n",
    "    \"criterion\": ['gini', 'entropy', 'log_loss']\n",
    "}\n",
    "\n",
    "cross_validation = StratifiedKFold(n_splits=5)\n",
    "cross_validation.get_n_splits(train_data, np.ravel(y_train))\n",
    "\n",
    "# Create the scoring dictionary\n",
    "SCORING = {\n",
    "    \"accuracy\": \"accuracy\",\n",
    "    \"balanced_accuracy\": \"balanced_accuracy\",\n",
    "    \"f1\": \"f1_macro\",\n",
    "}\n",
    "\n",
    "# Create and fit the GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=rf,\n",
    "    param_grid=parameter_grid,\n",
    "    n_jobs=-1,\n",
    "    cv=cross_validation,\n",
    "    verbose=3,\n",
    "    scoring=SCORING,\n",
    "    return_train_score=True,\n",
    "    refit=\"balanced_accuracy\",\n",
    ")\n",
    "\n",
    "grid_search.fit(train_data, np.ravel(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "35a074af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.7444008926792822\n",
      "Best parameters: {'criterion': 'gini', 'max_depth': 40, 'max_features': None, 'n_estimators': 30, 'random_state': 10}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_depth=40, max_features=None, max_leaf_nodes=100,\n",
       "                       n_estimators=30, n_jobs=-1, random_state=10)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=40, max_features=None, max_leaf_nodes=100,\n",
       "                       n_estimators=30, n_jobs=-1, random_state=10)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(max_depth=40, max_features=None, max_leaf_nodes=100,\n",
       "                       n_estimators=30, n_jobs=-1, random_state=10)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Best score: {}\".format(grid_search.best_score_))\n",
    "print(\"Best parameters: {}\".format(grid_search.best_params_))\n",
    "\n",
    "best_dtc = grid_search.best_estimator_\n",
    "best_dtc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "69089f07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8695186056162678"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model = best_dtc\n",
    "my_model.fit(train_data, np.ravel(y_train))\n",
    "my_model.score(test_data, np.ravel(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b587ca52",
   "metadata": {},
   "source": [
    "EXTRA TREE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "594e3215",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "47a73cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "column = ['criterion','max_features', 'n_estimators', 'random_state', 'accuracy']\n",
    "column_bar = ['try', 'Parameter_changed', 'Accuracy']\n",
    "\n",
    "### Create a single row equivalent to a single try for decision tree\n",
    "def create_bar_row(criterion,feature, stimatori,random, attempt, parameter):\n",
    "  xt = ExtraTreesClassifier(criterion=criterion,max_features=feature,n_estimators=stimatori, random_state=random, n_jobs=-1 )\n",
    "  xt.fit(train_data, np.ravel(y_train))\n",
    "  testset_score = xt.score(test_data, y_test)\n",
    "  row = pd.DataFrame(data=[[attempt, parameter, testset_score]], columns=column_bar)\n",
    "  return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5ae9c61a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  try Parameter_changed  Accuracy\n",
      "0   1             start  0.857587\n",
      "0   2      max_features  0.857587\n",
      "0   3       n_estimator  0.858556\n",
      "0   4      random_state  0.858902\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'Score sul testset durante il tuning dei parametri'}, xlabel='Accuracy', ylabel='Parameter_changed'>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.DataFrame(columns=column_bar)\n",
    "df = pd.concat([df, create_bar_row('gini', 'log2', 20, 4, 1, 'start')]) # try 1\n",
    "df = pd.concat([df, create_bar_row('gini', 'sqrt', 20, 4, 2, 'max_features')]) # try 2\n",
    "df = pd.concat([df, create_bar_row('gini', 'sqrt', 120, 4, 3, 'n_estimator')]) # try 3\n",
    "df = pd.concat([df, create_bar_row('gini', 'sqrt', 120, 30, 4, 'random_state')]) # try 4\n",
    "\n",
    "print(df)\n",
    "\n",
    "fig, axs = plt.subplots()\n",
    "axs.set_xlim([0.70,0.89])\n",
    "axs.set_title(\"Score sul testset durante il tuning dei parametri\")\n",
    "\n",
    "sns.barplot(data=df, x='Accuracy',y=\"Parameter_changed\",ax=axs, orient=\"h\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d2d23ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "column = ['criterion','max_features', 'n_estimators', 'random_state', 'accuracy']\n",
    "column_bar = ['try', 'Parameter_changed', 'Accuracy']\n",
    "\n",
    "### Create a single row equivalent to a single try for decision tree\n",
    "def create_bar_row(criterion,feature, stimatori,random, attempt, parameter):\n",
    "  xt = ExtraTreesClassifier(criterion=criterion,max_features=feature,n_estimators=stimatori, random_state=random, n_jobs=-1 )\n",
    "  xt.fit(train_data, np.ravel(y_train))\n",
    "  testset_score = xt.score(train_data, y_train)\n",
    "  row = pd.DataFrame(data=[[attempt, parameter, testset_score]], columns=column_bar)\n",
    "  return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dfcfe4d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  try Parameter_changed  Accuracy\n",
      "0   1             start  0.999991\n",
      "0   2      max_features  0.999991\n",
      "0   3       n_estimator  0.999991\n",
      "0   4      random_state  0.999991\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(columns=column_bar)\n",
    "df = pd.concat([df, create_bar_row('gini', 'log2', 20, 4, 1, 'start')]) # try 1\n",
    "df = pd.concat([df, create_bar_row('gini', 'sqrt', 20, 4, 2, 'max_features')]) # try 2\n",
    "df = pd.concat([df, create_bar_row('gini', 'sqrt', 120, 4, 3, 'n_estimator')]) # try 3\n",
    "df = pd.concat([df, create_bar_row('gini', 'sqrt', 120, 30, 4, 'random_state')]) # try 4\n",
    "\n",
    "print(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f57e65fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA44AAAIoCAYAAAAmxbXTAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAAClUklEQVR4nOzdd1xW5f/H8dfNkCkabnCFWlqOrK+pLSeu0kTDnbuszAma5RbNUWm7zDTIcJTiKEeiUtkvV6Y52pSWmuZGFJFxfn+cL/fXW0aK4LmB9/Px4NG5r3Odcz73DQd5d65zHZthGAYiIiIiIiIi2XCxugARERERERFxbgqOIiIiIiIikiMFRxEREREREcmRgqOIiIiIiIjkSMFRREREREREcqTgKCIiIiIiIjlScBQREREREZEcKTiKiIiIiIhIjhQcRUREREREJEcKjiJSaO3btw+bzYa7uzt///231eXIFb755hsmTZrE2bNn8/U4b7/9NpGRkVmu++uvv3jmmWe47bbb8PLywt/fnzp16vDEE0/w119/XfexfvjhByZNmsTBgwdvrOirHDx4EJvNlu37sIIz1pSdL774ApvNxhdffHHd20ZGRmKz2fL8e1oYvfjii6xcufK6ttHnK1KwKDiKSKH1/vvvA5CamsqHH35ocTVypW+++YbJkydbFhwPHz7M3XffTWxsLCNHjmTt2rUsWLCA7t27s3PnTn7//ffrPtYPP/zA5MmTi8QfwRUqVGDr1q08/PDDVpeSrx5++GG2bt1KhQoVrC7F6eUmOOrzFSlY3KwuQEQkPyQnJxMdHU29evU4efIkCxYs4LnnnrO6rCwlJSXh6emJzWazupQiY968eZw8eZIdO3Zw66232ts7duzICy+8QHp6uoXVOa+0tDRSU1Px8PCgUaNGebbflJQUbDYbbm7O9WdJmTJlKFOmjNVl2F28eBFvb2+ry7hhGb/znO3zFZGc6YqjiBRKK1eu5NSpUwwcOJA+ffrwyy+/8PXXX2fql5yczJQpU6hVqxaenp6UKlWKZs2a8c0339j7pKen88Ybb3DXXXfh5eVFyZIladSoEatXr7b3sdlsTJo0KdP+q1atSt++fe2vM4Zmbdiwgf79+1OmTBm8vb1JTk7mt99+o1+/ftSoUQNvb28CAwNp3749+/bty7Tfs2fPEhYWRlBQEB4eHpQtW5Z27drx008/YRgGNWrUoHXr1pm2S0xMpESJEgwePDjHz++TTz6hYcOGlChRAm9vb4KCgujfv3+m93H11bVrGRY4adIkRo0aBcCtt96KzWbLtM3SpUtp3LgxPj4++Pr60rp1a3bv3u2wn99//51u3boREBCAh4cH5cqVo0WLFuzZswcwP/sDBw7w5Zdf2o9RtWpVAE6dOoWLiwtly5bNskYXF8d/Hr/99ls6dOiAv78/np6e1K9fn48//tjh8wgNDQWgWbNm9uPlNJTzer7f/+bEiRMUK1aM8ePHZ1r3008/YbPZeP311+19n3nmGe644w58fX0pW7YszZs3Z8uWLQ7bZQxHnTVrFlOnTuXWW2/Fw8ODuLi4LIeqXuv7yfgZWbhwIWFhYQQGBuLh4cFvv/0GwMaNG2nRogV+fn54e3tz//33s2nTpmv6HH766SfatGmDt7c3pUuX5qmnnuL8+fNZ9r2W41zrUMpJkyZhs9nYvXs3nTp1ws/PjxIlStCrVy9OnDjh0Hfp0qW0atWKChUq4OXlRa1atRgzZgwXLlxw6Ne3b198fX3Zt28frVq1onjx4rRo0QKA2NhYHn30USpWrIinpyfVq1dn0KBBnDx5Msu69u7dS2hoKCVKlMDf35+RI0eSmprKzz//TJs2bShevDhVq1Zl1qxZmd5bQkIC4eHh3HrrrRQrVozAwECGDx/uUK/NZuPChQtERUXZf/abNm3q8Blm9TtPQ1VFChYFRxEplObPn4+Hhwc9e/akf//+2Gw25s+f79AnNTWVtm3bEhERwSOPPMKKFSuIjIzkvvvu488//7T369u3L8OGDaNBgwYsXbqUJUuW0KFDhxv6Y6d///64u7uzcOFCli1bhru7O0ePHqVUqVLMmDGD9evX89Zbb+Hm5kbDhg35+eef7dueP3+eBx54gLlz59KvXz8+/fRT3n33XW677Tb+/vtvbDYbQ4YMITY2ll9//dXhuB9++CEJCQk5BsetW7fStWtXgoKCWLJkCWvWrGHChAmkpqbm+v1eaeDAgQwZMgSAmJgYtm7dytatW7n77rsBc8hb9+7dueOOO/j4449ZuHAh58+f58EHH+SHH36w76ddu3bs2rWLWbNmERsbyzvvvEP9+vXtw19XrFhBUFAQ9evXtx9jxYoVADRu3Jj09HQ6derE559/TkJCQrb1xsXFcf/993P27FneffddVq1axV133UXXrl3twenhhx/mxRdfBOCtt96yHy+noZzX+v2+FmXKlOGRRx4hKioq09XSDz74gGLFitGzZ08ATp8+DcDEiRNZs2YNH3zwAUFBQTRt2jTLwP/666+zefNmXn75ZdatW0fNmjXz5P08//zz/Pnnn7z77rt8+umnlC1blo8++ohWrVrh5+dHVFQUH3/8Mf7+/rRu3fpfw+Px48dp0qQJ+/fv5+2332bhwoUkJiby7LPPZup7I8fJSUhICNWrV2fZsmVMmjSJlStX0rp1a1JSUux9fv31V9q1a8f8+fNZv349w4cP5+OPP6Z9+/aZ9nf58mU6dOhA8+bNWbVqFZMnTwYgPj6exo0b884777BhwwYmTJjA9u3beeCBBxyOlaFLly7Uq1eP5cuX88QTTzBnzhxGjBhBx44defjhh1mxYgXNmzfnueeeIyYmxr7dxYsXadKkCVFRUQwdOpR169bx3HPPERkZSYcOHTAMAzB/Z3h5edGuXTv7z/7bb7/tUENWv/NEpIAxREQKmYMHDxouLi5Gt27d7G1NmjQxfHx8jISEBHvbhx9+aADGvHnzst3XV199ZQDG2LFjczwmYEycODFTe5UqVYw+ffrYX3/wwQcGYPTu3ftf30dqaqpx+fJlo0aNGsaIESPs7VOmTDEAIzY2NtttExISjOLFixvDhg1zaL/jjjuMZs2a5Xjcl19+2QCMs2fPZtsn43388ccfDu1xcXEGYMTFxeV4jJdeeinL7f/880/Dzc3NGDJkiEP7+fPnjfLlyxtdunQxDMMwTp48aQDGq6++muNx7rzzTqNJkyaZ2tPT041BgwYZLi4uBmDYbDajVq1axogRIzLVVLNmTaN+/fpGSkqKQ/sjjzxiVKhQwUhLSzMMwzA++eSTa3rv2cnu+/3HH38YgPHBBx/kuP3q1asNwNiwYYPDPgMCAozOnTvneNyUlBSjRYsWRkhISKbjVqtWzbh8+bLDNtdSU3bvJ+Nn5KGHHnLof+HCBcPf399o3769Q3taWppRr1494957783x/T/33HOGzWYz9uzZ49AeHBzs8H25nuNk93N+tYkTJxqAw/s0DMOIjo42AOOjjz7Kcrv09HQjJSXF+PLLLw3A+P777+3r+vTpYwDGggULcjx2xj4OHTpkAMaqVasy1fXKK684bHPXXXcZgBETE2NvS0lJMcqUKWN06tTJ3jZ9+nTDxcXF2Llzp8P2y5YtMwBj7dq19jYfHx+H33UZcvqdd62fr4g4B11xFJFC54MPPiA9Pd1haGX//v25cOECS5cutbetW7cOT09Ph35XW7duHcC/Du28Xp07d87Ulpqayosvvsgdd9xBsWLFcHNzo1ixYvz666/8+OOPDjXddttttGzZMtv9Fy9enH79+hEZGWkfUrZ582Z++OGHLK/AXKlBgwaAeZXi448/5siRI7l5i7ny+eefk5qaSu/evUlNTbV/eXp60qRJE/sVMX9/f6pVq8ZLL73E7Nmz2b1793Xdl2iz2Xj33Xf5/fffefvtt+nXrx8pKSnMmTOHO++8ky+//BIwh1/+9NNP9qt1V9bUrl07/v777+u+OpjhWr/f16pt27aUL1+eDz74wN72+eefc/To0Uw/4++++y533303np6euLm54e7uzqZNm7I8bocOHa7p6tD1vp+rz4FvvvmG06dP06dPH4fPOT09nTZt2rBz585MwzmvFBcXx5133km9evUc2nv06JGnx8lJxs9Jhi5duuDm5kZcXJy97ffff6dHjx6UL18eV1dX3N3dadKkCcA1fU4A//zzD0899RSVKlWyf/+qVKmS7T4eeeQRh9e1atXCZrPRtm1be5ubmxvVq1fn0KFD9rbPPvuM2rVrc9dddzl8Vq1bt77umWqzeh8iUrAoOIpIoZKenk5kZCQBAQHcc889nD17lrNnz9KyZUt8fHwchqueOHGCgICATPezXenEiRO4urpSvnz5PK0zq1kER44cyfjx4+nYsSOffvop27dvZ+fOndSrV4+kpCSHmipWrPivxxgyZAjnz58nOjoagDfffJOKFSvy6KOP5rjdQw89xMqVK+0BrmLFitSuXZvFixdf57u8fsePHwfM8Oru7u7wtXTpUvs9XDabjU2bNtG6dWtmzZrF3XffTZkyZRg6dGi297RlpUqVKjz99NPMnz+fX3/9laVLl3Lp0iX7PZgZ9YSHh2eq55lnngHIdF/ZtbrW7/e1cnNz4/HHH2fFihX24bqRkZFUqFDB4X7X2bNn8/TTT9OwYUOWL1/Otm3b2LlzJ23atMnyuNc64+X1vp+r95vxWT/22GOZPuuZM2diGIZ9mG1WTp06leV5enXbjR4nJ1cfy83NjVKlSnHq1CnAvMf4wQcfZPv27UydOpUvvviCnTt32oeHXv05eXt74+fn59CWnp5Oq1atiImJYfTo0WzatIkdO3awbdu2LPcB5v9ouVKxYsXw9vbG09MzU/ulS5fsr48fP87evXszfU7FixfHMIzr+tnXzKkiBZ9zTV8mInKDNm7caP8/5qVKlcq0ftu2bfzwww/ccccdlClThq+//pr09PRsw2OZMmVIS0vj2LFjOf7h4+HhQXJycqb2jD8Yr5bVDKofffQRvXv3tt8rl+HkyZOULFnSoabDhw9nW0uG6tWr07ZtW9566y3atm3L6tWrmTx5Mq6urv+67aOPPsqjjz5KcnIy27ZtY/r06fTo0YOqVavSuHFj+x+cV7/n3IaoDKVLlwZg2bJl9iso2alSpYr9fwT88ssvfPzxx0yaNInLly/z7rvv5ur4Xbp0Yfr06ezfv9+hnueff55OnTpluc3tt9+eq2Nd6/f7evTr14+XXnqJJUuW0LVrV1avXs3w4cMdvucfffQRTZs25Z133nHYNrvAfa2z/V7v+7l6vxmf9RtvvJHtjK3lypXL9vilSpXi2LFjmdqvbrvR4+Tk2LFjBAYG2l+npqZy6tQp+++izZs3c/ToUb744gv7VUYg28fSZPXZ79+/n++//57IyEj69Oljb8+YXCgvlS5dGi8vLxYsWJDt+mulWaNFCj4FRxEpVObPn4+LiwsxMTGUKFHCYd3hw4d5/PHHWbBgAS+//DJt27Zl8eLFREZGZjtctW3btkyfPp133nmHKVOmZHvcqlWrsnfvXoe2zZs3k5iYeM2122w2PDw8HNrWrFnDkSNHqF69ukNNEyZMYPPmzTRv3jzHfQ4bNoxWrVrRp08fXF1deeKJJ665HjADcZMmTShZsiSff/45u3fvpnHjxvbZSffu3esQnK6cafbf9guZr460bt0aNzc34uPjr2to22233ca4ceNYvnw53333ncNxsroC8/fff2f5PwISExP566+/CAgIAMxQWKNGDb7//vtMgeha31N2rvX7fT1q1apFw4YN+eCDD0hLSyM5OZl+/fr963H37t3L1q1bqVSpUq6Om91+r+f93H///ZQsWfKahlNnpVmzZsyaNYvvv//eYbjqokWL8vQ4OYmOjuaee+6xv/74449JTU21zzCaEZ6u/pzmzp17zcfIi31cq0ceeYQXX3yRUqVKOTy2JivZnWsiUngoOIpIoXHq1ClWrVpF69atsx2OOWfOHD788EOmT59O9+7d+eCDD3jqqaf4+eefadasGenp6Wzfvp1atWrRrVs3HnzwQR5//HGmTp3K8ePHeeSRR/Dw8GD37t14e3vbZwd9/PHHGT9+PBMmTKBJkyb88MMPvPnmm5nCa04eeeQRIiMjqVmzJnXr1mXXrl289NJLmYalDh8+nKVLl/Loo48yZswY7r33XpKSkvjyyy955JFHaNasmb1vcHAwd9xxB3FxcfTq1Svbx09cacKECRw+fJgWLVpQsWJFzp49y2uvveZwL1aDBg24/fbbCQ8PJzU1lVtuuYUVK1Zk+ciTrNSpUweA1157jT59+uDu7s7tt99O1apVmTJlCmPHjuX333+nTZs23HLLLRw/fpwdO3bg4+PD5MmT2bt3L88++yyhoaHUqFGDYsWKsXnzZvbu3cuYMWMcjrNkyRKWLl1KUFAQnp6e1KlTh2nTpvF///d/dO3a1f6YlT/++IM333yTU6dO8dJLL9n3MXfuXNq2bUvr1q3p27cvgYGBnD59mh9//JHvvvuOTz75BIDatWsD8N5771G8eHE8PT259dZbs7zyDdf+/b5e/fv3Z9CgQRw9epT77rsv0xXRRx55hIiICCZOnEiTJk34+eefmTJlCrfeeusNzZx7o+/H19eXN954gz59+nD69Gkee+wxypYty4kTJ/j+++85ceJEpqukVxo+fDgLFizg4YcfZurUqZQrV47o6Gh++umnPD1OTmJiYnBzcyM4OJgDBw4wfvx46tWrR5cuXQC47777uOWWW3jqqaeYOHEi7u7uREdH8/3331/zMWrWrEm1atUYM2YMhmHg7+/Pp59+SmxsbK5qzsnw4cNZvnw5Dz30ECNGjKBu3bqkp6fz559/smHDBsLCwmjYsCFgnmtffPEFn376KRUqVKB48eK5vhovIk7K2rl5RETyzquvvmoAxsqVK7Pt8+677xqAsXz5csMwDCMpKcmYMGGCUaNGDaNYsWJGqVKljObNmxvffPONfZu0tDRjzpw5Ru3atY1ixYoZJUqUMBo3bmx8+umn9j7JycnG6NGjjUqVKhleXl5GkyZNjD179mQ7q+rVsxQahmGcOXPGGDBggFG2bFnD29vbeOCBB4wtW7YYTZo0yTQz6JkzZ4xhw4YZlStXNtzd3Y2yZcsaDz/8sPHTTz9l2u+kSZMMwNi2bds1fY6fffaZ0bZtWyMwMNAoVqyYUbZsWaNdu3bGli1bHPr98ssvRqtWrQw/Pz+jTJkyxpAhQ4w1a9Zc88yizz//vBEQEGCf2fTKbVauXGk0a9bM8PPzMzw8PIwqVaoYjz32mLFx40bDMAzj+PHjRt++fY2aNWsaPj4+hq+vr1G3bl1jzpw5Rmpqqn0/Bw8eNFq1amUUL17cAIwqVaoYhmEY27ZtMwYPHmzUq1fP8Pf3N1xdXY0yZcoYbdq0cZgpMsP3339vdOnSxShbtqzh7u5ulC9f3mjevLnx7rvvOvR79dVXjVtvvdVwdXX911lHr/X7fa2zqmY4d+6c4eXlle2MwcnJyUZ4eLgRGBhoeHp6GnfffbexcuVKo0+fPvbP58rjvvTSS5n2kVVN1/p+MmZV/eSTT7Ks/8svvzQefvhhw9/f33B3dzcCAwONhx9+ONv+V/rhhx+M4OBgw9PT0/D39zcGDBhgrFq1KsufyWs5zvXOqrpr1y6jffv2hq+vr1G8eHGje/fuxvHjxx36fvPNN0bjxo0Nb29vo0yZMsbAgQON7777LtPn2adPH8PHxyfH91m8eHHjlltuMUJDQ40///wz0+zOGXWdOHHCYfvs9t2kSRPjzjvvdGhLTEw0xo0bZ9x+++3233916tQxRowYYRw7dszeb8+ePcb9999veHt7G4D9e57T7zzNqipSsNgM478P4RERkULpP//5DzabjZ07d1pdikihNGnSJCZPnsyJEyeu674/EZGCRENVRUQKoYSEBPbv389nn33Grl277A++FxEREckNBUcRkULou+++o1mzZpQqVYqJEyfSsWNHq0sSERGRAkxDVUVERERERCRH2T/1WkRERERERAQFRxEREREREfkXCo4iIiIiIiKSI02O46TS09M5evQoxYsXx2azWV2OiIiIiIhYxDAMzp8/T0BAAC4u1lz7U3B0UkePHqVSpUpWlyEiIiIiIk7ir7/+omLFipYcW8HRSRUvXhwwfzj8/PwsrSUlJYUNGzbQqlUr3N3dLa1FRLKnc1WkYNC5KuL8nO08TUhIoFKlSvaMYAUFRyeVMTzVz8/PKYKjt7c3fn5+TnHiiEjWdK6KFAw6V0Wcn7Oep1bewqbJcURERERERCRHCo4iIiIiIiKSIwVHERERERERyZGCo4iIiIiIiORIwVFERERERERypOAoIiIiIiIiOVJwFBERERERkRwpOIqIiIiIiEiOFBxFREREREQkRwqOIiIiIiIikiMFRxEREREREcmRgqOIiIiIiIjkSMFRREREREREcqTgKCIiIiIikiEtDduXXxL41VfYvvwS0tKsrsgpKDiKiIiIiIgAxMRA1aq4BQfzn9mzcQsOhqpVzfYiTsFRREREREQkJgYeewwOH3ZsP3LEbC/i4VHBUUREREREira0NBg2DAwj87qMtuHDi/SwVQVHEREREREp2rZsyXyl8UqGAX/9ZfYrohQcRURERESkaNu169r6/f13/tbhxBQcRURERESkaIqPhz59YNSoa+tfoUL+1uPE3KwuQERERERE5KY6dAimToUPPvjffYuenpCcnPV9jjYbVKwIDz54c+t0IrriKCIiIiIiRcORI/DMM1CjBrz/vhka27SB7dshOtrsY7M5bpPx+tVXwdX1ppbrTBQcRURERESkcDt2zJwVtVo1eOcdSEmB5s3h669h3Tq4917o1AmWLYPAQMdtK1Y02zt1sqR0Z6GhqiIiIiIiUjidOAEvvQRvvglJSWbbAw9ARAQ0bZq5f6dO8OijpMbFsWfdOu5q2xa3Zs2K9JXGDAqOIiIiIiJSuJw+Da+8Aq+/DomJZlvDhmZgbNky83DUK7m6YjRpwpELF6jXpIlC438pOIqIiIiISOFw7px5L+Ls2ZCQYLbdfTdMmQLt2uUcGCVHCo4iIiIiIlKwJSbCG2+Yw1LPnDHb6tSByZOhY0cFxjyg4CgiIiIiIgXTxYvw9tswcyacPGm21axpBsbHHgMXzQWaVxQcRURERESkYLl0Cd57D6ZPN2dMBaheHSZOhO7ddV9iPlBwFBERERGRguHyZZg/H6ZNM5/JCFC1KowfD717g5viTX7RJysiIiIiIs4tJQU+/NCcFfXQIbOtYkUYNw769YNixaytrwhQcBQREREREeeUlgaLFpn3LMbHm23ly8MLL8ATT4Cnp7X1FSEKjiIiIiIi4lzS0+Hjj2HSJPj5Z7OtTBkYMwaeegq8vS0tryhScBQREREREedgGLBihTnJzf79Zpu/P4waBc8+C76+1tZXhCk4ioiIiIiItQwDPvvMDIy7d5ttJUrAyJEwfDj4+Vlanig4ioiIiIiIVQwDNmyACRNgxw6zzdfXDIsjR8Itt1hanvyPgqOIiIiIiNx8cXHmYzT+7//M197e5nDUUaOgdGlra5NMFBxFREREROTm+fpr8wpjXJz52sMDnnkGnnsOypWztjbJloKjiIiIiIjkvx07zCuMGzaYr93d4cknzUdrBARYW5v8KwVHERERERHJP7t3m1cYP/vMfO3mBv36wbhxULmytbXJNVNwFBERERGRvLdvnzlL6ooV5msXF+jd27zqGBRkbW1y3RQcRUREREQk7/z0E0yaBB9/bM6aarNB9+5miLztNqurk1xysbqArCQmJjJ8+HACAgLw9PTkrrvuYsmSJde0bVxcHMHBwZQtWxZfX1/q1q3L66+/TlpamkO/pk2bYrPZMn21adMm0z5/++03Hn/8cSpXroyXlxfVqlVj5MiRnDp1KlPf5cuXc//99+Pv70/JkiW59957WbhwYe4+CBERERGRguK338wrinfeCUuXmqHxscfMK4/R0QqNBZxTXnHs1KkTO3fuZMaMGdx2220sWrSI7t27k56eTo8ePbLdbuPGjbRu3ZqHHnqIefPm4ePjw+rVqxk2bBjx8fG89tprDv2DgoKIjo52aCtZsqTD6xMnTtCoUSP8/PyIiIigcuXK7N69m4kTJxIXF8euXbtwcTHz94IFCxgwYACdO3dm3Lhx2Gw2oqKi6N27NydPnmTEiBF58wGJiIiIiDiLgwchIgKioiDjYs2jj8LkyVCvnqWlSd5xuuC4du1aYmNj7WERoFmzZhw6dIhRo0bRtWtXXF1ds9w2MjISd3d3PvvsM3x8fABo2bIlP//8M5GRkZmCo5eXF40aNcqxnlWrVnHq1CmWLl1KixYt7PUkJyfzwgsv8P3331O/fn3ADI5VqlTh448/tofJ1q1bs2fPHiIjIxUcRURERKTwOHwYpk2D+fMhJcVsa9sWpkyB//zH2tokzzndUNUVK1bg6+tLaGioQ3u/fv04evQo27dvz3Zbd3d3ihUrhpeXl0N7yZIl8fT0zFU97u7uAJQoUSLTPgGH/bq7u+Pr62sPjQA2mw0/P79cH19ERERExKn8/TcMHQrVqsG775qhsWVL+OYbWLtWobGQcrrguH//fmrVqoWbm+PF0Lp169rXZ+epp57i8uXLDB06lKNHj3L27FkWLlzIihUrGD16dKb+8fHx+Pv74+bmRrVq1Rg7dixJSUkOfTp27EjlypUJCwvjwIEDJCYm8tVXXzFjxgzat29PrVq17H2HDBnCjz/+yLRp0zhx4gQnT57k5ZdfZteuXYSHh9/IxyIiIiIiYq0TJyA83AyMb7wBly/DQw/BF19AbCw0bmx1hZKPnG6o6qlTpwjKYnpef39/+/rsNGzYkM2bNxMaGspbb70FgKurK9OnTycsLMyh7wMPPEDXrl2pWbMmSUlJrFu3jlmzZvH1118TFxdnv2pYokQJtm3bRufOnaldu7Z9+9DQ0EyT3nTq1ImYmBj69OnDuHHjAHM4bFRUVKYrqFdLTk4mOTnZ/johIQGAlJQUUjIu/Vsk4/hW1yEiOdO5KlIw6FyVAuf0aVxmz8blrbewXbgAQHrDhqRPmoTRvLk5a2oh+3l2tvPUGepwuuAI5vDO3KzbtWsXISEhNGzYkLlz5+Lj48PmzZsZN24cly5dYvz48fa+U6dOddi2Xbt2VK1alfDwcFatWkVISAgAZ86c4dFHH+XixYtER0dTqVIl9u/fT0REBB06dGDNmjX2q6Pr16+nV69ehIaG0qVLF9zc3Fi9ejV9+/bl8uXL9OvXL9vap0+fzuTJkzO1b9iwAW9v72y3u5liY2OtLkFEroHOVZGCQeeqODu3xESqffop1VavxvW/o/LOVqvGjz168M/dd0NyMqxbZ3GV+ctZztOLFy9aXQI2wzAMq4u4UuPGjUlLS2PHjh0O7QcOHKB27drMnTuXJ598MsttGzVqxMWLF9m9e7fDBDoTJ05k6tSp/Prrr1lezcxw/Phxypcvz+jRo5k5cyYAY8aMYfbs2Rw6dIgKFSrY+8bFxdG8eXMiIyPp06cPhmEQGBhI/fr1WbNmjcN++/Tpw/Llyzl+/Lh90p6rZXXFsVKlSpw8eRI/P79sa74ZUlJSiI2NJTg42H7Pp4g4H52rIgWDzlVxeufP4/Lmm7jMmYPt7FkAjDp1SJs4EaN9e/MKYyHnbOdpQkICpUuX5ty5c5ZlA6e74linTh0WL15Mamqqw32O+/btA3AYLnq1PXv20L1790yzrjZo0ID09HR+/PHHHINjhisnt9mzZw+BgYEOoTFjn/C/ey6PHz/O33//zaBBgzLtr0GDBnz44YccPHiQO++8M8tjenh44OHhkand3d3dKX5YwblqEZHs6VwVKRh0rorTuXAB3n4bZs6EjNvDatWCyZOxde6Mm4vTTY+S75zlPHWGGpzuux8SEkJiYiLLly93aI+KiiIgIICGDRtmu21AQADffvstaRnPj/mvrVu3AlCxYsUcjx0VFQXg8IiOgIAADh8+zJEjR3Lc5y233IKnpyfbtm3LtN+tW7fi4uKSKXyKiIiIiFju0iV49VVz0pvRo83QWKMGREfDvn0QGgpFMDSKI6e74ti2bVuCg4N5+umnSUhIoHr16ixevJj169fz0Ucf2a8mDhgwgKioKOLj46lSpQoAI0aMYOjQobRv355Bgwbh7e3Npk2beOWVV2jZsiX1/vsA0i1btjBt2jRCQkIICgri0qVLrFu3jvfee4/mzZvTvn17ez2DBw8mOjqa4OBgxowZY7/HcerUqZQrV46ePXsC5hXDZ555htmzZ9O7d2/78yZXrlzJokWLGDBggH2CHxERERERyyUnm89gnDYNjh412269FSZOhJ49wc3pooJYyCl/GmJiYhg7diwTJkzg9OnT1KxZk8WLF9OtWzd7n7S0NNLS0rjyFs0hQ4YQGBjInDlzGDhwIElJSVStWpWJEycyYsQIe78KFSrg6upKREQEJ0+exGazUaNGDaZMmUJYWJjDUNV77rmHbdu2ERERwdixYzlx4gSBgYF06NCBCRMmULp0aXvfl156iVq1ajF37lx69epFeno61apV480338z2vkwRERERkZsqJQUiI2HqVPjzT7OtUiUYPx769gUnGBYpzsfpJscRU0JCAiVKlLD0BtgMKSkprF27lnbt2jnF+GoRyZrOVZGCQeeqWCY11Rx+OmUK/P672VahAowdCwMHQhbzbRRVznaeOkM2cMorjiIiIiIikkfS0mDpUpg8GX75xWwrWxaefx4GDQIvL2vrkwJBwVFEREREpDBKT4eYGPOexR9+MNtKlTInwBk8GLJ5TJxIVhQcRUREREQKE8OA1avNwPj992ZbyZIQFgbDhkHx4paWJwWTgqOIiIiISGFgGLB+PUyYAN9+a7YVLw4jRphfJUtaWp4UbAqOIiIiIiIFmWHA5s3mrKj/fdY43t4wdCiEh5vDU0VukIKjiIiIiEhB9dVXZmD86ivztaenef/i6NHmBDgieUTBUURERESkoNm2zQyMGzear4sVM2dIff558xEbInlMwVFEREREpKDYtcu8h3HtWvO1mxsMGGA+i7FSJWtrk0JNwVFERERExNnt3WsGxlWrzNeurtCnj3nVsWpVS0uTokHBUURERETEWf3wA0yaBJ98Yr622aBnTzNE1qhhaWlStCg4ioiIiIg4m19+gSlTYNEic9ZUgC5dzBBZq5alpUnRpOAoIiIiIuIs/vjDDIwLF0JamtkWEgKTJ0OdOtbWJkWagqOIiIiIiNX++gumToUFCyA11Wx7+GEzRN59t7W1iaDgKCIiIiJinaNH4cUXYd48uHzZbGvVyrzC2KiRtbWJXEHBUURERETkZvvnH5gxA955By5dMtuaNjWvMD74oKWliWRFwVFERERE5GY5dQpeegneeAMuXjTb7rsPIiKgeXNraxPJgYKjiIiIiEh+O3sWXnkFXn0VEhPNtgYNzMDYqpX5mA0RJ6bgKCIiIiKSXxIS4LXXzNB47pzZdtdd5pDURx5RYJQCQ8FRRERERCSvXbgAb74Js2bB6dNm2513mpPehISAi4u19YlcJwVHEREREZG8kpRkTngzYwacOGG23X47TJoEXbooMEqBpeAoIiIiInKjkpPNR2q8+CL8/bfZFhQEEydCjx7gpj+7pWDTT7CIiIiISG5dvgwffABTp8Lhw2Zb5cowfjz06QPu7tbWJ5JHFBxFRERERK5XaiosXGhOcnPwoNkWGAhjx8KAAVCsmKXlieQ1BUcRERERkWuVlgZLlpiT3Pz6q9lWrhw8/zwMGgSentbWJ5JPFBxFRERERP5NejosW2ZOcvPjj2Zb6dLw3HPwzDPg7W1peSL5TcFRRERERCQ7hgGrVpmT3Ozda7bdcguEh8OQIVC8uLX1idwkCo4iIiIiIlczDFi3DiZMgF27zDY/PxgxwvwqUcLa+kRuMgVHEREREZEMhgEbN5qBcds2s83HB4YNg7Aw8Pe3tj4Riyg4ioiIiIgAfPml+RiNLVvM115eMHgwjB4NZcpYW5uIxRQcRURERKRo++Yb8wrjpk3maw8Pc4bU55+H8uWtrU3ESSg4ioiIiEjRtHOnGRjXrzdfu7vDwIHwwgtQsaK1tYk4GQVHERERESla9uwxZ0ldvdp87eoKffvCuHFQtaqFhYk4LwVHERERESkaDhwwA+Py5eZrFxfo1cu8r7F6dWtrE3FyCo4iIiIiUrj9/DNMngxLlpizptps0LWrGSJr1rS6OpECQcFRRERERAqn+HiIiICFCyE93Wzr1MkMkbVrW1ubSAGj4CgiIiIihcuhQzB1KkRGQmqq2da+vRkY69e3tDSRgkrBUUREREQKhyNH4MUXYd48SEkx21q3hilT4N57ra1NpIBTcBQRERGRgu3YMZg5E955B5KTzbbmzc3AeP/91tYmUkgoOIqIiIhIwXTyJMyaBW++CUlJZtsDD5j3NTZtamlpIoWNgqOIiIiIFCxnzsArr8Brr0Fiotl2771mYAwONmdNFZE8peAoIiIiIgXDuXPw6qswezYkJJht9eubQ1IffliBUSQfKTiKiIiIiHNLTIQ33oCXXjKvNoL5OI0pU6BjRwVGkZtAwVFEREREnNPFi+aENzNnwokTZlvNmjBpEoSGgouLpeWJFCUKjiIiIiLiXC5dgvfeg+nTzRlTAapXh4kToXt3cHW1tj6RIkjBUUREREScw+XLsGABTJsGhw+bbVWqwIQJ0Ls3uOlPVxGr6OwTEREREWulpMCHH5qzoh46ZLYFBsK4cdC/PxQrZm19IqLgKCIiIiIWSUuDRYtg8mSIjzfbypeHF16AJ54AT09r6xMRO6e8ozgxMZHhw4cTEBCAp6cnd911F0uWLLmmbePi4ggODqZs2bL4+vpSt25dXn/9ddLS0hz6NW3aFJvNlumrTZs2mfb522+/8fjjj1O5cmW8vLyoVq0aI0eO5NSpU5n6GobBBx98wL333ouPjw9+fn7cfffdrFq1KncfhoiIiEhhk54OS5eaM6P27m2GxtKl4eWXzeUhQxQaRZyMU15x7NSpEzt37mTGjBncdtttLFq0iO7du5Oenk6PHj2y3W7jxo20bt2ahx56iHnz5uHj48Pq1asZNmwY8fHxvPbaaw79g4KCiI6OdmgrWbKkw+sTJ07QqFEj/Pz8iIiIoHLlyuzevZuJEycSFxfHrl27cLliRq+nn36ayMhIRowYwfTp00lNTWXfvn1cvHjxxj8YERERkYLMMGDFCnOSm/37zbZbboHRo+HZZ8HX19r6RCRbThcc165dS2xsrD0sAjRr1oxDhw4xatQounbtims2M2lFRkbi7u7OZ599ho+PDwAtW7bk559/JjIyMlNw9PLyolGjRjnWs2rVKk6dOsXSpUtp0aKFvZ7k5GReeOEFvv/+e+rXrw/AypUrmTt3LkuXLqVLly72fbRu3Tp3H4aIiIhIYWAYsGaNOcnN7t1mm58fhIXB8OHmsog4NacbqrpixQp8fX0JDQ11aO/Xrx9Hjx5l+/bt2W7r7u5OsWLF8PLycmgvWbIknrkc7uDu7g5AiRIlMu0TcNjva6+9RtWqVR1Co4iIiEiRZRiwYQM0bgzt25uh0dcXxo6FgwfNIKnQKFIgOF1w3L9/P7Vq1cLtqumW69ata1+fnaeeeorLly8zdOhQjh49ytmzZ1m4cCErVqxg9OjRmfrHx8fj7++Pm5sb1apVY+zYsSQlJTn06dixI5UrVyYsLIwDBw6QmJjIV199xYwZM2jfvj21atUCIDU1la1bt1K/fn1mz55NlSpVcHV1JSgoiJdffhnDMG70oxEREREpOOLi4KGHoHVr2L4dvLzMIal//AFTp5pDVEWkwHC6oaqnTp0iKCgoU7u/v799fXYaNmzI5s2bCQ0N5a233gLA1dWV6dOnExYW5tD3gQceoGvXrtSsWZOkpCTWrVvHrFmz+Prrr4mLi7Pft1iiRAm2bdtG586dqV27tn370NBQFi5caH998uRJkpOT2bRpEzt37mTatGlUrFiRTz75hFGjRnHmzBmmTZuWbe3JyckkJyfbXyckJACQkpJCSkpKttvdDBnHt7oOEcmZzlWRgqGwn6u2b77BZdIkXL74AgDDw4P0QYNIHzUKypUzOxXS9y6Fh7Odp85Qh9MFRwCbzZardbt27SIkJISGDRsyd+5cfHx82Lx5M+PGjePSpUuMHz/e3nfq1KkO27Zr146qVasSHh7OqlWrCAkJAeDMmTM8+uijXLx4kejoaCpVqsT+/fuJiIigQ4cOrFmzBjc3N9LT0wEz8H3++ef2eyebN2/OsWPHmD17Ns8//zy+2dz0PX36dCZPnpypfcOGDXh7e2f7nm+m2NhYq0sQkWugc1WkYChs52rJX36h5uLFlPvvPYzpbm4cCg7ml8ce41KpUrBrl8UVilw/ZzlPnWGiTZvhZGMoGzduTFpaGjt27HBoP3DgALVr12bu3Lk8+eSTWW7bqFEjLl68yO7dux0m0Jk4cSJTp07l119/zfJqZobjx49Tvnx5Ro8ezcyZMwEYM2YMs2fP5tChQ1SoUMHeNy4ujubNmxMZGUmfPn1ISkrCx8eH4sWLc+7cOYf9vvfeewwaNIjt27dz7733ZnnsrK44VqpUiZMnT+Jn8dj/lJQUYmNjCQ4Ott/zKSLOR+eqSMFQ6M7V3btxnTwZl7VrATDc3DD69CHt+eehcmWLixPJHWc7TxMSEihdujTnzp2zLBs43RXHOnXqsHjxYlJTUx3uc9y3bx+Aw3DRq+3Zs4fu3btnmnW1QYMGpKen8+OPP+YYHDNc+XiNPXv2EBgY6BAaM/YJ/7vn0svLixo1anDs2LFM+8vI5lfu92oeHh54eHhkand3d3eKH1ZwrlpEJHs6V0UKhgJ/ru7bZz5WY8UK87WLCzz+OLYJE7AFBTnfRBoiueAs56kz1OB053RISAiJiYksX77coT0qKoqAgAAaNmyY7bYBAQF8++23pKWlObRv3boVgIoVK+Z47KioKACHR3QEBARw+PBhjhw58q/77Ny5MwkJCXzzzTcOfdeuXYuvry933nlnjscXERERcXo//QTdukG9emZotNmgRw/44QeIjIRr+J/0IlLwON0Vx7Zt2xIcHMzTTz9NQkIC1atXZ/Hixaxfv56PPvrIfjVxwIABREVFER8fT5UqVQAYMWIEQ4cOpX379gwaNAhvb282bdrEK6+8QsuWLalXrx4AW7ZsYdq0aYSEhBAUFMSlS5dYt24d7733Hs2bN6d9+/b2egYPHkx0dDTBwcGMGTPGfo/j1KlTKVeuHD179rT3DQ8PJzo6mtDQUCIiIqhYsSLLli1j9erVvPzyy5keEyIiIiJSYPz2G0yZAtHR8N+5HXjsMZg0CfQ/x0UKPacLjgAxMTGMHTuWCRMmcPr0aWrWrMnixYvp1q2bvU9aWhppaWkOj7kYMmQIgYGBzJkzh4EDB5KUlETVqlWZOHEiI0aMsPerUKECrq6uREREcPLkSWw2GzVq1GDKlCmEhYU5DCm955572LZtGxEREYwdO5YTJ04QGBhIhw4dmDBhAqVLl7b39ff35+uvv2b06NGEh4dz4cIFatasyYIFC+jXr18+f2oiIiIi+eDgQYiIgKgoyBjV1aEDTJ4Md91lZWUichM53eQ4YkpISKBEiRKW3gCbISUlhbVr19KuXTunGF8tIlnTuSpSMBSYc/XwYZg2DebP/9/jM9q2NQPjf+d6ECmsnO08dYZs4JRXHEVERETEIn//DdOnw9y5cPmy2daihTlM9b77rK1NRCyj4CgiIiIicOIEzJwJb78NSUlm24MPmsNUmzSxtjYRsZyCo4iIiEhRdvo0vPwyvP46XLhgtjVqZAbGFi3MWVNFpMhTcBQREREpis6ehTlzzK/z5822e+4xh6S2bavAKCIOFBxFREREipLz582riy+/bIZHgLp1zUlvHn1UgVFEsqTgKCIiIlIUXLhg3r84cyacOmW21aplBsbOneGKx5GJiFxNwVFERESkMLt0Cd59F2bMgOPHzbYaNWDiROjWDVxdra1PRAoEBUcRERGRwig52XwG47RpcPSo2XbrrTBhAvTqBW76M1BErp1+Y4iIiIgUJikpEBkJU6fCn3+abZUqwbhx0LcvFCtmZXUiUkApOIqIiIgUBqmpEB1tzor6++9mW4UK8MIL8MQT4OFhbX0iUqApOIqIiIgUZGlp8PHHMGkS/PKL2Va2LIwZA089BV5elpYnIoWDgqOIiIhIQZSeDjExZmA8cMBs8/eH0aPh2WfBx8fS8kSkcFFwFBERESlIDAM+/dSc5Ob77822EiUgLAyGDQM/P2vrE5FCScFRREREpCAwDPj8czMw7txpthUvDsOHw8iRULKkldWJSCGn4CgiIiLizAwDNm82A+M335ht3t4wZAiMGgWlSllbn4gUCQqOIiIiIs5qyxYYPx6+/NJ87ekJzzxj3sdYrpy1tYlIkaLgKCIiIuJstm0zrzDGxpqvixWDJ5+E55+HgABraxORIknBUURERMRZ7NplBsa1a83Xbm7Qvz+MHQuVK1tbm4gUaQqOIiIiIjdLWhq2L78k8KuvsPn4QLNm4OoKe/fCxImwcqXZz9UVevc2h6neequlJYuIgIKjiIiIyM0REwPDhuF2+DD/AZg927xPMSgItm41+9hs0KOHGSJr1LCyWhERBwqOIiIiIvktJgYee8ycIfVKx4+bXwChoTBpEtxxx00vT0Tk3yg4ioiIiOSntDQYNixzaLxSuXKweLE5RFVExAm5WF2AiIiISKG2ZQscPpxzn+PHzX4iIk5KwVFEREQkP/39d972ExGxgIKjiIiISH6qUCFv+4mIWEDBUURERCQ/lS9vzpaaHZsNKlWCBx+8eTWJiFwnBUcRERGR/HLhgjlbasbEOFcHyIzXr76qiXFExKkpOIqIiIjkB8OAJ5+E/fvNq47vvw+BgY59KlaEZcugUydrahQRuUZ6HIeIiIhIfnjjDVi0CNzc4JNP4IEHoG9fUuPi2LNuHXe1bYtbs2a60igiBYKCo4iIiEhe+/prCAszl19+2QyNAK6uGE2acOTCBeo1aaLQKCIFhoaqioiIiOSlv/8272tMTYVu3WDoUKsrEhG5YQqOIiIiInklJQW6doVjx6B2bfO+xpxmVBURKSAUHEVERETyyujRsGUL+PlBTAz4+FhdkYhInlBwFBEREckLixebj9UA+PBDqFHD0nJERPKSgqOIiIjIjdq/HwYONJdfeAEefdTaekRE8piCo4iIiMiNOHfOfA7jxYsQHAxTplhdkYhInlNwFBEREcmt9HTo0wd+/RUqVzaf26hHbIhIIaTgKCIiIpJbM2fCqlXg4QHLl0Pp0lZXJCKSLxQcRURERHIjNhbGjTOX33oL/vMfa+sREclHCo4iIiIi1+vQIeje3RyqOnAgDBhgdUUiIvlKwVFERETkely6BI89BqdOmVcZ33jD6opERPKdgqOIiIjI9RgyBL79FkqVgmXLwNPT6opERPKdgqOIiIjItXr/ffPLxQUWL4YqVayuSETkplBwFBEREbkW334Lzz5rLk+daj6zUUSkiFBwFBEREfk3J09C586QnAyPPgrPPWd1RSIiN5WCo4iIiEhO0tKgRw/480+oUQOiosyhqiIiRYh+64mIiIjkZMIE85mN3t4QEwMlSlhdkYjITeeUwTExMZHhw4cTEBCAp6cnd911F0uWLLmmbePi4ggODqZs2bL4+vpSt25dXn/9ddLS0hz6NW3aFJvNlumrTZs2mfb522+/8fjjj1O5cmW8vLyoVq0aI0eO5NSpUznW0qtXL2w2G4888si1v3kRERFxHqtWwYsvmsvz50Pt2tbWIyJiETerC8hKp06d2LlzJzNmzOC2225j0aJFdO/enfT0dHr06JHtdhs3bqR169Y89NBDzJs3Dx8fH1avXs2wYcOIj4/ntddec+gfFBREdHS0Q1vJkiUdXp84cYJGjRrh5+dHREQElStXZvfu3UycOJG4uDh27dqFSxbDVdasWcPKlSvx8/PL/QchIiIi1vnlF+jd21wePhy6dbO0HBERKzldcFy7di2xsbH2sAjQrFkzDh06xKhRo+jatSuurq5ZbhsZGYm7uzufffYZPj4+ALRs2ZKff/6ZyMjITMHRy8uLRo0a5VjPqlWrOHXqFEuXLqVFixb2epKTk3nhhRf4/vvvqV+/vsM2586dY9CgQURERGQ6poiIiBQAFy5Ap06QkAAPPgizZlldkYiIpZxuqOqKFSvw9fUlNDTUob1fv34cPXqU7du3Z7utu7s7xYoVw8vLy6G9ZMmSeOby4bzu7u4AlLjqfoaMK5NZ7TcsLIwKFSowdOjQXB1TRERELGQYMHAgHDgAFSrAxx/Df/8eEBEpqpwuOO7fv59atWrh5uZ4MbRu3br29dl56qmnuHz5MkOHDuXo0aOcPXuWhQsXsmLFCkaPHp2pf3x8PP7+/ri5uVGtWjXGjh1LUlKSQ5+OHTtSuXJlwsLCOHDgAImJiXz11VfMmDGD9u3bU6tWLYf+Gzdu5MMPP+T999/P9sqoiIiIOLHXX4clS8DNzQyN5ctbXZGIiOWcbqjqqVOnCAoKytTu7+9vX5+dhg0bsnnzZkJDQ3nrrbcAcHV1Zfr06YSFhTn0feCBB+jatSs1a9YkKSmJdevWMWvWLL7++mvi4uLs9y2WKFGCbdu20blzZ2pfcUN8aGgoCxcudNhnYmIiTzzxBOHh4dSrV++63ndycjLJycn21wkJCQCkpKSQkpJyXfvKaxnHt7oOEcmZzlWRG2f7+mtcw8OxAWmzZpHesCHk8Tmlc1XE+TnbeeoMdThdcASw2Wy5Wrdr1y5CQkJo2LAhc+fOxcfHh82bNzNu3DguXbrE+PHj7X2nTp3qsG27du2oWrUq4eHhrFq1ipCQEADOnDnDo48+ysWLF4mOjqZSpUrs37+fiIgIOnTowJo1a+xXR8eMGYO7uzsTJky47vc8ffp0Jk+enKl9w4YNeHt7X/f+8kNsbKzVJYjINdC5KpI7HqdP0zQsDLfUVP566CG+u/VWWLs2346nc1XE+TnLeXrx4kWrS3C+4FiqVKksryqePn0a+N+Vx6wMHjyYcuXKsWLFCvsw0WbNmuHi4sKkSZPo2bNnllczM/Tq1Yvw8HC2bdtmD44zZ85kz549HDp0iAoVKgDw4IMPUrNmTZo3b050dDR9+vRhx44dvP3228TExHDp0iUuXboEQHp6OqmpqZw9exYvLy88PDyyPPbzzz/PyJEj7a8TEhKoVKkSrVq1snxm1pSUFGJjYwkODrbf8ykizkfnqsgNSEnBNTgYlzNnMGrXpvyqVbT770R7eX8onasizs7ZztOM0YhWcrrgWKdOHRYvXkxqaqrDfY779u0DcBguerU9e/bQvXv3TPcWNmjQgPT0dH788cccg2OGKx+vsWfPHgIDA+2h8cp9wv/uufzhhx8wDMMeOK/0119/ccsttzBnzhyGDx+e5TE9PDyyDJXu7u5O8cMKzlWLiGRP56pILoSHwzffQIkS2FaswP2qx3PlB52rIs7PWc5TZ6jB6SbHCQkJITExkeXLlzu0R0VFERAQQMOGDbPdNiAggG+//Za0tDSH9q1btwJQsWLFHI8dFRUF4PCIjoCAAA4fPsyRI0dy3GebNm2Ii4vL9FWuXDkaNWpEXFwcjz32WI7HFxEREQssWmROiAPw4YdQvbq19YiIOCGnu+LYtm1bgoODefrpp0lISKB69eosXryY9evX89FHH9mvJg4YMICoqCji4+OpUqUKACNGjGDo0KG0b9+eQYMG4e3tzaZNm3jllVdo2bKlfcKaLVu2MG3aNEJCQggKCuLSpUusW7eO9957j+bNm9O+fXt7PYMHDyY6Oprg4GDGjBljv8dx6tSplCtXjp49ewJQvnx5ymcx65qnpyelSpWiadOm+fzJiYiIyHXbtw+eeMJcHjsWOnSwth4RESfldMERICYmhrFjxzJhwgROnz5NzZo1Wbx4Md26dbP3SUtLIy0tDcMw7G1DhgwhMDCQOXPmMHDgQJKSkqhatSoTJ05kxIgR9n4VKlTA1dWViIgITp48ic1mo0aNGkyZMoWwsDCHoar33HMP27ZtIyIigrFjx3LixAkCAwPp0KEDEyZMoHTp0jfnQxEREZG8dfYsdOoEFy9Cq1aQxSR1IiJishlXJi9xGgkJCZQoUYJz5845xeQ4a9eupV27dk4xvlpEsqZzVeQ6pKdDx47w6adQpQrs2gWlSt2UQ+tcFXF+znaeOkM2cLp7HEVERETy3fTpZmj08IDly29aaBQRKagUHEVERKRo2bABMp7t/PbbcM891tYjIlIAKDiKiIhI0XHwIHTvDoZhTorTv7/VFYmIFAgKjiIiIlI0XLoEjz0Gp09DgwbwxhtWVyQiUmAoOIqIiEjR8Oyz5iQ4pUvDsmXm/Y0iInJNFBxFRESk8Js3D+bPBxcXWLIEKle2uiIRkQJFwVFEREQKt507zauNANOmQYsW1tYjIlIAKTiKiIhI4XXyJHTuDJcvm89tfO45qysSESmQFBxFRESkcEpLM2dQ/esvuO02iIwEm83qqkRECiQFRxERESmcxo+HjRvBxwdiYqBECasrEhEpsBQcRUREpPBZuRKmTzeX58+HO++0tBwRkYIuV8Hx5MmTeV2HiIiISN745Rfo3dtcHjECuna1th4RkUIgV8GxYsWKdO3aldjY2LyuR0RERCT3EhOhUyc4fx4eeghmzrS6IhGRQiFXwbFu3bp88skntGnThltvvZWpU6dy5MiRvK5NRERE5NoZBgwcCAcOQIUKsHQpuLtbXZWISKGQq+C4Y8cO9u7dy7PPPsv58+eZMGECVatWpUOHDqxevZr09PS8rlNEREQkZ6+9ZoZFNzdYtgzKl7e6IhGRQiPXk+PUrl2b1157jaNHj7Jo0SKaNGnCmjVrCAkJoVKlSowdO5bff/89L2sVERERydpXX0F4uLk8Zw7cd5+19YiIFDI3PKtqsWLF6NatGxs3biQ+Pp6xY8eSlpbGjBkzuO222wgODmb58uUYhpEX9YqIiIg4OnoUunQxn9vYsycMHmx1RSIihU6ePY7DMAz279/P3r17OXXqFIZhUKFCBb788ku6dOnCXXfdxa+//ppXhxMRERGBy5chNBSOH4e6deG998Bms7oqEZFC54aD4x9//MG4ceOoVKkSjz76KOvWraNjx45s2LCBv/76i0OHDhEWFsYPP/zA008/nRc1i4iIiJjCw+Gbb6BECVi+HLy9ra5IRKRQcsvNRikpKSxfvpz333+fL774gvT0dG699VamTZtG//79KVu2rL1vhQoVmDVrFufPn2fhwoV5VriIiIgUcdHR8MYb5vJHH0H16tbWIyJSiOUqOAYEBHD69GlcXV3p2LEjgwYNIjg4OMdtqlSpwsWLF3NVpIiIiIiDvXvhiSfM5fHj4ZFHrK1HRKSQy1Vw9PX1ZeTIkfTv359y5cpd0zbPPPMM3bt3z83hRERERP7n7Fno1AmSkqB1a5g40eqKREQKvVwFx99//x3bdd547ufnh5+fX24OJyIiImJKT4fevSE+HqpWhUWLwNXV6qpERAq9XE2Ok5CQwN69e7MdenrhwgX27t1LQkLCDRUnIiIi4uDFF+HTT8HDw5wMx9/f6opERIqEXAXHKVOmcN9995GWlpbl+rS0NO6//36mTZt2Q8WJiIiI2H3+OUyYYC6/8w7cfbe19YiIFCG5Co7r16+nVatWFC9ePMv1fn5+tG7dmrVr195QcSIiIiIAHDwIPXqAYcCgQdCvn9UViYgUKbkKjn/++Sc1atTIsU+1atX4888/c1WUiIiIiF1SEnTuDKdPw733wmuvWV2RiEiRk6vgaLPZSE5OzrFPcnJytkNZRURERK6JYcDgwfDdd1C6NCxbZt7fKCIiN1WugmOtWrVYv349hmFkuT49PZ1169Zx++2331BxIiIiUsTNmwcffAAuLrBkCVSqZHVFIiJFUq6CY48ePfjll1/o378/586dc1h37tw5+vfvz2+//UavXr3ypEgREREpgnbsgCFDzOUXX4QWLaytR0SkCMvVcxyfeeYZYmJiiIqKYtWqVTRo0IDAwECOHDnCzp07OXv2LA899BDPPvtsXtcrIiIiRcGJE/DYY3D5MoSEwOjRVlckIlKk5eqKo7u7Oxs2bCA8PJz09HRiY2OJjIwkNjaW9PR0Ro0axeeff467u3te1ysiIiKFXWoqdOsGf/0Ft98OkZFgs1ldlYhIkZarK44AHh4ezJo1ixkzZvDTTz9x9uxZSpYsye23346rq2te1igiIiJFybhxsHkz+PhATAz4+VldkYhIkZfr4JjBxcWFO+64Iy9qERERkaIuJgZmzjSXFywA/Y0hIuIUcjVUVURERCTP/fwz9O1rLo8cCV26WFqOiIj8T66vOJ4/f54333yTjRs3cvTo0Syf62iz2YiPj7+hAkVERKQISEyETp3g/Hlo0uR/Vx1FRMQp5Co4njhxgvvuu4/4+Hj8/PxISEigRIkSXL58maSkJAACAgI0OY6IiIj8O8OAAQPghx8gIACWLgW3G76bRkRE8lCuhqpOmjSJ+Ph4PvzwQ86cOQPAiBEjuHDhAtu3b+fee++latWqHDhwIE+LFRERkUJozhz4+GNwd4dly6BcOasrEhGRq+QqOK5du5YWLVrQq1cvbFdNj92gQQPWrVvHwYMHmTRpUl7UKCIiIoXVl1/+7xmNc+ZA48bW1iMiIlnKVXD8+++/qV+/vv21q6urfYgqwC233ELbtm355JNPbrxCERERKZyOHDEnwElLg1694JlnrK5IRESykavgWKJECVJSUuyvb7nlFg4fPuzQx8/Pj+PHj99YdSIiIlI4Xb4MoaHwzz9Qty7MnQtXjWISERHnkavgGBQUxMGDB+2v69evT2xsLKdPnwYgKSmJTz/9lMqVK+dJkSIiIlLIhIXB1q1QsqT57EZvb6srEhGRHOQqOLZq1YpNmzZx8eJFAAYNGsQ///xDvXr1CA0NpXbt2sTHx9M341lMIiIiIhk++gjefPN/y9WqWVuPiIj8q1wFx6eeeop58+bZg2OnTp146aWXSExMZPny5Rw7doyRI0cyatSoPC1WRERECrjvv4cnnzSXJ0yAhx+2th4REbkmuXpIUoUKFejatatDW1hYGMOHD+fkyZOULVs202yrIiIiUsSdOQOdOkFSErRpYwZHEREpEHJ1xbF///68+uqrmdpdXV0pV66cQqOIiIg4Sk+H3r3h99+halWIjgZXV6urEhGRa5Sr4Lho0SLNmCoiIiLXbto0+Owz8PQ0J8Px97e6IhERuQ65Co7Vq1fn77//zuta7BITExk+fDgBAQF4enpy1113sWTJkmvaNi4ujuDgYMqWLYuvry9169bl9ddfJy0tzaFf06ZNsdlsmb7atGmTaZ+//fYbjz/+OJUrV8bLy4tq1aoxcuRITp065dDv/fffp2PHjlStWhUvLy+qV6/O008/na+flYiIiNNbtw4mTjSX330XrngWtIiIFAy5usdxwIABvPjiixw5coTAwMC8rolOnTqxc+dOZsyYwW233caiRYvo3r076enp9OjRI9vtNm7cSOvWrXnooYeYN28ePj4+rF69mmHDhhEfH89rr73m0D8oKIjo6GiHtpIlSzq8PnHiBI0aNcLPz4+IiAgqV67M7t27mThxInFxcezatQsXFzN/T5w4kWbNmvHiiy8SGBjIzz//TEREBKtWrWL37t2UK1cubz4gERGRguKPP6BnTzAMeOop6NPH6opERCQXchUcQ0JC2LRpE/fddx+jR4+mQYMG2d7beL3Pcly7di2xsbH2sAjQrFkzDh06xKhRo+jatSuu2dwTERkZibu7O5999hk+Pj4AtGzZkp9//pnIyMhMwdHLy4tGjRrlWM+qVas4deoUS5cupUWLFvZ6kpOTeeGFF/j++++p/9//c7p7927Kli1r37ZJkybcfffdNGjQgHnz5jFu3Ljr+ixEREQKtKQk6NzZnBSnYUPIYn4EEREpGHIVHIOCgrDZbBiGwdChQ7PtZ7PZSE1Nva59r1ixAl9fX0JDQx3a+/XrR48ePdi+fTv33Xdfltu6u7tTrFgxvLy8HNpLliyJp6fnddVx5T4BSpQokWmfgMN+rwyNGe655x5cXV3566+/cnV8ERGRAskw4JlnYPduKFMGli0DDw+rqxIRkVzKVXDs3bt3vs2cun//fmrVqoWbm2NpdevWta/PLjg+9dRTLF68mKFDh/LCCy/g7e3Np59+yooVK5g+fXqm/vHx8fj7+5OQkECVKlXo1q0b48aNcwieHTt2pHLlyoSFhfH2229TpUoVvvvuO2bMmEH79u2pVatWju/nyy+/JC0tjTvvvPN6PwoREZGC6733IDISXFxgyRKoWNHqikRE5AbkKjhGRkbmcRn/c+rUKYKCgjK1+/939rWrJ6S5UsOGDdm8eTOhoaG89dZbgPmIkOnTpxMWFubQ94EHHqBr167UrFmTpKQk1q1bx6xZs/j666+Ji4uz37dYokQJtm3bRufOnaldu7Z9+9DQUBYuXJjjezl//jzPPPMMlSpVon///jn2TU5OJjk52f46ISEBgJSUFFJSUnLcNr9lHN/qOkQkZzpXxVnYduzAdcgQbEDatGmkP/gg6OfSTueqiPNztvPUGerIVXDMbzldzcxp3a5duwgJCaFhw4bMnTsXHx8fNm/ezLhx47h06RLjx4+39506darDtu3ataNq1aqEh4ezatUqQkJCADhz5gyPPvooFy9eJDo6mkqVKrF//34iIiLo0KEDa9asyXR1FODSpUt06tSJQ4cOsXnzZnx9fXN8z9OnT2fy5MmZ2jds2IC3t3eO294ssbGxVpcgItdA56pYqdjZszQNC8MtJYWjjRuzs2ZNWLvW6rKcks5VEefnLOfpxYsXrS4Bm2EYhtVFXKlx48akpaWxY8cOh/YDBw5Qu3Zt5s6dy5NPPpnlto0aNeLixYvs3r3bYQKdiRMnMnXqVH799dcsr2ZmOH78OOXLl2f06NHMnDkTgDFjxjB79mwOHTpEhQoV7H3j4uJo3rw5kZGR9Llqhrjk5GQ6duzIF198wWeffWafVCcnWV1xrFSpEidPnsTPz+9ft89PKSkpxMbGEhwcbL/nU0Scj85VsVxqKq7t2uHyxRcYt99O6jffQPHiVlfldHSuijg/ZztPExISKF26NOfOnbMsG+R6cpxrYbPZiI+Pv65916lTh8WLF5OamupwJW/fvn0ADsNFr7Znzx66d++eadbVBg0akJ6ezo8//nhNtWcMU83YZ2BgoENozNgnmPdcXikjNMbFxbFq1aprCo0AHh4eeGQxaYC7u7tT/LCCc9UiItnTuSqWGTcOvvgCfH2xrViB+39vM5Gs6VwVcX7Ocp46Qw0u/94ls/T0dAzDyPR19uxZDh48yMGDB0lOTiY9Pf269x0SEkJiYiLLly93aI+KiiIgIICGDRtmu21AQADffvstaWlpDu1bt24FoOK/3JgfFRUF4PCIjoCAAA4fPsyRI0f+dZ/JycmEhISwefNmli9fTuvWrXM8noiISKGxfDnMmmUuL1gA/zJ5nIiIFCy5uuJ48ODBHNeNHDmS48eP52pMcNu2bQkODubpp58mISGB6tWrs3jxYtavX89HH31kv5o4YMAAoqKiiI+Pp0qVKgCMGDGCoUOH0r59ewYNGoS3tzebNm3ilVdeoWXLltSrVw+ALVu2MG3aNEJCQggKCuLSpUusW7eO9957j+bNm9O+fXt7PYMHDyY6Oprg4GDGjBljv8dx6tSplCtXjp49e9r7PvbYY6xbt46xY8dSqlQptm3bZl/n5+fHHXfccd2fh4iIiNP76Sfo29dcDg+Hqx6pJSIihYCRDy5fvmzUqlXLGD58eK62P3/+vDF06FCjfPnyRrFixYy6desaixcvdujTp08fAzD++OMPh/bly5cbDzzwgFG6dGnDx8fHuPPOO42IiAgjMTHR3ufXX3812rVrZwQGBhoeHh6Gp6enUadOHWPatGnGpUuXMtXz3XffGSEhIUbFihUNDw8PIygoyBg4cKDx559/OvQDsv1q0qTJdX0G586dMwDj3Llz17Vdfrh8+bKxcuVK4/Lly1aXIiI50LkqlkhIMIxatQwDDKNpU8NISbG6Iqenc1XE+TnbeeoM2SDfJscZNmwYy5YtyzTEU65NQkICJUqUsPQG2AwpKSmsXbuWdu3aOcX4ahHJms5VuekMA7p0gWXLIDAQdu2CcuWsrsrp6VwVcX7Odp46QzbI1T2O1+LixYucPn06v3YvIiIiVps92wyN7u7wyScKjSIihVi+BMevvvqKxYsXc/vtt+fH7kVERMRqX3wBzz1nLr/6KjRubGU1IiKSz3I1OU7z5s2zbE9NTeXIkSMcPHgQwzAYN27cDRUnIiIiTujwYejaFdLSoHdvePppqysSEZF8lqvg+MUXX2TZbrPZuOWWWwgODmbEiBF6HIWIiEhhc/myOWvqP/9AvXrwzjtgs1ldlYiI5LNcBcfcPJ9RRERECoERI2DbNihZEmJiwNvb6opEROQmyLfJcURERKSQ+fBDePttczk6GoKCrK1HRERumlwFx3PnzrF3714uXryY5foLFy6wd+9eEhISbqg4ERERcRJ79sCgQebyxInQrp2l5YiIyM2Vq+A4ZcoU7rvvPtLS0rJcn5aWxv3338+0adNuqDgRERFxAmfOQOfOcOmSGRgnTLC6IhERuclyFRzXr19Pq1atKF68eJbr/fz8aN26NWvXrr2h4kRERMRi6enQqxf8/jvceissXAguutNFRKSoydVv/j///JMaNWrk2KdatWr8+eefuSpKREREnEREBKxdC56e5mQ4/v5WVyQiIhbIVXC02WwkJyfn2Cc5OTnboawiIiJSAKxdC5Mnm8tz58Jdd1lajoiIWCdXwbFWrVqsX78ewzCyXJ+ens66deu4/fbbb6g4ERERscjvv0PPnmAY8PTT0Lu31RWJiIiFchUce/TowS+//EL//v05d+6cw7pz587Rv39/fvvtN3r16pUnRYqIiMhNdPGiORnO2bPQqBG8+qrVFYmIiMXccrPRM888Q0xMDFFRUaxatYoGDRoQGBjIkSNH2LlzJ2fPnuWhhx7i2Wefzet6RUREJD9lXGHcswfKloVPPoFixayuSkRELJarK47u7u5s2LCB8PBw0tPTiY2NJTIyktjYWNLT0xk1ahSff/457u7ueV2viIiI5Kd334UPPwRXV1i6FCpWtLoiERFxArm64gjg4eHBrFmzmDFjBj/99BNnz56lZMmS3H777bi6uuZljSIiInIzbNsGw4aZyzNmQNOmlpYjIiLOI9fBMYOLiwt33HFHXtQiIiIiVvnnH3jsMUhJMf8bFmZ1RSIi4kRyNVT1hx9+4PXXX+fEiRNZrv/nn394/fXX+fHHH2+oOBEREbkJUlOha1c4cgRq1oQFC8Bms7oqERFxIrkKjjNmzGDmzJmUKlUqy/WlSpXipZdeYtasWTdUnIiIiNwEL7wAX3wBvr6wYgUUL251RSIi4mRyFRy3bNlCixYtcHHJenNXV1datGjBV199dUPFiYiISD5btgxeeslcjow0rziKiIhcJVfB8dixY1SqVCnHPoGBgfz999+5KkpERERugh9/hH79zOVRo8xnN4qIiGQhV8HRx8eHf/75J8c+//zzD56enrkqSkRERPLZ+fPQqRMkJkKzZvDii1ZXJCIiTixXwfGee+5h5cqVnD17Nsv1Z86cYcWKFdx99903UpuIiIjkB8MwrzT+9BMEBsKSJeB2wxOti4hIIZar4Dh48GBOnTpFs2bNMt3H+OWXX9KsWTPOnDnDs88+mydFioiISB565RVYvhzc3c17HMuWtboiERFxcrn634sdOnQgPDycl19+mWbNmuHh4UH58uU5duwYycnJGIZBeHg4HTt2zONyRURE5IbExcFzz5nLr78OjRpZW4+IiBQIubriCDBr1iw+++wz2rRpg6+vL4cPH8bX15e2bduyZs0aZs2aRWpqal7WKiIiIjfi8GHzeY3p6dCnDwwaZHVFIiJSQNzQDQ3t2rWjXbt2mdp/+OEHwsLCiI6O5tixYzdyCBEREckLycnw2GNw4gTcdRe88w7YbFZXJSIiBUSe3QmfmJjIkiVLmD9/Pjt27MAwDIoVK5ZXuxcREZEbMWIEbN8Ot9xi3t/o5WV1RSIiUoDccHD8+uuvWbBgAZ988gkXL17EMAzq169Pv3796NGjR17UKCIiIjciKup/VxijoyEoyOqKRESkgMlVcDx+/DhRUVEsWLCAX3/9FcMwKF++PBcuXKB3795ERkbmcZkiIiKSK7t3w1NPmcuTJkHbtpaWIyIiBdM1B8f09HTWrFnD/PnzWbt2LampqXh6etKlSxd69+5Nq1atcHd31/BUERERZ3H6NHTuDJcuwcMPw7hxVlckIiIF1DUHx4oVK3L8+HEA7r//fnr37k2XLl3w8/PLt+JEREQkl9LToVcv+OMPc2jqwoXgkuvJ1EVEpIi75uB47NgxXFxcCAsL4/nnn6dkyZL5WJaIiIjckClTYN068PSEmBhzUhwREZFcuub/9dirVy88PT15+eWXqVChAqGhoaxevVrPahQREXE2a9bA5Mnm8nvvQb161tYjIiIF3jUHxw8//JC///6bt99+mzp16rB8+XJCQkIoX748zz77LNu2bcvPOkVERORaxMebQ1QBBg+Gxx+3th4RESkUrutmh+LFizNo0CB27NjB3r17GTJkCDabjbfffpv7778fm83Gzz//zJ9//plf9YqIiEh2Ll40J8M5exYaN4bZs62uSEREColc3yVfu3ZtXn31VY4ePcqSJUsIDg7GZrOxZcsWgoKCCA4OZvHixXlZq4iIiGTHMMzHbnz/PZQtC598AprpXERE8sgNT6/m7u5Oly5dWL9+PQcPHmTSpElUrlyZTZs20StjqIyIiIjkr3feMWdOdXWFpUshMNDqikREpBDJ03m5K1asyIQJE/j999/ZsGEDXbt2zcvdi4iISFa2boXhw83lmTOhaVMrqxERkULomh/Hcb1atmxJy5Yt82v3IiIiAnD8ODz2GKSkQGgojBxpdUUiIlII6UnAIiIiBVVqKnTtCkePQq1aMH8+2GxWVyUiIoWQgqOIiEhBNWYMfPklFC8OMTHmf0VERPKBgqOIiEhB9Mkn8Mor5nJkJNSsaWk5IiJSuCk4ioiIFDQ//gj9+pnLo0dDp07W1iMiIoWegqOIiEhBkpAAISFw4QI0bw7TplldkYiIFAEKjiIiIgWFYZhXGn/+GSpWhMWLwS3fJkgXERGxU3AUEREpKF56yZwEp1gxWL4cypa1uiIRESkinDI4JiYmMnz4cAICAvD09OSuu+5iyZIl17RtXFwcwcHBlC1bFl9fX+rWrcvrr79OWlqaQ7+mTZtis9kyfbVp0ybTPn/77Tcef/xxKleujJeXF9WqVWPkyJGcOnUqU9/ff/+dTp06UbJkSXx9fQkODua7777L3QchIiKSYfNmeP55c/n11+Hee62tR0REihSnHN/SqVMndu7cyYwZM7jttttYtGgR3bt3Jz09nR49emS73caNG2ndujUPPfQQ8+bNw8fHh9WrVzNs2DDi4+N57bXXHPoHBQURHR3t0FayZEmH1ydOnKBRo0b4+fkRERFB5cqV2b17NxMnTiQuLo5du3bh4uJi7/vggw9yyy23sGDBAjw9PZk+fTpNmzZl586d3H777XnzAYmISNHy11/QrRukp0PfvvDkk1ZXJCIiRYzTBce1a9cSGxtrD4sAzZo149ChQ4waNYquXbvi6uqa5baRkZG4u7vz2Wef4ePjA0DLli35+eefiYyMzBQcvby8aNSoUY71rFq1ilOnTrF06VJatGhhryc5OZkXXniB77//nvr16wPw0ksvceLECb755huqVKkCwAMPPEC1atWYMGECS5cuzf0HIyIiRVNyMjz2GJw4AfXrw9tvg81mdVUiIlLEON1Q1RUrVuDr60toaKhDe79+/Th69Cjbt2/Pdlt3d3eKFSuGl5eXQ3vJkiXx9PTMVT3u7u4AlChRItM+AYf9rlixgubNm9tDI4Cfnx+dOnXi008/JTU1NVc1iIhIETZ8OOzYAbfcYt7XeNW/cSIiIjeD0wXH/fv3U6tWLdyumiWubt269vXZeeqpp7h8+TJDhw7l6NGjnD17loULF7JixQpGjx6dqX98fDz+/v64ublRrVo1xo4dS1JSkkOfjh07UrlyZcLCwjhw4ACJiYl89dVXzJgxg/bt21OrVi0AkpKSiI+Pt9d5de1JSUn8/vvv1/15iIhIERYZCe++a15hXLQIbr3V6opERKSIcrqhqqdOnSIoKChTu7+/v319dho2bMjmzZsJDQ3lrbfeAsDV1ZXp06cTFhbm0PeBBx6ga9eu1KxZk6SkJNatW8esWbP4+uuviYuLs9+3WKJECbZt20bnzp2pXbu2ffvQ0FAWLlxof33mzBkMw7DXeb21Jycnk5ycbH+dkJAAQEpKCikpKdludzNkHN/qOkQkZzpXC5ndu3F76ilsQNqECaS3aAH63hYKOldFnJ+znafOUIfTBUcAWw73buS0bteuXYSEhNCwYUPmzp2Lj48PmzdvZty4cVy6dInx48fb+06dOtVh23bt2lG1alXCw8NZtWoVISEhgBkIH330US5evEh0dDSVKlVi//79RERE0KFDB9asWeNwdTS3tU+fPp3Jkydnat+wYQPe3t7ZbnczxcbGWl2CiFwDnasFn/v58zQJC8M9OZlj//kP2+vVg7VrrS5L8pjOVRHn5yzn6cWLF60uwfmCY6lSpbK8Mnf69GmALK/oZRg8eDDlypVjxYoV9gl0mjVrhouLC5MmTaJnz55ZXs3M0KtXL8LDw9m2bZs9OM6cOZM9e/Zw6NAhKlSoAMCDDz5IzZo1ad68OdHR0fTp04dbbrkFm82W69qff/55Ro4caX+dkJBApUqVaNWqFX5+ftludzOkpKQQGxtLcHCw/Z5PEXE+OlcLibQ0XDt2xOWffzCqVaPU2rW0u2rGbynYdK6KOD9nO08zRiNayemCY506dVi8eDGpqakOV/L27dsH4DBc9Gp79uyhe/fumWZdbdCgAenp6fz44485BscMGcNUM/YZGBhoD41X7hP+d8+ll5cX1atXt9d5pX379uHl5ZXjsT08PPDw8MjU7u7u7hQ/rOBctYhI9nSuFnBTp8Lnn4OXF7aYGNzLlLG6IsknOldFnJ+znKfOUIPTTY4TEhJCYmIiy5cvd2iPiooiICCAhg0bZrttQEAA3377LWlpaQ7tW7duBaBixYo5HjsqKgrA4REdAQEBHD58mCNHjvzrPkNCQti8eTN//fWXve38+fPExMTQoUOHTBP+iIiIOPjsM5gyxVx+7z3IYsI1ERERKzhdkmnbti3BwcE8/fTTJCQkUL16dRYvXsz69ev56KOP7FcTBwwYQFRUFPHx8fbHX4wYMYKhQ4fSvn17Bg0ahLe3N5s2beKVV16hZcuW1KtXD4AtW7Ywbdo0QkJCCAoK4tKlS6xbt4733nuP5s2b0759e3s9gwcPJjo6muDgYMaMGWO/x3Hq1KmUK1eOnj172vuGh4ezcOFCHn74YaZMmYKHhwczZszg0qVLTJo06eZ9iCIiUvD89hv06mUuP/vs/5ZFREScgNMFR4CYmBjGjh3LhAkTOH36NDVr1mTx4sV069bN3ictLY20tDQMw7C3DRkyhMDAQObMmcPAgQNJSkqiatWqTJw4kREjRtj7VahQAVdXVyIiIjh58iQ2m40aNWowZcoUwsLCHIaq3nPPPWzbto2IiAjGjh3LiRMnCAwMpEOHDkyYMIHSpUvb+5YpU4YtW7YQHh5Onz59SE1NpXHjxnzxxRfUrFkznz81EREpsC5ehM6d4dw5uO8+eOUVqysSERFxYDOuTF7iNBISEihRogTnzp1zislx1q5dS7t27ZxifLWIZE3nagFlGNC7N3z0EZQrB999BwEBVlcl+Ujnqojzc7bz1BmygdPd4ygiIlKkvP22GRpdXWHpUoVGERFxSgqOIiIiVvnmGxg+3Fx+6SVo0sTSckRERLKj4CgiImKFY8cgNBRSU6Fr1/8FSBERESek4CgiInKzpaSYYfHoUbjjDnj/fbDZrK5KREQkWwqOIiIiN9uYMfDVV1C8OMTEgK+v1RWJiIjkSMFRRETkZvr4Y5g921yOioLbb7e2HhERkWug4CgiInKzHDgA/fuby2PGQEiItfWIiIhcIwVHERGRmyEhATp1ggsXoEULiIiwuiIREZFrpuAoIiKS3wwD+vaFX36BSpVg8WJwc7O6KhERkWum4CgiIpLfZs2CFSugWDFYtgzKlLG6IhERkeui4CgiIpKfNm2CF14wl994A+6919p6REREckHBUUREJL/8+Sd06wbp6eakOE88YXVFIiIiuaLgKCIikh+Sk+Gxx+DkSbj7bnjzTbDZrK5KREQkVxQcRURE8sPQobBzJ/j7w/Ll4OVldUUiIiK5puAoIiKS1xYsgPfeM68wLloEVataXZGIiMgNUXAUERHJS999B888Yy5PmQKtW1tbj4iISB5QcBQREckrp05Bp07m/Y3t2/9vNlUREZECTsFRREQkL6SlQc+ecOgQVK8OH34ILvpnVkRECgf9iyYiIpIXJk2Czz83J8GJiYGSJa2uSEREJM8oOIqIiNyoTz+FqVPN5XnzoE4da+sRERHJYwqOIiIiN+K33+Dxx83lIUPM4aoiIiKFjIKjiIhIbl24YE6Gc+4c3H8/vPyy1RWJiIjkCwVHERGR3DAMePJJ2LcPypeHjz+GYsWsrkpERCRfKDiKiIjkxptvwqJF4OpqhsaAAKsrEhERyTcKjiIiItfr//4PRo40l19+GR580Np6RERE8pmCo4iIyPU4dgxCQyE1Fbp2hWHDrK5IREQk3yk4ioiIXKuUFOjSBf7+G+68E95/H2w2q6sSERHJdwqOIiIi1+q552DLFvDzg5gY8PW1uiIREZGbQsFRRETkWixZAnPmmMsffgi33WZtPSIiIjeRgqOIiMi/OXAABgwwl59/Hh591Np6REREbjIFRxERkZycOwedOsHFi9CyJUREWF2RiIjITafgKCIikp30dOjbF375BSpXhsWLzec2ioiIFDEKjiIiItmZNQtWroRixWDZMihd2uqKRERELKHgKCIikpWNG2HsWHP5rbegQQNr6xEREbGQgqOIiMjV/vwTunUzh6oOGAADB1pdkYiIiKUUHEVERK506RJ07gynTsE998Cbb1pdkYiIiOUUHEVERK40dCh8+y34+8Py5eDpaXVFIiIillNwFBERyTB/PsybBzabOYNqlSpWVyQiIuIUFBxFRETAvMo4eLC5PHUqtGplbT0iIiJORMFRRETk5EnzvsbkZOjQAcaMsboiERERp6LgKCIiRVtaGvTsac6kWr06fPghuOifRxERkSvpX0YRESnaJk6EDRvA2xtiYqBECasrEhERcToKjiIiUnStXg3TppnL778PdepYW4+IiIiTUnAUEZGi6ddf4fHHzeVhw6B7d2vrERERcWIKjiIiUvRcuACdOkFCAjzwALz0ktUViYiIODUFRxERKVoMA558Evbvh/Ll4eOPwd3d6qpEREScmoKjiIgULW+8AYsWgZsbfPIJVKhgdUUiIiJOzymDY2JiIsOHDycgIABPT0/uuusulixZck3bxsXFERwcTNmyZfH19aVu3bq8/vrrpKWlOfRr2rQpNpst01ebNm0c+k2aNCnLfhlfV9e1fPly7r//fvz9/SlZsiT33nsvCxcuvLEPRERE8sbXX0NYmLn88svmMFURERH5V25WF5CVTp06sXPnTmbMmMFtt93GokWL6N69O+np6fTo0SPb7TZu3Ejr1q156KGHmDdvHj4+PqxevZphw4YRHx/Pa6+95tA/KCiI6Ohoh7aSJUs6vB44cGCmMAnwxBNPEB8f77BuwYIFDBgwgM6dOzNu3DhsNhtRUVH07t2bkydPMmLEiFx8GiIikif+/htCQyE11ZwIZ+hQqysSEREpMJwuOK5du5bY2Fh7WARo1qwZhw4dYtSoUXTt2hVXV9cst42MjMTd3Z3PPvsMHx8fAFq2bMnPP/9MZGRkpuDo5eVFo0aNcqynYsWKVKxY0aHt4MGDHDhwgJ49ezoEzQULFlClShU+/vhjXP778OjWrVuzZ88eIiMjFRxFRKySkgJdusCxY1C7NsybBzab1VWJiIgUGE43VHXFihX4+voSGhrq0N6vXz+OHj3K9u3bs93W3d2dYsWK4eXl5dBesmRJPD0986zGBQsWYBgGAwcOzHR8X19fe2gEsNls+Pn55enxRUTkOo0aZQ5T9fODmBj47/9cFBERkWvjdMFx//791KpVCzc3x4uhdevWta/PzlNPPcXly5cZOnQoR48e5ezZsyxcuJAVK1YwevToTP3j4+Px9/fHzc2NatWqMXbsWJKSknKsLz09ncjISKpXr06TJk0c1g0ZMoQff/yRadOmceLECU6ePMnLL7/Mrl27CA8Pv9aPQERE8tLixZAx4uTDD6FGDWvrERERKYCcbqjqqVOnCAoKytTu7+9vX5+dhg0bsnnzZkJDQ3nrrbcAcHV1Zfr06YRlTIbwXw888ABdu3alZs2aJCUlsW7dOmbNmsXXX39NXFycw1XDK23YsIG//vqL6dOnZ1rXqVMnYmJi6NOnD+PGjQPM4bBRUVGZrqBeLTk5meTkZPvrhIQEAFJSUkhJSclx2/yWcXyr6xCRnOlczcL+/bgNHIgNSHvuOdLbtTOHrYpYSOeqiPNztvPUGepwuuAI5vDO3KzbtWsXISEhNGzYkLlz5+Lj48PmzZsZN24cly5dYvz48fa+U6dOddi2Xbt2VK1alfDwcFatWkVISEiWx5g/fz5ubm707ds307r169fTq1cvQkND6dKlC25ubqxevZq+ffty+fJl+vXrl23t06dPZ/LkyZnaN2zYgLe3d7bb3UyxsbFWlyAi10DnqsntwgWajBqF+8WL/FOvHlvvvRfWrrW6LBE7nasizs9ZztOLFy9aXQI2wzAMq4u4UuPGjUlLS2PHjh0O7QcOHKB27drMnTuXJ598MsttGzVqxMWLF9m9e7fDBDoTJ05k6tSp/Prrr1lezcxw/Phxypcvz+jRo5k5c2am9SdPniQwMJC2bduycuVKh3WGYRAYGEj9+vVZs2aNw7o+ffqwfPlyjh8/bp+052pZXXGsVKkSJ0+exM/PL9uab4aUlBRiY2MJDg7GXQ/JFnFaOlevkJ6Oa2goLp9+ilG5MqnbtkHp0lZXJQLoXBUpCJztPE1ISKB06dKcO3fOsmzgdFcc69Spw+LFi0lNTXW4z3Hfvn0A1K5dO9tt9+zZQ/fu3TPNutqgQQPS09P58ccfcwyOGbIbprpw4UIuX76caVIcMEPn33//zaBBgzKta9CgAR9++CEHDx7kzjvvzHLfHh4eeHh4ZGp3d3d3ih9WcK5aRCR7OleBF1+ETz8FDw9sy5fjXqGC1RWJZKJzVcT5Oct56gw1ON3kOCEhISQmJrJ8+XKH9qioKAICAmjYsGG22wYEBPDtt9+Slpbm0L5161aATI/VuFpUVBRAto/omD9/PgEBAbRt2zbTultuuQVPT0+2bduWad3WrVtxcXGhgv5wERHJfxs2wH/vM+ett+A//7G2HhERkULA6a44tm3bluDgYJ5++mkSEhKoXr06ixcvZv369Xz00Uf2q4kDBgwgKiqK+Ph4qlSpAsCIESMYOnQo7du3Z9CgQXh7e7Np0yZeeeUVWrZsSb169QDYsmUL06ZNIyQkhKCgIC5dusS6det47733aN68Oe3bt89U1/bt2zlw4AAvvPBCls+R9PDw4JlnnmH27Nn07t3b/rzJlStXsmjRIgYMGGCf4EdERPLJoUPQowcYBgwcCAMGWF2RiIhIoeB0wREgJiaGsWPHMmHCBE6fPk3NmjVZvHgx3bp1s/dJS0sjLS2NK2/RHDJkCIGBgcyZM4eBAweSlJRE1apVmThxIiNGjLD3q1ChAq6urkRERHDy5ElsNhs1atRgypQphIWFZTlUdf78+dhsNgbk8EfISy+9RK1atZg7dy69evUiPT2datWq8eabb2Z7X6aIiOSRS5egc2c4dcq8yvjGG1ZXJCIiUmg43eQ4YkpISKBEiRKW3gCbISUlhbVr19KuXTunGF8tIlkr8ufqE0/A++9DqVKwaxf8dzSKiLMp8ueqSAHgbOepM2QDp7vHUURE5Lq9/7755eICS5YoNIqIiOQxBUcRESnYdu6EwYPN5alToWVLa+sREREphBQcRUSk4Dp5Eh57DC5fho4dYcwYqysSEREplBQcRUSkYEpLg+7d4c8/oUYNiIwEm83qqkRERAolBUcRESmYJkyAjRvB2xtiYqBECasrEhERKbQUHEVEpOBZtQpefNFcnj8fate2th4REZFCTsFRREQKll9+gd69zeXhw+GKZ/yKiIhI/lBwFBGRguPCBejUCRIS4MEHYdYsqysSEREpEhQcRUSkYDAMGDgQDhyAChXg44/BCR7KLCIiUhQoOIqISMHw+uuwZAm4ucEnn0D58lZXJCIiUmQoOIqIiPPbsgXCw83l2bPh/vutrUdERKSIUXAUERHn9vff0KULpKZCjx7w7LNWVyQiIlLkKDiKiIjzSkmB0FA4dgzq1IH33gObzeqqREREihwFRxERcV7h4fB//wclSkBMDPj4WF2RiIhIkaTgKCIizmnRInNCHICFC6F6dWvrERERKcIUHEVExPns2wdPPGEujxsH7dtbW4+IiEgRp+AoIiLO5exZ6NQJLl6E1q1h0iSrKxIRESnyFBxFRMR5pKdD797w229QpQpER4Orq9VViYiIFHkKjiIi4jymT4dPPwUPD1i+HEqVsroiERERQcFRREScxYYNMH68ufz223DPPdbWIyIiInYKjiIiYr2DB6F7dzAMePJJ6N/f6opERETkCgqOIiJirUuXoHNnOH0aGjT43yM4RERExGkoOIqIiLWefRa++w5Kl4Zly8z7G0VERMSpKDiKiIh15s2D+fPBxQWWLIHKla2uSERERLKg4CgiItbYudO82ggwbRq0aGFtPSIiIpItBUcREbn5Tpww72u8fBlCQuC556yuSERERHKg4CgiIjdXWpo5g+pff8Ftt0FkJNhsVlclIiIiOVBwFBGRm2vcONi0CXx8ICYG/PysrkhERET+hYKjiIjcPCtWwIwZ5vL8+XDnndbWIyIiItdEwVFERG6OX36BPn3M5REjoGtXa+sRERGRa6bgKCIi+S8x0ZwE5/x5eOghmDnT6opERETkOig4iohI/jIMGDgQfvgBAgJg6VJwd7e6KhEREbkOCo4iIpK/Xn3VDItubvDJJ1C+vNUViYiIyHVScBQRkfzz1VcwapS5PGcO3HeftfWIiIhIrig4iohI/jh6FLp0MZ/b2KsXDB5sdUUiIiKSSwqOIiKS9y5fhtBQOH4c6taFuXPBZrO6KhEREcklBUcREcl74eHwzTdQogQsXw7e3lZXJCIiIjdAwVFERPLWRx/BG2/8b7l6dWvrERERkRum4CgiInln71548klzefx4eOQRa+sRERGRPKHgKCIieePsWejUCZKSoE0bmDjR6opEREQkjyg4iojIjUtPh8cfh/h4qFoVoqPB1dXqqkRERCSPKDiKiMiNe/FF+Owz8PQ0J8Px97e6IhEREclDCo4iInJj1q+HCRPM5XfegbvvtrYeERERyXMKjiIiknt//AE9eoBhwKBB0Lev1RWJiIhIPlBwFBGR3ElKgscegzNn4N574bXXrK5IRERE8omCo4iIXD/DgMGD4bvvoHRpWLYMPDysrkpERETyiYKjiIhcv3nz4IMPwMUFli6FSpWsrkhERETykVMGx8TERIYPH05AQACenp7cddddLFmy5Jq2jYuLIzg4mLJly+Lr60vdunV5/fXXSUtLc+jXtGlTbDZbpq82bdo49Js0aVKW/TK+rq7LMAw++OAD7r33Xnx8fPDz8+Puu+9m1apVN/ahiIg4ix07YMgQc3n6dGje3Np6REREJN+5WV1AVjp16sTOnTuZMWMGt912G4sWLaJ79+6kp6fTo0ePbLfbuHEjrVu35qGHHmLevHn4+PiwevVqhg0bRnx8PK9ddf9NUFAQ0dHRDm0lS5Z0eD1w4MBMYRLgiSeeID4+PtO6p59+msjISEaMGMH06dNJTU1l3759XLx48To/BRERJ3TiBHTuDJcvQ6dOMGqU1RWJiIjITeB0wXHt2rXExsbawyJAs2bNOHToEKNGjaJr1664ZvNQ6cjISNzd3fnss8/w8fEBoGXLlvz8889ERkZmCo5eXl40atQox3oqVqxIxYoVHdoOHjzIgQMH6Nmzp0PQXLlyJXPnzmXp0qV06dLF3t66detrfv8iIk4rNRW6dYPDh+H2282hqjab1VWJiIjITeB0Q1VXrFiBr68voaGhDu39+vXj6NGjbN++Pdtt3d3dKVasGF5eXg7tJUuWxNPTM89qXLBgAYZhMHDgQIf21157japVqzqERhGRQmPcONi8GXx8ICYG/PysrkhERERuEqcLjvv376dWrVq4uTleDK1bt659fXaeeuopLl++zNChQzl69Chnz55l4cKFrFixgtGjR2fqHx8fj7+/P25ublSrVo2xY8eSlJSUY33p6elERkZSvXp1mjRpYm9PTU1l69at1K9fn9mzZ1OlShVcXV0JCgri5ZdfxjCM6/kYREScS0wMzJxpLn/wAdxxh7X1iIiIyE3ldENVT506RVBQUKZ2f39/+/rsNGzYkM2bNxMaGspbb70FgKurK9OnTycsLMyh7wMPPEDXrl2pWbMmSUlJrFu3jlmzZvH1118TFxeHi0vWmXrDhg389ddfTJ8+3aH95MmTJCcns2nTJnbu3Mm0adOoWLEin3zyCaNGjeLMmTNMmzYt29qTk5NJTk62v05ISAAgJSWFlJSUbLe7GTKOb3UdIpKzfDtXf/oJt759sQFpI0aQ3rEj6PeBSK7p31UR5+ds56kz1OF0wRHAlsM9Mzmt27VrFyEhITRs2JC5c+fi4+PD5s2bGTduHJcuXWL8+PH2vlOnTnXYtl27dlStWpXw8HBWrVpFSEhIlseYP38+bm5u9O3b16E9PT0dMAPf559/br93snnz5hw7dozZs2fz/PPP4+vrm+V+p0+fzuTJkzO1b9iwAW9v72zf880UGxtrdQkicg3y8lx1TUqiyahRFD9/npN33sk3DzyAsXZtnu1fpCjTv6sizs9ZzlNnmGjTZjjZGMrGjRuTlpbGjh07HNoPHDhA7dq1mTt3Lk8++WSW2zZq1IiLFy+ye/duhwl0Jk6cyNSpU/n111+zvJqZ4fjx45QvX57Ro0czM2NI1hVOnjxJYGAgbdu2ZeXKlQ7rkpKS8PHxoXjx4pw7d85h3XvvvcegQYPYvn079957b5bHzuqKY6VKlTh58iR+Ft9HlJKSQmxsLMHBwbi7u1tai4hkL8/PVcPAtWdPXJYtwwgIIHX7dihX7sb3K1LE6d9VEefnbOdpQkICpUuX5ty5c5ZlA6e74linTh0WL15Mamqqw32O+/btA6B27drZbrtnzx66d++eadbVBg0akJ6ezo8//phjcMyQ3TDVhQsXcvny5UyT4oA5Q2uNGjU4duxYpnUZ2Ty7/QJ4eHjg4eGRqd3d3d0pfljBuWoRkezl2bk6ezYsWwbu7tiWLcP9qhmmReTG6N9VEefnLOepM9TgdJPjhISEkJiYyPLlyx3ao6KiCAgIoGHDhtluGxAQwLfffktaWppD+9atWwEyPVbjalFRUQDZPqJj/vz5BAQE0LZt2yzXd+7cmYSEBL755huH9rVr1+Lr68udd96Z4/FFRJzGl19CxqRic+ZA48bW1iMiIiKWcrorjm3btiU4OJinn36ahIQEqlevzuLFi1m/fj0fffSR/WrigAEDiIqKIj4+nipVqgAwYsQIhg4dSvv27Rk0aBDe3t5s2rSJV155hZYtW1KvXj0AtmzZwrRp0wgJCSEoKIhLly6xbt063nvvPZo3b0779u0z1bV9+3YOHDjACy+8kO1zJMPDw4mOjiY0NJSIiAgqVqzIsmXLWL16NS+//HKmx4SIiDilI0egSxdIS4PHH4dnnrG6IhEREbGY0wVHgJiYGMaOHcuECRM4ffo0NWvWZPHixXTr1s3eJy0tjbS0NIfHXAwZMoTAwEDmzJnDwIEDSUpKomrVqkycOJERI0bY+1WoUAFXV1ciIiI4efIkNpuNGjVqMGXKFMLCwrIcUjp//nxsNhsDBgzItm5/f3++/vprRo8eTXh4OBcuXKBmzZosWLCAfv365dGnIyKSjy5fhtBQ+OcfqFcP3n0XcpiUTERERIoGp5scR0wJCQmUKFHC0htgM6SkpLB27VratWvnFOOrRSRreXKuDhkCb74JJUvCt99CtWp5WqOI6N9VkYLA2c5TZ8gGTnePo4iIWOSjj8zQmLGs0CgiIiL/peAoIiLw/feQ8aijCRPg4YetrUdEREScioKjiEhRd+YMdOoESUnQti1MnGh1RSIiIuJkFBxFRIqy9HRz5tTff4dbbzWHqObwzFkREREpmvTXgYhIUTZ1KqxZA56esHw5+PtbXZGIiIg4IQVHEZGiat06mDTJXH73Xahf39JyRERExHkpOIqIFEV//AE9e4JhwNNPQ58+VlckIiIiTkzBUUSkqElKMifDOXMGGjaEOXOsrkhEREScnIKjiEhRknGFcc8eKFMGli0DDw+rqxIREREnp+Ao/9/encdFVf3/A38NzLAvyqZsAiKCGqDmvgHSR1RA/SApmgZIVl9TrCSXLJFPmoZaah9FH6XgloqKGqnZorjkRikUKC0qbuAGKgiCLOf3B7+Zj+MsgqLj8no+HjyUc8+c+54798y9b+655xLRi2T5cmDVqrqZUzduBJycdB0RERERPQOYOBIRvSiOHgViY+v+P3cuEBCg23iIiIjomcHEkYjoRXD1KhAeDlRVAUOHAnFxuo6IiIiIniFMHImInnfV1UBEBHDxIuDlBSQnAxKJrqMiIiKiZwgTRyKi59306cDevYCZGZCWBpib6zoiIiIiesYwcSQiep5t2QIkJtb9PzkZaNNGt/EQERHRM4mJIxHR8yovD4iKqvt/XFzdPY5ERERED4GJIxHR86i0FAgLA27fBvz9gTlzdB0RERERPcOYOBIRPW+EAMaMAU6dAhwdgQ0bAKlU11ERERHRM4xnEqRdTQ0k+/bBcf9+SExN6577pq+v66iI6H739FW9nTuBzZsBmazu32bNdB0dERERPeOYOJJmaWnAxImQXryITgDw+eeAkxOwaFHdEDgiejrc31floqKAbt10FBQRERE9TzhUldRLS6ubSOPiReXyS5fqytPSdBMXESnT1FcB4Ouv2VeJiIioUfCKI6mqqQEmTqy7T+p+8rKoKODYMUCPf3sg0pnaWmDpUvV9Ve7dd4HBgznEnIiIiB4JE0dSdeCA+qsX9yotBT777MnEQ0QPRwjgwoW6Pu3vr+toiIiI6BnGxJFUFRbWr17//oCn5+ONhYg0+/NP4PvvH1yvvn2aiIiISAMmjqTK3r5+9aZM4VUMIl3KyKhf4ljfPk1ERESkAW9QI1W9e9fNniqRqF8ukQDOznX1iEh32FeJiIjoCWHiSKr09eseuQGonpDKf1+4kJNtEOka+yoRERE9IUwcSb2wsLoHhzs6Kpc7OdWV8zmORE8H9lUiIiJ6AniPI2kWFgYMHozqvXuRtWsX2g8YAGlAAK9eED1t2FeJiIjoMWPiSNrp60P4+eFSWRl8/fx4Ikr0tGJfJSIioseIQ1WJiIiIiIhIKyaOREREREREpBUTRyIiIiIiItKKiSMRERERERFpxcSRiIiIiIiItGLiSERERERERFoxcSQiIiIiIiKtmDgSERERERGRVkwciYiIiIiISCsmjkRERERERKQVE0ciIiIiIiLSiokjERERERERacXEkYiIiIiIiLSS6joAUk8IAQAoKSnRcSRAVVUVysvLUVJSAplMputwiEgD9lWiZwP7KtHT72nrp/KcQJ4j6AITx6dUaWkpAMDZ2VnHkRARERER0dOgtLQUlpaWOlm3ROgybSWNamtrUVBQAHNzc0gkEp3GUlJSAmdnZ1y4cAEWFhY6jYWINGNfJXo2sK8SPf2etn4qhEBpaSkcHBygp6ebuw15xfEppaenBycnJ12HocTCwuKp6DhEpB37KtGzgX2V6On3NPVTXV1plOPkOERERERERKQVE0ciIiIiIiLSiokjPZChoSHi4+NhaGio61CISAv2VaJnA/sq0dOP/VQVJ8chIiIiIiIirXjFkYiIiIiIiLRi4khERERERERaMXEkIiIiIiIirZg4PueOHj2Kf//732jRogUMDQ3RrFkzdO/eHZMmTVLUWbp0KVJSUh7L+svLyzFz5kxkZGQ8lvaJHkZKSgokEgkkEonafVMIgVatWkEikcDf3/+Jx3evL7/8Eq1atYKBgQEkEglu3rzZ6OsoKCjAzJkzkZWV1ehtEz2vdu7ciZkzZ6pd5urqiqioqCcaj9w333yDhQsX6mTdRLqgy/7WGBrjPPzTTz/Ftm3bGiUebZg4Psd27NiBHj16oKSkBImJifjhhx+waNEi9OzZExs3blTUe9yJY0JCAhNHeiqZm5tjxYoVKuX79u3D6dOnYW5uroOo/icrKwuxsbEICAjAnj17cPjw4ccSU0FBARISEpg4EjXAzp07kZCQoHbZ1q1b8fHHHz/hiOowcSR6tjxLiaP0sa+BdCYxMRFubm7YvXs3pNL/fdQRERFITEx8rOsWQqCiouKxroPoUQ0fPhzr1q3DkiVLYGFhoShfsWIFunfvjpKSEh1GB+Tm5gIAxo4diy5duug0lodRU1OD6upqTmVOL5wOHTroOoRGJT+mGxsb6zoUegaUl5fDxMRE12HQY8Arjs+xoqIi2NjYKCWNcnp6dR+9q6srcnNzsW/fPsXQPVdXVwBARUUFJk2ahPbt28PS0hJWVlbo3r07tm/frtKeRCLB+PHjsWzZMrRp0waGhoZYtWoVbG1tAQAJCQmK9p/l4QT0fBkxYgQAYP369YqyW7duYcuWLRgzZoxK/YSEBHTt2hVWVlawsLBAx44dsWLFCtz7VKODBw9CJpMhLi5O6bXy4bHqrnCq4+/vj1GjRgEAunbtqtJ3fvrpJwQGBsLCwgImJibo2bMnfv75Z6U2/vnnH0RHR8PDwwMmJiZwdHREaGgo/vjjD0WdjIwMdO7cGQAQHR2t6KfyIXj+/v5qh+tGRUUpvisAID8/HxKJBImJiZg1axbc3NxgaGiIvXv3AgB+/fVXDBo0CFZWVjAyMkKHDh2Qmpqq1GZ5eTni4uLg5uYGIyMjWFlZoVOnTkqfD72YZs6cCYlEgtzcXIwYMQKWlpZo1qwZxowZg1u3bjWorcbYF6OiorBkyRIAUPQZiUSC/Px8AKpD5zIyMiCRSPDNN99gypQpsLe3h5mZGUJDQ3HlyhWUlpbizTffhI2NDWxsbBAdHY3bt28rxbRkyRL06dMHdnZ2MDU1hbe3NxITE1FVVaWo4+/vjx07duDcuXNKcckVFxdj3LhxcHR0hIGBAVq2bInp06ejsrJSaV2ajukAkJSUBF9fX5iZmcHc3BxeXl748MMPG/QZ0PND3jePHz+O8PBwNG3aFO7u7vj1118REREBV1dXGBsbw9XVFSNGjMC5c+eUXi8/Nu7duxf/93//BxsbG1hbWyMsLAwFBQVKdauqqjB58mQ0b94cJiYm6NWrF44dO6Y2rpycHAwePBhNmzaFkZER2rdvr9iH5RqjXz7ImTNnEBERAQcHB8UtY4GBgYoRPo1xHi6RSFBWVoZVq1Yp2rj3uH358mW89dZbcHJygoGBAdzc3JCQkIDq6uoGvReAVxyfa927d8fXX3+N2NhYvPbaa+jYsSNkMplSna1btyI8PByWlpZYunQpACiuDlRWVqK4uBhxcXFwdHTE3bt38dNPPyEsLAzJycl4/fXXldratm0bDhw4gBkzZqB58+awsrLC999/j/79+yMmJgZvvPEGACiSSSJds7CwQHh4OFauXIm33noLQF0Sqaenh+HDh6sM98rPz8dbb72FFi1aAACOHDmCCRMm4NKlS5gxYwYAoFevXpg1axamTp2KPn36YNCgQcjNzcU777yDUaNGISYmpl6xLV26FOvXr8esWbOQnJwMLy8vRd9Zu3YtXn/9dQwePBirVq2CTCbD8uXLERQUhN27dyMwMBBA3RBUa2trzJ07F7a2tiguLsaqVavQtWtXnDhxAp6enujYsSOSk5MRHR2Njz76CMHBwQAAJyenh9qmixcvRuvWrTF//nxYWFjAw8MDe/fuRf/+/dG1a1csW7YMlpaW2LBhA4YPH47y8nLFCfb777+PNWvWYNasWejQoQPKysqQk5ODoqKih4qFnj9Dhw7F8OHDERMTgz/++APTpk0DAKxcubJer2+sffHjjz9GWVkZNm/ejMOHDyvat7e317r+Dz/8EAEBAUhJSUF+fj7i4uIwYsQISKVS+Pr6Yv369Thx4gQ+/PBDmJubY/HixYrXnj59GiNHjoSbmxsMDAyQnZ2N2bNnIy8vT/H+ly5dijfffBOnT5/G1q1bldZdUVGBgIAAnD59GgkJCfDx8cGBAwcwZ84cZGVlYceOHUr17z+m29nZYcOGDRg3bhwmTJiA+fPnQ09PD//88w9OnjxZr+1Pz6+wsDBERETg7bffRllZGfLz8+Hp6YmIiAhYWVmhsLAQSUlJ6Ny5M06ePAkbGxul17/xxhsIDg7GN998gwsXLuCDDz7AqFGjsGfPHkWdsWPHYvXq1YiLi8O//vUv5OTkICwsDKWlpUpt/fnnn+jRowfs7OywePFiWFtbY+3atYiKisKVK1cwefJkpfqP0i8fZODAgaipqUFiYiJatGiB69ev49ChQ4r5ChrjPPzw4cPo27cvAgICFEPk5aOoLl++jC5dukBPTw8zZsyAu7s7Dh8+jFmzZiE/Px/Jycn1fi8AAEHPrevXr4tevXoJAAKAkMlkokePHmLOnDmitLRUUa9du3bCz8/vge1VV1eLqqoqERMTIzp06KC0DICwtLQUxcXFSuXXrl0TAER8fHxjvCWiRpGcnCwAiMzMTLF3714BQOTk5AghhOjcubOIiooSQmjvGzU1NaKqqkr85z//EdbW1qK2tlaxrLa2VgwcOFA0adJE5OTkiLZt2wovLy9x+/bth45TrqysTFhZWYnQ0FCVeHx9fUWXLl00tlddXS3u3r0rPDw8xHvvvacoz8zMFABEcnKyymv8/PzUboPIyEjh4uKi+P3s2bMCgHB3dxd3795Vquvl5SU6dOggqqqqlMpDQkKEvb29qKmpEUII8dJLL4khQ4ZojJ9eXPHx8QKASExMVCofN26cMDIyUup/2jTmvvjOO+8ITadRLi4uIjIyUvG7/Hvm/n777rvvCgAiNjZWqXzIkCHCyspK47rl3z+rV68W+vr6Ssfe4OBgpb4pt2zZMgFApKamKpV/9tlnAoD44YcfFGWajunjx48XTZo00RgXvXjkfXPGjBla61VXV4vbt28LU1NTsWjRIkW5/Dg3btw4pfqJiYkCgCgsLBRCCHHq1CkBQOnYJYQQ69atEwCU+ltERIQwNDQU58+fV6o7YMAAYWJiIm7evCmEaPx+eb/r168LAGLhwoVa6zXGebipqanSNpB76623hJmZmTh37pxS+fz58wUAkZub+8D13otDVZ9j1tbWOHDgADIzMzF37lwMHjwYf/31F6ZNmwZvb29cv379gW1s2rQJPXv2hJmZGaRSKWQyGVasWIFTp06p1O3bty+aNm36ON4K0WPj5+cHd3d3rFy5En/88QcyMzPVDlMFgD179uCVV16BpaUl9PX1IZPJMGPGDBQVFeHq1auKehKJBKtXr4a5uTk6deqEs2fPIjU1Faampo8c76FDh1BcXIzIyEhUV1crfmpra9G/f39kZmairKwMAFBdXY1PP/0Ubdu2hYGBAaRSKQwMDPD333+r7cONYdCgQUojG/755x/k5eXhtddeU8Qk/xk4cCAKCwvx559/AgC6dOmCXbt2YerUqcjIyMCdO3ceS4z07Bo0aJDS7z4+PqioqFDqf5o8DftiSEiI0u9t2rQBAMWV/nvLi4uLlYbFnThxAoMGDYK1tbXi++f1119HTU0N/vrrrweue8+ePTA1NUV4eLhSufwq6/1D3dUd07t06YKbN29ixIgR2L59e73OI+jFMHToUKXfb9++jSlTpqBVq1aQSqWQSqUwMzNDWVmZ2uOPur4NQDG0VX7bg7z/yg0bNkzllqw9e/YgMDAQzs7OSuVRUVEoLy9XGiUAPFq/1MbKygru7u6YN28ePv/8c5w4cQK1tbX1eq1cQ87D1fnuu+8QEBAABwcHpe+8AQMGAKibDLAhmDi+ADp16oQpU6Zg06ZNKCgowHvvvYf8/PwHTpCTlpaGYcOGwdHREWvXrsXhw4cVJ9XqJr550BAdoqeRRCJBdHQ01q5di2XLlqF169bo3bu3Sr1jx46hX79+AICvvvoKv/zyCzIzMzF9+nQAUDmxtLa2xqBBg1BRUYH+/fvD29u7UeK9cuUKACA8PBwymUzp57PPPoMQAsXFxQDqhtt9/PHHGDJkCNLT03H06FFkZmbC19f3sSVl938PyOONi4tTiXfcuHEAoDj5XLx4MaZMmYJt27YhICAAVlZWGDJkCP7+++/HEis9e6ytrZV+lw/pqs/+/DTsi1ZWVkq/GxgYaC2XH2vPnz+P3r1749KlS1i0aJHij8Ly+yzr8/6LiorQvHlzpXseAcDOzg5SqVRlSLi6Y/ro0aOxcuVKnDt3DkOHDoWdnR26du2KH3/88YHrp+fb/fvLyJEj8d///hdvvPEGdu/ejWPHjiEzMxO2trZq99cH9W35/tm8eXOlelKpVOW1RUVFavdfBwcHpbbkHrZfPohEIsHPP/+MoKAgJCYmomPHjrC1tUVsbKzK8Fp1Gnoers6VK1eQnp6u8p3Xrl07AGjwH394j+MLRiaTIT4+Hl988QVycnK01l27di3c3NywceNGpQPN/TfRy91/MCJ6VkRFRWHGjBlYtmwZZs+erbbOhg0bIJPJ8N1338HIyEhRrmn66x9//BFJSUno0qULtm7dii1btqj8RfZhyO8L+fLLL9GtWze1dZo1awbgf/dCfvrpp0rLr1+/jiZNmtRrfUZGRmonH9F0sLn/e0Ae77Rp0xAWFqb2NZ6engAAU1NTJCQkICEhAVeuXFFc8QkNDUVeXl694iXS5FneF7dt24aysjKkpaXBxcVFUd6QR+hYW1vj6NGjEEIo9dOrV6+iurpa5Z4zTcf06OhoREdHo6ysDPv370d8fDxCQkLw119/KcVGL5Z795dbt27hu+++Q3x8PKZOnaool9+z9zDkyeHly5fh6OioKK+urlZJBK2trVFYWKjShnyynfv39cfJxcVFMSneX3/9hdTUVMycORN3797FsmXLtL62oefh6tjY2MDHx0fjuY08ma4vJo7PscLCQrV/cZFf3pbvLIaGhmr/+iORSBQPHZe7fPmy2llVNWnIX4OJdMXR0REffPAB8vLyEBkZqbaORCKBVCqFvr6+ouzOnTtYs2aNSt3CwkKMGjUKfn5++PHHHxEWFoaYmBh07NgRbm5ujxRrz5490aRJE5w8eRLjx4/XWlcikag8CmPHjh24dOkSWrVqpSjT1k9dXV2xadMmVFZWKuoVFRXh0KFDSo8w0cTT0xMeHh7Izs5WSWC1adasGaKiopCdnY2FCxdyend6ZI29L97bbx73Yyrkx+F7+7MQAl999ZVKXU3H9MDAQKSmpmLbtm3497//rShfvXq1YnlDmJqaYsCAAbh79y6GDBmC3NxcJo4EoG5/FUKoHH++/vpr1NTUPFSb8llC161bh5dffllRnpqaqjI7aGBgILZu3YqCggKlxGj16tUwMTHR+EfXx61169b46KOPsGXLFhw/flxR3hjn4ZraCAkJwc6dO+Hu7t4ot5MxcXyOBQUFwcnJCaGhofDy8kJtbS2ysrKwYMECmJmZYeLEiQAAb29vbNiwARs3bkTLli1hZGQEb29vhISEIC0tDePGjUN4eDguXLiATz75BPb29vUermNubg4XFxds374dgYGBsLKygo2NjdI0/kRPg7lz52pdHhwcjM8//xwjR47Em2++iaKiIsyfP1/lwFhTU4MRI0YopvjW19dHSkoK2rdvj+HDh+PgwYOK4S4Pw8zMDF9++SUiIyNRXFyM8PBw2NnZ4dq1a8jOzsa1a9eQlJQEoO6AkZKSAi8vL/j4+OC3337DvHnzVGZMdXd3h7GxMdatW4c2bdrAzMwMDg4OcHBwwOjRo7F8+XKMGjUKY8eORVFRERITE+uVNMotX74cAwYMQFBQEKKiouDo6Iji4mKcOnUKx48fx6ZNmwDUPXYkJCQEPj4+aNq0KU6dOoU1a9age/fuTBqpUTTmvigffv7ZZ59hwIAB0NfXh4+PzyP1b03+9a9/wcDAACNGjMDkyZNRUVGBpKQk3LhxQ6Wut7c30tLSkJSUhJdffhl6enro1KkTXn/9dSxZsgSRkZHIz8+Ht7c3Dh48iE8//RQDBw7EK6+88sA4xo4dC2NjY/Ts2RP29va4fPky5syZA0tLS8VjfYgsLCzQp08fzJs3T3HOt2/fPqxYsaLeo13u16ZNG4waNQoLFy6ETCbDK6+8gpycHMUM3veKj49X3Ns3Y8YMWFlZYd26ddixYwcSExNhaWnZCO/ywX7//XeMHz8er776Kjw8PGBgYIA9e/bg999/V7oS2xjn4d7e3sjIyEB6ejrs7e1hbm4OT09P/Oc//8GPP/6IHj16IDY2Fp6enqioqEB+fj527tyJZcuWNWwW9QZNpUPPlI0bN4qRI0cKDw8PYWZmJmQymWjRooUYPXq0OHnypKJefn6+6NevnzA3NxcAlGZjmzt3rnB1dRWGhoaiTZs24quvvlLMoHUvAOKdd95RG8dPP/0kOnToIAwNDVVmviLSBXWzlapz/0xnK1euFJ6ensLQ0FC0bNlSzJkzR6xYsUIAEGfPnhVCCDF9+nShp6cnfv75Z6W2Dh06JKRSqZg4cWKjxLlv3z4RHBwsrKyshEwmE46OjiI4OFhs2rRJUefGjRsiJiZG2NnZCRMTE9GrVy9x4MABtTOlrl+/Xnh5eQmZTKYyE/KqVatEmzZthJGRkWjbtq3YuHGjxllV582bp/a9ZGdni2HDhgk7Ozshk8lE8+bNRd++fcWyZcsUdaZOnSo6deokmjZtqtjG7733nrh+/Xq9txk9n+THnWvXrimVy/uIvP/VR2Pti5WVleKNN94Qtra2QiKRKMWhaVbVe/vnvfHf38fVvd/09HTh6+srjIyMhKOjo/jggw/Erl27BACxd+9eRb3i4mIRHh4umjRpoohLrqioSLz99tvC3t5eSKVS4eLiIqZNmyYqKiqU1q/pmL5q1SoREBAgmjVrJgwMDISDg4MYNmyY+P333x+84em5pKlvXrx4UQwdOlQ0bdpUmJubi/79+4ucnByVvqGpD8j7zL37dmVlpZg0aZKws7MTRkZGolu3buLw4cMqbQohxB9//CFCQ0OFpaWlMDAwEL6+viozhzdGv9TmypUrIioqSnh5eQlTU1NhZmYmfHx8xBdffCGqq6sV9RrjPDwrK0v07NlTmJiYCABKx/hr166J2NhY4ebmJmQymbCyshIvv/yymD59eoNne5cIcc+Tq4mIiIiIiIjuw1lViYiIiIiISCve40hE9ITV1tY+8FlO9z+Xiog0Y58ioifpRf3O4RVHIqInbMyYMSrPVLr/h4jqj32KiJ6kF/U7h/c4EhE9Yfn5+Q986G6nTp2eUDREzz72KSJ6kl7U7xwmjkRERERERKQVh6oSERERERGRVkwciYiIiIiISCsmjkRERERERKQVE0ciIiIiIiLSiokjERERPTFRUVGQSCTIz8/XdShERNQATByJiOiR5efnQyKRKP0YGBjA2dkZI0eOxO+//67rEJ8K/v7+kEgkug7jmZeSkgKJRIKUlBRdh0JE9MKQ6joAIiJ6fri7u2PUqFEAgNu3b+PIkSNYv3490tLSsGfPHvTo0UPHEZKuzZkzB1OnToWjo6OuQyEiogZg4khERI2mVatWmDlzplLZRx99hNmzZ2P69OnYu3evbgKjp4a9vT3s7e11HQYRETUQh6oSEdFjNWHCBABAZmYmAKCgoADx8fHo1q0b7OzsYGhoCFdXV4wbNw5Xr15Veb38nrgzZ87giy++QLt27WBoaIioqKhHbm/+/Plo3bo1jI2N0bZtW2zYsAEAUFVVhRkzZsDNzQ1GRkbw8fHB7t271b6/0tJSxMfHo127djA2NkaTJk3Qv39/HDx4UKmeRCLBvn37FP+X/8jfh3y4b1RUFPLy8hAWFgYbGxul+wGrq6vxxRdfwNfXF8bGxrC0tERAQAB27NhRr89i//79kEgkiImJUbv84sWL0NfXR2BgoKLst99+w/jx4/HSSy/B0tISxsbG8Pb2xty5c1FVVaXShqurK1xdXXHz5k3ExsbC2dkZUqlUMaxU3T2Od+/exZdffomgoCA4OzvD0NAQdnZ2CAsLw4kTJ5Taj4qKQnR0NAAgOjpaaVve6/z584iJiYGjoyMMDAzg5OSEmJgYXLhwoV7bioiIlPGKIxERPVb3n9Dv378fCxYsQGBgILp27QqZTIYTJ04gKSkJu3fvxvHjx2FpaanSzoQJE3DkyBEEBwcjJCQEzZo1e6T23n//fRw9ehShoaHQ19fHhg0bMHLkSDRt2hRLlixBTk4OBg4ciIqKCnzzzTcYNGgQ8vLy4ObmpmijuLgYffr0QW5uLnr37o2goCDcunUL27dvR0BAADZt2oQhQ4YAAOLj45GSkoJz584hPj5e0Ub79u2V4vrnn3/QrVs3tGvXDpGRkSguLoaBgQGEEBg+fDjS0tLQunVrvPPOOygrK0NqaipCQkKwaNEixMbGav0sevfuDVdXV2zZsgVLliyBkZGR0vJ169ahtrYWo0ePVpR99dVXSE9PR58+fTBw4ECUl5cjIyMD06ZNQ2ZmJrZs2aKynsrKSvTt2xelpaUIDQ2FgYGB4vNSp7i4GO+++y569+6NgQMHomnTpjhz5gy+/fZb7Nq1C/v370fnzp0BAEOGDMHNmzexfft2DB48WGX7AcDff/+NXr164erVqwgNDUW7du2Qm5uLlStX4rvvvsMvv/yCVq1aad1WRER0H0FERPSIzp49KwCIoKAglWXTp08XAIS/v78QQogrV66I0tJSlXqrVq0SAMSsWbOUyiMjIwUA4eTkJM6dO6fyuodtz8PDQ1y9elVRfuTIEQFANGnSRPTq1Uvcvn1bsWzjxo0CgIiNjVVqa+TIkQKAWLlypVL55cuXhbOzs7C1tRV37txRlPv5+QlNh175NgQgPv74Y5Xlq1evFgCEn5+fqKysVJRfuHBB2NnZCZlMJs6cOaO27XvJP4/U1FSVZd7e3sLY2FiUlJQoyvLz80V1dbVSvdraWjFmzBgBQBw8eFBpmYuLiwAg+vXrJ8rLy1XWId/+Z8+eVZRVVFSIixcvqtTNyckRZmZm4pVXXlEqT05OFgBEcnKy2vfYt29fAUAsX75cqXz58uUCgAgMDFT7OiIi0oyJIxERPTJ50uPu7i7i4+NFfHy8mDRpkujZs6cAIIyMjMShQ4e0tlFbWyssLCwUCaacPNFYtGhRg2J6UHspKSkqr2nZsqUAIPbt26dUXl1dLWQymfDz81OUXbt2Tejr62tMQhYvXiwAiPT0dEVZfRLH5s2bKyWGcvJk6OjRoyrL5syZIwCITz75RG3b98rLyxMAxKBBg5TKs7KyBAARERHxwDaEEOK3334TAMTMmTOVyuWJY3Z2ttrXqUsctQkNDRUGBgbi7t27ijJtieP58+cFANG2bVtRW1urtKy2tla0adNGABDnz5+v1/qJiKgOh6oSEVGjOX36NBISEgAAMpkMzZo1w8iRIzF16lR4e3sr6qWlpWH58uU4fvw4bty4gZqaGsWygoICtW136dJF43ofpr0OHTqolNnb2+PMmTMqwx/19fVhZ2eHS5cuKcoyMzNRU1ODiooKlQmBgLrhkgCQl5eHkJAQjbHfz9fXFwYGBirlJ06cgLGxsdrt4O/vDwDIysp6YPuenp7o1KkTdu3aheLiYlhZWQEA1qxZAwBKw1SBuvsP//vf/2LDhg3Iy8vD7du3IYRQLFe3fY2MjJQ+7/rIyspCYmIiDh48iMuXL6vcP3n9+vV6TaojvyfSz89PZZi0RCJBnz59cOrUKWRnZ8PZ2blBMRIRvciYOBIRUaMJCgrC999/r7XOggULEBcXB1tbW/Tr1w9OTk4wNjYGACxcuBCVlZVqX6fpHrmHbc/CwkKlTCqVal12bzJTXFwMAPjll1/wyy+/aHq7KCsr07hMHU3vs6SkRGOi07x5cwDArVu36rWO0aNH49dff0Vqairefvtt1NbWYv369bCzs0O/fv2U6oaHhyM9PR2tW7fG8OHDYWdnB5lMhps3b2LRokVqt6+dnV2Dnld56NAh9O3bFwDQr18/eHh4wMzMDBKJBNu2bUN2drbGz/F+JSUlADRvx4ZuKyIiqsPEkYiInpjq6mp88skncHBwQFZWFmxtbRXLhBBITEzU+Fp1icijtPeo5MnlpEmTMH/+/EZrV1PCZWFhgStXrqhdJi9Xl/CqExERgUmTJmHt2rV4++23sWfPHhQUFGDixImK5Bmou6qanp6OoKAg7NixA/r6+oplR44cwaJFixr0HjSZPXs2KisrcfDgQfTs2VNp2ZEjR5CdnV3vtuTboLG2FRER1eHjOIiI6Im5fv06bt26hW7duikleQDw66+/4s6dOzptryE6d+4MiUSCw4cP1/s18sTr3qG09dWhQwfcuXMHx44dU1kmf8yHuhlG1ZFfWTx06BDOnj2LtWvXAgBGjRqlVO/06dMAgODgYKWkEQAOHDjQ0Leg0enTp2FlZaWSNJaXl+P48eMq9bVtR/k22L9/v9KQWqDujwnyuOu7rYiIqA4TRyIiemLs7OxgbGyM48ePo7y8XFF+48YNxfMeddleQzRv3hzDhg3DoUOHMG/ePJUkBQCOHj2qFJf8fsKLFy82eH2RkZEAgGnTpikNmb106RI+//xzSKVSvPbaa/Vub/To0RBC4Ouvv0ZaWhq8vLzQqVMnpTouLi4AoPJMytzcXMyZM6fB70ETFxcX3LhxA7m5uYqympoaxMXF4dq1ayr1tW3HFi1aICAgQPH4jXutXLkSubm56Nu3L+9vJCJqIA5VJSKiJ0ZPTw/jxo3DggUL4Ovri9DQUJSUlGDXrl1wcXGBg4ODTttrqKVLl+LPP//E5MmTsWbNGnTv3h2Wlpa4cOECfvvtN/z9998oLCyEiYkJAKBv377YvHkzXn31VQwcOFAxiUxwcPAD1zV69GikpaVh+/bt8PHxQUhIiOI5jkVFRViwYAFatmxZ79gHDx4MCwsLzJs3D1VVVSqT4gB1ExJ16dIFqampKCwsRLdu3XD+/Hl8++23CA4OxubNm+u/sbSYMGECfvjhB/Tq1QvDhg2DkZERMjIycOnSJfj7+yMjI0Opfvfu3WFsbIyFCxeipKREcbV56tSpAICkpCT06tULY8eORXp6Otq2bYuTJ0/i22+/ha2tLZKSkholbiKiF4oOZ3QlIqLnhLbnON7v7t27Yvbs2cLDw0MYGhqKFi1aiPfff1+UlpYKFxcX4eLiolT/QY9vaMz2tD0uQ11bQghRXl4uEhMTxcsvvyxMTU2FsbGxcHNzE0OGDBGrV68WVVVVirpVVVVi8uTJokWLFkIqlQoAIjIyUgjxv20o/12dqqoqMX/+fOHt7S0MDQ2Fubm58PPzE9u3b9f4Gm2io6MFACGRSER+fr7aOlevXhVjxowRDg4OwsjISHh7e4slS5aIM2fOqI1X03aS07T9N2/eLDp27ChMTEyEjY2NGDZsmDh9+rTG+jt27BCdO3cWxsbGiudf3is/P19ER0cLe3t7IZVKhb29vYiOjtb4PomISDuJEGrG1hARERERERH9f7zHkYiIiIiIiLRi4khERERERERaMXEkIiIiIiIirZg4EhERERERkVZMHImIiIiIiEgrJo5ERERERESkFRNHIiIiIiIi0oqJIxEREREREWnFxJGIiIiIiIi0YuJIREREREREWjFxJCIiIiIiIq2YOBIREREREZFW/w/eFVf3ECSX2AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "algoritmo=[\"Start\",\"Max_features\",\"n_estimators\",\"random_state\"]\n",
    "accuracy=[0.8575,0.8575,0.8585,0.8589]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(algoritmo, accuracy, marker='o', linestyle='-', color='r')\n",
    "plt.title(' Accuracy su testSet al variare dei parametri')\n",
    "plt.xlabel('Parametro variato')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.grid(True)\n",
    "plt.xticks(algoritmo)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4b44ba0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 36 candidates, totalling 360 fits\n",
      "[CV 1/10] END criterion=gini, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.740) f1: (train=1.000, test=0.774) total time=   1.8s\n",
      "[CV 2/10] END criterion=gini, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.863) balanced_accuracy: (train=1.000, test=0.747) f1: (train=1.000, test=0.783) total time=   1.2s\n",
      "[CV 3/10] END criterion=gini, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.740) f1: (train=1.000, test=0.774) total time=   1.1s\n",
      "[CV 4/10] END criterion=gini, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.739) f1: (train=1.000, test=0.775) total time=   1.2s\n",
      "[CV 5/10] END criterion=gini, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.745) f1: (train=1.000, test=0.781) total time=   1.2s\n",
      "[CV 6/10] END criterion=gini, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.743) f1: (train=1.000, test=0.777) total time=   1.3s\n",
      "[CV 7/10] END criterion=gini, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.860) balanced_accuracy: (train=1.000, test=0.744) f1: (train=1.000, test=0.778) total time=   1.2s\n",
      "[CV 8/10] END criterion=gini, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.743) f1: (train=1.000, test=0.777) total time=   1.2s\n",
      "[CV 9/10] END criterion=gini, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.861) balanced_accuracy: (train=1.000, test=0.747) f1: (train=1.000, test=0.781) total time=   1.2s\n",
      "[CV 10/10] END criterion=gini, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.863) balanced_accuracy: (train=1.000, test=0.754) f1: (train=1.000, test=0.787) total time=   1.3s\n",
      "[CV 1/10] END criterion=gini, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.855) balanced_accuracy: (train=1.000, test=0.739) f1: (train=1.000, test=0.772) total time=   1.3s\n",
      "[CV 2/10] END criterion=gini, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.864) balanced_accuracy: (train=1.000, test=0.749) f1: (train=1.000, test=0.785) total time=   1.3s\n",
      "[CV 3/10] END criterion=gini, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.856) balanced_accuracy: (train=1.000, test=0.738) f1: (train=1.000, test=0.772) total time=   1.2s\n",
      "[CV 4/10] END criterion=gini, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.738) f1: (train=1.000, test=0.773) total time=   1.2s\n",
      "[CV 5/10] END criterion=gini, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.745) f1: (train=1.000, test=0.781) total time=   1.3s\n",
      "[CV 6/10] END criterion=gini, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.860) balanced_accuracy: (train=1.000, test=0.743) f1: (train=1.000, test=0.777) total time=   1.2s\n",
      "[CV 7/10] END criterion=gini, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.741) f1: (train=1.000, test=0.775) total time=   1.1s\n",
      "[CV 8/10] END criterion=gini, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.742) f1: (train=1.000, test=0.777) total time=   1.2s\n",
      "[CV 9/10] END criterion=gini, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.861) balanced_accuracy: (train=1.000, test=0.748) f1: (train=1.000, test=0.781) total time=   1.2s\n",
      "[CV 10/10] END criterion=gini, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.752) f1: (train=1.000, test=0.785) total time=   1.2s\n",
      "[CV 1/10] END criterion=gini, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.741) f1: (train=1.000, test=0.775) total time=   1.1s\n",
      "[CV 2/10] END criterion=gini, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.861) balanced_accuracy: (train=1.000, test=0.744) f1: (train=1.000, test=0.780) total time=   1.2s\n",
      "[CV 3/10] END criterion=gini, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.856) balanced_accuracy: (train=1.000, test=0.738) f1: (train=1.000, test=0.772) total time=   1.3s\n",
      "[CV 4/10] END criterion=gini, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.737) f1: (train=1.000, test=0.772) total time=   1.2s\n",
      "[CV 5/10] END criterion=gini, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.863) balanced_accuracy: (train=1.000, test=0.747) f1: (train=1.000, test=0.782) total time=   1.4s\n",
      "[CV 6/10] END criterion=gini, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.744) f1: (train=1.000, test=0.777) total time=   1.3s\n",
      "[CV 7/10] END criterion=gini, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.741) f1: (train=1.000, test=0.775) total time=   1.4s\n",
      "[CV 8/10] END criterion=gini, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.740) f1: (train=1.000, test=0.775) total time=   1.2s\n",
      "[CV 9/10] END criterion=gini, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.863) balanced_accuracy: (train=1.000, test=0.749) f1: (train=1.000, test=0.783) total time=   1.3s\n",
      "[CV 10/10] END criterion=gini, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.863) balanced_accuracy: (train=1.000, test=0.753) f1: (train=1.000, test=0.786) total time=   1.2s\n",
      "[CV 1/10] END criterion=gini, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.740) f1: (train=1.000, test=0.774) total time=   2.1s\n",
      "[CV 2/10] END criterion=gini, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.863) balanced_accuracy: (train=1.000, test=0.747) f1: (train=1.000, test=0.783) total time=   2.1s\n",
      "[CV 3/10] END criterion=gini, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.740) f1: (train=1.000, test=0.773) total time=   2.1s\n",
      "[CV 4/10] END criterion=gini, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.738) f1: (train=1.000, test=0.773) total time=   2.1s\n",
      "[CV 5/10] END criterion=gini, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.863) balanced_accuracy: (train=1.000, test=0.747) f1: (train=1.000, test=0.782) total time=   2.2s\n",
      "[CV 6/10] END criterion=gini, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.744) f1: (train=1.000, test=0.778) total time=   2.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 7/10] END criterion=gini, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.743) f1: (train=1.000, test=0.777) total time=   2.1s\n",
      "[CV 8/10] END criterion=gini, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.860) balanced_accuracy: (train=1.000, test=0.743) f1: (train=1.000, test=0.778) total time=   2.1s\n",
      "[CV 9/10] END criterion=gini, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.747) f1: (train=1.000, test=0.782) total time=   2.1s\n",
      "[CV 10/10] END criterion=gini, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.752) f1: (train=1.000, test=0.785) total time=   2.1s\n",
      "[CV 1/10] END criterion=gini, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.741) f1: (train=1.000, test=0.774) total time=   2.1s\n",
      "[CV 2/10] END criterion=gini, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.863) balanced_accuracy: (train=1.000, test=0.747) f1: (train=1.000, test=0.783) total time=   2.1s\n",
      "[CV 3/10] END criterion=gini, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.856) balanced_accuracy: (train=1.000, test=0.739) f1: (train=1.000, test=0.773) total time=   2.0s\n",
      "[CV 4/10] END criterion=gini, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.737) f1: (train=1.000, test=0.772) total time=   2.2s\n",
      "[CV 5/10] END criterion=gini, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.745) f1: (train=1.000, test=0.780) total time=   2.0s\n",
      "[CV 6/10] END criterion=gini, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.860) balanced_accuracy: (train=1.000, test=0.743) f1: (train=1.000, test=0.777) total time=   2.2s\n",
      "[CV 7/10] END criterion=gini, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.742) f1: (train=1.000, test=0.776) total time=   2.1s\n",
      "[CV 8/10] END criterion=gini, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.743) f1: (train=1.000, test=0.777) total time=   2.0s\n",
      "[CV 9/10] END criterion=gini, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.861) balanced_accuracy: (train=1.000, test=0.748) f1: (train=1.000, test=0.782) total time=   2.1s\n",
      "[CV 10/10] END criterion=gini, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.863) balanced_accuracy: (train=1.000, test=0.754) f1: (train=1.000, test=0.787) total time=   2.0s\n",
      "[CV 1/10] END criterion=gini, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.856) balanced_accuracy: (train=1.000, test=0.740) f1: (train=1.000, test=0.773) total time=   2.1s\n",
      "[CV 2/10] END criterion=gini, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.865) balanced_accuracy: (train=1.000, test=0.749) f1: (train=1.000, test=0.785) total time=   2.1s\n",
      "[CV 3/10] END criterion=gini, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.856) balanced_accuracy: (train=1.000, test=0.738) f1: (train=1.000, test=0.771) total time=   2.0s\n",
      "[CV 4/10] END criterion=gini, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.739) f1: (train=1.000, test=0.774) total time=   2.0s\n",
      "[CV 5/10] END criterion=gini, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.747) f1: (train=1.000, test=0.782) total time=   2.0s\n",
      "[CV 6/10] END criterion=gini, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.742) f1: (train=1.000, test=0.776) total time=   2.0s\n",
      "[CV 7/10] END criterion=gini, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.742) f1: (train=1.000, test=0.775) total time=   2.0s\n",
      "[CV 8/10] END criterion=gini, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.860) balanced_accuracy: (train=1.000, test=0.743) f1: (train=1.000, test=0.778) total time=   2.1s\n",
      "[CV 9/10] END criterion=gini, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.748) f1: (train=1.000, test=0.783) total time=   2.0s\n",
      "[CV 10/10] END criterion=gini, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.754) f1: (train=1.000, test=0.786) total time=   2.0s\n",
      "[CV 1/10] END criterion=gini, max_features=log2, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.740) f1: (train=1.000, test=0.774) total time=   1.2s\n",
      "[CV 2/10] END criterion=gini, max_features=log2, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.863) balanced_accuracy: (train=1.000, test=0.747) f1: (train=1.000, test=0.783) total time=   1.1s\n",
      "[CV 3/10] END criterion=gini, max_features=log2, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.740) f1: (train=1.000, test=0.774) total time=   1.1s\n",
      "[CV 4/10] END criterion=gini, max_features=log2, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.739) f1: (train=1.000, test=0.775) total time=   1.1s\n",
      "[CV 5/10] END criterion=gini, max_features=log2, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.745) f1: (train=1.000, test=0.781) total time=   1.1s\n",
      "[CV 6/10] END criterion=gini, max_features=log2, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.743) f1: (train=1.000, test=0.777) total time=   1.1s\n",
      "[CV 7/10] END criterion=gini, max_features=log2, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.860) balanced_accuracy: (train=1.000, test=0.744) f1: (train=1.000, test=0.778) total time=   1.1s\n",
      "[CV 8/10] END criterion=gini, max_features=log2, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.743) f1: (train=1.000, test=0.777) total time=   1.2s\n",
      "[CV 9/10] END criterion=gini, max_features=log2, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.861) balanced_accuracy: (train=1.000, test=0.747) f1: (train=1.000, test=0.781) total time=   1.1s\n",
      "[CV 10/10] END criterion=gini, max_features=log2, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.863) balanced_accuracy: (train=1.000, test=0.754) f1: (train=1.000, test=0.787) total time=   1.1s\n",
      "[CV 1/10] END criterion=gini, max_features=log2, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.855) balanced_accuracy: (train=1.000, test=0.739) f1: (train=1.000, test=0.772) total time=   1.1s\n",
      "[CV 2/10] END criterion=gini, max_features=log2, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.864) balanced_accuracy: (train=1.000, test=0.749) f1: (train=1.000, test=0.785) total time=   1.1s\n",
      "[CV 3/10] END criterion=gini, max_features=log2, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.856) balanced_accuracy: (train=1.000, test=0.738) f1: (train=1.000, test=0.772) total time=   1.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/10] END criterion=gini, max_features=log2, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.738) f1: (train=1.000, test=0.773) total time=   1.1s\n",
      "[CV 5/10] END criterion=gini, max_features=log2, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.745) f1: (train=1.000, test=0.781) total time=   1.1s\n",
      "[CV 6/10] END criterion=gini, max_features=log2, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.860) balanced_accuracy: (train=1.000, test=0.743) f1: (train=1.000, test=0.777) total time=   1.1s\n",
      "[CV 7/10] END criterion=gini, max_features=log2, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.741) f1: (train=1.000, test=0.775) total time=   1.1s\n",
      "[CV 8/10] END criterion=gini, max_features=log2, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.742) f1: (train=1.000, test=0.777) total time=   1.1s\n",
      "[CV 9/10] END criterion=gini, max_features=log2, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.861) balanced_accuracy: (train=1.000, test=0.748) f1: (train=1.000, test=0.781) total time=   1.2s\n",
      "[CV 10/10] END criterion=gini, max_features=log2, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.752) f1: (train=1.000, test=0.785) total time=   1.1s\n",
      "[CV 1/10] END criterion=gini, max_features=log2, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.740) f1: (train=1.000, test=0.774) total time=   1.1s\n",
      "[CV 2/10] END criterion=gini, max_features=log2, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.864) balanced_accuracy: (train=1.000, test=0.748) f1: (train=1.000, test=0.784) total time=   1.1s\n",
      "[CV 3/10] END criterion=gini, max_features=log2, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.739) f1: (train=1.000, test=0.773) total time=   1.1s\n",
      "[CV 4/10] END criterion=gini, max_features=log2, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.739) f1: (train=1.000, test=0.774) total time=   1.1s\n",
      "[CV 5/10] END criterion=gini, max_features=log2, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.861) balanced_accuracy: (train=1.000, test=0.745) f1: (train=1.000, test=0.780) total time=   1.1s\n",
      "[CV 6/10] END criterion=gini, max_features=log2, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.743) f1: (train=1.000, test=0.776) total time=   1.2s\n",
      "[CV 7/10] END criterion=gini, max_features=log2, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.743) f1: (train=1.000, test=0.777) total time=   1.2s\n",
      "[CV 8/10] END criterion=gini, max_features=log2, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.741) f1: (train=1.000, test=0.775) total time=   1.2s\n",
      "[CV 9/10] END criterion=gini, max_features=log2, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.863) balanced_accuracy: (train=1.000, test=0.750) f1: (train=1.000, test=0.784) total time=   1.2s\n",
      "[CV 10/10] END criterion=gini, max_features=log2, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.754) f1: (train=1.000, test=0.786) total time=   1.2s\n",
      "[CV 1/10] END criterion=gini, max_features=log2, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.740) f1: (train=1.000, test=0.774) total time=   2.1s\n",
      "[CV 2/10] END criterion=gini, max_features=log2, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.863) balanced_accuracy: (train=1.000, test=0.747) f1: (train=1.000, test=0.783) total time=   2.0s\n",
      "[CV 3/10] END criterion=gini, max_features=log2, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.740) f1: (train=1.000, test=0.773) total time=   2.1s\n",
      "[CV 4/10] END criterion=gini, max_features=log2, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.738) f1: (train=1.000, test=0.773) total time=   2.0s\n",
      "[CV 5/10] END criterion=gini, max_features=log2, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.863) balanced_accuracy: (train=1.000, test=0.747) f1: (train=1.000, test=0.782) total time=   2.1s\n",
      "[CV 6/10] END criterion=gini, max_features=log2, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.744) f1: (train=1.000, test=0.778) total time=   2.1s\n",
      "[CV 7/10] END criterion=gini, max_features=log2, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.743) f1: (train=1.000, test=0.777) total time=   2.1s\n",
      "[CV 8/10] END criterion=gini, max_features=log2, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.860) balanced_accuracy: (train=1.000, test=0.743) f1: (train=1.000, test=0.778) total time=   2.1s\n",
      "[CV 9/10] END criterion=gini, max_features=log2, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.747) f1: (train=1.000, test=0.782) total time=   2.1s\n",
      "[CV 10/10] END criterion=gini, max_features=log2, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.752) f1: (train=1.000, test=0.785) total time=   2.1s\n",
      "[CV 1/10] END criterion=gini, max_features=log2, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.741) f1: (train=1.000, test=0.774) total time=   2.1s\n",
      "[CV 2/10] END criterion=gini, max_features=log2, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.863) balanced_accuracy: (train=1.000, test=0.747) f1: (train=1.000, test=0.783) total time=   2.0s\n",
      "[CV 3/10] END criterion=gini, max_features=log2, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.856) balanced_accuracy: (train=1.000, test=0.739) f1: (train=1.000, test=0.773) total time=   2.0s\n",
      "[CV 4/10] END criterion=gini, max_features=log2, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.737) f1: (train=1.000, test=0.772) total time=   2.1s\n",
      "[CV 5/10] END criterion=gini, max_features=log2, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.745) f1: (train=1.000, test=0.780) total time=   2.0s\n",
      "[CV 6/10] END criterion=gini, max_features=log2, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.860) balanced_accuracy: (train=1.000, test=0.743) f1: (train=1.000, test=0.777) total time=   2.0s\n",
      "[CV 7/10] END criterion=gini, max_features=log2, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.742) f1: (train=1.000, test=0.776) total time=   2.0s\n",
      "[CV 8/10] END criterion=gini, max_features=log2, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.743) f1: (train=1.000, test=0.777) total time=   2.1s\n",
      "[CV 9/10] END criterion=gini, max_features=log2, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.861) balanced_accuracy: (train=1.000, test=0.748) f1: (train=1.000, test=0.782) total time=   2.1s\n",
      "[CV 10/10] END criterion=gini, max_features=log2, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.863) balanced_accuracy: (train=1.000, test=0.754) f1: (train=1.000, test=0.787) total time=   2.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/10] END criterion=gini, max_features=log2, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.741) f1: (train=1.000, test=0.774) total time=   2.2s\n",
      "[CV 2/10] END criterion=gini, max_features=log2, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.865) balanced_accuracy: (train=1.000, test=0.749) f1: (train=1.000, test=0.785) total time=   2.3s\n",
      "[CV 3/10] END criterion=gini, max_features=log2, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.740) f1: (train=1.000, test=0.773) total time=   2.4s\n",
      "[CV 4/10] END criterion=gini, max_features=log2, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.740) f1: (train=1.000, test=0.775) total time=   2.2s\n",
      "[CV 5/10] END criterion=gini, max_features=log2, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.746) f1: (train=1.000, test=0.781) total time=   2.3s\n",
      "[CV 6/10] END criterion=gini, max_features=log2, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.742) f1: (train=1.000, test=0.776) total time=   2.3s\n",
      "[CV 7/10] END criterion=gini, max_features=log2, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.856) balanced_accuracy: (train=1.000, test=0.740) f1: (train=1.000, test=0.773) total time=   2.2s\n",
      "[CV 8/10] END criterion=gini, max_features=log2, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.742) f1: (train=1.000, test=0.776) total time=   2.2s\n",
      "[CV 9/10] END criterion=gini, max_features=log2, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.861) balanced_accuracy: (train=1.000, test=0.747) f1: (train=1.000, test=0.782) total time=   2.1s\n",
      "[CV 10/10] END criterion=gini, max_features=log2, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.863) balanced_accuracy: (train=1.000, test=0.754) f1: (train=1.000, test=0.787) total time=   2.2s\n",
      "[CV 1/10] END criterion=entropy, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.855) balanced_accuracy: (train=1.000, test=0.738) f1: (train=1.000, test=0.771) total time=   1.2s\n",
      "[CV 2/10] END criterion=entropy, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.863) balanced_accuracy: (train=1.000, test=0.747) f1: (train=1.000, test=0.783) total time=   1.2s\n",
      "[CV 3/10] END criterion=entropy, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.856) balanced_accuracy: (train=1.000, test=0.739) f1: (train=1.000, test=0.772) total time=   1.2s\n",
      "[CV 4/10] END criterion=entropy, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.740) f1: (train=1.000, test=0.774) total time=   1.2s\n",
      "[CV 5/10] END criterion=entropy, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.861) balanced_accuracy: (train=1.000, test=0.745) f1: (train=1.000, test=0.779) total time=   1.2s\n",
      "[CV 6/10] END criterion=entropy, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.742) f1: (train=1.000, test=0.776) total time=   1.2s\n",
      "[CV 7/10] END criterion=entropy, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.741) f1: (train=1.000, test=0.775) total time=   1.2s\n",
      "[CV 8/10] END criterion=entropy, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.742) f1: (train=1.000, test=0.776) total time=   1.2s\n",
      "[CV 9/10] END criterion=entropy, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.861) balanced_accuracy: (train=1.000, test=0.747) f1: (train=1.000, test=0.781) total time=   1.2s\n",
      "[CV 10/10] END criterion=entropy, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.753) f1: (train=1.000, test=0.785) total time=   1.2s\n",
      "[CV 1/10] END criterion=entropy, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.856) balanced_accuracy: (train=1.000, test=0.739) f1: (train=1.000, test=0.772) total time=   1.3s\n",
      "[CV 2/10] END criterion=entropy, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.865) balanced_accuracy: (train=1.000, test=0.749) f1: (train=1.000, test=0.785) total time=   1.2s\n",
      "[CV 3/10] END criterion=entropy, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.740) f1: (train=1.000, test=0.774) total time=   1.2s\n",
      "[CV 4/10] END criterion=entropy, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.738) f1: (train=1.000, test=0.772) total time=   1.2s\n",
      "[CV 5/10] END criterion=entropy, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.861) balanced_accuracy: (train=1.000, test=0.745) f1: (train=1.000, test=0.780) total time=   1.2s\n",
      "[CV 6/10] END criterion=entropy, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.742) f1: (train=1.000, test=0.776) total time=   1.2s\n",
      "[CV 7/10] END criterion=entropy, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.855) balanced_accuracy: (train=1.000, test=0.739) f1: (train=1.000, test=0.771) total time=   1.2s\n",
      "[CV 8/10] END criterion=entropy, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.741) f1: (train=1.000, test=0.776) total time=   1.2s\n",
      "[CV 9/10] END criterion=entropy, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.860) balanced_accuracy: (train=1.000, test=0.746) f1: (train=1.000, test=0.779) total time=   1.1s\n",
      "[CV 10/10] END criterion=entropy, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.753) f1: (train=1.000, test=0.785) total time=   1.2s\n",
      "[CV 1/10] END criterion=entropy, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.740) f1: (train=1.000, test=0.774) total time=   1.1s\n",
      "[CV 2/10] END criterion=entropy, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.863) balanced_accuracy: (train=1.000, test=0.748) f1: (train=1.000, test=0.783) total time=   1.3s\n",
      "[CV 3/10] END criterion=entropy, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.856) balanced_accuracy: (train=1.000, test=0.739) f1: (train=1.000, test=0.772) total time=   1.2s\n",
      "[CV 4/10] END criterion=entropy, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.739) f1: (train=1.000, test=0.773) total time=   1.2s\n",
      "[CV 5/10] END criterion=entropy, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.746) f1: (train=1.000, test=0.782) total time=   1.2s\n",
      "[CV 6/10] END criterion=entropy, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.860) balanced_accuracy: (train=1.000, test=0.744) f1: (train=1.000, test=0.778) total time=   1.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 7/10] END criterion=entropy, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.740) f1: (train=1.000, test=0.774) total time=   1.2s\n",
      "[CV 8/10] END criterion=entropy, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.743) f1: (train=1.000, test=0.777) total time=   1.2s\n",
      "[CV 9/10] END criterion=entropy, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.860) balanced_accuracy: (train=1.000, test=0.746) f1: (train=1.000, test=0.780) total time=   1.2s\n",
      "[CV 10/10] END criterion=entropy, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.752) f1: (train=1.000, test=0.785) total time=   1.2s\n",
      "[CV 1/10] END criterion=entropy, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.855) balanced_accuracy: (train=1.000, test=0.738) f1: (train=1.000, test=0.771) total time=   2.2s\n",
      "[CV 2/10] END criterion=entropy, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.864) balanced_accuracy: (train=1.000, test=0.747) f1: (train=1.000, test=0.783) total time=   2.2s\n",
      "[CV 3/10] END criterion=entropy, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.856) balanced_accuracy: (train=1.000, test=0.739) f1: (train=1.000, test=0.772) total time=   2.2s\n",
      "[CV 4/10] END criterion=entropy, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.739) f1: (train=1.000, test=0.774) total time=   2.1s\n",
      "[CV 5/10] END criterion=entropy, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.861) balanced_accuracy: (train=1.000, test=0.745) f1: (train=1.000, test=0.780) total time=   2.2s\n",
      "[CV 6/10] END criterion=entropy, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.740) f1: (train=1.000, test=0.774) total time=   2.1s\n",
      "[CV 7/10] END criterion=entropy, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.742) f1: (train=1.000, test=0.776) total time=   2.2s\n",
      "[CV 8/10] END criterion=entropy, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.743) f1: (train=1.000, test=0.777) total time=   2.2s\n",
      "[CV 9/10] END criterion=entropy, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.748) f1: (train=1.000, test=0.782) total time=   2.2s\n",
      "[CV 10/10] END criterion=entropy, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.863) balanced_accuracy: (train=1.000, test=0.752) f1: (train=1.000, test=0.785) total time=   2.1s\n",
      "[CV 1/10] END criterion=entropy, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.856) balanced_accuracy: (train=1.000, test=0.739) f1: (train=1.000, test=0.772) total time=   2.2s\n",
      "[CV 2/10] END criterion=entropy, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.865) balanced_accuracy: (train=1.000, test=0.748) f1: (train=1.000, test=0.784) total time=   2.1s\n",
      "[CV 3/10] END criterion=entropy, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.856) balanced_accuracy: (train=1.000, test=0.739) f1: (train=1.000, test=0.772) total time=   2.1s\n",
      "[CV 4/10] END criterion=entropy, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.736) f1: (train=1.000, test=0.771) total time=   2.1s\n",
      "[CV 5/10] END criterion=entropy, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.861) balanced_accuracy: (train=1.000, test=0.744) f1: (train=1.000, test=0.779) total time=   2.1s\n",
      "[CV 6/10] END criterion=entropy, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.742) f1: (train=1.000, test=0.776) total time=   2.1s\n",
      "[CV 7/10] END criterion=entropy, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.856) balanced_accuracy: (train=1.000, test=0.740) f1: (train=1.000, test=0.773) total time=   2.1s\n",
      "[CV 8/10] END criterion=entropy, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.860) balanced_accuracy: (train=1.000, test=0.742) f1: (train=1.000, test=0.777) total time=   2.1s\n",
      "[CV 9/10] END criterion=entropy, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.861) balanced_accuracy: (train=1.000, test=0.747) f1: (train=1.000, test=0.781) total time=   2.1s\n",
      "[CV 10/10] END criterion=entropy, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.863) balanced_accuracy: (train=1.000, test=0.753) f1: (train=1.000, test=0.786) total time=   2.1s\n",
      "[CV 1/10] END criterion=entropy, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.740) f1: (train=1.000, test=0.774) total time=   2.1s\n",
      "[CV 2/10] END criterion=entropy, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.864) balanced_accuracy: (train=1.000, test=0.748) f1: (train=1.000, test=0.784) total time=   2.2s\n",
      "[CV 3/10] END criterion=entropy, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.740) f1: (train=1.000, test=0.774) total time=   2.1s\n",
      "[CV 4/10] END criterion=entropy, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.740) f1: (train=1.000, test=0.775) total time=   2.1s\n",
      "[CV 5/10] END criterion=entropy, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.863) balanced_accuracy: (train=1.000, test=0.747) f1: (train=1.000, test=0.782) total time=   2.1s\n",
      "[CV 6/10] END criterion=entropy, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.743) f1: (train=1.000, test=0.777) total time=   2.1s\n",
      "[CV 7/10] END criterion=entropy, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.740) f1: (train=1.000, test=0.773) total time=   2.1s\n",
      "[CV 8/10] END criterion=entropy, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.861) balanced_accuracy: (train=1.000, test=0.743) f1: (train=1.000, test=0.779) total time=   2.0s\n",
      "[CV 9/10] END criterion=entropy, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.748) f1: (train=1.000, test=0.782) total time=   2.0s\n",
      "[CV 10/10] END criterion=entropy, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.752) f1: (train=1.000, test=0.785) total time=   2.0s\n",
      "[CV 1/10] END criterion=entropy, max_features=log2, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.855) balanced_accuracy: (train=1.000, test=0.738) f1: (train=1.000, test=0.771) total time=   1.1s\n",
      "[CV 2/10] END criterion=entropy, max_features=log2, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.863) balanced_accuracy: (train=1.000, test=0.747) f1: (train=1.000, test=0.783) total time=   1.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/10] END criterion=entropy, max_features=log2, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.856) balanced_accuracy: (train=1.000, test=0.739) f1: (train=1.000, test=0.772) total time=   1.1s\n",
      "[CV 4/10] END criterion=entropy, max_features=log2, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.740) f1: (train=1.000, test=0.774) total time=   1.1s\n",
      "[CV 5/10] END criterion=entropy, max_features=log2, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.861) balanced_accuracy: (train=1.000, test=0.745) f1: (train=1.000, test=0.779) total time=   1.1s\n",
      "[CV 6/10] END criterion=entropy, max_features=log2, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.742) f1: (train=1.000, test=0.776) total time=   1.1s\n",
      "[CV 7/10] END criterion=entropy, max_features=log2, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.741) f1: (train=1.000, test=0.775) total time=   1.1s\n",
      "[CV 8/10] END criterion=entropy, max_features=log2, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.742) f1: (train=1.000, test=0.776) total time=   1.1s\n",
      "[CV 9/10] END criterion=entropy, max_features=log2, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.861) balanced_accuracy: (train=1.000, test=0.747) f1: (train=1.000, test=0.781) total time=   1.1s\n",
      "[CV 10/10] END criterion=entropy, max_features=log2, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.753) f1: (train=1.000, test=0.785) total time=   1.1s\n",
      "[CV 1/10] END criterion=entropy, max_features=log2, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.856) balanced_accuracy: (train=1.000, test=0.739) f1: (train=1.000, test=0.772) total time=   1.1s\n",
      "[CV 2/10] END criterion=entropy, max_features=log2, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.865) balanced_accuracy: (train=1.000, test=0.749) f1: (train=1.000, test=0.785) total time=   1.1s\n",
      "[CV 3/10] END criterion=entropy, max_features=log2, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.740) f1: (train=1.000, test=0.774) total time=   1.1s\n",
      "[CV 4/10] END criterion=entropy, max_features=log2, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.738) f1: (train=1.000, test=0.772) total time=   1.2s\n",
      "[CV 5/10] END criterion=entropy, max_features=log2, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.861) balanced_accuracy: (train=1.000, test=0.745) f1: (train=1.000, test=0.780) total time=   1.2s\n",
      "[CV 6/10] END criterion=entropy, max_features=log2, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.742) f1: (train=1.000, test=0.776) total time=   1.1s\n",
      "[CV 7/10] END criterion=entropy, max_features=log2, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.855) balanced_accuracy: (train=1.000, test=0.739) f1: (train=1.000, test=0.771) total time=   1.1s\n",
      "[CV 8/10] END criterion=entropy, max_features=log2, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.741) f1: (train=1.000, test=0.776) total time=   1.1s\n",
      "[CV 9/10] END criterion=entropy, max_features=log2, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.860) balanced_accuracy: (train=1.000, test=0.746) f1: (train=1.000, test=0.779) total time=   1.1s\n",
      "[CV 10/10] END criterion=entropy, max_features=log2, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.753) f1: (train=1.000, test=0.785) total time=   1.3s\n",
      "[CV 1/10] END criterion=entropy, max_features=log2, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.856) balanced_accuracy: (train=1.000, test=0.739) f1: (train=1.000, test=0.773) total time=   1.3s\n",
      "[CV 2/10] END criterion=entropy, max_features=log2, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.864) balanced_accuracy: (train=1.000, test=0.747) f1: (train=1.000, test=0.784) total time=   1.3s\n",
      "[CV 3/10] END criterion=entropy, max_features=log2, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.739) f1: (train=1.000, test=0.773) total time=   1.4s\n",
      "[CV 4/10] END criterion=entropy, max_features=log2, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.740) f1: (train=1.000, test=0.775) total time=   1.3s\n",
      "[CV 5/10] END criterion=entropy, max_features=log2, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.863) balanced_accuracy: (train=1.000, test=0.747) f1: (train=1.000, test=0.783) total time=   1.4s\n",
      "[CV 6/10] END criterion=entropy, max_features=log2, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.742) f1: (train=1.000, test=0.775) total time=   1.3s\n",
      "[CV 7/10] END criterion=entropy, max_features=log2, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.740) f1: (train=1.000, test=0.773) total time=   1.4s\n",
      "[CV 8/10] END criterion=entropy, max_features=log2, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.860) balanced_accuracy: (train=1.000, test=0.743) f1: (train=1.000, test=0.778) total time=   1.2s\n",
      "[CV 9/10] END criterion=entropy, max_features=log2, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.750) f1: (train=1.000, test=0.783) total time=   1.4s\n",
      "[CV 10/10] END criterion=entropy, max_features=log2, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.752) f1: (train=1.000, test=0.785) total time=   1.3s\n",
      "[CV 1/10] END criterion=entropy, max_features=log2, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.855) balanced_accuracy: (train=1.000, test=0.738) f1: (train=1.000, test=0.771) total time=   2.4s\n",
      "[CV 2/10] END criterion=entropy, max_features=log2, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.864) balanced_accuracy: (train=1.000, test=0.747) f1: (train=1.000, test=0.783) total time=   2.2s\n",
      "[CV 3/10] END criterion=entropy, max_features=log2, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.856) balanced_accuracy: (train=1.000, test=0.739) f1: (train=1.000, test=0.772) total time=   2.2s\n",
      "[CV 4/10] END criterion=entropy, max_features=log2, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.739) f1: (train=1.000, test=0.774) total time=   2.2s\n",
      "[CV 5/10] END criterion=entropy, max_features=log2, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.861) balanced_accuracy: (train=1.000, test=0.745) f1: (train=1.000, test=0.780) total time=   2.1s\n",
      "[CV 6/10] END criterion=entropy, max_features=log2, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.740) f1: (train=1.000, test=0.774) total time=   2.2s\n",
      "[CV 7/10] END criterion=entropy, max_features=log2, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.742) f1: (train=1.000, test=0.776) total time=   2.2s\n",
      "[CV 8/10] END criterion=entropy, max_features=log2, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.743) f1: (train=1.000, test=0.777) total time=   2.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 9/10] END criterion=entropy, max_features=log2, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.748) f1: (train=1.000, test=0.782) total time=   2.1s\n",
      "[CV 10/10] END criterion=entropy, max_features=log2, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.863) balanced_accuracy: (train=1.000, test=0.752) f1: (train=1.000, test=0.785) total time=   2.1s\n",
      "[CV 1/10] END criterion=entropy, max_features=log2, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.856) balanced_accuracy: (train=1.000, test=0.739) f1: (train=1.000, test=0.772) total time=   2.2s\n",
      "[CV 2/10] END criterion=entropy, max_features=log2, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.865) balanced_accuracy: (train=1.000, test=0.748) f1: (train=1.000, test=0.784) total time=   2.1s\n",
      "[CV 3/10] END criterion=entropy, max_features=log2, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.856) balanced_accuracy: (train=1.000, test=0.739) f1: (train=1.000, test=0.772) total time=   2.1s\n",
      "[CV 4/10] END criterion=entropy, max_features=log2, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.736) f1: (train=1.000, test=0.771) total time=   2.1s\n",
      "[CV 5/10] END criterion=entropy, max_features=log2, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.861) balanced_accuracy: (train=1.000, test=0.744) f1: (train=1.000, test=0.779) total time=   2.1s\n",
      "[CV 6/10] END criterion=entropy, max_features=log2, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.742) f1: (train=1.000, test=0.776) total time=   2.1s\n",
      "[CV 7/10] END criterion=entropy, max_features=log2, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.856) balanced_accuracy: (train=1.000, test=0.740) f1: (train=1.000, test=0.773) total time=   2.1s\n",
      "[CV 8/10] END criterion=entropy, max_features=log2, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.860) balanced_accuracy: (train=1.000, test=0.742) f1: (train=1.000, test=0.777) total time=   2.1s\n",
      "[CV 9/10] END criterion=entropy, max_features=log2, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.861) balanced_accuracy: (train=1.000, test=0.747) f1: (train=1.000, test=0.781) total time=   2.1s\n",
      "[CV 10/10] END criterion=entropy, max_features=log2, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.863) balanced_accuracy: (train=1.000, test=0.753) f1: (train=1.000, test=0.786) total time=   2.1s\n",
      "[CV 1/10] END criterion=entropy, max_features=log2, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.856) balanced_accuracy: (train=1.000, test=0.739) f1: (train=1.000, test=0.772) total time=   2.1s\n",
      "[CV 2/10] END criterion=entropy, max_features=log2, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.864) balanced_accuracy: (train=1.000, test=0.748) f1: (train=1.000, test=0.784) total time=   2.1s\n",
      "[CV 3/10] END criterion=entropy, max_features=log2, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.856) balanced_accuracy: (train=1.000, test=0.739) f1: (train=1.000, test=0.772) total time=   2.1s\n",
      "[CV 4/10] END criterion=entropy, max_features=log2, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.738) f1: (train=1.000, test=0.773) total time=   2.1s\n",
      "[CV 5/10] END criterion=entropy, max_features=log2, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.746) f1: (train=1.000, test=0.781) total time=   2.1s\n",
      "[CV 6/10] END criterion=entropy, max_features=log2, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.743) f1: (train=1.000, test=0.777) total time=   2.1s\n",
      "[CV 7/10] END criterion=entropy, max_features=log2, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.741) f1: (train=1.000, test=0.775) total time=   2.1s\n",
      "[CV 8/10] END criterion=entropy, max_features=log2, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.860) balanced_accuracy: (train=1.000, test=0.743) f1: (train=1.000, test=0.778) total time=   2.1s\n",
      "[CV 9/10] END criterion=entropy, max_features=log2, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.861) balanced_accuracy: (train=1.000, test=0.748) f1: (train=1.000, test=0.781) total time=   2.1s\n",
      "[CV 10/10] END criterion=entropy, max_features=log2, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.861) balanced_accuracy: (train=1.000, test=0.751) f1: (train=1.000, test=0.783) total time=   2.1s\n",
      "[CV 1/10] END criterion=log_loss, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.855) balanced_accuracy: (train=1.000, test=0.738) f1: (train=1.000, test=0.771) total time=   1.1s\n",
      "[CV 2/10] END criterion=log_loss, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.863) balanced_accuracy: (train=1.000, test=0.747) f1: (train=1.000, test=0.783) total time=   1.1s\n",
      "[CV 3/10] END criterion=log_loss, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.856) balanced_accuracy: (train=1.000, test=0.739) f1: (train=1.000, test=0.772) total time=   1.1s\n",
      "[CV 4/10] END criterion=log_loss, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.740) f1: (train=1.000, test=0.774) total time=   1.1s\n",
      "[CV 5/10] END criterion=log_loss, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.861) balanced_accuracy: (train=1.000, test=0.745) f1: (train=1.000, test=0.779) total time=   1.1s\n",
      "[CV 6/10] END criterion=log_loss, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.742) f1: (train=1.000, test=0.776) total time=   1.1s\n",
      "[CV 7/10] END criterion=log_loss, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.741) f1: (train=1.000, test=0.775) total time=   1.1s\n",
      "[CV 8/10] END criterion=log_loss, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.742) f1: (train=1.000, test=0.776) total time=   1.1s\n",
      "[CV 9/10] END criterion=log_loss, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.861) balanced_accuracy: (train=1.000, test=0.747) f1: (train=1.000, test=0.781) total time=   1.1s\n",
      "[CV 10/10] END criterion=log_loss, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.753) f1: (train=1.000, test=0.785) total time=   1.1s\n",
      "[CV 1/10] END criterion=log_loss, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.856) balanced_accuracy: (train=1.000, test=0.739) f1: (train=1.000, test=0.772) total time=   1.1s\n",
      "[CV 2/10] END criterion=log_loss, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.865) balanced_accuracy: (train=1.000, test=0.749) f1: (train=1.000, test=0.785) total time=   1.1s\n",
      "[CV 3/10] END criterion=log_loss, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.740) f1: (train=1.000, test=0.774) total time=   1.1s\n",
      "[CV 4/10] END criterion=log_loss, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.738) f1: (train=1.000, test=0.772) total time=   1.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/10] END criterion=log_loss, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.861) balanced_accuracy: (train=1.000, test=0.745) f1: (train=1.000, test=0.780) total time=   1.1s\n",
      "[CV 6/10] END criterion=log_loss, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.742) f1: (train=1.000, test=0.776) total time=   1.0s\n",
      "[CV 7/10] END criterion=log_loss, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.855) balanced_accuracy: (train=1.000, test=0.739) f1: (train=1.000, test=0.771) total time=   1.1s\n",
      "[CV 8/10] END criterion=log_loss, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.741) f1: (train=1.000, test=0.776) total time=   1.1s\n",
      "[CV 9/10] END criterion=log_loss, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.860) balanced_accuracy: (train=1.000, test=0.746) f1: (train=1.000, test=0.779) total time=   1.1s\n",
      "[CV 10/10] END criterion=log_loss, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.753) f1: (train=1.000, test=0.785) total time=   1.1s\n",
      "[CV 1/10] END criterion=log_loss, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.856) balanced_accuracy: (train=1.000, test=0.740) f1: (train=1.000, test=0.773) total time=   1.2s\n",
      "[CV 2/10] END criterion=log_loss, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.864) balanced_accuracy: (train=1.000, test=0.749) f1: (train=1.000, test=0.785) total time=   1.1s\n",
      "[CV 3/10] END criterion=log_loss, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.856) balanced_accuracy: (train=1.000, test=0.738) f1: (train=1.000, test=0.772) total time=   1.2s\n",
      "[CV 4/10] END criterion=log_loss, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.856) balanced_accuracy: (train=1.000, test=0.736) f1: (train=1.000, test=0.771) total time=   1.2s\n",
      "[CV 5/10] END criterion=log_loss, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.863) balanced_accuracy: (train=1.000, test=0.747) f1: (train=1.000, test=0.782) total time=   1.2s\n",
      "[CV 6/10] END criterion=log_loss, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.742) f1: (train=1.000, test=0.776) total time=   1.2s\n",
      "[CV 7/10] END criterion=log_loss, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.856) balanced_accuracy: (train=1.000, test=0.739) f1: (train=1.000, test=0.773) total time=   1.2s\n",
      "[CV 8/10] END criterion=log_loss, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.860) balanced_accuracy: (train=1.000, test=0.743) f1: (train=1.000, test=0.778) total time=   1.2s\n",
      "[CV 9/10] END criterion=log_loss, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.861) balanced_accuracy: (train=1.000, test=0.747) f1: (train=1.000, test=0.781) total time=   1.2s\n",
      "[CV 10/10] END criterion=log_loss, max_features=sqrt, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.752) f1: (train=1.000, test=0.785) total time=   1.1s\n",
      "[CV 1/10] END criterion=log_loss, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.855) balanced_accuracy: (train=1.000, test=0.738) f1: (train=1.000, test=0.771) total time=   2.0s\n",
      "[CV 2/10] END criterion=log_loss, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.864) balanced_accuracy: (train=1.000, test=0.747) f1: (train=1.000, test=0.783) total time=   2.2s\n",
      "[CV 3/10] END criterion=log_loss, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.856) balanced_accuracy: (train=1.000, test=0.739) f1: (train=1.000, test=0.772) total time=   2.1s\n",
      "[CV 4/10] END criterion=log_loss, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.739) f1: (train=1.000, test=0.774) total time=   2.1s\n",
      "[CV 5/10] END criterion=log_loss, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.861) balanced_accuracy: (train=1.000, test=0.745) f1: (train=1.000, test=0.780) total time=   2.1s\n",
      "[CV 6/10] END criterion=log_loss, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.740) f1: (train=1.000, test=0.774) total time=   2.1s\n",
      "[CV 7/10] END criterion=log_loss, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.742) f1: (train=1.000, test=0.776) total time=   2.4s\n",
      "[CV 8/10] END criterion=log_loss, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.743) f1: (train=1.000, test=0.777) total time=   2.3s\n",
      "[CV 9/10] END criterion=log_loss, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.748) f1: (train=1.000, test=0.782) total time=   2.4s\n",
      "[CV 10/10] END criterion=log_loss, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.863) balanced_accuracy: (train=1.000, test=0.752) f1: (train=1.000, test=0.785) total time=   2.3s\n",
      "[CV 1/10] END criterion=log_loss, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.856) balanced_accuracy: (train=1.000, test=0.739) f1: (train=1.000, test=0.772) total time=   2.1s\n",
      "[CV 2/10] END criterion=log_loss, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.865) balanced_accuracy: (train=1.000, test=0.748) f1: (train=1.000, test=0.784) total time=   2.2s\n",
      "[CV 3/10] END criterion=log_loss, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.856) balanced_accuracy: (train=1.000, test=0.739) f1: (train=1.000, test=0.772) total time=   2.2s\n",
      "[CV 4/10] END criterion=log_loss, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.736) f1: (train=1.000, test=0.771) total time=   2.2s\n",
      "[CV 5/10] END criterion=log_loss, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.861) balanced_accuracy: (train=1.000, test=0.744) f1: (train=1.000, test=0.779) total time=   2.2s\n",
      "[CV 6/10] END criterion=log_loss, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.742) f1: (train=1.000, test=0.776) total time=   2.2s\n",
      "[CV 7/10] END criterion=log_loss, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.856) balanced_accuracy: (train=1.000, test=0.740) f1: (train=1.000, test=0.773) total time=   2.0s\n",
      "[CV 8/10] END criterion=log_loss, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.860) balanced_accuracy: (train=1.000, test=0.742) f1: (train=1.000, test=0.777) total time=   2.1s\n",
      "[CV 9/10] END criterion=log_loss, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.861) balanced_accuracy: (train=1.000, test=0.747) f1: (train=1.000, test=0.781) total time=   2.1s\n",
      "[CV 10/10] END criterion=log_loss, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.863) balanced_accuracy: (train=1.000, test=0.753) f1: (train=1.000, test=0.786) total time=   2.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/10] END criterion=log_loss, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.856) balanced_accuracy: (train=1.000, test=0.740) f1: (train=1.000, test=0.773) total time=   2.2s\n",
      "[CV 2/10] END criterion=log_loss, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.864) balanced_accuracy: (train=1.000, test=0.747) f1: (train=1.000, test=0.783) total time=   2.3s\n",
      "[CV 3/10] END criterion=log_loss, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.740) f1: (train=1.000, test=0.774) total time=   2.2s\n",
      "[CV 4/10] END criterion=log_loss, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.738) f1: (train=1.000, test=0.772) total time=   2.1s\n",
      "[CV 5/10] END criterion=log_loss, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.747) f1: (train=1.000, test=0.782) total time=   2.1s\n",
      "[CV 6/10] END criterion=log_loss, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.860) balanced_accuracy: (train=1.000, test=0.743) f1: (train=1.000, test=0.778) total time=   2.1s\n",
      "[CV 7/10] END criterion=log_loss, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.742) f1: (train=1.000, test=0.775) total time=   2.1s\n",
      "[CV 8/10] END criterion=log_loss, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.860) balanced_accuracy: (train=1.000, test=0.742) f1: (train=1.000, test=0.777) total time=   2.2s\n",
      "[CV 9/10] END criterion=log_loss, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.748) f1: (train=1.000, test=0.782) total time=   2.2s\n",
      "[CV 10/10] END criterion=log_loss, max_features=sqrt, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.753) f1: (train=1.000, test=0.785) total time=   2.1s\n",
      "[CV 1/10] END criterion=log_loss, max_features=log2, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.855) balanced_accuracy: (train=1.000, test=0.738) f1: (train=1.000, test=0.771) total time=   1.2s\n",
      "[CV 2/10] END criterion=log_loss, max_features=log2, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.863) balanced_accuracy: (train=1.000, test=0.747) f1: (train=1.000, test=0.783) total time=   1.2s\n",
      "[CV 3/10] END criterion=log_loss, max_features=log2, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.856) balanced_accuracy: (train=1.000, test=0.739) f1: (train=1.000, test=0.772) total time=   1.2s\n",
      "[CV 4/10] END criterion=log_loss, max_features=log2, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.740) f1: (train=1.000, test=0.774) total time=   1.1s\n",
      "[CV 5/10] END criterion=log_loss, max_features=log2, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.861) balanced_accuracy: (train=1.000, test=0.745) f1: (train=1.000, test=0.779) total time=   1.2s\n",
      "[CV 6/10] END criterion=log_loss, max_features=log2, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.742) f1: (train=1.000, test=0.776) total time=   1.1s\n",
      "[CV 7/10] END criterion=log_loss, max_features=log2, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.741) f1: (train=1.000, test=0.775) total time=   1.2s\n",
      "[CV 8/10] END criterion=log_loss, max_features=log2, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.742) f1: (train=1.000, test=0.776) total time=   1.2s\n",
      "[CV 9/10] END criterion=log_loss, max_features=log2, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.861) balanced_accuracy: (train=1.000, test=0.747) f1: (train=1.000, test=0.781) total time=   1.2s\n",
      "[CV 10/10] END criterion=log_loss, max_features=log2, n_estimators=100, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.753) f1: (train=1.000, test=0.785) total time=   1.2s\n",
      "[CV 1/10] END criterion=log_loss, max_features=log2, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.856) balanced_accuracy: (train=1.000, test=0.739) f1: (train=1.000, test=0.772) total time=   1.2s\n",
      "[CV 2/10] END criterion=log_loss, max_features=log2, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.865) balanced_accuracy: (train=1.000, test=0.749) f1: (train=1.000, test=0.785) total time=   1.1s\n",
      "[CV 3/10] END criterion=log_loss, max_features=log2, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.740) f1: (train=1.000, test=0.774) total time=   1.2s\n",
      "[CV 4/10] END criterion=log_loss, max_features=log2, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.738) f1: (train=1.000, test=0.772) total time=   1.1s\n",
      "[CV 5/10] END criterion=log_loss, max_features=log2, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.861) balanced_accuracy: (train=1.000, test=0.745) f1: (train=1.000, test=0.780) total time=   1.2s\n",
      "[CV 6/10] END criterion=log_loss, max_features=log2, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.742) f1: (train=1.000, test=0.776) total time=   1.1s\n",
      "[CV 7/10] END criterion=log_loss, max_features=log2, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.855) balanced_accuracy: (train=1.000, test=0.739) f1: (train=1.000, test=0.771) total time=   1.2s\n",
      "[CV 8/10] END criterion=log_loss, max_features=log2, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.741) f1: (train=1.000, test=0.776) total time=   1.2s\n",
      "[CV 9/10] END criterion=log_loss, max_features=log2, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.860) balanced_accuracy: (train=1.000, test=0.746) f1: (train=1.000, test=0.779) total time=   1.2s\n",
      "[CV 10/10] END criterion=log_loss, max_features=log2, n_estimators=100, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.753) f1: (train=1.000, test=0.785) total time=   1.2s\n",
      "[CV 1/10] END criterion=log_loss, max_features=log2, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.740) f1: (train=1.000, test=0.773) total time=   1.2s\n",
      "[CV 2/10] END criterion=log_loss, max_features=log2, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.865) balanced_accuracy: (train=1.000, test=0.749) f1: (train=1.000, test=0.785) total time=   1.2s\n",
      "[CV 3/10] END criterion=log_loss, max_features=log2, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.856) balanced_accuracy: (train=1.000, test=0.738) f1: (train=1.000, test=0.771) total time=   1.2s\n",
      "[CV 4/10] END criterion=log_loss, max_features=log2, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.738) f1: (train=1.000, test=0.772) total time=   1.2s\n",
      "[CV 5/10] END criterion=log_loss, max_features=log2, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.746) f1: (train=1.000, test=0.781) total time=   1.2s\n",
      "[CV 6/10] END criterion=log_loss, max_features=log2, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.743) f1: (train=1.000, test=0.777) total time=   1.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 7/10] END criterion=log_loss, max_features=log2, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.742) f1: (train=1.000, test=0.775) total time=   1.2s\n",
      "[CV 8/10] END criterion=log_loss, max_features=log2, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.742) f1: (train=1.000, test=0.777) total time=   1.1s\n",
      "[CV 9/10] END criterion=log_loss, max_features=log2, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.863) balanced_accuracy: (train=1.000, test=0.749) f1: (train=1.000, test=0.784) total time=   1.1s\n",
      "[CV 10/10] END criterion=log_loss, max_features=log2, n_estimators=100, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.752) f1: (train=1.000, test=0.785) total time=   1.1s\n",
      "[CV 1/10] END criterion=log_loss, max_features=log2, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.855) balanced_accuracy: (train=1.000, test=0.738) f1: (train=1.000, test=0.771) total time=   2.0s\n",
      "[CV 2/10] END criterion=log_loss, max_features=log2, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.864) balanced_accuracy: (train=1.000, test=0.747) f1: (train=1.000, test=0.783) total time=   2.1s\n",
      "[CV 3/10] END criterion=log_loss, max_features=log2, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.856) balanced_accuracy: (train=1.000, test=0.739) f1: (train=1.000, test=0.772) total time=   2.1s\n",
      "[CV 4/10] END criterion=log_loss, max_features=log2, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.739) f1: (train=1.000, test=0.774) total time=   2.1s\n",
      "[CV 5/10] END criterion=log_loss, max_features=log2, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.861) balanced_accuracy: (train=1.000, test=0.745) f1: (train=1.000, test=0.780) total time=   2.1s\n",
      "[CV 6/10] END criterion=log_loss, max_features=log2, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.740) f1: (train=1.000, test=0.774) total time=   2.1s\n",
      "[CV 7/10] END criterion=log_loss, max_features=log2, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.742) f1: (train=1.000, test=0.776) total time=   2.1s\n",
      "[CV 8/10] END criterion=log_loss, max_features=log2, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.743) f1: (train=1.000, test=0.777) total time=   2.1s\n",
      "[CV 9/10] END criterion=log_loss, max_features=log2, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.748) f1: (train=1.000, test=0.782) total time=   2.1s\n",
      "[CV 10/10] END criterion=log_loss, max_features=log2, n_estimators=200, n_jobs=-1, random_state=50; accuracy: (train=1.000, test=0.863) balanced_accuracy: (train=1.000, test=0.752) f1: (train=1.000, test=0.785) total time=   2.1s\n",
      "[CV 1/10] END criterion=log_loss, max_features=log2, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.856) balanced_accuracy: (train=1.000, test=0.739) f1: (train=1.000, test=0.772) total time=   2.1s\n",
      "[CV 2/10] END criterion=log_loss, max_features=log2, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.865) balanced_accuracy: (train=1.000, test=0.748) f1: (train=1.000, test=0.784) total time=   2.1s\n",
      "[CV 3/10] END criterion=log_loss, max_features=log2, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.856) balanced_accuracy: (train=1.000, test=0.739) f1: (train=1.000, test=0.772) total time=   2.0s\n",
      "[CV 4/10] END criterion=log_loss, max_features=log2, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.857) balanced_accuracy: (train=1.000, test=0.736) f1: (train=1.000, test=0.771) total time=   2.1s\n",
      "[CV 5/10] END criterion=log_loss, max_features=log2, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.861) balanced_accuracy: (train=1.000, test=0.744) f1: (train=1.000, test=0.779) total time=   2.1s\n",
      "[CV 6/10] END criterion=log_loss, max_features=log2, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.742) f1: (train=1.000, test=0.776) total time=   2.1s\n",
      "[CV 7/10] END criterion=log_loss, max_features=log2, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.856) balanced_accuracy: (train=1.000, test=0.740) f1: (train=1.000, test=0.773) total time=   2.0s\n",
      "[CV 8/10] END criterion=log_loss, max_features=log2, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.860) balanced_accuracy: (train=1.000, test=0.742) f1: (train=1.000, test=0.777) total time=   2.1s\n",
      "[CV 9/10] END criterion=log_loss, max_features=log2, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.861) balanced_accuracy: (train=1.000, test=0.747) f1: (train=1.000, test=0.781) total time=   1.9s\n",
      "[CV 10/10] END criterion=log_loss, max_features=log2, n_estimators=200, n_jobs=-1, random_state=100; accuracy: (train=1.000, test=0.863) balanced_accuracy: (train=1.000, test=0.753) f1: (train=1.000, test=0.786) total time=   2.1s\n",
      "[CV 1/10] END criterion=log_loss, max_features=log2, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.856) balanced_accuracy: (train=1.000, test=0.739) f1: (train=1.000, test=0.772) total time=   2.1s\n",
      "[CV 2/10] END criterion=log_loss, max_features=log2, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.864) balanced_accuracy: (train=1.000, test=0.748) f1: (train=1.000, test=0.784) total time=   2.1s\n",
      "[CV 3/10] END criterion=log_loss, max_features=log2, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.856) balanced_accuracy: (train=1.000, test=0.738) f1: (train=1.000, test=0.772) total time=   2.1s\n",
      "[CV 4/10] END criterion=log_loss, max_features=log2, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.740) f1: (train=1.000, test=0.775) total time=   2.2s\n",
      "[CV 5/10] END criterion=log_loss, max_features=log2, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.745) f1: (train=1.000, test=0.780) total time=   2.4s\n",
      "[CV 6/10] END criterion=log_loss, max_features=log2, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.859) balanced_accuracy: (train=1.000, test=0.742) f1: (train=1.000, test=0.776) total time=   2.2s\n",
      "[CV 7/10] END criterion=log_loss, max_features=log2, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.858) balanced_accuracy: (train=1.000, test=0.741) f1: (train=1.000, test=0.775) total time=   2.4s\n",
      "[CV 8/10] END criterion=log_loss, max_features=log2, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.861) balanced_accuracy: (train=1.000, test=0.744) f1: (train=1.000, test=0.779) total time=   2.1s\n",
      "[CV 9/10] END criterion=log_loss, max_features=log2, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.863) balanced_accuracy: (train=1.000, test=0.749) f1: (train=1.000, test=0.783) total time=   2.2s\n",
      "[CV 10/10] END criterion=log_loss, max_features=log2, n_estimators=200, n_jobs=-1, random_state=None; accuracy: (train=1.000, test=0.862) balanced_accuracy: (train=1.000, test=0.751) f1: (train=1.000, test=0.784) total time=   2.2s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=StratifiedKFold(n_splits=10, random_state=None, shuffle=False),\n",
       "             estimator=ExtraTreesClassifier(n_estimators=150, n_jobs=-1,\n",
       "                                            random_state=30),\n",
       "             param_grid={&#x27;criterion&#x27;: [&#x27;gini&#x27;, &#x27;entropy&#x27;, &#x27;log_loss&#x27;],\n",
       "                         &#x27;max_features&#x27;: [&#x27;sqrt&#x27;, &#x27;log2&#x27;],\n",
       "                         &#x27;n_estimators&#x27;: [100, 200], &#x27;n_jobs&#x27;: [-1],\n",
       "                         &#x27;random_state&#x27;: [50, 100, None]},\n",
       "             refit=&#x27;balanced_accuracy&#x27;, return_train_score=True,\n",
       "             scoring={&#x27;accuracy&#x27;: &#x27;accuracy&#x27;,\n",
       "                      &#x27;balanced_accuracy&#x27;: &#x27;balanced_accuracy&#x27;,\n",
       "                      &#x27;f1&#x27;: &#x27;f1_macro&#x27;},\n",
       "             verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=StratifiedKFold(n_splits=10, random_state=None, shuffle=False),\n",
       "             estimator=ExtraTreesClassifier(n_estimators=150, n_jobs=-1,\n",
       "                                            random_state=30),\n",
       "             param_grid={&#x27;criterion&#x27;: [&#x27;gini&#x27;, &#x27;entropy&#x27;, &#x27;log_loss&#x27;],\n",
       "                         &#x27;max_features&#x27;: [&#x27;sqrt&#x27;, &#x27;log2&#x27;],\n",
       "                         &#x27;n_estimators&#x27;: [100, 200], &#x27;n_jobs&#x27;: [-1],\n",
       "                         &#x27;random_state&#x27;: [50, 100, None]},\n",
       "             refit=&#x27;balanced_accuracy&#x27;, return_train_score=True,\n",
       "             scoring={&#x27;accuracy&#x27;: &#x27;accuracy&#x27;,\n",
       "                      &#x27;balanced_accuracy&#x27;: &#x27;balanced_accuracy&#x27;,\n",
       "                      &#x27;f1&#x27;: &#x27;f1_macro&#x27;},\n",
       "             verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: ExtraTreesClassifier</label><div class=\"sk-toggleable__content\"><pre>ExtraTreesClassifier(n_estimators=150, n_jobs=-1, random_state=30)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ExtraTreesClassifier</label><div class=\"sk-toggleable__content\"><pre>ExtraTreesClassifier(n_estimators=150, n_jobs=-1, random_state=30)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=10, random_state=None, shuffle=False),\n",
       "             estimator=ExtraTreesClassifier(n_estimators=150, n_jobs=-1,\n",
       "                                            random_state=30),\n",
       "             param_grid={'criterion': ['gini', 'entropy', 'log_loss'],\n",
       "                         'max_features': ['sqrt', 'log2'],\n",
       "                         'n_estimators': [100, 200], 'n_jobs': [-1],\n",
       "                         'random_state': [50, 100, None]},\n",
       "             refit='balanced_accuracy', return_train_score=True,\n",
       "             scoring={'accuracy': 'accuracy',\n",
       "                      'balanced_accuracy': 'balanced_accuracy',\n",
       "                      'f1': 'f1_macro'},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extra = ExtraTreesClassifier( n_jobs=-1, n_estimators=150, random_state=30)\n",
    "\n",
    "# Create the parameter grids\n",
    "parameter_grid = {\n",
    "    \"n_estimators\": [100, 200],\n",
    "    \"criterion\": ['gini', 'entropy', 'log_loss'],\n",
    "    \"max_features\": ['sqrt', 'log2'],\n",
    "    \"n_jobs\":[-1],\n",
    "   # \"bootstrap\":[True,False],\n",
    "    \"random_state\": [ 50, 100, None],\n",
    "   # \"warm_start\": [True, False],\n",
    "    \n",
    "}\n",
    "\n",
    "# Create Stratified folds\n",
    "# primi tentativi n_splits = 5 per limitare i tempi di esecuzione della gridSearch poi aumentato\n",
    "cross_validation = StratifiedKFold(n_splits=10)\n",
    "cross_validation.get_n_splits(train_data, np.ravel(y_train))\n",
    "\n",
    "# Create the scoring dictionary\n",
    "SCORING = {\n",
    "    \"accuracy\": \"accuracy\",\n",
    "    \"balanced_accuracy\": \"balanced_accuracy\",\n",
    "    \"f1\": \"f1_macro\",\n",
    "}\n",
    "\n",
    "# Create and fit the GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=extra,\n",
    "    param_grid=parameter_grid,\n",
    "    cv=cross_validation,\n",
    "    verbose=3,\n",
    "    scoring=SCORING,\n",
    "    return_train_score=True,\n",
    "    refit=\"balanced_accuracy\",\n",
    ")\n",
    "\n",
    "grid_search.fit(train_data, np.ravel(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e5c00f24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.7443125339355887\n",
      "Best parameters: {'criterion': 'gini', 'max_features': 'sqrt', 'n_estimators': 100, 'n_jobs': -1, 'random_state': 50}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>ExtraTreesClassifier(n_jobs=-1, random_state=50)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" checked><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ExtraTreesClassifier</label><div class=\"sk-toggleable__content\"><pre>ExtraTreesClassifier(n_jobs=-1, random_state=50)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "ExtraTreesClassifier(n_jobs=-1, random_state=50)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Best score: {}\".format(grid_search.best_score_))\n",
    "print(\"Best parameters: {}\".format(grid_search.best_params_))\n",
    "\n",
    "best_dtc = grid_search.best_estimator_\n",
    "best_dtc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "19c3a08d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.858244570480011"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model = best_dtc\n",
    "my_model.fit(train_data, np.ravel(y_train))\n",
    "my_model.score(test_data, np.ravel(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7227a9",
   "metadata": {},
   "source": [
    "Test con outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d320a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "outtrain_data=pd.read_csv('/Users/ragno/Documents/Progetti/Mldm/ProgettoMLDM/Dataset/outtrain_data.csv')\n",
    "outtest_data=pd.read_csv('/Users/ragno/Documents/Progetti/Mldm/ProgettoMLDM/Dataset/outtest_data.csv')\n",
    "y_trainout=pd.read_csv('/Users/ragno/Documents/Progetti/Mldm/ProgettoMLDM/Dataset/outtrain_y.csv')\n",
    "y_testout=pd.read_csv('/Users/ragno/Documents/Progetti/Mldm/ProgettoMLDM/Dataset/outtest_y.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d40dea0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8572341427322258"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xt = ExtraTreesClassifier(criterion='gini',max_features='sqrt',n_estimators=100, random_state=50, n_jobs=-1 )\n",
    "xt.fit(outtrain_data, np.ravel(y_trainout))\n",
    "xt.score(outtest_data, y_testout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930be595",
   "metadata": {},
   "outputs": [],
   "source": [
    "Test con outliers e random_state disattivato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "050e93eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8568641958700478"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xt = ExtraTreesClassifier(criterion='gini',max_features='sqrt',n_estimators=100, random_state=None, n_jobs=-1 )\n",
    "xt.fit(outtrain_data, np.ravel(y_trainout))\n",
    "xt.score(outtest_data, y_testout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "796dce4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA8QAAAInCAYAAABeC5BvAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAACtkUlEQVR4nOzdd1yVdf/H8ddhCAjucoADcaSlZsPANDfOTDFx507TcqWZqbkN08ps3uYIcpCVeyYKrtylpbYUcyRqoimiiIzz++P6eeoIOAi9DvB+Ph487vtc63zOBV7x5vpen6/FarVaEREREREREcllnMwuQERERERERMQMCsQiIiIiIiKSKykQi4iIiIiISK6kQCwiIiIiIiK5kgKxiIiIiIiI5EoKxCIiIiIiIpIrKRCLiIiIiIhIrqRALCIiIiIiIrmSArGIiIiIiIjkSgrEIpJrHThwAIvFgqurK6dPnza7nFzr6tWrjBs3jk2bNt2T4//888+MGzeOY8eO3ZPjZxehoaFYLBbTzoPFYmHcuHH39D2OHTuGxWIhNDT0rvd1tJ+T7du3M27cOC5evHhH248bNw6LxXJvi7oLMTExjBs3jv3795tdiojILSkQi0iuNXv2bACSk5P54osvTK4m97p69Srjx4+/p4F4/PjxDhN0zNKiRQt27NhBiRIlzC7FITnaz8n27dsZP378HQfi3r17s2PHjntb1F2IiYlh/PjxCsQi4vAUiEUkV0pMTGTBggU8+uij+Pj4MHfuXLNLylBCQgJWq9XsMhzG1atXs/Xx77cbPz8PPvggAQEBuLm5mV2S3AMlS5YkICDA7DJERLIdBWIRyZWWLVvG+fPn6d27N926deP3339n27ZtabZLTExkwoQJVK5cGXd3d4oUKUL9+vXZvn27bZvU1FQ+/PBDqlevjoeHBwULFiQgIIAVK1bYtslouKivry/du3e3vb4xrHX9+vX07NmTBx98kLx585KYmMiRI0fo0aMHFSpUIG/evPj4+NCyZUsOHDiQ5rgXL15k6NCh+Pn54ebmRtGiRWnevDm//vorVquVChUq0KRJkzT7xcfHU6BAAV5++eVbnj+r1conn3xi+8yFChWibdu2HD161LbNl19+icVi4aOPPrLbd+zYsTg7OxMREcGxY8d48MEHARg/fjwWiwWLxWI7JzeGgf7www+0bduWQoUKUa5cOQD27t1Lhw4d8PX1xcPDA19fXzp27Mjx48ftzmdwcDAA9evXtx3/xpDaevXqUaVKFbZs2cLTTz9N3rx56dmzJwBxcXEMGzaMsmXLkidPHnx8fBg8eDBXrly563ORnmXLlmGxWNi4cWOadZ9++ikWi4Wffvrpjj/rjc+b0c9PekOmIyIiaNWqFSVLlsTd3Z3y5cvTt29fYmNj7Y574/tw6NAhOnbsSIECBShWrBg9e/bk0qVLdtvGxcXx4osvUqRIEby8vGjatCm///57uudg27ZtNGzYkHz58pE3b16efvppVq9efcvzdkNMTAzt2rUjX758FChQgPbt23PmzJk022XFz8mdnqdz587Rp08fSpUqhZubGw8++CC1atViw4YNdttt2LCBhg0bkj9/fvLmzUutWrXsfg7GjRvHa6+9BkDZsmVt9dxqFEV6Q6Z9fX159tlnWbduHY8//jgeHh5UqlQpzR8Ab/xsRERE0KNHDwoXLoynpyctW7ZM83N88zXrhnr16lGvXj0ANm3aRI0aNQDo0aOHrf57PWReRCQzXMwuQETEDHPmzMHNzY3OnTtz4cIFQkJCmDNnDrVr17Ztk5ycTLNmzdi6dSuDBw+mQYMGJCcns3PnTk6cOMHTTz8NQPfu3Zk/fz69evViwoQJ5MmThx9++OE/Db3s2bMnLVq0YN68eVy5cgVXV1diYmIoUqQIU6ZM4cEHH+TChQuEhYXh7+/Pvn37eOihhwC4fPkytWvX5tixY7z++uv4+/sTHx/Pli1bOH36NJUqVWLAgAEMHjyYw4cPU6FCBdv7fvHFF8TFxd02EPft25fQ0FAGDhzI22+/zYULF5gwYQJPP/00P/74I8WKFaNDhw5s3ryZoUOHEhAQwJNPPklkZCSTJk1i5MiRBAYGkpiYyLp162jatCm9evWid+/eALaQfEObNm3o0KEDL730ki2QHjt2jIceeogOHTpQuHBhTp8+zaeffkqNGjX4+eefeeCBB2jRogVvvfUWI0eO5OOPP+bxxx8HsIVqgNOnT9OlSxeGDx/OW2+9hZOTE1evXqVu3br8+eefjBw5kmrVqnHo0CHGjBnDgQMH2LBhgy183Mm5SM+zzz5L0aJF+fzzz2nYsKHdutDQUB5//HGqVat2x5/1dj8/6YmOjqZmzZr07t2bAgUKcOzYMd577z1q167NgQMH0uz3/PPP0759e3r16sWBAwd44403AGwBy2q10rp1a7Zv386YMWOoUaMG3333Hc2aNUvz3ps3byYwMJBq1arZ/j1+8skntGzZkvDwcNq3b59uzWDc9W7UqBExMTGEhIRQsWJFVq9ene4+WfFzcqfn6YUXXuCHH35g8uTJVKxYkYsXL/LDDz9w/vx5Wz3z58+na9eutGrVirCwMFxdXZk5cyZNmjTh22+/pWHDhvTu3ZsLFy7w4YcfsmTJEtsw94cffjjDc5KRH3/8kaFDhzJixAiKFSvG7Nmz6dWrF+XLl6dOnTp22/bq1YvAwEAWLlzIyZMnGT16NPXq1eOnn36iYMGCd/yejz/+OJ9//jk9evRg9OjRtGjRAjDuYouIOByriEguc+zYMauTk5O1Q4cOtmV169a1enp6WuPi4mzLvvjiCytgnTVrVobH2rJlixWwjho16pbvCVjHjh2bZnmZMmWs3bp1s73+/PPPrYC1a9eut/0cycnJ1uvXr1srVKhgHTJkiG35hAkTrIA1IiIiw33j4uKs+fLlsw4aNMhu+cMPP2ytX7/+Ld93x44dVsD67rvv2i0/efKk1cPDwzp8+HDbsmvXrlkfe+wxa9myZa0///yztVixYta6detak5OTbducO3cuw/MzduxYK2AdM2bMLWuyWo3zER8fb/X09LTOmDHDtvzrr7+2AtaoqKg0+9StW9cKWDdu3Gi3PCQkxOrk5GTds2eP3fJvvvnGCljXrFlz1+ciPa+++qrVw8PDevHiRduyn3/+2QpYP/zww7v+rLf6+bmx7o8//kj3mKmpqdakpCTr8ePHrYB1+fLltnU3vg9Tp06126d///5Wd3d3a2pqqtVqtVrXrl1rBexqslqt1smTJ6f5HgcEBFiLFi1qvXz5st3nqlKlirVkyZK2Y6bn008/TVOj1Wq1vvjii1bA+vnnn2e4b2Z+Tv7tVufJy8vLOnjw4Az3vXLlirVw4cLWli1b2i1PSUmxPvroo9annnrKtmzatGm3/H7d7Mb36N/KlCljdXd3tx4/fty2LCEhwVq4cGFr3759bctu/GwEBQXZ7f/dd99ZAeukSZPsjvnva9YNdevWtdatW9f2es+ePbf9XoiIOAINmRaRXOfzzz8nNTXVNjQWjDtqV65cYdGiRbZla9euxd3d3W67m61duxbgtndU79bzzz+fZllycjJvvfUWDz/8MHny5MHFxYU8efJw+PBhfvnlF7uaKlasSKNGjTI8fr58+ejRowehoaG2O66RkZH8/PPPvPLKK7esbdWqVVgsFrp06UJycrLtq3jx4jz66KN2wzrd3Nz46quvOH/+PI8//jhWq5Xw8HCcnZ3/8/mIj4/n9ddfp3z58ri4uODi4oKXlxdXrlyxOx+3U6hQIRo0aJDmM1apUoXq1avbfcYmTZrYDV29m3ORnp49e5KQkGD3c/f555/j5uZGp06dMv1Z0ztf6fnrr7946aWXKFWqFC4uLri6ulKmTBmAdI/73HPP2b2uVq0a165d46+//gIgKioKgM6dO9tt9+/PAnDlyhV27dpF27Zt8fLysi13dnbmhRde4M8//+S3337LsO6oqCjy5cuXpp6b3wey5ufkTs/TU089RWhoKJMmTWLnzp0kJSXZHWf79u1cuHCBbt262f28pKam0rRpU/bs2ZNmSP5/Vb16dUqXLm177e7uTsWKFdMMt4e037enn36aMmXK2L6vIiI5kYZMi0iukpqaSmhoKN7e3jzxxBO2Dq6NGjXC09OTOXPm2Ibtnjt3Dm9vb5ycMv7b4blz53B2dqZ48eJZWmd6nYBfffVVPv74Y15//XXq1q1LoUKFcHJyonfv3iQkJNjV9O9fgDMyYMAAPvroIxYsWECfPn346KOPKFmyJK1atbrlfmfPnsVqtWY4FNjPz8/udfny5XnmmWdYvXo1/fr1y1SX4/T26dSpExs3buTNN9+kRo0a5M+fH4vFQvPmze3OR2aOffbsWY4cOZLhUOMbz47e7bm42SOPPEKNGjX4/PPP6dOnDykpKcyfP59WrVpRuHBh23Z3+1nv5BynpqbSuHFjYmJiePPNN6latSqenp6kpqYSEBCQ7nGLFCli9/pGg64b254/fx4XF5c029387+Pvv//GarWmW6e3t7ftWBk5f/58uuc8vX+H//Xn5G7O06JFi5g0aRKzZ8/mzTffxMvLi6CgIKZOnUrx4sU5e/YsAG3bts3w/S5cuICnp+dt67pTN38vwPi+pffZ0zt/xYsXv+X3QkQku1MgFpFcZcOGDbY7I+n9orhz505+/vlnHn74YR588EG2bdtGampqhqH4wQcfJCUlhTNnztwyhLi5uZGYmJhmeUa/aKY3n+iNZw/feustu+WxsbF2z/c9+OCD/PnnnxnWckP58uVp1qwZH3/8Mc2aNWPFihWMHz/+tndvH3jgASwWC1u3bk23Y/HNy2bPns3q1at56qmn+Oijj2jfvj3+/v63re/fbj4fly5dYtWqVYwdO5YRI0bYlicmJnLhwoX/dGwwPqOHh0eG3cdvPLN7t+ciPT169KB///788ssvHD16lNOnT9OjRw/b+sx81juZj/bgwYP8+OOPhIaG0q1bN9vyI0eO3HbfjBQpUoTk5GTOnz9v9+/r5mZXN/6Yk9783zExMQBpnou++X12796dZvnN75MVPyd3c54eeOAB3n//fd5//31OnDjBihUrGDFiBH/99Rfr1q2zfaYPP/www47QGf1x5X5IrynZmTNnKF++vO21u7t7utey2NjYW37PREQclYZMi0iuMmfOHJycnFi2bBlRUVF2X/PmzQP+aRDUrFkzrl27Zus0m54bzYI+/fTTW76vr6+vrWPwDZGRkcTHx99x7RaLJU3AWr16NadOnUpT0++//05kZORtjzlo0CB++uknunXrhrOzMy+++OJt93n22WexWq2cOnWKJ598Ms1X1apVbdseOHCAgQMH0rVrV7Zu3Uq1atVo3749f//9t22bm+8y3gmLxYLVak03fKekpNgty8zxn332WaKjoylSpEi6n9HX1/euz0VGOnbsiLu7O6GhoYSGhuLj40Pjxo0z9Vnvxo3QfPNxZ86cmelj1q9fH4AFCxbYLV+4cKHda09PT/z9/VmyZInd9yU1NZX58+dTsmRJKlaseMv3uXz5sl0n9/TeJyt+TjJ7nkqXLs0rr7xCYGAgP/zwAwC1atWiYMGC/Pzzz+n+vDz55JPkyZPnlvXcSzd/37Zv387x48dt3aMh/WvZ77//nmaIuxn1i4hkhu4Qi0iucf78eZYvX06TJk0yHBY8ffp0vvjiC0JCQujYsSOff/45L730Er/99hv169cnNTWVXbt2UblyZTp06MAzzzzDCy+8wKRJkzh79izPPvssbm5u7Nu3j7x58zJgwADA6D775ptvMmbMGOrWrcvPP//MRx99RIECBe64/meffZbQ0FAqVapEtWrV+P7775k2bVqazq2DBw9m0aJFtGrVihEjRvDUU0+RkJDA5s2befbZZ22hBSAwMJCHH36YqKgounTpQtGiRW9bR61atejTpw89evRg79691KlTB09PT06fPs22bduoWrUq/fr148qVK7Rr146yZcvyySefkCdPHr766isef/xxevTowbJlywDjeeYyZcqwfPlyGjZsSOHChXnggQdsoTM9+fPnp06dOkybNs227ebNm5kzZ06abrhVqlQB4LPPPiNfvny4u7tTtmzZdEcI/PscLl68mDp16jBkyBCqVatGamoqJ06cYP369QwdOhR/f/87Phe3UrBgQYKCgggNDeXixYsMGzbMbkTC3XzWu1GpUiXKlSvHiBEjsFqtFC5cmJUrVxIREZHpYzZu3Jg6deowfPhwrly5wpNPPsl3331n+2PTv4WEhBAYGEj9+vUZNmwYefLk4ZNPPuHgwYOEh4ff8i53165dmT59Ol27dmXy5MlUqFCBNWvW8O2339ptlxU/J3d6ni5dukT9+vXp1KkTlSpVIl++fOzZs4d169bRpk0bALy8vPjwww/p1q0bFy5coG3bthQtWpRz587x448/cu7cOdsf1278MWXGjBl069YNV1dXHnroIfLly3d335S7sHfvXnr37k1wcDAnT55k1KhR+Pj40L9/f9s2L7zwAl26dKF///48//zzHD9+nKlTp6bpDF+uXDk8PDxYsGABlStXxsvLC29vb9uQeBERh2FSMy8Rkfvu/ffftwLWZcuWZbjN//73PytgXbx4sdVqNTqyjhkzxlqhQgVrnjx5rEWKFLE2aNDAun37dts+KSkp1unTp1urVKlizZMnj7VAgQLWmjVrWleuXGnbJjEx0Tp8+HBrqVKlrB4eHta6deta9+/fn2GX6Zu7G1utVuvff/9t7dWrl7Vo0aLWvHnzWmvXrm3dunVrmu6uN7YdNGiQtXTp0lZXV1dr0aJFrS1atLD++uuvaY47btw4K2DduXPnnZ5Kq9Vqtc6dO9fq7+9v9fT0tHp4eFjLlStn7dq1q3Xv3r1Wq9Vq7dKlizVv3rzWQ4cO2e13o5vv9OnTbcs2bNhgfeyxx6xubm5WwHZObnTOPXfuXJr3//PPP63PP/+8tVChQtZ8+fJZmzZtaj148GC6XXDff/99a9myZa3Ozs52nW/r1q1rfeSRR9L9fPHx8dbRo0dbH3roIdv3tWrVqtYhQ4ZYz5w5c1fn4nbWr19vBayA9ffff8/0Z73Vz096XaZ//vlna2BgoDVfvnzWQoUKWYODg60nTpxI0xE6o+9Dese8ePGitWfPntaCBQta8+bNaw0MDLT++uuv6XYS37p1q7VBgwa28xYQEGD37+ZWbpwTLy8va758+azPP/+8dfv27Wk6G2fFz8mdnKdr165ZX3rpJWu1atWs+fPnt3p4eFgfeugh69ixY61Xrlyxe5/NmzdbW7RoYS1cuLDV1dXV6uPjY23RooX166+/ttvujTfesHp7e1udnJxu2wE7oy7TLVq0SLPtzdeMG9/H9evXW1944QVrwYIFrR4eHtbmzZtbDx8+bLdvamqqderUqVY/Pz+ru7u79cknn7RGRkamex0KDw+3VqpUyerq6pphJ3kREbNZrFar9T7mbxERcTBPPvkkFouFPXv2mF2KiJggNDSUHj16sGfPHp588kmzyxERua80ZFpEJBeKi4vj4MGDrFq1iu+//56lS5eaXZKIiIjIfadALCKSC/3www/Ur1+fIkWKMHbsWFq3bm12SSIiIiL3nYZMi4iIiIiISK6kaZdEREREREQkV1IgFhERERERkVxJgVhERERERERyJTXVclCpqanExMSQL18+LBaL2eWIiIiIiIhJrFYrly9fxtvbGycn3dPMSgrEDiomJoZSpUqZXYaIiIiIiDiIkydPUrJkSbPLyFEUiB1Uvnz5AOOHPn/+/KbWkpSUxPr162ncuDGurq6m1iIikpvo+isiYg5Hu/7GxcVRqlQpW0aQrKNA7KBuDJPOnz+/QwTivHnzkj9/foe4IIiI5Ba6/oqImMNRr796lDLraQC6iIiIiIiI5EoKxCIiIiIiIpIrKRCLiIiIiIhIrqRALCIiIiIiIrmSArGIiIiIiIjkSgrEIiIiIiIikispEIuIiIiIiEiupEAsIiIiIiIiuZICsYiIiIiIiORKCsQiIiIiIiKSKykQi4iIiIiISK6kQCwiIiIiIiK5kkMG4vj4eAYPHoy3tzfu7u5Ur16dL7/88o72jYqKIjAwkKJFi+Ll5UW1atX44IMPSElJsduuXr16WCyWNF9NmzZNc8wjR47wwgsvULp0aTw8PChXrhyvvvoq58+ft9tu9uzZtG7dGl9fXzw8PChfvjz9+vXj9OnTmT8ZIiIiIiIick+4mF1Aetq0acOePXuYMmUKFStWZOHChXTs2JHU1FQ6deqU4X4bNmygSZMm1KlTh1mzZuHp6cmKFSsYNGgQ0dHRzJgxw257Pz8/FixYYLesYMGCdq/PnTtHQEAA+fPnZ+LEiZQuXZp9+/YxduxYoqKi+P7773FyMv6uMHbsWOrXr89bb72Fj48Pv/32GxMnTmT58uXs27ePYsWKZc0Jup9SUrBs3ozPli1YPD2hfn1wdja7KhERERERkf/M4QLxmjVriIiIsIVggPr163P8+HFee+012rdvj3MGgSw0NBRXV1dWrVqFp6cnAI0aNeK3334jNDQ0TSD28PAgICDglvUsX76c8+fPs2jRIho2bGirJzExkZEjR/Ljjz/y2GOPAbBv3z6KFi1q27du3bo8/vjj1KhRg1mzZjF69OjMnRSzLFkCgwbh8uefPAnw3ntQsiTMmAFt2phdnYiIiIiIyH/icEOmly5dipeXF8HBwXbLe/ToQUxMDLt27cpwX1dXV/LkyYOHh4fd8oIFC+Lu7p6pelxdXQEoUKBAmmMCdsf9dxi+4YknnsDZ2ZmTJ09m6v1Ns2QJtG0Lf/5pv/zUKWP5kiXm1CUiIiIiIpJFHC4QHzx4kMqVK+PiYn/zulq1arb1GXnppZe4fv06AwcOJCYmhosXLzJv3jyWLl3K8OHD02wfHR1N4cKFcXFxoVy5cowaNYqEhAS7bVq3bk3p0qUZOnQohw4dIj4+ni1btjBlyhRatmxJ5cqVb/l5Nm/eTEpKCo888sidngLzpaTAoEFgtaZdd2PZ4MHGdiIiIiIiItmUww2ZPn/+PH5+fmmWFy5c2LY+I/7+/kRGRhIcHMzHH38MgLOzMyEhIQwdOtRu29q1a9O+fXsqVapEQkICa9euZerUqWzbto2oqCjbc8EFChRg586dPP/881SpUsW2f3BwMPPmzbvlZ7l8+TL9+/enVKlS9OzZ85bbJiYmkpiYaHsdFxcHQFJSEklJSbfcN6tZNm/G5eY7w/9mtcLJkyRHRWGtW/f+FSYiksvcuP7f7/8OiIjkdo52/XWUOnIihwvEABaLJVPrvv/+e4KCgvD392fmzJl4enoSGRnJ6NGjuXbtGm+++aZt20mTJtnt27x5c3x9fRk2bBjLly8nKCgIgL///ptWrVpx9epVFixYQKlSpTh48CATJ07kueeeY/Xq1WnuZgNcu3aNNm3acPz4cSIjI/Hy8rrlZw4JCWH8+PFplq9fv568efPect+s5rNli/HM8G3sX7uWU1eu3PN6RERyu4iICLNLEBHJlRzl+nv16lWzS8ixLFZreuNizVOzZk1SUlLYvXu33fJDhw5RpUoVZs6cSZ8+fdLdNyAggKtXr7Jv3z67xltjx45l0qRJHD58ON27zzecPXuW4sWLM3z4cN5++20ARowYwXvvvcfx48cpUaKEbduoqCgaNGhAaGgo3bp1sztOYmIirVu3ZtOmTaxatcrWjOtW0rtDXKpUKWJjY8mfP/9t989Kls2bcQkMvO12yRERukMsInIPJSUlERERQWBgoK2nhYiI3HuOdv2Ni4vjgQce4NKlS/c9G+R0DneHuGrVqoSHh5OcnGx35/XAgQMAdsOWb7Z//346duyYpgt1jRo1SE1N5ZdffrllIL7hxnDpG8f08fGxC8M3jglpn2m+EYajoqJYvnz5HYVhADc3N9zc3NIsd3V1vf//COvXN7pJnzqV/nPEAO7uuDz5JDjABUJEJKcz5b8FIiLiMNdfR6ghp3K4plpBQUHEx8ezePFiu+VhYWF4e3vj7++f4b7e3t7s3buXlJuaPe3YsQOAkiVL3vK9w8LCAOymYvL29ubPP//k1KlTtz1mYmIiQUFBREZGsnjxYpo0aXLL93NYzs7G1EoAGQ1Rv3YN6tWD7NY9W0RERERE5P853B3iZs2aERgYSL9+/YiLi6N8+fKEh4ezbt065s+fb7v726tXL8LCwoiOjqZMmTIADBkyhIEDB9KyZUv69u1L3rx52bhxI++++y6NGjXi0UcfBWDr1q1MnjyZoKAg/Pz8uHbtGmvXruWzzz6jQYMGtGzZ0lbPyy+/zIIFCwgMDGTEiBG2Z4gnTZpEsWLF6Ny5s23btm3bsnbtWkaNGkWRIkXYuXOnbV3+/Pl5+OGH78cpzBpt2sA33xjdpv/dYKtUKejfH95/H378Efz9YeVKeOIJ00oVERERERHJDId7hhggPj6eUaNG8dVXX3HhwgUqVarEG2+8QYcOHWzbdO/enbCwMP744w98fX1ty5csWcL06dP59ddfSUhIwNfXlw4dOjBkyBA8PT0BOHLkCIMGDeLHH38kNjYWi8VChQoV6NChA0OHDk0zdHnfvn1MnDiRPXv2cO7cOXx8fGjQoAFjxoyhVKlStu1u1fCrbt26bNq06Y7PQVxcHAUKFDD/OYGUFJKjoti/di3VmzXDpX594w7y8ePQogUcOgR588KCBdC6tXl1iojkQElJSaxZs4bmzZtruJyIyH3kaNdfh8kGOZBDBmJxrB/6DC8Ily5B+/bw7bfG0OqpU2Ho0IyHWYuIyF1xtF/IRERyC0e7/jpSNshpHO4ZYslGChSAVaugXz+j+dZrr0HfvqB50kREREREJBtQIJb/xsUFPv7YeKbYYoFZs6BZM7h40ezKREREREREbkmBWP47i8VovrV8OXh6wsaNULMmHD1qdmUiIiIiIiIZUiCWrNOyJWzbBj4+8OuvRgfq7dvNrkpERERERCRdCsSStapXh9274fHHITYWGjSA8HCzqxIREREREUlDgViynrc3bNliTMOUmAidOsGECUbjLREREREREQehQCz3hqcnLF4Mw4YZr8eOha5djYAsIiIiIiLiABSI5d5xcoJp02DmTHB2hvnzoVEjYyi1iIiIiIiIyRSI5d7r0wfWrTPmLd62DQICjKZbIiIiIiIiJlIglvujUSOj43TZshAdbUzLFBlpdlUiIiIiIpKLKRDL/fPww7BzpxGGL16EJk1g7lyzqxIRERERkVxKgVjur6JFjTvDHTpAcjL06gUjRkBqqtmViYiIiIhILqNALPefuzssXAhjxhiv334b2rWDq1fNrUtERERERHIVBWIxh8UC48fDvHmQJ48xRVO9enD6tNmViYiIiIhILqFALObq0gU2bIAiRWDPHvD3h59+MrsqERERERHJBRSIxXzPPGM026pYEU6ehFq1YM0as6sSEREREZEcToFYHEP58kYorl8f4uOhZUv46COzqxIRERERkRxMgVgcR6FCsG4d9OxpdJ0eMAAGDjS6UYuIiIiIiGQxBWJxLHnywOzZMGWK8frDD6FVK7h82dy6REREREQkx1EgFsdjscDrr8PXXxtTNK1ZA7Vrw4kTZlcmIiIiIiI5iAKxOK62bWHzZihWzOg87e8Pe/eaXZWIiIiIiOQQCsTi2J56CnbvhqpV4cwZqFMHliwxuyoREREREckBFIjF8ZUuDdu2QbNmkJAAzz8PU6eC1Wp2ZSIiIiIiko0pEEv2kD8/rFgBL79svH79dXjxRUhKMrcuERERERHJthSIJftwcTHmJv7gA3BygjlzoGlT+PtvsysTEREREZFsSIFYsp8BA4y7xV5eEBkJNWtCdLTZVYmIiIiISDajQCzZU4sWxnPFJUvCb79BQAB8953ZVYmIiIiISDaiQCzZ16OPGh2on3gCYmOhQQNYsMDsqkREREREJJtQIJbsrUQJY67ioCC4fh26dIFx49SBWkREREREbkuBWLI/T0/45hsYPtx4PX68EYyvXTO3LhERERERcWgKxJIzODnB22/DrFlGN+qFC6FRIzh3zuzKRERERETEQSkQS87SuzesWwcFChhNtgIC4Ndfza5KREREREQckAKx5DwNG8KOHeDnB0ePGqF440azqxIREREREQejQCw5U+XKsHMnPP00XLoETZvC7NlmVyUiIiIiIg5EgVhyrgcfNO4Md+oEycnw4otG463UVLMrExERERERB6BALDmbuzvMn29MxQQwbRq0bQtXr5paloiIiIiImE+BWHI+iwXGjjWCcZ48sHQp1K0Lp0+bXZmIiIiIiJhIgVhyj86djSHUDzwAe/fCU0/Bjz+aXZWIiIiIiJhEgVhyl9q1jWZblSrBn38ar1evNrsqERERERExgQKx5D7lysH27dCgAcTHw3PPwYcfml2ViIiIiIjcZwrEkjsVKgTr1kGvXkbX6YEDYcAAoxu1iIiIiIjkCgrEknu5usKsWTB1qvH6o4+Mu8VxcebWJSIiIiIi94UCseRuFgu89hosXgweHrB2rfFc8YkTZlcmIiIiIiL3mAKxCECbNrBlCxQvDgcOGB2o9+wxuyoREREREbmHFIhFbnjySdi9G6pVg7NnjbmKFy82uyoREREREblHFIhF/q1UKdi2DZo3h4QEaNsW3n4brFazKxMRERERkSymQCxys3z5YPlyo+s0wIgR0Ls3XL9ubl0iIiIiIpKlHDIQx8fHM3jwYLy9vXF3d6d69ep8+eWXd7RvVFQUgYGBFC1aFC8vL6pVq8YHH3xASkqK3Xb16tXDYrGk+WratGmaYx45coQXXniB0qVL4+HhQbly5Xj11Vc5f/58mm2PHj1KmzZtKFiwIF5eXgQGBvLDDz9k7kSIeVxc4IMPjPmJnZxg7lxo2hT+/tvsykREREREJIu4mF1Aetq0acOePXuYMmUKFStWZOHChXTs2JHU1FQ6deqU4X4bNmygSZMm1KlTh1mzZuHp6cmKFSsYNGgQ0dHRzJgxw257Pz8/FixYYLesYMGCdq/PnTtHQEAA+fPnZ+LEiZQuXZp9+/YxduxYoqKi+P7773FycrJt+8wzz1CoUCHmzp2Lu7s7ISEh1KtXjz179vDQQw9lzQmS++eVV8DPD9q3h6goCAiA1auhfHmzKxMRERERkf/I4QLxmjVriIiIsIVggPr163P8+HFee+012rdvj7Ozc7r7hoaG4urqyqpVq/D09ASgUaNG/Pbbb4SGhqYJxB4eHgQEBNyynuXLl3P+/HkWLVpEw4YNbfUkJiYycuRIfvzxRx577DEApk2bxrlz59i+fTtlypQBoHbt2pQrV44xY8awaNGizJ8YMU/z5vDdd/Dss/D770YoXroUnnnG7MpEREREROQ/cLgh00uXLsXLy4vg4GC75T169CAmJoZdu3ZluK+rqyt58uTBw8PDbnnBggVxd3fPVD2urq4AFChQIM0xAbvjLl26lAYNGtjCMED+/Plp06YNK1euJDk5OVM1iAOoVg127YIaNeD8eWjUCObPN7sqERERERH5DxwuEB88eJDKlSvj4mJ/87patWq29Rl56aWXuH79OgMHDiQmJoaLFy8yb948li5dyvDhw9NsHx0dTeHChXFxcaFcuXKMGjWKhIQEu21at25N6dKlGTp0KIcOHSI+Pp4tW7YwZcoUWrZsSeXKlQFISEggOjraVufNtSckJHD06NG7Ph/iQEqUgE2b4PnnjQZbL7wAY8eqA7WIiIiISDblcEOmz58/j5+fX5rlhQsXtq3PiL+/P5GRkQQHB/Pxxx8D4OzsTEhICEOHDrXbtnbt2rRv355KlSqRkJDA2rVrmTp1Ktu2bSMqKsr2XHCBAgXYuXMnzz//PFWqVLHtHxwczLx582yv//77b6xWq63Ou609MTGRxMRE2+u4uDgAkpKSSEpKynC/++HG+5tdh0NwdYUFC3AqWxbnd96BCRNI/e03UmbNgkyOQhARyYiuvyIi5nC066+j1JETOVwgBrBYLJla9/333xMUFIS/vz8zZ87E09OTyMhIRo8ezbVr13jzzTdt206aNMlu3+bNm+Pr68uwYcNYvnw5QUFBgBF0W7VqxdWrV1mwYAGlSpXi4MGDTJw4keeee47Vq1fb3c3ObO0hISGMHz8+zfL169eTN2/eDPe7nyIiIswuwXHUrk3pa9d49NNPcVq0iIv797Nr5Eiu3zS0XkQkK+j6KyJiDke5/l69etXsEnIshwvERYoUSfdO6oULFwDSvQN7w8svv0yxYsVYunSprfFW/fr1cXJyYty4cXTu3Dndu883dOnShWHDhrFz505bIH777bfZv38/x48fp0SJEgA888wzVKpUiQYNGrBgwQK6detGoUKFsFgsma79jTfe4NVXX7W9jouLo1SpUjRu3Jj8+fNnuN/9kJSUREREBIGBgbZnqgVo3pzU557D0q4dhX/7jabjxpG8dCk8/LDZlYlIDqHrr4iIORzt+ntj9KhkPYcLxFWrViU8PJzk5GS7O68HDhwAsBu2fLP9+/fTsWPHNF2oa9SoQWpqKr/88sstA/ENN4ZL3zimj4+PLQz/+5jwzzPNHh4elC9f3lbnvx04cAAPD49bvrebmxtubm5plru6ujrEP0JwrFocRmAg7NgBzz6LJToa17p14ZtvjKZbIiJZRNdfERFzOMr11xFqyKkcrqlWUFAQ8fHxLF682G55WFgY3t7e+Pv7Z7ivt7c3e/fuJSUlxW75jh07AChZsuQt3zssLAzAbiomb29v/vzzT06dOnXbYwYFBREZGcnJkydtyy5fvsySJUt47rnn0jQKkxyiUiXYuRNq1YJLl6BpU5g1y+yqRERERETkNhwuEDdr1ozAwED69evHrFmziIqKok+fPqxbt46pU6fa7v726tULFxcXjh8/btt3yJAhHDx4kJYtW7J8+XIiIiIYMWIEU6dOpVGjRjz66KMAbN26laZNmzJz5kwiIiJYuXIl/fv3Z+TIkTRo0ICWLVvajvnyyy/j5OREYGAgX3zxBVFRUXz44Yd06dKFYsWK0blzZ9u2w4YNo0iRIrRo0YJly5axdu1ann32Wa5du8a4cePuzwkUczzwAGzcCJ07Q0oK9OkDr71m/H8REREREXFIDnnLcsmSJYwaNYoxY8Zw4cIFKlWqRHh4OB06dLBtk5KSQkpKCtZ/TXkzYMAAfHx8mD59Or179yYhIQFfX1/Gjh3LkCFDbNuVKFECZ2dnJk6cSGxsLBaLhQoVKjBhwgSGDh1qN2T6iSeeYOfOnUycOJFRo0Zx7tw5fHx8eO655xgzZgwPPPCAbdsHH3yQrVu3MmzYMLp160ZycjI1a9Zk06ZNVKpU6R6fNTGdmxvMmwcVKxrTMb3zDhw5YsxX7OlpdnUiIiIiInITi9WqSVQdUVxcHAUKFODSpUsO0VRrzZo1NG/eXM8v3KnwcOje3Ziv+PHHYeVK8PY2uyoRyWZ0/RURMYejXX8dKRvkNA43ZFokR+jYESIjjaHUP/wATz0F+/ebXZWIiIiIiPyLArHIvVKrFuzaZTTdOnUKateGVavMrkpERERERP6fArHIveTnZ0zL1LAhXLkCrVrBjBmgJxVEREREREynQCxyrxUsCGvXwosvQmoqDB4Mr7wCyclmVyYiIiIikqspEIvcD66uMHMmTJsGFgt88gm0bAlxcWZXJiIiIiKSaykQi9wvFgsMGwaLF4OHB6xbZzxn/K+5tEVERERE5P5RIBa534KCYOtWKFECDh40OlDv2mV2VSIiIiIiuY4CsYgZnngCdu+GRx+Fv/6CevXg66/NrkpEREREJFdRIBYxS8mSxp3iFi3g2jVo1w5CQtSBWkRERETkPlEgFjFTvnywfDkMGmS8HjkSevaE69fNrUtEREREJBdQIBYxm7MzvP8+fPQRODlBaCg0bgwXLphdmYiIiIhIjqZALOIoXn4ZVq827hpv3gwBAXD4sNlViYiIiIjkWArEIo6kaVP47jsoXdoIwwEBsGWL2VWJiIiIiORICsQijqZqVWMapqeeMoZNN2oEX3xhdlUiIiIiIjmOArGIIypeHKKioG1bSEqCbt3gzTchNdXsykREREREcgwFYhFHlTcvLFoEb7xhvJ40CTp1goQEc+sSEREREckhFIhFHJmTE7z1FsydC66uRkBu0AD++svsykREREREsj0FYpHsoEcPWL8eChWCnTvB3x8OHTK7KhERERGRbE2BWCS7qFcPduyAcuXg2DF4+mmIiDC7KhERERGRbEuBWCQ7eegh4w7xM89AXBw0awYzZ5pdlYiIiIhItqRALJLdPPCAcWf4hRcgJQVeegmGDjX+v4iIiIiI3DEFYpHsyM0NwsJg4kTj9XvvQZs2EB9vbl0iIiIiItmIArFIdmWxwOjREB5uBOQVK6BOHTh1yuzKRERERESyBQVikeyuQweIioIHH4R9++Cpp4z/FRERERGRW1IgFskJataEXbugcmWIiTGabq1caXZVIiIiIiIOTYFYJKcoWxa2b4fAQLhyBVq1gunTwWo1uzIREREREYekQCySkxQsCKtXQ9++RhB+9VXo3x+Sk82uTERERETE4SgQi+Q0rq7w6afw7rtG463//Q9atIBLl8yuTERERETEoSgQi+REFotxd3jpUsibF9avh1q14NgxsysTEREREXEYCsQiOVmrVrB1K3h7w6FD4O8PO3eaXZWIiIiIiENQIBbJ6R5/3OhAXb06/PUX1KsHixaZXZWIiIiIiOkUiEVyg5IljTvFLVtCYqIxd/HkyepALSIiIiK5mgKxSG7h5WU8UzxkiPF69Gjo0cMIyCIiIiIiuZACsUhu4uwM770Hn3xi/P+wMGjcGM6fN7syEREREZH7ToFYJDfq18+YrzhfPtiyBQIC4Pffza5KREREROS+UiAWya2aNIHt26FMGThyBGrWhM2bza5KREREROS+USAWyc2qVDE6UPv7w4ULEBhoDKMWEREREckFFIhFcrtixSAqCoKDISkJunc3Gm6lpppdmYiIiIjIPaVALCLg4QFffgmjRhmvJ082pmZKSDC3LhERERGRe0iBWEQMTk4waRKEhoKrK3z9NdSvD2fPml2ZiIiIiMg9oUAsIva6dYOICChU6J/niw8eNLsqEREREZEsp0AsImnVrQs7d0KFCnD8ONSqBd9+a3ZVIiIiIiJZSoFYRNJXsSLs2AF16kBcHLRoAZ9+anZVIiIiIiJZRoFYRDJWpAisX28Mo05Jgf79YcgQ4/+LiIiIiGRzCsQicmtubvD550bnaYD334egIIiPN7UsEREREZH/SoFYRG7PYoGRI2HRIiMgr1wJzzwDf/5pdmUiIiIiIpmmQCwid65dO9i0CYoWhf37jQ7UP/xgdlUiIiIiIpnikIE4Pj6ewYMH4+3tjbu7O9WrV+fLL7+8o32joqIIDAykaNGieHl5Ua1aNT744ANSbnrmsV69elgsljRfTZs2tdtu3Lhx6W534+vmuhYvXkytWrUoXLgwBQsW5KmnnmLevHn/7YSIOJKAAGM6pocfhpgY407x8uVmVyUiIiIictdczC4gPW3atGHPnj1MmTKFihUrsnDhQjp27EhqaiqdOnXKcL8NGzbQpEkT6tSpw6xZs/D09GTFihUMGjSI6OhoZsyYYbe9n58fCxYssFtWsGBBu9e9e/dOE5IBXnzxRaKjo+3WzZ07l169evH8888zevRoLBYLYWFhdO3aldjYWIYMGZKJsyHigHx9Yft2447x+vXGM8XTpsGrrxrDq0VEREREsgGL1Wq1ml3Ev61Zs4YWLVrYQvANjRs35tChQ5w4cQJnZ+d09+3SpQvffPMN58+fx9PT07a8SZMm7Ny5k0uXLtmW1atXj9jYWA4ePHjXNR47dgw/Pz86d+5sd/e3du3a/Pnnnxw9ehQnJ+Pmu9Vq5eGHHyZPnjz8+OOPd/wecXFxFChQgEuXLpE/f/67rjErJSUlsWbNGpo3b46rq6uptYiDSU6GAQPgf/8zXvftCx9+CPo5EckSuv6KiJjD0a6/jpQNchqHGzK9dOlSvLy8CA4Otlveo0cPYmJi2LVrV4b7urq6kidPHjw8POyWFyxYEHd39yyrce7cuVitVnr37p3m/b28vGxhGMBisZA/f/4sfX8Rh+HiAp98AtOnG3eGZ8405iu+eNHsykREREREbsvhAvHBgwepXLkyLi72o7mrVatmW5+Rl156ievXrzNw4EBiYmK4ePEi8+bNY+nSpQwfPjzN9tHR0RQuXBgXFxfKlSvHqFGjSEhIuGV9qamphIaGUr58eerWrWu3bsCAAfzyyy9MnjyZc+fOERsbyzvvvMP333/PsGHD7vQUiGQvFgsMHgzLloGnJ0REQK1a8McfZlcmIiIiInJLDvcM8fnz5/Hz80uzvHDhwrb1GfH39ycyMpLg4GA+/vhjAJydnQkJCWHo0KF229auXZv27dtTqVIlEhISWLt2LVOnTmXbtm1ERUXZ3eX9t/Xr13Py5ElCQkLSrGvTpg1LliyhW7dujB49GgAPDw/CwsLS3PG+WWJiIomJibbXcXFxgDFcIykp6Zb73ms33t/sOsTBNWsGkZG4BAVh+flnrP7+pCxejDUgwOzKRLItXX9FRMzhaNdfR6kjJ3K4QAzGMOPMrPv+++8JCgrC39+fmTNn4unpSWRkJKNHj+batWu8+eabtm0nTZpkt2/z5s3x9fVl2LBhLF++nKCgoHTfY86cObi4uNC9e/c069atW0eXLl0IDg6mXbt2uLi4sGLFCrp3787169fp0aNHhrWHhIQwfvz4NMvXr19P3rx5M9zvfoqIiDC7BMkG3CdOxH/yZAoePYqlYUP2DxzIqWeeMbsskWxN118REXM4yvX36tWrZpeQYzlcU62aNWuSkpLC7t277ZYfOnSIKlWqMHPmTPr06ZPuvgEBAVy9epV9+/bZNd4aO3YskyZN4vDhw+nefb7h7NmzFC9enOHDh/P222+nWR8bG4uPjw/NmjVj2bJlduusVis+Pj489thjrF692m5dt27dWLx4MWfPnrVr9vVv6d0hLlWqFLGxsaY/OJ+UlERERASBgYEO0VRAsoH4eJy7dsVp1SoAUsaNI/WNN9SBWuQu6forImIOR7v+xsXF8cADD6ip1j3gcHeIq1atSnh4OMnJyXbPER84cACAKlWqZLjv/v376dixY5ou1DVq1CA1NZVffvnlloH4hoyGS8+bN4/r16+naaYFRpg+ffo0ffv2TbOuRo0afPHFFxw7doxHHnkk3WO7ubnh5uaWZrmrq6tD/CMEx6pFHFyhQsYzxcOHw3vv4TxuHM7R0TBrFqTzcy4it6brr4iIORzl+usINeRUDtdUKygoiPj4eBYvXmy3PCwsDG9vb/z9/TPc19vbm71795KSkmK3fMeOHQCULFnylu8dFhYGGHea0zNnzhy8vb1p1qxZmnWFChXC3d2dnTt3plm3Y8cOnJycKFGixC3fXyRHcXaGd981pmRydoZ58yAwEG7RB0BERERE5H5yuDvEzZo1IzAwkH79+hEXF0f58uUJDw9n3bp1zJ8/33b3t1evXoSFhREdHU2ZMmUAGDJkCAMHDqRly5b07duXvHnzsnHjRt59910aNWrEo48+CsDWrVuZPHkyQUFB+Pn5ce3aNdauXctnn31GgwYNaNmyZZq6du3axaFDhxg5cmS68yC7ubnRv39/3nvvPbp27Ur79u1xdnZm2bJlLFy4kF69etkag4nkKn37QtmyEBwMW7dCQACsWgUPPWR2ZSIiIiKSyzlcIAZYsmQJo0aNYsyYMVy4cIFKlSoRHh5Ohw4dbNukpKSQkpLCvx+BHjBgAD4+PkyfPp3evXuTkJCAr68vY8eOZciQIbbtSpQogbOzMxMnTiQ2NhaLxUKFChWYMGECQ4cOTXfI9Jw5c7BYLPTq1SvDuqdNm0blypWZOXMmXbp0ITU1lXLlyvHRRx9l+NyzSK7QuDFs3w7PPgtHjkDNmrBkCdSrZ3ZlIiIiIpKLOVxTLTHExcVRoEABh3hwPikpiTVr1tC8eXM9vyD/zV9/QatWsHMnuLjAZ5/BLbqvi+R2uv6KiJjD0a6/jpQNchqHe4ZYRHKwokUhMhLat4fkZOjZE0aOhNRUsysTERERkVxIgVhE7i8PD1i4EEaPNl6HhBgBOSHB3LpEREREJNdRIBaR+8/JCSZOhLAwcHWFb74xnic+c8bsykREREQkF1EgFhHzdO0KGzZA4cKwezf4+8P/zzkuIiIiInKvKRCLiLnq1DGabFWsCCdOQK1asG6d2VWJiIiISC6gQCwi5qtQAXbsMIZNX74MLVrAJ5+YXZWIiIiI5HAKxCLiGAoXhm+/he7dja7TL78MgwdDSorZlYmIiIhIDqVALCKOI08emDsX3nrLeD1jhjFv8eXL5tYlIiIiIjmSArGIOBaLBd54A776CtzdYfVqeOYZOHnS7MpEREREJIdRIBYRxxQcDJs2QbFi8OOPRgfq7783uyoRERERyUEUiEXEcfn7w65d8MgjcPq00ZF62TKzqxIRERGRHEKBWEQcW5ky8N130KQJXL0KbdrAO++A1Wp2ZSIiIiKSzSkQi4jjK1AAVq2C/v2NIPzaa9C3LyQlmV2ZiIiIiGRjCsQikj24uMBHH8H77xuNt2bNgmbN4OJFsysTERERkWxKgVhEsg+LBQYNguXLwdMTNm6EmjXh6FGzKxMRERGRbEiBWESyn5YtYds28PGBX381mm9t3252VSIiIiKSzSgQi0j2VL067N4Njz8OsbHQoAGEh5tdlYiIiIhkIwrEIpJ9eXvDli3QujUkJkKnTjBhgjpQi4iIiMgdUSAWkezN0xMWL4Zhw4zXY8dC165GQBYRERERuQUFYhHJ/pycYNo0mDkTnJ1h/nxo1MgYSi0iIiIikgEFYhHJOfr0gXXrjHmLt22DgACj6ZaIiIiISDoUiEUkZ2nUyOg4XbYsREcb0zJFRppdlYiIiIg4IAViEcl5Hn4Ydu40wvDFi9CkCcyda3ZVIiIiIuJgFIhFJGcqWtS4M9yhAyQnQ69eMGIEpKaaXZmIiIiIOAgFYhHJudzdYeFCGDPGeP3229CuHVy9am5dIiIiIuIQFIhFJGezWGD8eJg3D/LkMaZoqlcPTp82uzIRERERMZkCsYjkDl26wIYNUKQI7NkD/v7w009mVyUiIiIiJlIgFpHc45lnjGZbFSvCyZNQqxasWWN2VSIiIiJiEgViEcldypc3QnH9+hAfDy1bwkcfmV2ViIiIiJhAgVhEcp9ChWDdOujZ0+g6PWAADBwIKSlmVyYiIiIi95ECsYjkTnnywOzZMGWK8frDD6FVK7h82dy6REREROS+USAWkdzLYoHXX4evvzamaFq9GmrXhhMnzK5MRERERO4DBWIRkbZtYfNmKFbM6Dzt7w9795pdlYiIiIjcYwrEIiIATz0Fu3dD1apw5gzUqQNLlphdlYiIiIjcQwrEIiI3lC4N27ZBs2aQkADPPw9Tp4LVanZlIiIiInIPKBCLiPxb/vywYgW8/LLx+vXXoU8fSEoyty4RERERyXIKxCIiN3NxMeYm/uADcHIyulE3bQp//212ZSIiIiKShRSIRUQyMmCAcbfYywsiI6FmTYiONrsqEREREckiCsQiIrfSooXxXHHJkvDbbxAQAN99Z3ZVIiIiIpIFFIhFRG7n0UeNDtRPPAGxsdCgASxcaHZVIiIiIvIfKRCLiNyJEiWMuYqDguD6dejcGcaPVwdqERERkWwsU4E4NjY2q+sQEXF8np7wzTcwfLjxetw46NIFrl0ztSwRERERyZxMBeKSJUvSvn17IiIisroeERHH5uQEb78Ns2YZ3agXLoRGjeDcObMrExEREZG7lKlAXK1aNb7++muaNm1K2bJlmTRpEqdOncrq2kREHFfv3rBuHRQoYDTZCgiAX381uyoRERERuQuZCsS7d+/mp59+4pVXXuHy5cuMGTMGX19fnnvuOVasWEFqampW1yki4ngaNoQdO8DPD44eNULxxo1mVyUiIiIidyjTTbWqVKnCjBkziImJYeHChdStW5fVq1cTFBREqVKlGDVqFEePHs3KWkVEHE/lyrBzJ9SqBZcuQdOmMHu22VWJiIiIyB34z12m8+TJQ4cOHdiwYQPR0dGMGjWKlJQUpkyZQsWKFQkMDGTx4sVY1YlVRHKqBx+EDRugUydIToYXXzQab2m0jIiIiIhDy7Jpl6xWKwcPHuSnn37i/PnzWK1WSpQowebNm2nXrh3Vq1fn8OHDd3Ss+Ph4Bg8ejLe3N+7u7lSvXp0vv/zyjvaNiooiMDCQokWL4uXlRbVq1fjggw9ISUmx265evXpYLJY0X02bNrXbbty4celud+Pr5rqsViuff/45Tz31FJ6enuTPn5/HH3+c5cuX31H9IpJNubvD/PlG52mAadOgbVu4etXUskREREQkYy7/9QB//PEHc+bMITQ0lNOnT+Pi4kLr1q3p27cvjRo14vTp00yfPp3p06fTr18/NmzYcNtjtmnThj179tjuMi9cuJCOHTuSmppKp06dMtxvw4YNNGnShDp16jBr1iw8PT1ZsWIFgwYNIjo6mhkzZtht7+fnx4IFC+yWFSxY0O51796904RkgBdffJHo6Og06/r160doaChDhgwhJCSE5ORkDhw4wFX9UiyS81ksMHYslC8PPXvC0qVQty6sWGHMYywiIiIiDiVTgTgpKYnFixcze/ZsNm3aRGpqKmXLlmXy5Mn07NmTokWL2rYtUaIEU6dO5fLly8ybN++2x16zZg0RERG2EAxQv359jh8/zmuvvUb79u1xdnZOd9/Q0FBcXV1ZtWoVnp6eADRq1IjffvuN0NDQNIHYw8ODgICAW9ZTsmRJSpYsabfs2LFjHDp0iM6dO9sF6GXLljFz5kwWLVpEu3btbMubNGly288tIjlI585QpgwEBcHevfDUU7BqFTz6qNmViYiIiMi/ZGrItLe3N507d2bLli20bt2ab7/9lujoaEaMGGEXhv+tTJkyd3SXdOnSpXh5eREcHGy3vEePHsTExLBr164M93V1dSVPnjx4eHjYLS9YsCDu7u538MnuzNy5c7FarfTu3dtu+YwZM/D19bULwyKSS9WubTTbqlQJ/vzTeL16tdlViYiIiMi/ZCoQe3l5MWnSJE6ePMk333xDYGDgbffp378/f/zxx223O3jwIJUrV8bFxf7mdbVq1WzrM/LSSy9x/fp1Bg4cSExMDBcvXmTevHksXbqU4cOHp9k+OjqawoUL4+LiQrly5Rg1ahQJCQm3rC81NZXQ0FDKly9P3bp1bcuTk5PZsWMHjz32GO+99x5lypTB2dkZPz8/3nnnHTUVE8mNypWD7duhQQOIj4fnnoMPPzS7KhERERH5f5kaMn306FEsFstd7ZM/f37y589/2+3Onz+Pn59fmuWFCxe2rc+Iv78/kZGRBAcH8/HHHwPg7OxMSEgIQ4cOtdu2du3atG/fnkqVKpGQkMDatWuZOnUq27ZtIyoqCien9P9WsH79ek6ePElISIjd8tjYWBITE9m4cSN79uxh8uTJlCxZkq+//prXXnuNv//+m8mTJ2dYe2JiIomJibbXcXFxgDE8PSkpKcP97ocb7292HSLZkpcXrFyJ8yuv4PT55zBwICm//krqO++Ay39u4yA5nK6/IiLmcLTrr6PUkRNl6rexuLg4jh8/Tvny5cmbN2+a9VeuXCE6OhpfX987CsE3u1XYvtW677//nqCgIPz9/Zk5cyaenp5ERkYyevRorl27xptvvmnbdtKkSXb7Nm/eHF9fX4YNG8by5csJCgpK9z3mzJmDi4sL3bt3t1ue+v/Tq8TFxfHtt9/ank1u0KABZ86c4b333uONN97Ay8sr3eOGhIQwfvz4NMvXr1+f7jk2Q0REhNkliGRfzz1H+dRUHgkLw/mTT4jduZO9w4aR7CD/vsWx6forImIOR7n+qkHvvWOxZmIs79ChQ5k5cyanT58mX758adbHxcXh4+ND//79efvtt+/q2DVr1iQlJYXdu3fbLT906BBVqlRh5syZ9OnTJ919AwICuHr1Kvv27bNrvDV27FgmTZrE4cOH0737fMPZs2cpXrw4w4cPT7fu2NhYfHx8aNasGcuWLbNbl5CQgKenJ/ny5ePSpUt26z777DP69u3Lrl27eOqpp9J97/TuEJcqVYrY2NhM/VEhKyUlJREREUFgYCCurq6m1iKS3VmWLsW5e3csCQlYq1QhedkyKF3a7LLEQen6KyJiDke7/sbFxfHAAw9w6dIl07NBTpOpO8Tr1q2jcePG6YZhMIZHN2nShDVr1tx1IK5atSrh4eEkJyfbPUd84MABAKpUqZLhvvv376djx45pulDXqFGD1NRUfvnll1sG4hsyGi49b948rl+/nqaZFhgdqytUqMCZM2fSrLvxN4eMjgvg5uaGm5tbmuWurq4O8Y8QHKsWkWyrXTvw84OWLbEcPIhrrVqwciXUqGF2ZeLAdP0VETGHo1x/HaGGnCpTTbVOnDhBhQoVbrlNuXLlOHHixF0fOygoiPj4eBYvXmy3PCwsDG9vb/z9/TPc19vbm71795KSkmK3fMeOHQBppk+6WVhYGECGUzHNmTMHb29vmjVrlu76559/nri4OLZv3263fM2aNXh5efHII4/c8v1FJJd48knYvRuqVYOzZ425im+65omIiIjIvZepO8QWi8VueG96EhMT0wTTO9GsWTMCAwPp168fcXFxlC9fnvDwcNatW8f8+fNtd3979epFWFgY0dHRlClTBoAhQ4YwcOBAWrZsSd++fcmbNy8bN27k3XffpVGjRjz6/3OAbt26lcmTJxMUFISfnx/Xrl1j7dq1fPbZZzRo0ICWLVumqWvXrl0cOnSIkSNHZjgP8rBhw1iwYAHBwcFMnDiRkiVL8s0337BixQreeeedNNNBiUguVqoUbNsGHTrAmjXQti1MmQLDh8NdNi0UERERkczJVCCuXLky69atw2q1ptvkKjU1lbVr1/LQQw9lqqglS5YwatQoxowZw4ULF6hUqRLh4eF06NDBtk1KSgopKSl20xkNGDAAHx8fpk+fTu/evUlISMDX15exY8cyZMgQ23YlSpTA2dmZiRMnEhsbi8VioUKFCkyYMIGhQ4emO7R5zpw5WCwWevXqlWHdhQsXZtu2bQwfPpxhw4Zx5coVKlWqxNy5c+nRo0emzoWI5GD58sHy5fDqq8Z0TCNGwO+/w6efQp48ZlcnIiIikuNlqqnWjBkzGDJkCN26deP999+nQIECtnWXLl1i0KBBzJs3j3feeccuiMqdi4uLo0CBAg7x4HxSUhJr1qyhefPmen5B5F756CMYNAhSU6F+fWMIdaFCZlclJtP1V0TEHI52/XWkbJDTZOoOcf/+/VmyZAlhYWEsX76cGjVq4OPjw6lTp9izZw8XL16kTp06vPLKK1ldr4hIzvTKK0azrfbtISoKAgJg9WooX97sykRERERyrEw11XJ1dWX9+vUMGzaM1NRUIiIiCA0NJSIigtTUVF577TW+/fZbh/hriohIttG8OXz3nfF88e+/G6F461azqxIRERHJsTIViMGYJmjq1KlcuHCBgwcPsm3bNg4ePMj58+d5++23051CSEREbqNaNdi1y5iG6fx5aNQI5s83uyoRERGRHClTQ6b/zcnJiYcffjgrahEREYASJWDTJuja1XiW+IUX4PBhGDdOHahFREREslCm7xCLiMg9lDcvfPUVvP668XrCBOjcGa5dM7cuERERkRwk03eIL1++zEcffcSGDRuIiYlJd15ii8VCdHT0fypQRCTXcnIy5iauWBH69oXwcDh2zJiq6cEHza5OREREJNvLVCA+d+4cTz/9NNHR0eTPn9/WBvz69eskJCQA4O3traZaIiJZoWdPKFsW2rSBHTvA3x9WrQI9riIiIiLyn2RqyPS4ceOIjo7miy++4O+//wZgyJAhXLlyhV27dvHUU0/h6+vLoUOHsrRYEZFcq359IwyXKwd//AFPPw0bNphdlYiIiEi2lqlAvGbNGho2bEiXLl2w3NTgpUaNGqxdu5Zjx44xbty4rKhRREQAKlWCnTuhVi24dAmaNoVZs8yuSkRERCTbylQgPn36NI899pjttbOzs22oNEChQoVo1qwZX3/99X+vUERE/vHAA7Bxo9FgKyUF+vSB114z/r+IiIiI3JVMBeICBQqQlJRke12oUCH+/PNPu23y58/P2bNn/1t1IiKSlpsbzJsH48cbr995B9q2hStXzK1LREREJJvJVCD28/Pj2LFjttePPfYYERERXLhwAYCEhARWrlxJ6dKls6RIERG5icUCY8bAwoWQJw8sWwZ16kBMjNmViYiIiGQbmQrEjRs3ZuPGjVy9ehWAvn378tdff/Hoo48SHBxMlSpViI6Opnv37llZq4iI3KxjR4iMNIZS//ADPPUU7N9vdlUiIiIi2UKmAvFLL73ErFmzbIG4TZs2TJs2jfj4eBYvXsyZM2d49dVXee2117K0WBERSUetWrBrl9F069QpqF3bmJZJRERERG4pU4G4RIkStG/fngceeMC2bOjQocTGxnL69Gni4+OZNm0azs7OWVaoiIjcgp+fMS1Tw4bGs8StWsGMGWC1ml2ZiIiIiMPKVCDu2bMn77//fprlzs7OFCtWLM1UTCIich8ULAhr18KLL0JqKgweDK+8AsnJZlcmIiIi4pAyFYgXLlyoDtIiIo7I1RVmzoRp04zGW598Ai1bQlyc2ZWJiIiIOJxMBeLy5ctz+vTprK5FRESygsUCw4bB4sXg4QHr1hnPGR8/bnZlIiIiIg4lU4G4V69erF69mlOnTmV1PSIiklWCgmDrVihRAg4eBH9/o/mWiIiIiADgkpmdgoKC2LhxI08//TTDhw+nRo0aGT47rLmIRURM9MQTsHs3PPss/Pgj1KsHX3wBwcFmVyYiIiJiukwFYj8/PywWC1arlYEDB2a4ncViIVnNXEREzFWypHGnuGNHWL0a2rWDt96CESOM4dUiIiIiuVSmAnHXrl3VSVpEJDvJlw+WL4ehQ43pmEaOhN9/Nxpw5cljdnUiIiIipshUIA4NDc3iMkRE5J5zdob334cKFWDgQAgNhT/+gCVLoHBhs6sTERERue8y1VRLRESysZdfNoZO58sHmzdDQAAcPmx2VSIiIiL3nQKxiEhu1LQpfPcdlC5thOGAANiyxeyqRERERO6rTDfVuhMWi4Xo6OjMvIWIiNxrVasa0zC1amV0om7UCGbPhq5dza5MRERE5L7I1B3i1NRUrFZrmq+LFy9y7Ngxjh07RmJiIqmpqVldr4iIZKXixSEqCtq2haQk6NYN3nwTdP0WERGRXCBTd4iPHTt2y3WvvvoqZ8+eJSIiIrN1iYjI/ZI3LyxaBKNHQ0gITJpkDKP+/HPw8DC7OhEREZF7JsufIfb19WXRokX8/fffjBo1KqsPLyIi94KTkzE38dy54OpqBOQGDeCvv8yuTEREROSeuSdNtVxdXQkMDOSrr766F4cXEZF7pUcPWL8eChWCnTvB3x8OHTK7KhEREZF74p51mb569SoXLly4V4cXEZF7pV492LEDypWDY8fg6adBj8CIiIhIDnRPAvGWLVsIDw/noYceuheHFxGRe+2hh4w7xM88A3Fx0KwZzJxpdlUiIiIiWSpTTbUaNGiQ7vLk5GROnTrFsWPHsFqtjB49+j8VJyIiJnrgAePO8Isvwrx58NJL8PvvMHUqODubXZ2IiIjIf5apQLxp06Z0l1ssFgoVKkRgYCBDhgyhSZMm/6U2ERExm5sbhIVBxYrGdEzvvQdHjsCCBeDlZXZ1IiIiIv9JpgKx5hcWEclFLBZjSqby5aF7d1ixAurUgZUrwcfH7OpEREREMu2eNdUSEZEcpkMHiIqCBx+EffvgqaeM/xURERHJpjIViC9dusRPP/3E1atX011/5coVfvrpJ+Li4v5TcSIi4mBq1oRdu6ByZYiJMZpurVxpdlUiIiIimZKpQDxhwgSefvppUlJS0l2fkpJCrVq1mDx58n8qTkREHFDZsrB9OwQGwpUr0KoVTJ8OVqvZlYmIiIjclUwF4nXr1tG4cWPy5cuX7vr8+fPTpEkT1qxZ85+KExERB1WwIKxeDX37GkH41Vehf39ITja7MhEREZE7lqlAfOLECSpUqHDLbcqVK8eJEycyVZSIiGQDrq7w6afw7rtG463//Q9atIBLl8yuTEREROSOZCoQWywWEhMTb7lNYmJihkOqRUQkh7BYjLvDS5dC3rywfj3UqgXHjpldmYiIiMhtZSoQV65cmXXr1mHN4Hmx1NRU1q5dy0MPPfSfihMRkWyiVSvYuhW8veHQIfD3h507za5KRERE5JYyFYg7derE77//Ts+ePbl009C4S5cu0bNnT44cOUKXLl2ypEgREckGHn/c6EBdvTr89RfUqweLFpldlYiIiEiGXDKzU//+/VmyZAlhYWEsX76cGjVq4OPjw6lTp9izZw8XL16kTp06vPLKK1ldr4iIOLKSJY07xZ06GdMxdegAR47AyJHG8GoRERERB5KpO8Surq6sX7+eYcOGkZqaSkREBKGhoURERJCamsprr73Gt99+i6ura1bXKyIijs7Ly3imeMgQ4/Xo0dCjB9ym94SIiIjI/ZapO8QAbm5uTJ06lSlTpvDrr79y8eJFChYsyEMPPYSzs3NW1igiItmNszO89x5UqAADBkBYGPzxByxZAkWKmF2diIiICPAfAvENTk5OPPzww1lRi4iI5DT9+oGfHwQHw5YtULOmMX/xbabuExEREbkfMjVk+ueff+aDDz7g3Llz6a7/66+/+OCDD/jll18yVVR8fDyDBw/G29sbd3d3qlevzpdffnlH+0ZFRREYGEjRokXx8vKiWrVqfPDBB2mmgKpXrx4WiyXNV9OmTe22GzduXLrb3fi6VV1dunTBYrHw7LPP3v1JEBHJKZo0ge3boUwZOHwYAgJg82azqxIRERHJ3B3iKVOmsHHjxgybZhUpUoRp06axb98+Pv/887s+fps2bdizZw9TpkyhYsWKLFy4kI4dO5KamkqnTp0y3G/Dhg00adKEOnXqMGvWLDw9PVmxYgWDBg0iOjqaGTNm2G3v5+fHggUL7JYVLFjQ7nXv3r3ThGSAF198kejo6HTXAaxevZply5aRP3/+O/zUIiI5WJUqRgfqVq2M/w0MhFmzoFs3sysTERGRXCxTgXjr1q00bNgQJ6f0bzA7OzvTsGFDtmzZctfHXrNmDREREbYQDFC/fn2OHz/Oa6+9Rvv27TN8Rjk0NBRXV1dWrVqFp6cnAI0aNeK3334jNDQ0TSD28PAgICDglvWULFmSkiVL2i07duwYhw4donPnzmkCNBhTT/Xt25eJEyemeU8RkVyrWDGIijJC8NdfQ/fuxh3jCRMgg/+eiIiIiNxLmfoN5MyZM5QqVeqW2/j4+HD69Om7PvbSpUvx8vIiODjYbnmPHj2IiYlh165dGe7r6upKnjx58PDwsFtesGBB3N3d77qWjMydOxer1Urv3r3TXT906FBKlCjBwIEDs+w9RURyBA8P+PJLGDXKeD15MnTsCAkJ5tYlIiIiuVKmArGnpyd//fXXLbf566+/MhVCDx48SOXKlXFxsb95Xa1aNdv6jLz00ktcv36dgQMHEhMTw8WLF5k3bx5Lly5l+PDhabaPjo6mcOHCuLi4UK5cOUaNGkXCbX4pS01NJTQ0lPLly1O3bt006zds2MAXX3zB7Nmz1W1bRCQ9Tk4waRKEhoKrK3z1FdSvD2fPml2ZiIiI5DKZGjL9xBNPsGzZMqZNm5bukOG///6bpUuX8vjjj9/1sc+fP4+fn1+a5YULF7atz4i/vz+RkZEEBwfz8ccfA8bw7ZCQEIYOHWq3be3atWnfvj2VKlUiISGBtWvXMnXqVLZt20ZUVFSGw8HXr1/PyZMnCQkJSbMuPj6eF198kWHDhvHoo4/e8WcGSExMJPFfc3TGxcUBkJSURFJS0l0dK6vdeH+z6xCRHKZTJywlS+IcHIxl1y6s/v4kL11qPG8sgK6/IiJmcbTrr6PUkRNlKhC//PLLtG7dmvr16zNjxgzq1KljW7d582YGDRrE33//nWHTrduxWCyZWvf9998TFBSEv78/M2fOxNPTk8jISEaPHs21a9d48803bdtOmjTJbt/mzZvj6+vLsGHDWL58OUFBQem+x5w5c3BxcaF79+5p1o0YMQJXV1fGjBlzm0+YVkhICOPHj0+zfP369eTNm/euj3cvREREmF2CiORAnpMmETB5Ml7Hj0Pt2ux57TXOPfaY2WU5FF1/RUTM4SjX36tXr5pdQo5lsVqt1szsOHz4cN555x0sFgtubm4UL16cM2fOkJiYiNVqZdiwYUydOvWuj1uzZk1SUlLYvXu33fJDhw5RpUoVZs6cSZ8+fdLdNyAggKtXr7Jv3z674cpjx45l0qRJHD58ON27zzecPXuW4sWLM3z4cN5+++0062NjY/Hx8aFZs2YsW7bMbt3u3bsJCAhgyZIl1KtXz7a8WrVqPPzww3z55Zd4eHjg5uaW7nund4e4VKlSxMbGmt6pOikpiYiICAIDA3F1dTW1FhHJoc6fx7ldO5y2bsXq7Ezq+++T2rev2VWZTtdfERFzONr1Ny4ujgceeIBLly6Zng1ymkzdIQaYOnUq9erV4+OPP2bPnj38+eefFCxYkAYNGvDyyy/TrFkzkpOT0zwLfDtVq1YlPDw8zb4HDhwAoMothtLt37+fjh07pnl2t0aNGqSmpvLLL7/cMhDfkNFw6Xnz5nH9+vV0m2n9/PPPWK3WdO8snzx5kkKFCjF9+nQGDx6c7rHd3NzSDcuurq4O8Y8QHKsWEclhiheHiAjo2xdLWBjOAwbgfPQoTJsG6seg66+IiEkc5frrCDXkVJkOxGAMM27evHma5T///DNDhw5lwYIFnDlz5q6OGRQUxKxZs1i8eDHt27e3LQ8LC8Pb2xt/f/8M9/X29mbv3r2kpKTYheIdO3YApJk+6WZhYWEAGU7FNGfOHLy9vWnWrFmadU2bNiUqKirN8g4dOlC2bFlCQkIoX778Ld9fRCRXc3ODzz+HihWNLtTTp8ORI7BwIXh5mV2diIiI5ED/KRD/W3x8PF9++SVz5sxh9+7dWK1W8uTJc9fHadasGYGBgfTr14+4uDjKly9PeHg469atY/78+bag26tXL8LCwoiOjqZMmTIADBkyhIEDB9KyZUv69u1L3rx52bhxI++++y6NGjWyNbraunUrkydPJigoCD8/P65du8batWv57LPPaNCgAS1btkxT165duzh06BAjR45Mt3t08eLFKV68eJrl7u7uFClSxG4YtYiIZMBigZEjoXx56NoVVq6EZ54x/vc2f9QUERERuVv/ORBv27aNuXPn8vXXX3P16lWsViuPPfYYPXr0oFOnTpk65pIlSxg1ahRjxozhwoULVKpUifDwcDp06GDbJiUlhZSUFP79CPSAAQPw8fFh+vTp9O7dm4SEBHx9fRk7dixDhgyxbVeiRAmcnZ2ZOHEisbGxWCwWKlSowIQJExg6dGi6Q6bnzJmDxWKhV69emfpMIiJyF9q1g9KloVUr2L8f/P2NUJyJ2QtEREREMpKpplpnz54lLCyMuXPncvjwYaxWq62pVteuXQkNDb0HpeYucXFxFChQwCEenE9KSmLNmjU0b95czy+IyP117Bi0aAE//wx58xrDp1u1Mruq+0bXXxERczja9deRskFOk373qHSkpqaycuVKWrduTalSpRgxYgQnTpygXbt2rF69mpMnTwJkapi0iIhIunx9Yft2aNwYrl6FoCB4913I3AQJIiIiInbueMh0yZIlOXv2LAC1atWia9eutGvXTn+hEBGRe6tAAVi9GgYMgP/9D4YNg8OH4cMPwQH+ai8iIiLZ1x3fIT5z5gwWi4Vhw4axYsUKevfurTAsIiL3h4sLfPKJ0XnaYoGZM42h1Bcvml2ZiIiIZGN3HIi7dOmCu7s777zzDiVKlCA4OJgVK1aQnJx8L+sTERExWCwweDAsWwaensa8xbVqwR9/mF2ZiIiIZFN3HIi/+OILTp8+zSeffELVqlVZvHgxQUFBFC9enFdeeYWdO3feyzpFREQMzz0HW7eCt7fRbMvfH/5/vnkRERGRu3HHgRggX7589O3bl927d/PTTz8xYMAALBYLn3zyCbVq1cJisfDbb79x4sSJe1WviIgIPPYY7N5t/O+5c1C/Pnz5pdlViYiISDZzV4H436pUqcL7779PTEwMX375JYGBgVgsFrZu3Yqfnx+BgYGEh4dnZa0iIiL/8PGBLVuMO8aJidCxI0yapA7UIiIicscyHYhvcHV1pV27dqxbt45jx44xbtw4SpcuzcaNG+nSpUtW1CgiIpI+Ly9YsgRefdV4/eab0K2bEZBFREREbuM/B+J/K1myJGPGjOHo0aOsX7+e9u3bZ+XhRURE0nJ2NuYm/t//jP8/bx4EBsL582ZXJiIiIg4uSwPxvzVq1IiFCxfeq8OLiIjY69sX1qyB/PmNplsBAfDbb2ZXJSIiIg7sngViERGR+65xY9i+HXx94cgRqFkTNm0yuyoRERFxUArEIiKSszzyCOzaZdwh/vtvY/j055+bXZWIiIg4IAViERHJeYoWhchIaN8ekpOhZ08YORJSU82uTERERByIArGIiORMHh6wcCGMHm28DgkxAnJCgrl1iYiIiMNQIBYRkZzLyQkmToSwMHB1hW++gXr14MwZsysTERERB6BALCIiOV/XrrBhAxQuDLt3g78/HDhgdlUiIiJiMgViERHJHerUgZ07oWJFOHECatWCdevMrkpERERMpEAsIiK5R4UKsGOHMWz68mVo0QI++cTsqkRERMQkCsQiIpK7FC4M334L3bsbXadffhkGD4aUFLMrExERkftMgVhERHKfPHlg7lx46y3j9YwZ0Lq1cddYREREcg0FYhERyZ0sFnjjDfjqK3B3h1Wr4Jln4ORJsysTERGR+0SBWEREcrfgYNi0CYoVgx9/NDpQf/+92VWJiIjIfaBALCIi4u8Pu3bBI4/A6dNGR+ply8yuSkRERO4xBWIRERGAMmXgu++gSRO4ehXatIF33gGr1ezKRERE5B5RIBYREbmhQAHjWeL+/Y0g/Npr0LcvJCWZXZmIiIjcAwrEIiIi/+biAh99BO+/bzTemjULmjWDixfNrkxERESymAKxiIjIzSwWGDQIli8HT0/YuBFq1oSjR82uTERERLKQArGIiEhGWraEbdvAxwd+/dVovrV9u9lViYiISBZRIBYREbmV6tVh9254/HGIjYUGDSA83OyqREREJAsoEIuIiNyOtzds2QKtW0NiInTqBBMmqAO1iIhINqdALCIicic8PWHxYhg2zHg9dix07WoEZBEREcmWFIhFRETulJMTTJsGM2eCszPMnw+NGhlDqUVERCTbUSAWERG5W336wLp1xrzF27ZBQIDRdEtERESyFQViERGRzGjUyOg4XbYsREcb0zJFRppdlYiIiNwFBWIREZHMevhh2LnTCMMXL0KTJjB3rtlViYiIyB1SIBYREfkvihY17gx36ADJydCrF4wYAampZlcmIiIit6FALCIi8l+5u8PChTBmjPH67behXTu4etXcukREROSWFIhFRESygsUC48fDvHmQJ48xRVO9enD6tNmViYiISAYUiEVERLJSly6wYQMUKQJ79oC/P/z0k9lViYiISDoUiEVERLLaM88YzbYqVoSTJ6FWLVizxuyqRERE5CYKxCIiIvdC+fJGKK5fH+LjoWVL+Ogjs6sSERGRf1EgFhERuVcKFYJ166BnT6Pr9IABMHAgpKSYXZmIiIigQCwiInJv5ckDs2fDlCnG6w8/hFat4PJlc+sSERERBWIREZF7zmKB11+Hr782pmhavRpq14YTJ8yuTEREJFdTIBYREblf2raFzZuhWDGj87S/P+zda3ZVIiIiuZYCsYiIyP301FOwezdUrQpnzkCdOrBkidlViYiI5EoKxCIiIvdb6dKwbRs0awYJCfD88zB1KlitZlcmIiKSqzhkII6Pj2fw4MF4e3vj7u5O9erV+fLLL+9o36ioKAIDAylatCheXl5Uq1aNDz74gJSbOnrWq1cPi8WS5qtp06Z2240bNy7d7W58/buu2bNn07p1a3x9ffHw8KB8+fL069eP06dP//eTIiIiOUv+/LBiBbz8svH69dehTx9ISjK3LhERkVzExewC0tOmTRv27NnDlClTqFixIgsXLqRjx46kpqbSqVOnDPfbsGEDTZo0oU6dOsyaNQtPT09WrFjBoEGDiI6OZsaMGXbb+/n5sWDBArtlBQsWtHvdu3fvNCEZ4MUXXyQ6Otpu3dixY6lfvz5vvfUWPj4+/Pbbb0ycOJHly5ezb98+ihUrlomzISIiOZaLizE38UMPweDBRjfqo0fhm28gf34smzfjs2ULFk9PYz5jZ2ezKxYREclRLFarY43PWrNmDS1atLCF4BsaN27MoUOHOHHiBM4Z/ELQpUsXvvnmG86fP4+np6dteZMmTdi5cyeXLl2yLatXrx6xsbEcPHjwrms8duwYfn5+dO7cmXnz5tmW//XXXxQtWtRu271791KjRg0mTpzI6NGj7/g94uLiKFCgAJcuXSJ//vx3XWNWSkpKYs2aNTRv3hxXV1dTaxERybFWr4YOHSA+Hry9jXmLz5z5Z33JkjBjBrRpY16NIiK5hKP9/utI2SCncbgh00uXLsXLy4vg4GC75T169CAmJoZdu3ZluK+rqyt58uTBw8PDbnnBggVxd3fPshrnzp2L1Wqld+/edstvDsMATzzxBM7Ozpw8eTLL3l9ERHKgFi2M54qLFIGYGPswDHDqlNGlWg24REREsozDBeKDBw9SuXJlXFzsR3NXq1bNtj4jL730EtevX2fgwIHExMRw8eJF5s2bx9KlSxk+fHia7aOjoylcuDAuLi6UK1eOUaNGkZCQcMv6UlNTCQ0NpXz58tStW/e2n2fz5s2kpKTwyCOP3HZbERHJ5apUgTx50l93Y0DX4MFwU18MERERyRyHe4b4/Pnz+Pn5pVleuHBh2/qM+Pv7ExkZSXBwMB9//DEAzs7OhISEMHToULtta9euTfv27alUqRIJCQmsXbuWqVOnsm3bNqKionBySv9vBevXr+fkyZOEhITc9rNcvnyZ/v37U6pUKXr27HnLbRMTE0lMTLS9jouLA4zhGkkmN1i58f5m1yEiktNZNm/G5VaNGK1WOHmS5KgorHfwR1kREckcR/v911HqyIkcLhADWCyWTK37/vvvCQoKwt/fn5kzZ+Lp6UlkZCSjR4/m2rVrvPnmm7ZtJ02aZLdv8+bN8fX1ZdiwYSxfvpygoKB032POnDm4uLjQvXv3W36Ga9eu0aZNG44fP05kZCReXl633D4kJITx48enWb5+/Xry5s17y33vl4iICLNLEBHJ0Xy2bOHJO9ju/Ouv81v79vxdsSLc4r+LIiLy3zjK779Xr141u4Qcy+GaatWsWZOUlBR2795tt/zQoUNUqVKFmTNn0qdPn3T3DQgI4OrVq+zbt8+u8dbYsWOZNGkShw8fTvfu8w1nz56lePHiDB8+nLfffjvN+tjYWHx8fGjWrBnLli3L8DiJiYm0bt2aTZs2sWrVKho2bHibT53+HeJSpUoRGxtr+oPzSUlJREREEBgY6BBNBUREcirL5s24BAbe8fbWMmVIbduW1HbtoHp1hWMRkSziaL//xsXF8cADD6ip1j3gcHeIq1atSnh4OMnJyXbPER84cACAKlWqZLjv/v376dixY5ou1DVq1CA1NZVffvnlloH4hoyGS8+bN4/r16+naab1bzfCcFRUFMuXL7+jMAzg5uaGm5tbmuWurq4O8Y8QHKsWEZEcqX59o5v0qVP/PDP8bxaL0XSrUSNYtQrL8eM4v/suzu++C+XLQ/v2RqfqW/y3UkRE7pyj/P7rCDXkVA7XVCsoKIj4+HgWL15stzwsLAxvb2/8/f0z3Nfb25u9e/eSclOzkR07dgBQsmTJW753WFgYYNxpTs+cOXPw9vamWbNm6a5PTEwkKCiIyMhIFi9eTJMmTW75fiIiInacnY2plSDt3d4br2fOhPBw+OsvY77i4GDw8IAjR2DyZKhaFR55BCZMgN9+u7/1i4iIZDMOd4e4WbNmBAYG0q9fP+Li4ihfvjzh4eGsW7eO+fPn2+7+9urVi7CwMKKjoylTpgwAQ4YMYeDAgbRs2ZK+ffuSN29eNm7cyLvvvkujRo149NFHAdi6dSuTJ08mKCgIPz8/rl27xtq1a/nss89o0KABLVu2TFPXrl27OHToECNHjsxwHuS2bduydu1aRo0aRZEiRdi5c6dtXf78+Xn44Yez+nSJiEhO06aNEXQHDYI///xnecmS8P77/8xD7OEBzz9vfMXHw8qVsGgRrF0LP/8MY8caX48+atw5bt8e7mCUlIiISG7icM8QA8THxzNq1Ci++uorLly4QKVKlXjjjTfo0KGDbZvu3bsTFhbGH3/8ga+vr235kiVLmD59Or/++isJCQn4+vrSoUMHhgwZgqenJwBHjhxh0KBB/Pjjj8TGxmKxWKhQoQIdOnRg6NCh6Q5d7tOnD7Nnz+bIkSMZDru+VcOvunXrsmnTpjs+B440+bajTUwuIpIrpKSQHBXF/rVrqd6sGS716xt3kG/n0iVYvhy+/BIiIiA5+Z91NWoYwbhdOyhV6t7VLiKSzTna77+OlA1yGocMxOJYP/SOdkEQEckt/vP19/x5WLrUuHMcGQmpqf+se/pp43njtm2hRImsK1pEJAdwtN9/HSkb5DQO9wyxiIiIZJEiRaB3b+NOcUwMfPwx1KljPI+8fTsMHAg+PkYzr//9D86dM7tiERGR+0qBWEREJDcoVgz694fNm+HkSeN55Jo1jW7WmzZBv37GneImTWDuXPj7b7MrFhERuecUiEVERHIbHx+jadf27XDsGEydCk88ASkpsH499OplBOhnn4V58yAuzuyKRURE7gkFYhERkdysTBl47TXYuxcOH/5n6qakJFi9Grp2haJFje7WixbBlStmVywiIpJlFIhFRETEUL48jBwJP/30z9RNlSpBYqLRnKtDByMct29vvL52zeyKRURE/hMFYhEREUmrcmUYN84Ixvv3wxtvGPMYX70KX31l3DEuWhReeAFWrYLr182uWERE5K4pEIuIiEjGLBZ49FF46y04cgT27IFhw4x5jC9fhvnzoWVL45njXr2MZ5D/PfexiIiIA1MgFhERkTtjscCTT8K0aUYzru++M6ZuKlECLl40ulM3aWK8fukliIoyGnWJiIg4KAViERERuXtOTvD00zBjhjGN06ZNRgh+4AGIjYWZM6FBAyhZ0gjN330HqalmVy0iImJHgVhERET+G2dnqFsXPv0UTp/+Z+qmQoXgzBn48EOoXRt8fY3h1nv2GPMfi4iImEyBWERERLKOiwsEBsLs2UYYXrXKaLyVL59xJ/ndd+Gpp4yO1m+8YTTsUjgWERGTKBCLiIjIvZEnD7RoAV98AX/99c/UTXnzwtGjMGUKPPaY0dF67Fijo7WIiMh9pEAsIiIi9567O7RuDeHhRjhetMiYusnNDX77DSZMgEcegapVYdIkOHzY7IpFRCQXUCAWERGR+8vTE9q1g8WLjXA8bx48+yy4usLBg/Dmm1CxIjzxBEydanS0FhERuQcUiEVERMQ8+fNDly6wciWcPfvP1E3OzvDDD/D661C2LAQEwPvvw6lTZlcsIiI5iAKxiIiIOIZChaBHD1i3zuhW/b//Qf36xvzHu3bBkCFQqhTUqQMff2wEaBERkf9AgVhEREQcz4MPQt++EBkJMTHG1E21ahkdqbduhVdeAW9vaNQIZs2C8+fNrlhERLIhBWIRERFxbMWLGwF42zY4ceKfqZtSU2HjRujTx9imWTMIDYWLF82uWEREsgkFYhEREck+SpWCV181hlBHR0NICFSvDsnJxlDrHj2gWDFo1QoWLoT4eLMrFhERB6ZALCIiItmTnx+MGAH79tlP3XT9OqxYAZ07G0Ovg4Phm2/g6lWzKxYREQejQCwiIiLZX8WKxnRNBw/CgQMwejRUqADXrhlhODgYihaFTp1g+XJITDS7YhERcQAKxCIiIpKzVKkCEycad41vTN3k6wtXrkB4OLRubYTj7t1h7VpISjK5YBERMYsCsYiIiORMFgs89hhMmQJHj8LOncbUTT4+EBcHYWHQvLnRkOvFF2HDBuNZZBERyTUUiEVERCTns1jA3x/ee8/oVH1j6qZixeDCBZg9GwIDjbD88suwZYvRxVpERHI0BWIRERHJXZycoHZtY27jU6f+mbqpSBH46y/45BOoW9foaD14sHFn2Wo1u2oREbkHFIhFREQk93J2hgYNYOZMOH3amLqpe3coUABiYmDGDKhZE8qWheHD4fvvFY5FRHIQBWIRERERAFdXaNIEPv8czp79Z+omLy84fhymTYMnnzQ6Wo8ebXSzVjgWEcnWFIhFREREbubmBi1bwvz5xjDqG1M3eXjAkSMweTJUq2bMezx+PPz6q9kVi4hIJigQi4iIiNyKhwc8/zx89ZURjsPDoVUryJMHfvkFxo2DypWhenUICTE6WouISLagQCwiIiJyp7y8oEMHWLbMCMc3pm5ycYEff4SRI6FcOahRA959F06eNLtiERG5BQViERERkcwoUAC6doXVq+HMGZg1Cxo1MrpY790Lw4ZB6dJQqxZ88IHRtEtERByKArGIiIjIf1WkCPTuDRERRvC9MXWTxQLbt8OgQcYcx/Xrw//+B+fOmV2xiIigQCwiIiKStYoWhX79YNMm+PNPeP99Y+omq9VY1q8flCgBjRvDnDlw4YLJBYuI5F4KxCIiIiL3ire3cXd4+3Y4dsyYuumJJyAlxbib3Ls3FC8Ozz4L8+ZBXJzZFYuI5CoKxCIiIiL3Q5kyxnPFe/fC4cP/TN2UlGQ8h9y1q3F3OSgIFi2CK1fMrlhEJMdTIBYRERG538qXNzpS//gj/PwzjB0LlSpBYqLRwbpDByMct28PS5ZAQoLZFYuI5EgKxCIiIiJmqlzZmMv455//mbrJzw+uXjXmPn7+eShWDF54AVatguvXza5YRCTHUCAWERERcQQWizGEevJkOHIE9uz5Z+qmy5dh/nxo2dIIxz17wrffGsOtRUQk0xSIRURERByNxQJPPmk04frjD6Mp18CBRnfqixfh88+haVOjaddLL0FUlNGoS0RE7ooCsYiIiIgjc3Iypm2aMQNOnvxn6qYHH4TYWJg5Exo0gJIlYcAA+O47SE01u2oRkWxBgVhEREQku3B2hrp14ZNPICYG1q+HXr2gUCE4cwY++ghq1zY6Wg8dCrt3G/Mfi4hIuhSIRURERLIjFxcIDITZs40wfGPqpnz54M8/4b33wN8fypWDN96A/fsVjkVEbqJALCIiIpLd5ckDzZtDWBj89RcsXWpM3ZQ3r/EM8pQp8NhjxtROY8YYHa1FRESBWERERCRHcXeH1q0hPBzOnTOmbmrTxlj+++8wcSI88ghUrQqTJsHhw2ZXLCJiGgViERERkZwqb14IDobFi407xzembnJ1hYMH4c03oWJFePxxmDoVjh0zu2IRkftKgVhEREQkN8iXDzp3hhUr4OxZmDsXmjQxGnXt2wevvw5ly0JAAEyfbjyHLCKSwykQi4iIiOQ2hQpBjx6wbp3RkGvmTKhf35jiadcuePVVKFUK6tSBjz82ArSISA7kkIE4Pj6ewYMH4+3tjbu7O9WrV+fLL7+8o32joqIIDAykaNGieHl5Ua1aNT744ANSbpqsvl69elgsljRfTZs2tdtu3Lhx6W534+vmuo4ePUqbNm0oWLAgXl5eBAYG8sMPP/y3EyIiIiJyrzzwAPTpA5GRcOoUfPihMXUTwNat8Mor4O0NDRvCZ58Zcx+LiOQQLmYXkJ42bdqwZ88epkyZQsWKFVm4cCEdO3YkNTWVTp06Zbjfhg0baNKkCXXq1GHWrFl4enqyYsUKBg0aRHR0NDNmzLDb3s/PjwULFtgtK1iwoN3r3r17pwnJAC+++CLR0dF2686dO8czzzxDoUKFmDt3Lu7u7oSEhFCvXj327NnDQw89lImzISIiInKfFC9uBOBXXoGTJ+Hrr2HRImM+48hI46t/f2O6p/btjeZdN/3uJCKSnVisVseakG7NmjW0aNHCFoJvaNy4MYcOHeLEiRM4Ozunu2+XLl345ptvOH/+PJ6enrblTZo0YefOnVy6dMm2rF69esTGxnLw4MG7rvHYsWP4+fnRuXNn5s2bZ1s+fPhw3n//fQ4fPkyZMmUAiIuLo1y5cjRo0IBFixbd8XvExcVRoEABLl26RP78+e+6xqyUlJTEmjVraN68Oa6urqbWIiKSm+j6Kw7jjz+MbtWLFhnPG9+QJ4/xHHKHDkazrnz5zKtRJAs52vXXkbJBTuNwQ6aXLl2Kl5cXwcHBdst79OhBTEwMu3btynBfV1dX8uTJg4eHh93yggUL4u7unmU1zp07F6vVSu/evdPU3qBBA1sYBsifPz9t2rRh5cqVJCcnZ1kNIiIiIvdN2bJG060ffoDffoMJE4ypm65fh5UrjWZdRYtC27bGXeWrV82uWETkjjhcID548CCVK1fGxcV+NHe1atVs6zPy0ksvcf36dQYOHEhMTAwXL15k3rx5LF26lOHDh6fZPjo6msKFC+Pi4kK5cuUYNWoUCQkJt6wvNTWV0NBQypcvT926dW3LExISiI6OttV5c+0JCQkcPXr0lscWERERcXgVKxrTNR08+M/UTRUqwLVrxvRO7doZ4bhTJ1i+HBITza5YRCRDDvcM8fnz5/Hz80uzvHDhwrb1GfH39ycyMpLg4GA+/vhjAJydnQkJCWHo0KF229auXZv27dtTqVIlEhISWLt2LVOnTmXbtm1ERUXh5JT+3wrWr1/PyZMnCQkJsVv+999/Y7VabXXebe2JiYkk/us/GHFxcYAxXCMpKSnD/e6HG+9vdh0iIrmNrr/i8G6E49GjYf9+nL7+GqdvvsFy7BiEh0N4ONb8+bE+9xyp7dphbdjQmANZxME52vXXUerIiRwuEANYLJZMrfv+++8JCgrC39+fmTNn4unpSWRkJKNHj+batWu8+eabtm0nTZpkt2/z5s3x9fVl2LBhLF++nKCgoHTfY86cObi4uNC9e/csrT0kJITx48enWb5+/Xry5s2b4X73U0REhNkliIjkSrr+SrZRuzbUqkXBw4fx2bYNn+++w+P8eSzz5+M0fz7X8+UjJiCAmNq1ia1SBWsGfWFEHIWjXH+v6jGEe8bhAnGRIkXSvZN64cIFgHTvwN7w8ssvU6xYMZYuXWprvFW/fn2cnJwYN24cnTt3Tvfu8w1dunRh2LBh7Ny5M91AHBsby4oVK2jRogXFixe3W1eoUCEsFkuma3/jjTd49dVXba/j4uIoVaoUjRs3Nv3B+aSkJCIiIggMDHSIpgIiIrmFrr+SrQ0eDKmpJO/YgeXrr3FavJg8Z8/iGxGBb0QE1qJFSQ0KwhocjLV2bWMOZBEH4WjX3xujRyXrOVwgrlq1KuHh4SQnJ9s9R3zgwAEAqlSpkuG++/fvp2PHjmm6UNeoUYPU1FR++eWXWwbiGzIaLj1v3jyuX7+eppkWgIeHB+XLl7fV+W8HDhzAw8Pjlu/t5uaGm5tbmuWurq4O8Y8QHKsWEZHcRNdfydbq1TO+PvgANm82OlUvXozlr79wnjkTZs405jkODjamcgoIgFuMqhO5nxzl+usINeRUDvenuKCgIOLj41m8eLHd8rCwMLy9vfH3989wX29vb/bu3UtKSord8h07dgBQsmTJW753WFgYAAEBAemunzNnDt7e3jRr1izD2iMjIzl58qRt2eXLl1myZAnPPfdcmkZhIiIiIrmGszM0aGAE4NOnYd066N4dChSAmBiYMQOefhp8fWH4cPj+e3Cs2UFFJAdyuEDcrFkzAgMD6devH7NmzSIqKoo+ffqwbt06pk6darv726tXL1xcXDh+/Lht3yFDhnDw4EFatmzJ8uXLiYiIYMSIEUydOpVGjRrx6KOPArB161aaNm3KzJkziYiIYOXKlfTv35+RI0fSoEEDWrZsmaauXbt2cejQIbp3757hPMjDhg2jSJEitGjRgmXLlrF27VqeffZZrl27xrhx47L+ZImIiIhkR66uxvzFn38OZ8/CihXG1E1eXnDiBEybBk8+aXSvHjUKfvpJ4VhE7gmHvGW5ZMkSRo0axZgxY7hw4QKVKlUiPDycDh062LZJSUkhJSUF678ujgMGDMDHx4fp06fTu3dvEhIS8PX1ZezYsQwZMsS2XYkSJXB2dmbixInExsZisVioUKECEyZMYOjQoekOmZ4zZw4Wi4VevXplWPeDDz7I1q1bGTZsGN26dSM5OZmaNWuyadMmKlWqlEVnR0RERCQHcXODli2Nr4QEWLPGGFa9ahVER8NbbxlflSsbQ6rbtwf9XiUiWcRiterPbY4oLi6OAgUKcOnSJYdoqrVmzRqaN2+u5xdERO4jXX8lV4uPN0LxokWwdq39fMbVqv0TjsuVM69GybEc7frrSNkgp3G4IdMiIiIiInh5QYcOsHSpMaw6LAyaNwcXF2MI9ahRUL481KgB77xjDLUWEblLCsQiIiIi4tgKFICuXWH1aiMcz54NgYHGVE1798Jrr0GZMkZTrg8+MJp2iYjcAQViEREREck+/q+9+wyPqlr/Pv6d9EogdAgkNCHSPUrkUBJACFUEBAHpCEoTOOBRQZqIFFHhgAioFEXpvQoY6kUxqOCh/VEEIVKEIAkdkqznxX4yh2ESCFImkN/nuubFrL323vfeDCtzz1p7reBg6NwZ1q61Et9JkyAy0lqqaft26N0bCha0lnr69FP4809XRywimZgSYhERERF5NOXJA926wcaNEBcH48ZB5crWjNSbNkH37tYax3XqwBdfwLlzro5YRDIZJcQiIiIi8ugrUMDqHd62DX7//X9LNyUnw7p18MorkC8fNGgAX34JCQmujlhEMgElxCIiIiLyeClcGPr3h9hY+OUXGDHCmpn6xg1rWaf27SFvXmjSBObMgUuXXB2xiLiIEmIREREReXwVLw4DBsCePXDgAAwdaq1jfO0aLFkCrVpB7tzWEk6LFllrIYtIlqGEWERERESyhlKlYMgQ2L/fSpAHDLDWMb5yBebNg2bNrOeS27SB5csd1z4WkceSEmIRERERyVpsNmsI9YgR1pDqXbusIdaFC8PFi/D11/D889Yzx506wbffWsOtReSxo4RYRERERLIumw3+8Q9rEq4jR6xJuXr3hvz54fx5mD4d6ta13r/6KmzYYE3UJSKPBSXEIiIiIiIAbm7Wsk3jxsHx49ZyTt26Wc8Yx8fD1KlQsyaEhECvXrB1K6SkuDpqEbkHSohFRERERG7l7g6RkTBpEpw4YS3d1Lkz5MgBp07BxIlQrRqEhsK//gXff2+tfywijxQlxCIiIiIit+PhAc89B59/biXDK1dCu3aQLRvExcHHH0NEhDVB11tvwU8/KTkWeUQoIRYRERERySgvL6hfH2bOhNOnYfFiaNkS/P2tZ5BHj4annrJmtB48GPbtc3XEInIbSohFRERERP4OHx944QWYPRv+/PN/Szf5+MChQzB8OJQpY72GD7fKRCRTUUIsIiIiInKv/PygeXNYsMBKjmfNgkaNwNPT6iUePBhKlrR6j0ePtnqTRcTllBCLiIiIiNxPgYHw8suwbJmVHE+fDtHR1kRdP/1kPWdctKj13PHHH1vPIYuISyghFhERERF5ULJnhw4dYM0aa0KuKVOspZvc3KyZqf/1LyhUyJqxeuJEq46IPDRKiEVEREREHoZcuaBrV/juO/jjD5gwAapWtbZt3WqtbVywINSqZa15fPasa+MVyQKUEIuIiIiIPGz58kHPnrBlCxw/Dh99ZA2hTkmBmBh49VWrTt261pDr8+ddHbHIY0kJsYiIiIiIK4WEQN++sGMH/PYbjBoFFStCcjJ8+y106gR588Lzz8PXX8OFC66OWOSxoYRYRERERCSzKFIE3nwTfvwR/u//4N13oXRpuH4dli+HNm0gTx548UWYPx8uX3Z1xCKPNCXEIiIiIiKZ0RNPwKBBsHev9Ro0yCq7ehUWLoQWLazkuFUrWLLEKheRu6KEWEREREQksytd2uotPnjQ6j1+800IC4NLl2DOHGjSxBpW3b49rFpl9SiLyB0pIRYREREReVTYbNbzxaNGWc8b79xpLd1UsCAkJsKXX0KDBtaEXK+8AuvXQ1KSq6MWybSUEIuIiIiIPIpsNqhUCT78EI4ds2as7tnT6in+6y/44guoXRsKFIDu3WHTJmuiLhGxU0IsIiIiIvKoc3Oz1jSeMMFa4zgmxlrzOGdOOHMGPv0UoqKgUCHo0we2bwdjXB21iMspIRYREREReZy4u0ONGjBlCpw8CWvWQMeOkD279X78ePjnP61nkN94A3btUnIsWZYSYhERERGRx5WnJ0RHw7RpcOoULFsGL78MAQHWMOuxY+GZZ6BECRg4EH7+WcmxZClKiEVEREREsgJvb2jUCGbNgj///N/STb6+cPgwvP8+lC8PTz4JQ4fCgQOujljkgVNCLCIiIiKS1fj6QtOmMHeulRzPng0vvGAlzQcPwrBhVmJcvryVKB8+7OqIRR4IJcQiIiIiIllZQAC0bAmLF8Pp0zBzJtSvDx4e1hDqgQOheHF4+mlriPWxY66OWOS+UUIsIiIiIiKWoCBo1w5WrrSS488/t5ZucnODH36wJuEKDbUm5Ro/Hk6ccHXEIvdECbGIiIiIiDgLDobOnWHtWmt26kmTIDLSWv94+3Zr+aaQEGs5p08/tYZeizxilBCLiIiIiMjt5ckD3brBxo0QF2f1DleubM1IvWkTdO8O+fNbvcmffw7nzrk6YpEMUUIsIiIiIiIZV6AAvP46bNsGv/8OH3xgPV+ckgLr10OXLpA3LzRoAF9+CQkJro5YJF1KiEVERERE5O8pXBj694fYWPj1VxgxAsqVg6QkWLUK2re3kuMXXoA5c+DiRVdHLOJACbGIiIiIiNy7YsVgwADYs8daw3joUChVCq5dg6VLoVUra+h1ixbWGshXrrg6YhElxCIiIiIicp+VKgVDhsD+/VaCPGCAlTBfuQLz58OLL1rJcZs2sHy5lTSLuIASYhEREREReTBsNmsI9YgR8MsvsGuXtXRT4cLW8Omvv4bnn7eGVXfsCN9+CzduuDpqyUKUEIuIiIiIyINns8E//gFjxsDRo9akXL17W5N0JSTAjBlQt641W/Wrr0JMDCQnuzpqecwpIRYRERERkYfLZrOWbRo3Do4ft5Zu6tYNcueG+HiYOhVq1YKCBaFXL9i61ZrFWuQ+U0IsIiIiIiKu4+YG1avDpElw4gSsWwevvALBwXD6NEycCNWqQWgo/OtfsHOntf6xyH2ghFhERERERDIHDw947jn47DM4dcpauqldO8iWDeLi4OOP4dlnoWhReOst+OknJcdyT5QQi4iIiIhI5uPpCfXqwcyZVk/xkiXW0k3+/tYzyKNHw1NPQcmSMGgQ7Nvn6ojlEaSEWEREREREMjcfH2jcGL75Bv78E+bNg2bNrPJffoH33oMyZazX8OFw6JCrI5ZHhBJiERERERF5dPj5QfPmsGCBlRx//TU0amT1KO/bB4MHW73GFStavchHjrg6YsnEMmVCfPHiRfr06UOBAgXw8fGhQoUKzJkzJ0P7btiwgdq1a5MnTx4CAgIoV64c//nPf0i+Zcr2qKgobDab06tu3bppHnfv3r00b96c3Llz4+3tTVhYGN27d3eqt3DhQqpUqUJwcDDZs2enUqVKfPXVV3d/E0RERERE5PYCA6F1a1i2zEqOp0+3lm5yd4fdu63njIsWhYgI+Ogj6zlkkZt4uDqAtDRt2pTY2FhGjRrFE088wTfffEOrVq1ISUmhdevW6e63fv16oqOjqV69Op999hn+/v4sW7aM3r17c/jwYcaPH+9Qv2jRonz99dcOZdmzZ3c67oYNG2jQoAHVqlVj8uTJ5MqVi2PHjvHTTz851Js2bRqdO3emWbNmvPPOO9hsNmbOnEm7du04e/Ysffv2/fs3RURERERE0pc9O3ToYL3OnoVFi2DuXNi4Eb7/3nr16wdVqkDLlvDii5Avn/NxkpOxbdpEwc2bsfn7Q40aVoItjyWbMZlrWrZVq1bRoEEDexKcqk6dOuzbt49jx47hns4Hsk2bNixYsID4+Hj8/f3t5dHR0ezYsYOEhAR7WVRUFGfPnmXv3r23jefy5csUL16cp556iuXLl2Oz2dKtW7VqVeLi4vjtt99wc7M6340xPPnkk3h5ebFnz54M3QOAxMREgoKCSEhIIFu2bBne70G4ceMGq1aton79+nh6ero0FhGRrETtr4jIfXDqFCxcCHPmWOsZp3Jzg8hIeOkl63nkXLmsJLp3b8ee5JAQGD8emjZ9+LH/f5kpN3jcZLoh04sXLyYgIIDmzZs7lHfs2JETJ06wc+fOdPf19PTEy8sLX19fh/Ls2bPj4+Pzt+KZP38+J0+e5I033rhtMpx6/oCAAHsyDGCz2ciWLdvfPr+IiIiIiNyDfPmgRw/YsgWOH7eGTkdEQEoKbNgAr71m1alY0UqMbx1W/ccfVm/yokWuiV8eqEyXEO/du5fw8HA8PBxHc5crV86+PT2vvfYa169f5/XXX+fEiROcP3+er776isWLF/Pvf//bqf7hw4cJDg7Gw8ODYsWKMXDgQK5cueJQZ/PmzQAkJydTtWpVvLy8yJEjB61ateLEiRMOdXv16sWBAwcYMWIEZ86c4ezZs4wdO5YffviB/v37/637ISIiIiIi90lICPTtCzt2WJNtjR5tJcLJydYzx2lJHVDbp49VTx4rme4Z4vj4eIoWLepUHhwcbN+enoiICGJiYmjevDmffPIJAO7u7owcOZJ+/fo51K1atSovvfQSpUqV4sqVK6xevZoxY8awdetWNmzYYO/l/eOPPwBo1qwZXbt2Zfjw4Rw6dIiBAwcSGRnJnj178PPzA6xnnxctWkT79u155513APD19WXmzJlOPd63unbtGteuXbO/T0xMBKzhcjdu3Ljtvg9a6vldHYeISFaj9ldE5AEqWNBKjvv2xTZrFh6dOqVf1xg4fpykDRswkZEPL8b/T38HHpxMlxADtx2afLttP/zwA02aNCEiIoIpU6bg7+9PTEwM77zzDlevXmXQoEH2uu+9957DvvXr1ycsLIz+/fuzdOlSmjRpAkBKSgoAL730EqNHjwagRo0a5MuXjxdeeIFvvvmGV155BYA1a9bQpk0bmjdvTosWLfDw8GDZsmV06NCB69ev07Fjx3RjHzlyJMOGDXMqX7t2rT3hdrV169a5OgQRkSxJ7a+IyINVcO9ens5Avd2rV/PHpUsPPJ5bXb58+aGfM6vIdAlxzpw50+wFPnfuHPC/nuK09OjRg7x587J48WL7xFs1atTAzc2NoUOH8vLLL6fZ+5yqTZs29O/fnx07dtgT4pw5cwLWxFw3i46Oxmaz8eOPPwLW5FmdOnWievXqTJs2zV7vueeeIyEhgV69etGiRQuHyb5u9vbbb/Ovf/3L/j4xMZFChQpRp04dlz84f+PGDdatW0ft2rU1qYuIyEOk9ldE5OGw+ftbzxbfQYV69Sjvgh7i1NGjcv9luoS4bNmyzJ49m6SkJIfniP/73/8CUKZMmXT33b17N61atXKahfqZZ54hJSWFAwcO3DYhTnXzpFjlypW77RrIqXVPnz7NyZMnefXVV53qPPPMM3z55ZccPXqU0qVLp3kcb29vvL29nco9PT0zzZegzBSLiEhWovZXROQBq1HDer74jz/+98zwzWw2CAnBw0VLMOlvwIOT6SbVatKkCRcvXmThwoUO5TNnzqRAgQJERESku2+BAgXYtWsXybc87L59+3YAQkJCbnvumTNnAvDss886xGOz2Vi9erVD3dWrV2OMsdfNkSMHPj4+7Nixw+m427dvx83Njfz589/2/CIiIiIi4gLu7tbSSmAlvzdLfT9unNYjfgxluh7ievXqUbt2bbp160ZiYiLFixdn9uzZrFmzhlmzZtl7fzt37szMmTM5fPgwoaGhAPTt25fXX3+dRo0a8eqrr+Ln58d3333Hhx9+yHPPPUf58uUB2LJlCyNGjKBJkyYULVqUq1evsnr1aqZOnUrNmjVp1KiRPZ5SpUrRo0cPJk2aRGBgIPXq1ePQoUO88847VKxYkRYtWgBWD2/37t356KOPaNeuHS+99BLu7u4sWbKEb775hs6dO992uLeIiIiIiLhQ06awYEHa6xCPG+fSdYjlwcl0CTHAokWLGDhwIIMHD+bcuXOUKlWK2bNn07JlS3ud5ORkkpOTMTcNaejVqxcFCxbk448/5pVXXuHKlSuEhYUxZMgQ+vbta6+XP39+3N3dGT58OGfPnsVms1GiRAneffdd+vXr5zBkGmDcuHGEhITw+eefM2HCBHLlykXLli15//338fLystf74IMPCA8PZ8qUKbRp04aUlBSKFSvGxIkT6dq16wO8YyIiIiIics+aNoXGjUnasIHdq1dToV49lw2TlofDZkxag+TF1RITEwkKCiIhISFTTKq1atUq6tevr+cXREQeIrW/IiKukdna38yUGzxuMt0zxCIiIiIiIiIPgxJiERERERERyZKUEIuIiIiIiEiWpIRYREREREREsiQlxCIiIiIiIpIlKSEWERERERGRLEkJsYiIiIiIiGRJSohFREREREQkS1JCLCIiIiIiIlmSEmIRERERERHJkpQQi4iIiIiISJakhFhERERERESyJCXEIiIiIiIikiV5uDoASZsxBoDExEQXRwI3btzg8uXLJCYm4unp6epwRESyDLW/IiKukdna39ScIDVHkPtHCXEmdeHCBQAKFSrk4khERERERCQzuHDhAkFBQa4O47FiM/qZIVNKSUnhxIkTBAYGYrPZXBpLYmIihQoV4vjx42TLls2lsYiIZCVqf0VEXCOztb/GGC5cuECBAgVwc9NTr/eTeogzKTc3N0JCQlwdhoNs2bJligZBRCSrUfsrIuIaman9Vc/wg6GfF0RERERERCRLUkIsIiIiIiIiWZISYrkjb29vhgwZgre3t6tDERHJUtT+ioi4htrfrEOTaomIiIiIiEiWpB5iERERERERyZKUEIuIiIiIiEiWpIRYREREREREsiQlxPfBzp07adKkCYULF8bb25u8efNSuXJl+vXr5+rQMp3Lly8zdOhQNm7c6LRtxowZ2Gw2jh49ai/r0KEDYWFhDy0+EXk8/fzzz3Ts2JEiRYrg4+NDQEAATz31FGPGjOHcuXOuDu+e7d+/n6FDhzq0n6nSakfDwsLo0KHDQ4lNRCxqh8IcytQOZR1Dhw7FZrO5Oox0ebg6gEfdypUref7554mKimLMmDHkz5+fkydPsmvXLubMmcOHH37o6hAzlcuXLzNs2DAAoqKi7lh/0KBB9O7d+wFHJSKPs88++4zu3btTsmRJ3njjDZ588klu3LjBrl27mDx5Mtu3b2fx4sWuDvOe7N+/n2HDhhEVFZWhHxEXL15MtmzZHnxgIgKoHUqL2iHJLJQQ36MxY8ZQpEgRvv32Wzw8/nc7W7ZsyZgxY1wY2eOhWLFi9/V4ly9fxs/P774eU0Qyr+3bt9OtWzdq167NkiVLHJbPqF27Nv369WPNmjUujNA1KlaseN+OZYzh6tWr+Pr63rdjijxO1A6lTe2QayQnJ5OUlKTlpG6iIdP3KD4+nly5cjkkw6nc3Jxv79y5c6lcuTL+/v4EBAQQHR3NTz/95FCnQ4cOBAQE8Ouvv1K/fn0CAgIoVKgQ/fr149q1aw71bDZbmq+hQ4cCcPXqVfr160eFChUICgoiODiYypUrs3Tp0gxf47Rp0yhfvjw+Pj4EBwfTpEkTDhw44FAnKioqzR7fm4fIHD16lNy5cwMwbNgwe6y3Gy6T1hAbYwyTJk2iQoUK+Pr6kiNHDl588UV+++03p5jKlCnD5s2b+ec//4mfnx+dOnUCICYmhqioKHLmzImvry+FCxemWbNmXL58OcP3RUQyv/fffx+bzcbUqVPT/OPv5eXF888/b3+fkpLCmDFjKFWqFN7e3uTJk4d27doRFxfnsF9q+xIbG0u1atXw8/OjaNGijBo1ipSUlDvGdfXqVd5++22KFCmCl5cXBQsWpEePHpw/f96h3s3t+c1uHmo4Y8YMmjdvDkCNGjXsbeuMGTPSPX9aQxUTExPp37+/Q0x9+vTh0qVLTjH17NmTyZMnEx4ejre3NzNnzgTg008/pXz58gQEBBAYGEipUqUYMGDAHe+HyONM7VDaMls7NH/+fCIiIggKCrLfy9TvjX83vq+++orw8HD8/PwoX748K1ascKqX3it16PmuXbto2bIlYWFh+Pr6EhYWRqtWrfj999/veE1Hjx7FZrMxZswY3nvvPYoUKYK3tzcbNmy4qxwho9cD1ujZChUq4O3tTZEiRRg7dmyasWX08xcWFkbDhg1ZsWIFFStWxNfXl/DwcPu5Z8yYQXh4OP7+/lSqVIldu3bd8b44MXJPXnnlFQOYXr16mR07dpjr16+nW3fEiBHGZrOZTp06mRUrVphFixaZypUrG39/f7Nv3z57vfbt2xsvLy8THh5uxo4da9avX28GDx5sbDabGTZsmL3er7/+arZv3+7watOmjQHM3LlzjTHGnD9/3nTo0MF89dVXJiYmxqxZs8b079/fuLm5mZkzZ97x+t5//30DmFatWpmVK1eaL7/80hQtWtQEBQWZQ4cO2etFRkaayMhIp/3bt29vQkNDjTHGXL161axZs8YApnPnzvaYf/31V2OMMdOnTzeAOXLkSJr7p+rSpYvx9PQ0/fr1M2vWrDHffPONKVWqlMmbN685deqUQ0zBwcGmUKFCZsKECWbDhg1m06ZN5siRI8bHx8fUrl3bLFmyxGzcuNF8/fXXpm3btuavv/664z0RkUdDUlKS8fPzMxERERnep2vXrgYwPXv2NGvWrDGTJ082uXPnNoUKFTJnzpyx14uMjDQ5c+Y0JUqUMJMnTzbr1q0z3bt3N8Ad29aUlBQTHR1tPDw8zKBBg8zatWvN2LFjjb+/v6lYsaK5evWqvS5ghgwZ4nSM0NBQ0759e2OMMX/++ae9rf7kk0/sbeuff/5pjEm7Hb15f2OMuXTpkqlQoYLJlSuX+eijj8z69evN+PHjTVBQkKlZs6ZJSUlxiKlgwYKmXLly5ptvvjExMTFm7969Zvbs2fa/h2vXrjXr1683kydPNq+//noG777I40ft0KPRDm3bts3YbDbTsmVLs2rVKhMTE2OmT59u2rZt+7fjCwsLM5UqVTLz5s0zq1atMlFRUcbDw8McPnzYXu/W7/ExMTGmYMGCJl++fCYhIcEYY8z8+fPN4MGDzeLFi82mTZvMnDlzTGRkpMmdO7fD5yEtR44csd+rGjVqmAULFpi1a9eaI0eO3FWOkNHrWb9+vXF3dzdVq1Y1ixYtMvPnzzfPPPOMKVy4sLk57bybz19oaKgJCQkxZcqUMbNnzzarVq0yERERxtPT0wwePNhUqVLFLFq0yCxevNg88cQTJm/evOby5cu3vS+3UkJ8j86ePWuqVq1qAAMYT09P889//tOMHDnSXLhwwV7v2LFjxsPDw/Tq1cth/wsXLph8+fKZFi1a2Mvat29vADNv3jyHuvXr1zclS5ZMN5Z58+YZm81mBgwYkG6dpKQkc+PGDdO5c2dTsWLF217bX3/9ZXx9fU39+vUdyo8dO2a8vb1N69at7WUZSYiNMebMmTPpNqwZSYi3b99uAPPhhx867Hv8+HHj6+tr/v3vfzvEBJjvvvvOoe6CBQsMYHbv3n2bqxeRR92pU6cMYFq2bJmh+gcOHDCA6d69u0P5zp07DeDQtqa2Lzt37nSo++STT5ro6Ojbnif1h8ExY8Y4lM+dO9cAZurUqfayjHwRNcb6wgSYDRs2ONXNyBfRkSNHGjc3NxMbG+tQL7W9XLVqlUNMQUFB5ty5cw51e/bsabJnz57OVYtkTWqHLJm9HRo7dqwBzPnz59Otc7fx5c2b1yQmJtrLTp06Zdzc3MzIkSPTPH5SUpJp3LixCQgIMD/88EO6cSQlJZmLFy8af39/M378+NteV2pCXKxYsdt22qUeN70cIaPXExERYQoUKGCuXLliL0tMTDTBwcEOCfHdfP5CQ0ONr6+viYuLs5ft3r3bACZ//vzm0qVL9vIlS5YYwCxbtuy213orDZm+Rzlz5mTLli3ExsYyatQoGjduzKFDh3j77bcpW7YsZ8+eBeDbb78lKSmJdu3akZSUZH/5+PgQGRnpNOuyzWajUaNGDmXlypVLd3jEpk2baNu2LW3atGHEiBEO2+bPn0+VKlUICAjAw8MDT09PvvjiC6dhz7favn07V65ccRrOUqhQIWrWrMl3332XgTt0f61YsQKbzUabNm0c7mO+fPkoX768033MkSMHNWvWdCirUKECXl5edO3alZkzZzoNtRaRrGnDhg0ATm1epUqVCA8Pd2rz8uXLR6VKlRzKbtdOp4qJiUnzPM2bN8ff399lbWuZMmWoUKGCQ9saHR2NzWZzaltr1qxJjhw5HMoqVarE+fPnadWqFUuXLrX//RORjFM75Jp26JlnngGgRYsWzJs3jz/++OOe46tRowaBgYH293nz5iVPnjzp/tv07NmTlStXMn/+fJ566il7+cWLF3nzzTcpXrw4Hh4eeHh4EBAQwKVLl+74XT7V888/j6enp1P53eQId7qeS5cuERsbS9OmTfHx8bHXCwwMdMpp7vbzV6FCBQoWLGh/Hx4eDliPDdw8N1BqeUaGk99MCfF98vTTT/Pmm28yf/58Tpw4Qd++fTl69Kh9Yq3Tp08D1n84T09Ph9fcuXOd/sP6+fk5fJgAvL29uXr1qtO59+3bxwsvvEC1atX44osvHLYtWrSIFi1aULBgQWbNmsX27duJjY2lU6dOaR7rZvHx8QDkz5/faVuBAgXs2x+m06dPY4whb968Tvdxx44dTvcxrdiLFSvG+vXryZMnDz169KBYsWIUK1aM8ePHP6zLEJGHIFeuXPj5+XHkyJEM1b/bNi9nzpxO9by9vbly5codz+Ph4WGfUyGVzWYjX758Lmtbf/75Z6d2NTAwEGNMhtrWtm3bMm3aNH7//XeaNWtGnjx5iIiIYN26dQ/rMkQyHbVDGefKdqh69eosWbLE3nkVEhJCmTJlmD179t+O727+bd577z0mT57MlClTqFu3rsO21q1bM3HiRF555RW+/fZbvv/+e2JjY8mdO/cd/51TpXWv7jZHuNP1/PXXX6SkpJAvXz6nereW3e3nLzg42OG9l5fXbcvvlOPcSrNMPwCenp4MGTKEjz/+mL179wJWgwiwYMECQkND79u54uLiqFu3LoULF2bhwoVOv/7MmjWLIkWKMHfuXIf1v26enCs9qR/8kydPOm07ceKE/ZoAfHx8SEhIcKp3v3sIcuXKhc1mY8uWLWlOTHFrWXprnlWrVo1q1aqRnJzMrl27mDBhAn369CFv3ry0bNnyvsYsIq7h7u5OrVq1WL16NXFxcYSEhNy2/s1t3q11b23z7kXOnDlJSkrizJkzDl8GjDGcOnXK3lMBVpuWVnt9v7+s5sqVC19fX6ZNm5bu9pul17Z27NiRjh07cunSJTZv3syQIUNo2LAhhw4duq9/+0QeFWqHMs7V7VDjxo1p3Lgx165dY8eOHYwcOZLWrVsTFhZG5cqV7zq+jJoxYwaDBg1i6NChTpN4JSQksGLFCoYMGcJbb71lL7927dpdrV2d1r26lxwhLTly5MBms3Hq1CmnbbeW3c3n72FQD/E9SitZBOxDDQoUKABAdHQ0Hh4eHD58mKeffjrN191KSEigXr162Gw2Vq1aleZabjabDS8vL4cP+qlTpzI0y3TlypXx9fVl1qxZDuVxcXHExMRQq1Yte1lYWBiHDh1y+E8UHx/Ptm3bHPZNTVgz+ovWrRo2bIgxhj/++CPNe1i2bNm7Op67uzsRERF88sknAPz4449/Ky4RyZzefvttjDF06dKF69evO22/ceMGy5cvB7A/XnFrmxcbG8uBAwcc2rx7kXqcW8+zcOFCLl265NS2/vzzzw71YmJiuHjxokPZ/WhbDx8+TM6cOdNsWzOypujN/P39qVevHgMHDuT69evs27fvb8Ul8jhQO5QxmaUd8vb2JjIyktGjRwPYV4O53/EBrFmzhi5dutCpUyeGDBnitN1ms2GMcerw+fzzz0lOTr7r89167L+bI6QldZbnRYsWOfTQXrhwwf75TnU3n7+HQT3E9yg6OpqQkBAaNWpEqVKlSElJYffu3Xz44YcEBATQu3dvwGpM3n33XQYOHMhvv/1G3bp1yZEjB6dPn+b777/H39+fYcOG3dW5W7duzf79+5k6dSrHjx/n+PHj9m0hISGEhITQsGFDFi1aRPfu3XnxxRc5fvw4w4cPJ3/+/Pzyyy+3PX727NkZNGgQAwYMoF27drRq1Yr4+HiGDRuGj4+Pw3/ctm3bMmXKFNq0aUOXLl2Ij49nzJgxTkl6YGAgoaGhLF26lFq1ahEcHEyuXLky3IhUqVKFrl270rFjR3bt2kX16tXx9/fn5MmTbN26lbJly9KtW7fbHmPy5MnExMTQoEEDChcuzNWrV+2/9j333HMZikNEHg2VK1fm008/pXv37vzjH/+gW7dulC5dmhs3bvDTTz8xdepUypQpQ6NGjShZsiRdu3ZlwoQJuLm5Ua9ePY4ePcqgQYMoVKgQffv2vS8x1a5dm+joaN58800SExOpUqUKP//8M0OGDKFixYq0bdvWXrdt27YMGjSIwYMHExkZyf79+5k4cSJBQUEOxyxTpgwAU6dOJTAwEB8fH4oUKZLmELe09OnTh4ULF1K9enX69u1LuXLlSElJ4dixY6xdu5Z+/foRERFx22N06dIFX19fqlSpQv78+Tl16hQjR44kKCjoof/aL5KZqB3KfO3QzUuCAgwePJi4uDhq1apFSEgI58+fZ/z48Xh6ehIZGXnf4rvZkSNHaN68OUWLFqVjx47s2LHDYXvFihXJli0b1atX54MPPrB/X960aRNffPEF2bNnz/C50nIvOUJ6hg8fTt26de3raycnJzN69Gj8/f0derTv5vP3UNzVFFziZO7cuaZ169amRIkSJiAgwHh6eprChQubtm3bmv379zvVX7JkialRo4bJli2b8fb2NqGhoebFF18069evt9dp37698ff3d9p3yJAhDjO0hYaG2me3vvV182yAo0aNMmFhYcbb29uEh4ebzz77zOlYt/P555+bcuXKGS8vLxMUFGQaN27ssExUqpkzZ5rw8HDj4+NjnnzySTN37tw0ZxVcv369qVixovH29jaAfYbBjC67ZIwx06ZNMxEREcbf39/4+vqaYsWKmXbt2pldu3bZ60RGRprSpUs77bt9+3bTpEkTExoaary9vU3OnDlNZGTkXc9IJyKPjt27d5v27dubwoULGy8vL/vSDoMHD7YvC2KMMcnJyWb06NHmiSeeMJ6eniZXrlymTZs25vjx4w7HS699Sa/NutWVK1fMm2++aUJDQ42np6fJnz+/6datm9PSb9euXTP//ve/TaFChYyvr6+JjIw0u3fvdpqd1Rhjxo0bZ4oUKWLc3d0NYKZPn55uTGntf/HiRfPOO++YkiVL2tv7smXLmr59+zosaQeYHj16OF3TzJkzTY0aNUzevHmNl5eXKVCggGnRooX5+eef73g/RLICtUOOMbmyHcqVK5d59tln7e9XrFhh6tWrZwoWLGi8vLxMnjx5TP369c2WLVvua3w3X/OGDRvS/R5/8/fhuLg406xZM5MjRw4TGBho6tata/bu3Zvm/btV6izTH3zwQZrbM5ojZOR6Ui1btsyeNxQuXNiMGjUqzWNm9PMXGhpqGjRo4HTutGK60/Wmx/b/DygiIiIiIvJY279/P6VLl2bFihU0aNDA1eFIJqBniEVEREREJEvYsGEDlStXVjIsduohFhERERERkSxJPcQiIiIiIiKSJSkhFhERERERkSxJCbGIiIiIiIhkSUqIRUREREREJEtSQiwiIiIiIiJZkhJiERERERERyZKUEIuIiDwAHTp0wGazcfTo0YdyPpvNRlRU1EM5l4iIyONCCbGIiIiIiIhkSTZjjHF1ECIiIo+bkydPkpCQQLFixfD09Hzg5zt48CB+fn4ULlz4gZ9LRETkcaGEWERERERERLIkDZkWEZHH0ubNm7HZbHTu3DnN7XFxcbi7u1OrVi0AfvjhB3r27EmZMmUICgrC19eXsmXLMmrUKG7cuOG0f1hYGGFhYZw/f57XX3+dQoUK4eHhwYwZM4C0nyG+fv06EyZMIDo6mkKFCuHt7U2ePHlo2rQpP/30k9M5bDbbbV8bN250qJvWM8Tx8fH07duXIkWK2M/30ksvsX//fqe6N8c8adIkwsPD8fHxITQ0lGHDhpGSkpLmvVy6dCm1atUiR44c+Pj4UKZMGcaOHUtycnKa9UVERDILD1cHICIi8iBUq1aNsLAwFi5cyCeffIKPj4/D9q+//pqUlBTatm0LwGeffcby5cupXr069evX5/Lly2zcuJG3336b2NhYFi5c6HSOa9euUbNmTS5cuECjRo3w8vIib9686cZ07tw5+vTpQ7Vq1ahfvz45cuTgt99+Y9myZaxevZrNmzfzzDPP2OsPGTLE6RgpKSmMGzeOCxcu4Ofnd9t7EB8fz7PPPsuvv/5KVFQULVu25OjRoyxYsICVK1eybt06Kleu7LTfG2+8wcaNG2nYsCF16tRhyZIlDB06lOvXrzNixAiHugMGDGDkyJGEhITQrFkzsmXLxubNm3njjTfYuXMn8+fPv22MIiIiLmVEREQeUwMHDjSAmTdvntO2smXLGl9fX5OYmGiMMebo0aMmKSnJoU5KSorp1KmTAczWrVsdtoWGhhrA1KlTx1y+fNnp+O3btzeAOXLkiL3s6tWrJi4uzqnu3r17TUBAgHnuuefueE39+/c3gOnRo4dDOWAiIyMdylJjf/vttx3K16xZYwBTokQJk5yc7BRzkSJFzIkTJ+zlZ86cMdmzZzeBgYHm2rVr9vK1a9cawNSrV89cunTJXp6SkmJee+01A5gFCxbc8ZpERERcRUOmRUTksZXa+ztr1iyH8j179vDf//6Xxo0bExgYCEBoaCju7u4O9Ww2Gz169ABg/fr1aZ7jgw8+wNfXN0PxeHt7U7BgQafy0qVLU6NGDTZv3pzm8OxU06ZNY+zYsdSuXZtx48bd9lzXr19n9uzZ5MyZk3feecdhW3R0NNHR0fzyyy9s27bNad9BgwaRP39++/tcuXLRuHFjLly4wP/93//ZyydOnAjAlClTHHqrbTYbo0aNwmazMXv27NvGKSIi4koaMi0iIo+tkiVL8vTTT7N69WrOnTtHcHAwAF999RXwv4QZrARy4sSJzJkzh4MHD3Lx4kXMTfNOnjhxwun4Pj4+lC1b9q5i2r17N2PGjGHr1q2cOnXKKQE+e/asQzKaavPmzbz22muULFmSefPm4eFx+z/hBw8e5MqVK0RFRaU5tDoqKopvv/2W3bt3U7VqVYdtTz31lFP9kJAQAM6fP28v27FjB/7+/nzxxRdpxuDr68vBgwdvG6eIiIgrKSEWEZHHWtu2bdm1axfz5s3jtddeIyUlhdmzZ5MnTx7q1Kljr/fiiy+yfPlynnjiCV566SXy5MmDp6cn58+fZ/z48Vy7ds3p2Hny5MFms2U4lm3btlGzZk0A6tSpQ4kSJQgICMBms7FkyRL27NmT5nkOHz5M06ZNCQwMZMWKFWTPnv2O50pMTARI95nmfPnyAZCQkOC0LSgoyKksNQG/eaKsc+fOkZSUxLBhw9KN49KlS3eMVURExFWUEIuIyGOtZcuW9OvXj1mzZvHaa68RExPDiRMn6N27tz3Ji42NZfny5URHR7Ny5UqHodM7duxg/PjxaR77bpJhgBEjRnDt2jW2bt1KlSpVHLbt2LGDPXv2OO2TkJBAw4YNSUxMZO3atRQvXjxD58qWLRsAp0+fTnN7anlqvb8jW7Zs2Gw2zp49+7ePISIi4kp6hlhERB5rqT3B27Zt48iRI/bnidu0aWOvc/jwYQAaNGjg9Bzxli1b7lsshw8fJjg42CkZvnz5Mj/++KNT/aSkJJo3b87Bgwf55JNP0lxWKT2lSpXCx8eH2NhYLl++7LR906ZNAFSoUOGuruFmERERxMfH88svv/ztY4iIiLiSEmIREXnstW3bFmMMn3/+OYsWLaJUqVI8/fTT9u2hoaEAbN261WG/ffv2MXLkyPsWR2hoKH/99Rf79u2zlyUnJ9O/f3/OnDnjVL93796sW7eOvn370qVLl7s6l5eXF61ateLs2bNO17B+/XpWr15N8eLFnZLzu/H6668D0KlTJ+Lj4522nzp1igMHDvzt44uIiDxoGjItIiKPvcaNG5MtWzY++OADbty44TCZFkClSpWoVKkS8+bN4+TJkzz77LMcO3aMZcuW0aBBAxYsWHBf4ujVqxdr166latWqtGjRAh8fHzZu3Mgff/xBVFQUGzdutNf9/vvvmTRpEv7+/gQEBDB06FCn43Xo0IGwsLB0zzd69Gg2bdrEe++9x7Zt24iIiLCvQ+zn58f06dNxc/v7v43XrVuXQYMGMXz4cIoXL07dunUJDQ0lPj6eX3/9lS1btvDee+8RHh7+t88hIiLyICkhFhGRx56vry/NmjVj+vTp2Gw2Xn75ZYft7u7urFixgrfeeos1a9YQGxtLiRIlGDt2LPXq1btvCXHDhg1ZsGAB77//PrNmzcLPz4+aNWuyePFi3n33XYe6qcOcL126xPDhw9M8XlRU1G0T4ty5c7Nz506GDx/O0qVL2bJlC0FBQTRu3JghQ4ZQpkyZe76md999l+rVq/Of//yH7777jvPnz5MzZ06KFCnC0KFDne61iIhIZmIzN68pISIiIiIiIpJF6BliERERERERyZKUEIuIiIiIiEiWpIRYREREREREsiQlxCIiIiIiIpIlKSEWERERERGRLEkJsYiIiIiIiGRJSohFREREREQkS1JCLCIiIiIiIlmSEmIRERERERHJkpQQi4iIiIiISJakhFhERERERESyJCXEIiIiIiIikiX9Pxc2HIk+CmrZAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "algoritmo=[\"Senza outliers\",\"Con outliers\",\"Con outliers,senza random\"]\n",
    "accuracy=[0.8582,0.8572,0.8568]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(algoritmo, accuracy, marker='o', linestyle='-', color='r')\n",
    "plt.title(' Accuracy extratree variando dataset input')\n",
    "plt.xlabel('variazione')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.grid(True)\n",
    "plt.xticks(algoritmo)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e54eb0a",
   "metadata": {},
   "source": [
    "Risultato accuracy su testSet in base all'algoritmo utilizzato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b9e27e5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "algoritmo=[\"Decision_Tree\",\"Random_forest\",\"Extra_Tree\"]\n",
    "accuracy=[0.8686,0.8695,0.8582]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(algoritmo, accuracy, marker='o', linestyle='-', color='r')\n",
    "plt.title(' Accuracy su testSet al Variare dell algoritmo')\n",
    "plt.xlabel('Algoritmo')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.grid(True)\n",
    "plt.xticks(algoritmo)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2cac543",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
